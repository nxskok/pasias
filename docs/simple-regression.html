<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 18 Simple regression | Problems and Solutions in Applied Statistics</title>
  <meta name="description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 18 Simple regression | Problems and Solutions in Applied Statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
  <meta name="github-repo" content="nxskok/pasias" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 18 Simple regression | Problems and Solutions in Applied Statistics" />
  
  <meta name="twitter:description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
  

<meta name="author" content="Ken Butler" />


<meta name="date" content="2022-06-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tidying-data.html"/>
<link rel="next" href="multiple-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Problems and Solutions in Applied Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#packages-used-somewhere-in-this-book"><i class="fa fa-check"></i>Packages used somewhere in this book</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-used-to-r-and-r-studio.html"><a href="getting-used-to-r-and-r-studio.html"><i class="fa fa-check"></i><b>1</b> Getting used to R and R Studio</a></li>
<li class="chapter" data-level="2" data-path="reading-in-data.html"><a href="reading-in-data.html"><i class="fa fa-check"></i><b>2</b> Reading in data</a></li>
<li class="chapter" data-level="3" data-path="drawing-graphs.html"><a href="drawing-graphs.html"><i class="fa fa-check"></i><b>3</b> Drawing graphs</a></li>
<li class="chapter" data-level="4" data-path="data-exploration.html"><a href="data-exploration.html"><i class="fa fa-check"></i><b>4</b> Data exploration</a></li>
<li class="chapter" data-level="5" data-path="working-with-dataframes.html"><a href="working-with-dataframes.html"><i class="fa fa-check"></i><b>5</b> Working with dataframes</a></li>
<li class="chapter" data-level="6" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>6</b> One-sample inference</a></li>
<li class="chapter" data-level="7" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>7</b> Two-sample inference</a></li>
<li class="chapter" data-level="8" data-path="power-and-sample-size.html"><a href="power-and-sample-size.html"><i class="fa fa-check"></i><b>8</b> Power and sample size</a></li>
<li class="chapter" data-level="9" data-path="the-sign-test.html"><a href="the-sign-test.html"><i class="fa fa-check"></i><b>9</b> The sign test</a></li>
<li class="chapter" data-level="10" data-path="mood-median-test.html"><a href="mood-median-test.html"><i class="fa fa-check"></i><b>10</b> Mood median test</a></li>
<li class="chapter" data-level="11" data-path="matched-pairs-t-and-sign-test.html"><a href="matched-pairs-t-and-sign-test.html"><i class="fa fa-check"></i><b>11</b> Matched pairs t and sign test</a></li>
<li class="chapter" data-level="12" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html"><i class="fa fa-check"></i><b>12</b> Normal quantile plots</a>
<ul>
<li class="chapter" data-level="12.1" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#lengths-of-heliconia-flowers"><i class="fa fa-check"></i><b>12.1</b> Lengths of heliconia flowers</a></li>
<li class="chapter" data-level="12.2" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#ferritin-and-normality"><i class="fa fa-check"></i><b>12.2</b> Ferritin and normality</a></li>
<li class="chapter" data-level="12.3" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#lengths-of-heliconia-flowers-1"><i class="fa fa-check"></i><b>12.3</b> Lengths of heliconia flowers</a></li>
<li class="chapter" data-level="12.4" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#ferritin-and-normality-1"><i class="fa fa-check"></i><b>12.4</b> Ferritin and normality</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>13</b> Analysis of variance</a></li>
<li class="chapter" data-level="14" data-path="writing-reports.html"><a href="writing-reports.html"><i class="fa fa-check"></i><b>14</b> Writing reports</a></li>
<li class="chapter" data-level="15" data-path="learning-to-code.html"><a href="learning-to-code.html"><i class="fa fa-check"></i><b>15</b> Learning to code</a>
<ul>
<li class="chapter" data-level="15.1" data-path="learning-to-code.html"><a href="learning-to-code.html#introduction-1"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="learning-to-code.html"><a href="learning-to-code.html#data-and-pre-processing"><i class="fa fa-check"></i><b>15.2</b> Data and pre-processing</a></li>
<li class="chapter" data-level="15.3" data-path="learning-to-code.html"><a href="learning-to-code.html#analysis"><i class="fa fa-check"></i><b>15.3</b> Analysis</a></li>
<li class="chapter" data-level="15.4" data-path="learning-to-code.html"><a href="learning-to-code.html#conclusions-see-note-9"><i class="fa fa-check"></i><b>15.4</b> Conclusions (see note 9)</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="treating-dandruff.html"><a href="treating-dandruff.html"><i class="fa fa-check"></i><b>16</b> Treating dandruff</a>
<ul>
<li class="chapter" data-level="16.1" data-path="treating-dandruff.html"><a href="treating-dandruff.html#introduction-2"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="treating-dandruff.html"><a href="treating-dandruff.html#exploratory-analysis"><i class="fa fa-check"></i><b>16.2</b> Exploratory analysis</a></li>
<li class="chapter" data-level="16.3" data-path="treating-dandruff.html"><a href="treating-dandruff.html#analysis-of-variance-1"><i class="fa fa-check"></i><b>16.3</b> Analysis of Variance</a></li>
<li class="chapter" data-level="16.4" data-path="treating-dandruff.html"><a href="treating-dandruff.html#assessment-of-assumptions"><i class="fa fa-check"></i><b>16.4</b> Assessment of Assumptions</a></li>
<li class="chapter" data-level="16.5" data-path="treating-dandruff.html"><a href="treating-dandruff.html#conclusions"><i class="fa fa-check"></i><b>16.5</b> Conclusions</a></li>
<li class="chapter" data-level="16.6" data-path="treating-dandruff.html"><a href="treating-dandruff.html#end"><i class="fa fa-check"></i><b>16.6</b> End</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="tidying-data.html"><a href="tidying-data.html"><i class="fa fa-check"></i><b>17</b> Tidying data</a></li>
<li class="chapter" data-level="18" data-path="simple-regression.html"><a href="simple-regression.html"><i class="fa fa-check"></i><b>18</b> Simple regression</a>
<ul>
<li class="chapter" data-level="18.1" data-path="simple-regression.html"><a href="simple-regression.html#rainfall-in-california"><i class="fa fa-check"></i><b>18.1</b> Rainfall in California</a></li>
<li class="chapter" data-level="18.2" data-path="simple-regression.html"><a href="simple-regression.html#carbon-monoxide-in-cigarettes"><i class="fa fa-check"></i><b>18.2</b> Carbon monoxide in cigarettes</a></li>
<li class="chapter" data-level="18.3" data-path="simple-regression.html"><a href="simple-regression.html#maximal-oxygen-uptake-in-young-boys"><i class="fa fa-check"></i><b>18.3</b> Maximal oxygen uptake in young boys</a></li>
<li class="chapter" data-level="18.4" data-path="simple-regression.html"><a href="simple-regression.html#facebook-friends-and-grey-matter"><i class="fa fa-check"></i><b>18.4</b> Facebook friends and grey matter</a></li>
<li class="chapter" data-level="18.5" data-path="simple-regression.html"><a href="simple-regression.html#endogenous-nitrogen-excretion-in-carp"><i class="fa fa-check"></i><b>18.5</b> Endogenous nitrogen excretion in carp</a></li>
<li class="chapter" data-level="18.6" data-path="simple-regression.html"><a href="simple-regression.html#salaries-of-social-workers"><i class="fa fa-check"></i><b>18.6</b> Salaries of social workers</a></li>
<li class="chapter" data-level="18.7" data-path="simple-regression.html"><a href="simple-regression.html#predicting-volume-of-wood-in-pine-trees"><i class="fa fa-check"></i><b>18.7</b> Predicting volume of wood in pine trees</a></li>
<li class="chapter" data-level="18.8" data-path="simple-regression.html"><a href="simple-regression.html#tortoise-shells-and-eggs"><i class="fa fa-check"></i><b>18.8</b> Tortoise shells and eggs</a></li>
<li class="chapter" data-level="18.9" data-path="simple-regression.html"><a href="simple-regression.html#roller-coasters"><i class="fa fa-check"></i><b>18.9</b> Roller coasters</a></li>
<li class="chapter" data-level="18.10" data-path="simple-regression.html"><a href="simple-regression.html#running-and-blood-sugar"><i class="fa fa-check"></i><b>18.10</b> Running and blood sugar</a></li>
<li class="chapter" data-level="18.11" data-path="simple-regression.html"><a href="simple-regression.html#calories-and-fat-in-pizza"><i class="fa fa-check"></i><b>18.11</b> Calories and fat in pizza</a></li>
<li class="chapter" data-level="18.12" data-path="simple-regression.html"><a href="simple-regression.html#where-should-the-fire-stations-be"><i class="fa fa-check"></i><b>18.12</b> Where should the fire stations be?</a></li>
<li class="chapter" data-level="18.13" data-path="simple-regression.html"><a href="simple-regression.html#making-it-stop"><i class="fa fa-check"></i><b>18.13</b> Making it stop</a></li>
<li class="chapter" data-level="18.14" data-path="simple-regression.html"><a href="simple-regression.html#predicting-height-from-foot-length"><i class="fa fa-check"></i><b>18.14</b> Predicting height from foot length</a></li>
<li class="chapter" data-level="18.15" data-path="simple-regression.html"><a href="simple-regression.html#rainfall-in-california-1"><i class="fa fa-check"></i><b>18.15</b> Rainfall in California</a></li>
<li class="chapter" data-level="18.16" data-path="simple-regression.html"><a href="simple-regression.html#carbon-monoxide-in-cigarettes-1"><i class="fa fa-check"></i><b>18.16</b> Carbon monoxide in cigarettes</a></li>
<li class="chapter" data-level="18.17" data-path="simple-regression.html"><a href="simple-regression.html#maximal-oxygen-uptake-in-young-boys-1"><i class="fa fa-check"></i><b>18.17</b> Maximal oxygen uptake in young boys</a></li>
<li class="chapter" data-level="18.18" data-path="simple-regression.html"><a href="simple-regression.html#facebook-friends-and-grey-matter-1"><i class="fa fa-check"></i><b>18.18</b> Facebook friends and grey matter</a></li>
<li class="chapter" data-level="18.19" data-path="simple-regression.html"><a href="simple-regression.html#endogenous-nitrogen-excretion-in-carp-1"><i class="fa fa-check"></i><b>18.19</b> Endogenous nitrogen excretion in carp</a></li>
<li class="chapter" data-level="18.20" data-path="simple-regression.html"><a href="simple-regression.html#salaries-of-social-workers-1"><i class="fa fa-check"></i><b>18.20</b> Salaries of social workers</a></li>
<li class="chapter" data-level="18.21" data-path="simple-regression.html"><a href="simple-regression.html#predicting-volume-of-wood-in-pine-trees-1"><i class="fa fa-check"></i><b>18.21</b> Predicting volume of wood in pine trees</a></li>
<li class="chapter" data-level="18.22" data-path="simple-regression.html"><a href="simple-regression.html#tortoise-shells-and-eggs-1"><i class="fa fa-check"></i><b>18.22</b> Tortoise shells and eggs</a></li>
<li class="chapter" data-level="18.23" data-path="simple-regression.html"><a href="simple-regression.html#roller-coasters-1"><i class="fa fa-check"></i><b>18.23</b> Roller coasters</a></li>
<li class="chapter" data-level="18.24" data-path="simple-regression.html"><a href="simple-regression.html#running-and-blood-sugar-1"><i class="fa fa-check"></i><b>18.24</b> Running and blood sugar</a></li>
<li class="chapter" data-level="18.25" data-path="simple-regression.html"><a href="simple-regression.html#calories-and-fat-in-pizza-1"><i class="fa fa-check"></i><b>18.25</b> Calories and fat in pizza</a></li>
<li class="chapter" data-level="18.26" data-path="simple-regression.html"><a href="simple-regression.html#where-should-the-fire-stations-be-1"><i class="fa fa-check"></i><b>18.26</b> Where should the fire stations be?</a></li>
<li class="chapter" data-level="18.27" data-path="simple-regression.html"><a href="simple-regression.html#making-it-stop-1"><i class="fa fa-check"></i><b>18.27</b> Making it stop</a></li>
<li class="chapter" data-level="18.28" data-path="simple-regression.html"><a href="simple-regression.html#predicting-height-from-foot-length-1"><i class="fa fa-check"></i><b>18.28</b> Predicting height from foot length</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>19</b> Multiple regression</a></li>
<li class="chapter" data-level="20" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html"><i class="fa fa-check"></i><b>20</b> Regression with categorical variables</a>
<ul>
<li class="chapter" data-level="20.1" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#crickets-revisited"><i class="fa fa-check"></i><b>20.1</b> Crickets revisited</a></li>
<li class="chapter" data-level="20.2" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#pulse-rates-and-marching"><i class="fa fa-check"></i><b>20.2</b> Pulse rates and marching</a></li>
<li class="chapter" data-level="20.3" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#crickets-revisited-1"><i class="fa fa-check"></i><b>20.3</b> Crickets revisited</a></li>
<li class="chapter" data-level="20.4" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#pulse-rates-and-marching-1"><i class="fa fa-check"></i><b>20.4</b> Pulse rates and marching</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dates-and-times.html"><a href="dates-and-times.html"><i class="fa fa-check"></i><b>21</b> Dates and times</a></li>
<li class="chapter" data-level="22" data-path="functions.html"><a href="functions.html"><i class="fa fa-check"></i><b>22</b> Functions</a></li>
<li class="chapter" data-level="23" data-path="vector-and-matrix-algebra.html"><a href="vector-and-matrix-algebra.html"><i class="fa fa-check"></i><b>23</b> Vector and matrix algebra</a>
<ul>
<li class="chapter" data-level="23.1" data-path="vector-and-matrix-algebra.html"><a href="vector-and-matrix-algebra.html#heights-and-foot-lengths-again"><i class="fa fa-check"></i><b>23.1</b> Heights and foot lengths again</a></li>
<li class="chapter" data-level="23.2" data-path="vector-and-matrix-algebra.html"><a href="vector-and-matrix-algebra.html#heights-and-foot-lengths-again-1"><i class="fa fa-check"></i><b>23.2</b> Heights and foot lengths again</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="the-bootstrap.html"><a href="the-bootstrap.html"><i class="fa fa-check"></i><b>24</b> The Bootstrap</a></li>
<li class="chapter" data-level="25" data-path="bayesian-statistics-with-stan.html"><a href="bayesian-statistics-with-stan.html"><i class="fa fa-check"></i><b>25</b> Bayesian Statistics with Stan</a></li>
<li class="chapter" data-level="26" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>26</b> Logistic regression</a></li>
<li class="chapter" data-level="27" data-path="logistic-regression-with-ordinal-response.html"><a href="logistic-regression-with-ordinal-response.html"><i class="fa fa-check"></i><b>27</b> Logistic regression with ordinal response</a></li>
<li class="chapter" data-level="28" data-path="logistic-regression-with-nominal-response.html"><a href="logistic-regression-with-nominal-response.html"><i class="fa fa-check"></i><b>28</b> Logistic regression with nominal response</a></li>
<li class="chapter" data-level="29" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>29</b> Survival analysis</a></li>
<li class="chapter" data-level="30" data-path="analysis-of-variance-revisited.html"><a href="analysis-of-variance-revisited.html"><i class="fa fa-check"></i><b>30</b> Analysis of variance revisited</a></li>
<li class="chapter" data-level="31" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html"><i class="fa fa-check"></i><b>31</b> Analysis of covariance</a></li>
<li class="chapter" data-level="32" data-path="multivariate-analysis-of-variance.html"><a href="multivariate-analysis-of-variance.html"><i class="fa fa-check"></i><b>32</b> Multivariate analysis of variance</a></li>
<li class="chapter" data-level="33" data-path="repeated-measures.html"><a href="repeated-measures.html"><i class="fa fa-check"></i><b>33</b> Repeated measures</a></li>
<li class="chapter" data-level="34" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html"><i class="fa fa-check"></i><b>34</b> Discriminant analysis</a></li>
<li class="chapter" data-level="35" data-path="hierarchical-cluster-analysis.html"><a href="hierarchical-cluster-analysis.html"><i class="fa fa-check"></i><b>35</b> Hierarchical cluster analysis</a></li>
<li class="chapter" data-level="36" data-path="k-means-cluster-analysis.html"><a href="k-means-cluster-analysis.html"><i class="fa fa-check"></i><b>36</b> K-means cluster analysis</a></li>
<li class="chapter" data-level="37" data-path="drawing-maps-with-leaflet.html"><a href="drawing-maps-with-leaflet.html"><i class="fa fa-check"></i><b>37</b> Drawing maps with Leaflet</a></li>
<li class="chapter" data-level="38" data-path="multidimensional-scaling.html"><a href="multidimensional-scaling.html"><i class="fa fa-check"></i><b>38</b> Multidimensional Scaling</a></li>
<li class="chapter" data-level="39" data-path="principal-components.html"><a href="principal-components.html"><i class="fa fa-check"></i><b>39</b> Principal Components</a>
<ul>
<li class="chapter" data-level="39.1" data-path="principal-components.html"><a href="principal-components.html#the-weather-somewhere"><i class="fa fa-check"></i><b>39.1</b> The weather, somewhere</a></li>
<li class="chapter" data-level="39.2" data-path="principal-components.html"><a href="principal-components.html#the-weather-somewhere-1"><i class="fa fa-check"></i><b>39.2</b> The weather, somewhere</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>40</b> Factor Analysis</a></li>
<li class="chapter" data-level="41" data-path="frequency-table-analysis.html"><a href="frequency-table-analysis.html"><i class="fa fa-check"></i><b>41</b> Frequency table analysis</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Problems and Solutions in Applied Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-regression" class="section level1 hasAnchor" number="18">
<h1><span class="header-section-number">Chapter 18</span> Simple regression<a href="simple-regression.html#simple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="simple-regression.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<div id="rainfall-in-california" class="section level2 hasAnchor" number="18.1">
<h2><span class="header-section-number">18.1</span> Rainfall in California<a href="simple-regression.html#rainfall-in-california" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The data in
<a href="http://ritsokiguess.site/datafiles/calirain.txt">link</a> are
rainfall and other measurements for 30 weather stations in
California. Our aim is to understand how well the annual rainfall at
these stations (measured in inches) can be predicted from the other
measurements, which are the altitude (in feet above sea level), the
latitude (degrees north of the equator) and the distance from the
coast (in miles).</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R. You’ll have to be careful here, since the
values are space-delimited, but sometimes by more than one space, to
make the columns line up. <code>read_table2</code>, with filename or
url, will read it in.
One of the variables
is called <code>rainfall</code>, so as long as you <em>do not</em> call
the data frame that, you should be safe.</p></li>
<li><p>Make a boxplot of the rainfall figures, and explain why the
values are reasonable. (A rainfall cannot be negative, and it is
unusual for a annual rainfall to exceed 60 inches.) A
<code>ggplot</code> boxplot needs <em>something</em> on the <span class="math inline">\(x\)</span>-axis: the
number 1 will do.</p></li>
<li><p>Plot <code>rainfall</code> against each of the other quantitative
variables (that is, not <code>station</code>).</p></li>
<li><p>Look at the relationship of each other variable with
<code>rainfall</code>.
Justify the assertion that <code>latitude</code> seems most strongly
related with <code>rainfall</code>. Is that relationship positive or negative? linear? Explain
briefly.</p></li>
<li><p>Fit a regression with <code>rainfall</code> as the response
variable, and <code>latitude</code> as your explanatory variable. What
are the intercept, slope and R-squared values? Is there a
<em>significant</em> relationship between <code>rainfall</code> and your
explanatory variable? What does that mean?</p></li>
<li><p>Fit a multiple regression predicting <code>rainfall</code> from
all three of the other (quantitative) variables. Display the
results. Comment is coming up later.</p></li>
<li><p>What is the R-squared for the regression of the last part?
How does that compare with the R-squared of your regression in part (e)?</p></li>
<li><p>What do you conclude about the importance of the variables
that you did <em>not</em> include in your model in
(e)? Explain briefly.</p></li>
<li><p>Make a suitable hypothesis test that the variables
<code>altitude</code> and <code>fromcoast</code> significantly improve the
prediction of <code>rainfall</code> over the use of <code>latitude</code>
alone. What do you conclude?</p></li>
</ol>
</div>
<div id="carbon-monoxide-in-cigarettes" class="section level2 hasAnchor" number="18.2">
<h2><span class="header-section-number">18.2</span> Carbon monoxide in cigarettes<a href="simple-regression.html#carbon-monoxide-in-cigarettes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The (US) Federal Trade Commission assesses cigarettes
according to their tar, nicotine and carbon monoxide contents. In a
particular year, 25 brands were assessed. For each brand, the tar,
nicotine and carbon monoxide (all in milligrams) were measured, along
with the weight in grams. Our aim is to predict carbon monoxide from
any or all of the other variables. The data are in
<a href="http://ritsokiguess.site/datafiles/ftccigar.txt">link</a>. These are
aligned by column (except for the variable names), with more than one
space between each column of data.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R, and check that you have 25 observations
and 4 variables.</p></li>
<li><p>Run a regression to predict carbon monoxide from the other
variables, and obtain a summary of the output.</p></li>
<li><p>Which one of your explanatory variables would you
remove from this regression? Explain (very) briefly. Go ahead and
fit the regression without it, and describe how the change in
R-squared from the regression in (b) was entirely predictable.</p></li>
<li><p>Fit a regression predicting carbon monoxide from
<code>nicotine</code> <em>only</em>, and display the summary.</p></li>
<li><p><code>nicotine</code> was far from being significant in the model
of (c), and yet in the model of
(d), it was <em>strongly</em> significant, and the
R-squared value of (d) was almost as high as that
of (c). What does this say about the importance of
<code>nicotine</code> as an explanatory variable? Explain, as briefly as
you can manage.</p></li>
<li><p>Make a “pairs plot”: that is, scatter plots between all
pairs of variables. This can be done by feeding the whole data frame
into <code>plot</code>.<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a>
Do you see any strong relationships that do
<em>not</em> include <code>co</code>? Does that shed any light on the last
part? Explain briefly (or “at length” if that’s how it comes
out).</p></li>
</ol>
</div>
<div id="maximal-oxygen-uptake-in-young-boys" class="section level2 hasAnchor" number="18.3">
<h2><span class="header-section-number">18.3</span> Maximal oxygen uptake in young boys<a href="simple-regression.html#maximal-oxygen-uptake-in-young-boys" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A physiologist wanted to understand the relationship between
physical characteristics of pre-adolescent boys and their maximal
oxygen uptake (millilitres of oxygen per kilogram of body weight). The
data are in
<a href="http://ritsokiguess.site/datafiles/youngboys.txt">link</a> for a
random sample of 10 pre-adolescent boys. The variables are (with
units):</p>
<ul>
<li><p><code>uptake</code>: Oxygen uptake (millitres of oxygen per kilogram
of body weight)</p></li>
<li><p><code>age</code>: boy’s age (years)</p></li>
<li><p><code>height</code>: boy’s height (cm)</p></li>
<li><p><code>weight</code>: boy’s weight (kg)</p></li>
<li><p><code>chest</code>: chest depth (cm).</p></li>
</ul>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R and confirm that you do indeed have
10 observations.</p></li>
<li><p>Fit a regression predicting oxygen uptake from all the
other variables, and display the results.</p></li>
<li><p>(A one-mark question.) Would you say, on the evidence so
far, that the regression fits well or badly? Explain (very)
briefly.</p></li>
<li><p>It seems reasonable that an older boy should have a
greater oxygen uptake, all else being equal. Is this supported
by your output? Explain briefly.</p></li>
<li><p>It seems reasonable that a boy with larger weight
should have larger lungs and thus a <em>statistically
significantly</em> larger oxygen uptake. Is that what happens
here? Explain briefly.</p></li>
<li><p>Fit a model that contains only the significant
explanatory variables from your first regression. How do
the R-squared values from the two regressions compare?
(The last sentence asks for more or less the same thing as
the next part. Answer it either here or there. Either
place is good.)</p></li>
<li><p>How has R-squared changed between your two
regressions? Describe what you see in a few words.</p></li>
<li><p>Carry out a test comparing the fit of your
two regression models. What do you conclude, and
therefore what recommendation would you make about the
regression that would be preferred?</p></li>
<li><p>Obtain a table of correlations between all
the variables in the data frame. Do this by feeding
the whole data frame into <code>cor</code>.
We found that a regression predicting oxygen uptake
from just <code>height</code> was acceptably good. What
does your table of correlations say about why that
is? (Hint: look for all the correlations that are
<em>large</em>.)</p></li>
</ol>
</div>
<div id="facebook-friends-and-grey-matter" class="section level2 hasAnchor" number="18.4">
<h2><span class="header-section-number">18.4</span> Facebook friends and grey matter<a href="simple-regression.html#facebook-friends-and-grey-matter" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Is there a relationship between the number
of Facebook friends a person has, and the density of grey matter in
the areas of the brain associated with social perception and
associative memory? To find out, a 2012 study measured both of these
variables for a sample of 40 students at City University in London
(England). The data are at
<a href="http://ritsokiguess.site/datafiles/facebook.txt">link</a>. The grey
matter density is on a <span class="math inline">\(z\)</span>-score standardized scale. The values are
separated by <em>tabs</em>.</p>
<p>The aim of this question is to produce an R Markdown report that
contains your answers to the questions below.</p>
<p>You should aim to make your report flow smoothly, so that it would be
pleasant for a grader to read, and can stand on its own as an analysis
(rather than just being the answer to a question that I set you).
Some suggestions: give your report a title and arrange it into
sections with an Introduction; add a small amount of additional text
here and there explaining what you are doing and why. I don’t expect
you to spend a large amount of time on this, but I <em>do</em> hope
you will make some effort. (My report came out to 4 Word pages.)</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in the data and make a scatterplot for predicting the
number of Facebook friends from the grey matter density. On your
scatterplot, add a smooth trend.</p></li>
<li><p>Describe what you see on your scatterplot: is there a
trend, and if so, what kind of trend is it? (Don’t get too taken in
by the exact shape of your smooth trend.) Think “form, direction, strength”.</p></li>
<li><p>Fit a regression predicting the number of Facebook friends
from the grey matter density, and display the output.</p></li>
<li><p>Is the slope of your regression line significantly
different from zero? What does that mean, in the context of the
data?</p></li>
<li><p>Are you surprised by the results of
parts (b) and (d)? Explain briefly.</p></li>
<li><p>Obtain a scatterplot with the regression line on it.</p></li>
<li><p>Obtain a plot of the residuals from the regression against
the fitted values, and comment briefly on it.</p></li>
</ol>
</div>
<div id="endogenous-nitrogen-excretion-in-carp" class="section level2 hasAnchor" number="18.5">
<h2><span class="header-section-number">18.5</span> Endogenous nitrogen excretion in carp<a href="simple-regression.html#endogenous-nitrogen-excretion-in-carp" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A paper in Fisheries Science reported on variables that
affect “endogenous nitrogen excretion” or ENE in carp raised in
Japan. A number of carp were divided into groups based on body weight,
and each group was placed in a different tank. The mean body weight of
the carp placed in each tank was recorded. The carp were then fed a
protein-free diet three times daily for a period of 20 days. At the
end of the experiment, the amount of ENE in each tank was measured, in
milligrams of total fish body weight per day. (Thus it should not
matter that some of the tanks had more fish than others, because the
scaling is done properly.)</p>
<p>For this question, write a report in R Markdown that answers the
questions below and contains some narrative that describes your
analysis. Create an HTML document from your R Markdown.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data in from
<a href="http://ritsokiguess.site/datafiles/carp.txt">link</a>. There are 10
tanks.</p></li>
<li><p>Create a scatterplot of ENE (response) against bodyweight
(explanatory). Add a smooth trend to your plot.</p></li>
<li><p>Is there an upward or downward trend (or neither)? Is the
relationship a line or a curve? Explain briefly.</p></li>
<li><p>Fit a straight line to the data, and obtain the R-squared
for the regression.</p></li>
<li><p>Obtain a residual plot (residuals against fitted values)
for this regression. Do you see any problems? If so, what does that
tell you about the relationship in the data?</p></li>
<li><p>Fit a parabola to the data (that is, including an
<span class="math inline">\(x\)</span>-squared term). Compare the R-squared values for the models in
this part and part (d). Does that suggest that the parabola
model is an improvement here over the linear model?</p></li>
<li><p>Is the test for the slope coefficient for the squared term
significant? What does this mean?</p></li>
<li><p>Make the scatterplot of part (b), but add
the fitted curve. Describe any way in which the curve fails to fit well.</p></li>
<li><p>Obtain a residual plot for the parabola model. Do you see
any problems with it? (If you do, I’m not asking you to do anything
about them in this question, but I will.)</p></li>
</ol>
</div>
<div id="salaries-of-social-workers" class="section level2 hasAnchor" number="18.6">
<h2><span class="header-section-number">18.6</span> Salaries of social workers<a href="simple-regression.html#salaries-of-social-workers" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Another salary-prediction question: does the number of years
of work experience that a social worker has help to predict their
salary? Data for 50 social workers are in
<a href="http://ritsokiguess.site/datafiles/socwork.txt">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R. Check that you have 50 observations on
two variables. Also do something to check that the years of
experience and annual salary figures look reasonable overall.</p></li>
<li><p>Make a scatterplot showing how salary depends on
experience. Does the nature of the trend make sense?</p></li>
<li><p>Fit a regression predicting salary from experience, and
display the results. Is the slope positive or negative? Does that
make sense?</p></li>
<li><p>Obtain and plot the residuals against the fitted values. What
problem do you see?</p></li>
<li><p>The problem you unearthed in the previous part is often helped
by a transformation. Run Box-Cox on your data to find a suitable
transformation. What transformation is suggested?</p></li>
<li><p>Calculate a new variable as suggested by your
transformation. Use your transformed response in a regression,
showing the summary.</p></li>
<li><p>Obtain and plot the residuals against the fitted values for
this regression. Do you seem to have solved the problem with the
previous residual plot?</p></li>
</ol>
</div>
<div id="predicting-volume-of-wood-in-pine-trees" class="section level2 hasAnchor" number="18.7">
<h2><span class="header-section-number">18.7</span> Predicting volume of wood in pine trees<a href="simple-regression.html#predicting-volume-of-wood-in-pine-trees" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In forestry, the financial value of a tree
is the volume of wood that it contains. This is difficult to estimate
while the tree is still standing, but the diameter is easy to measure
with a tape measure (to measure the circumference) and a calculation
involving <span class="math inline">\(\pi\)</span>, assuming that the cross-section of the tree is at
least approximately circular. The standard measurement is
“diameter at breast height”
(that is, at the height of a human breast or
chest), defined as being 4.5 feet above the ground.</p>
<p>Several pine trees had their diameter measured shortly before being
cut down, and for each tree, the volume of wood was recorded. The data
are in
<a href="http://ritsokiguess.site/datafiles/pinetrees.txt">link</a>. The
diameter is in inches and the volume is in cubic inches. Is it
possible to predict the volume of wood from the diameter?</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R and display the values (there are not
very many).</p></li>
<li><p>Make a suitable plot.</p></li>
<li><p>Describe what you learn from your plot about the
relationship between diameter and volume, if anything.</p></li>
<li><p>Fit a (linear) regression, predicting volume from diameter,
and obtain the <code>summary</code>. How would you describe the R-squared?</p></li>
<li><p>Draw a graph that will help you decide whether you trust
the linearity of this regression. What do you conclude? Explain briefly.</p></li>
<li><p>What would you guess would be the volume of a tree of
diameter zero? Is that what the regression predicts? Explain briefly.</p></li>
<li><p>A simple way of modelling a tree’s shape is to pretend it is a
cone, like this, but probably taller and skinnier:</p></li>
</ol>
<p><img src="/home/ken/Pictures/conebnw.png" /></p>
<p>with its base on the ground. What is the relationship between the
<em>diameter</em> (at the base) and volume of a cone? (If you don’t
remember, look it up. You’ll probably get a formula in terms of the
radius, which you’ll have to convert.
Cite the website you used.)</p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Fit a regression model that predicts volume from diameter
according to the formula you obtained in the previous part. You can
assume that the trees in this data set are of similar heights, so
that the height can be treated as a constant.<br />
Display the
results.</li>
</ol>
</div>
<div id="tortoise-shells-and-eggs" class="section level2 hasAnchor" number="18.8">
<h2><span class="header-section-number">18.8</span> Tortoise shells and eggs<a href="simple-regression.html#tortoise-shells-and-eggs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A biologist measured the length of the carapace (shell) of
female tortoises, and then x-rayed the tortoises to count how many
eggs they were carrying. The length is measured in millimetres. The
data are in
<a href="http://ritsokiguess.site/datafiles/tortoise-eggs.txt">link</a>. The
biologist is wondering what kind of relationship, if any, there is
between the carapace length (as an explanatory variable) and the
number of eggs (as a response variable).</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in the data, and check that your values look
reasonable.</p></li>
<li><p>Obtain a scatterplot, with a smooth trend, of the data.</p></li>
<li><p>The biologist expected that a larger tortoise would be able
to carry more eggs. Is that what the scatterplot is suggesting?
Explain briefly why or why not.</p></li>
<li><p>Fit a straight-line relationship and display the summary.</p></li>
<li><p>Add a squared term to your regression, fit that and display
the summary.</p></li>
<li><p>Is a curve better than a line for these data? Justify your
answer in two ways: by comparing a measure of fit, and by doing a
suitable test of significance.</p></li>
<li><p>Make a residual plot for the straight line model: that is, plot
the residuals against the fitted values.
Does this echo
your conclusions of the previous part? In what way? Explain briefly.</p></li>
</ol>
</div>
<div id="roller-coasters" class="section level2 hasAnchor" number="18.9">
<h2><span class="header-section-number">18.9</span> Roller coasters<a href="simple-regression.html#roller-coasters" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A poll on the Discovery Channel asked people to nominate the
best roller-coasters in the United States. We will examine the 10
roller-coasters that received the most votes. Two features of a
roller-coaster that are of interest are the distance it drops from
start to finish, measured here in feet<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> and the duration of the ride,
measured in seconds. Is it true that roller-coasters with a bigger
drop also tend to have a longer ride? The data are at
<a href="http://ritsokiguess.site/datafiles/coasters.csv">link</a>.<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a></p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R and verify that you have a sensible
number of rows and columns.</p></li>
<li><p>Make a scatterplot of duration (response) against drop
(explanatory), labelling each roller-coaster with its name in such a
way that the labels do not overlap. Add a regression line to your plot.</p></li>
<li><p>Would you say that roller-coasters with a larger drop tend
to have a longer ride? Explain briefly.</p></li>
<li><p>Find a roller-coaster that is unusual compared to the
others. What about its combination of <code>drop</code> and
<code>duration</code> is unusual?</p></li>
</ol>
</div>
<div id="running-and-blood-sugar" class="section level2 hasAnchor" number="18.10">
<h2><span class="header-section-number">18.10</span> Running and blood sugar<a href="simple-regression.html#running-and-blood-sugar" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A diabetic wants to know how aerobic exercise affects his
blood sugar. When his blood sugar reaches 170 (mg/dl), he goes out for
a run at a pace of 10 minutes per mile. He runs different distances on
different days. Each time he runs, he measures his blood sugar after
the run. (The preferred blood sugar level is between 80 and 120 on
this scale.) The data are in the file
<a href="http://ritsokiguess.site/datafiles/runner.txt">link</a>. Our aim is
to predict blood sugar from distance.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in the data and display the data frame that you read
in.</p></li>
<li><p>Make a scatterplot and add a smooth trend to it.</p></li>
<li><p>Would you say that the relationship between blood sugar and
running distance is approximately linear, or not? It is therefore
reasonable to use a regression of blood sugar on distance? Explain briefly.</p></li>
<li><p>Fit a suitable regression, and obtain the regression output.</p></li>
<li><p>How would you <em>interpret</em> the slope? That is, what is
the slope, and what does that mean about blood sugar and running distance?</p></li>
<li><p>Is there a (statistically) significant relationship between
running distance and blood sugar? How do you know? Do you find this
surprising, given what you have seen so far? Explain briefly.</p></li>
<li><p>This diabetic is planning to go for a 3-mile run tomorrow
and a 5-mile run the day after. Obtain suitable 95% intervals that
say what his blood sugar might be after each of these runs.</p></li>
<li><p>Which of your two intervals is longer? Does this make
sense? Explain briefly.</p></li>
</ol>
</div>
<div id="calories-and-fat-in-pizza" class="section level2 hasAnchor" number="18.11">
<h2><span class="header-section-number">18.11</span> Calories and fat in pizza<a href="simple-regression.html#calories-and-fat-in-pizza" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The file at
<a href="http://ritsokiguess.site/datafiles/Pizza.csv">link</a>
came from a spreadsheet of information about 24 brands
of pizza: specifically, per 5-ounce serving, the number of calories,
the grams of fat, and the cost (in US dollars). The names of the pizza
brands are quite long. This file may open in a spreadsheet when you
browse to the link, depending on your computer’s setup.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in the data and display at least some of the data
frame. Are the variables of the right types? (In particular, why is
the number of calories labelled one way and the cost labelled a
different way?)</p></li>
<li><p>Make a scatterplot for predicting calories from the number
of grams of fat. Add a smooth trend. What kind of relationship do
you see, if any?</p></li>
<li><p>Fit a straight-line relationship, and display the intercept,
slope, R-squared, etc. Is there a real relationship between the two
variables, or is any apparent trend just chance?</p></li>
<li><p>Obtain a plot of the residuals against the fitted values
for this regression. Does this indicate that there are any problems
with this regression, or not? Explain briefly.</p></li>
<li><p>The research assistant in this study returns with two
new brands of pizza (ones that were not in the original data). The
fat content of a 5-ounce serving was 12 grams for the first brand
and 20 grams for the second brand. For each of these brands of
pizza, obtain a suitable 95% interval for the number of calories
contained in a 5-ounce serving.</p></li>
</ol>
</div>
<div id="where-should-the-fire-stations-be" class="section level2 hasAnchor" number="18.12">
<h2><span class="header-section-number">18.12</span> Where should the fire stations be?<a href="simple-regression.html#where-should-the-fire-stations-be" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In city planning, one major issue is where to locate fire
stations. If a city has too many fire stations, it will spend too much
on running them, but if it has too few, there may be unnecessary fire
damage because the fire trucks take too long to get to the fire.</p>
<p>The first part of a study of this kind of issue is to understand the
relationship between the distance from the fire station (measured in
miles in our data set) and the amount of fire damage caused (measured
in thousands of dollars). A city recorded the fire damage and distance
from fire station for 15 residential fires (which you can take as a
sample of “all possible residential fires in that city”). The data
are in <a href="http://ritsokiguess.site/datafiles/fire_damage.txt">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and display the data, verifying that you have the
right number of rows and the right columns.</p></li>
<li><p><a name="part:ttest">*</a> Obtain a 95% confidence interval for the
mean fire damage. (There is nothing here from STAD29, and your
answer should have nothing to do with distance.)</p></li>
<li><p>Draw a scatterplot for predicting the amount of fire damage
from the distance from the fire station. Add a smooth trend to your
plot.</p></li>
<li><p><a name="part:howgood">*</a> Is there a relationship between distance from fire station
and fire damage? Is it linear or definitely curved? How strong is
it? Explain briefly.</p></li>
<li><p>Fit a regression predicting fire damage from distance. How
is the R-squared consistent (or inconsistent) with your answer from
part~(<a href="#part:howgood">here</a>)?</p></li>
<li><p><a name="part:cim"><em></a> Obtain a 95% confidence interval for the mean fire damage
</em>for a residence that is 4 miles from the nearest fire station*.
(Note the contrast with part~(<a href="#part:ttest">here</a>).)</p></li>
<li><p>Compare the confidence intervals of parts
(<a href="#part:ttest">here</a>) and (<a href="#part:cim">here</a>). Specifically, compare their
centres and their lengths, and explain briefly why the results
make sense.</p></li>
</ol>
</div>
<div id="making-it-stop" class="section level2 hasAnchor" number="18.13">
<h2><span class="header-section-number">18.13</span> Making it stop<a href="simple-regression.html#making-it-stop" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If you are driving, and you hit the brakes, how far do you travel before coming to a complete stop?
Presumably this depends on how fast you are going.
Knowing this relationship is important in setting speed limits on roads. For example, on a very bendy road, the speed limit needs to be low, because you cannot see very far ahead, and there could be something just
out of sight that you need to stop for.</p>
<p>Data were collected for a typical car and driver, as shown in <a href="http://ritsokiguess.site/datafiles/stopping.csv">http://ritsokiguess.site/datafiles/stopping.csv</a>. These are American data, so the speeds are miles per hour and the stopping distances are in feet.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and display (probably all of) the data.</p></li>
<li><p>Make a suitable plot of the data.</p></li>
<li><p>Describe any trend you see in your graph.</p></li>
<li><p>Fit a linear regression predicting stopping distance from speed. (You might have some misgivings about doing this, but do it anyway.)</p></li>
<li><p>Plot the residuals against the fitted values for this regression.</p></li>
<li><p>What do you learn from the residual plot? Does that surprise you? Explain briefly.</p></li>
<li><p>What is the actual relationship between stopping distance and speed, according to the physics? See if you can find out. Cite any books or websites that you use: that is, include a link to a website, or give enough information about a book that the grader could find it.</p></li>
<li><p>Fit the relationship that your research indicated (in the previous part) and display the results. Comment briefly on the R-squared value.</p></li>
<li><p>Somebody says to you “if you have a regression with a high R-squared, like 95%, there is no need to look for a better model.” How do you respond to this? Explain briefly.</p></li>
</ol>
</div>
<div id="predicting-height-from-foot-length" class="section level2 hasAnchor" number="18.14">
<h2><span class="header-section-number">18.14</span> Predicting height from foot length<a href="simple-regression.html#predicting-height-from-foot-length" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Is it possible to estimate the height of a person from the length of their foot? To find out, 33 (male) students had their height and foot length measured. The data are in
<a href="http://ritsokiguess.site/datafiles/heightfoot.csv">http://ritsokiguess.site/datafiles/heightfoot.csv</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and display (some of) the data. (If you are having trouble, make sure you have <em>exactly</em> the right URL. The correct URL has no spaces or other strange characters in it.)</p></li>
<li><p>Make a suitable plot of the two variables in the data frame.</p></li>
<li><p>Are there any observations not on the trend of the other points? What is unusual about those observations?</p></li>
<li><p>Fit a regression predicting height from foot length, <em>including</em> any observations that you identified in the previous part. For that regression, plot the residuals against the fitted values and make a normal quantile plot of the residuals.</p></li>
<li><p>Earlier, you identified one or more observations that were off the trend. How does this point or points show up on each of the plots you drew in the previous part?</p></li>
<li><p>Any data points that concerned you earlier were actually errors.
Create and save a new data frame that does not contain any of those data points.</p></li>
<li><p>Run a regression predicting height from foot length for your data set without errors. Obtain a plot of the residuals against fitted values and a normal quantile plot of the residuals for this regression.</p></li>
<li><p>Do you see any problems on the plots you drew in the previous part? Explain briefly.</p></li>
<li><p>Find a way to plot the data and <em>both</em> regression lines on the same plot, in such a way that you can see which regression line is which. If you get help from anything outside the course materials, cite your source(s).</p></li>
<li><p>Discuss briefly how removing the observation(s) that were errors has changed where the regression line goes, and whether that is what you expected.</p></li>
</ol>
<p>My solutions follow:</p>
</div>
<div id="rainfall-in-california-1" class="section level2 hasAnchor" number="18.15">
<h2><span class="header-section-number">18.15</span> Rainfall in California<a href="simple-regression.html#rainfall-in-california-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The data in
<a href="http://ritsokiguess.site/datafiles/calirain.txt">link</a> are
rainfall and other measurements for 30 weather stations in
California. Our aim is to understand how well the annual rainfall at
these stations (measured in inches) can be predicted from the other
measurements, which are the altitude (in feet above sea level), the
latitude (degrees north of the equator) and the distance from the
coast (in miles).</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R. You’ll have to be careful here, since the
values are space-delimited, but sometimes by more than one space, to
make the columns line up. <code>read_table2</code>, with filename or
url, will read it in.
One of the variables
is called <code>rainfall</code>, so as long as you <em>do not</em> call
the data frame that, you should be safe.</li>
</ol>
<p>Solution</p>
<p>I used <code>rains</code> as the name of my data frame:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="simple-regression.html#cb117-1" aria-hidden="true" tabindex="-1"></a>my_url<span class="ot">=</span><span class="st">&quot;http://ritsokiguess.site/datafiles/calirain.txt&quot;</span></span>
<span id="cb117-2"><a href="simple-regression.html#cb117-2" aria-hidden="true" tabindex="-1"></a>rains<span class="ot">=</span><span class="fu">read_table2</span>(my_url)</span></code></pre></div>
<pre><code>## Warning: `read_table2()` was deprecated in readr 2.0.0.
## Please use `read_table()` instead.</code></pre>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   station = col_character(),
##   rainfall = col_double(),
##   altitude = col_double(),
##   latitude = col_double(),
##   fromcoast = col_double()
## )</code></pre>
<p>I have the right number of rows and columns.</p>
<p>There is also <code>read_table</code>, but that requires <em>all</em> the
columns, including the header row, to be lined up. You can try that
here and see how it fails.</p>
<p>I don’t need you to investigate the data yet (that happens in the next
part), but this is interesting (to me):</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="simple-regression.html#cb120-1" aria-hidden="true" tabindex="-1"></a>rains</span></code></pre></div>
<pre><code>## # A tibble: 30 × 5
##    station      rainfall altitude latitude fromcoast
##    &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
##  1 Eureka           39.6       43     40.8         1
##  2 RedBluff         23.3      341     40.2        97
##  3 Thermal          18.2     4152     33.8        70
##  4 FortBragg        37.5       74     39.4         1
##  5 SodaSprings      49.3     6752     39.3       150
##  6 SanFrancisco     21.8       52     37.8         5
##  7 Sacramento       18.1       25     38.5        80
##  8 SanJose          14.2       95     37.4        28
##  9 GiantForest      42.6     6360     36.6       145
## 10 Salinas          13.8       74     36.7        12
## # … with 20 more rows</code></pre>
<p>Some of the station names are two words, but they have been smooshed
into one word, so that <code>read_table2</code> will recognize them as a
single thing. Someone had already done that for us, so I didn’t even
have to do it myself.</p>
<p>If the station names had been two genuine words, a <code>.csv</code> would
probably have been the best choice (the actual data values being
separated by commas then, and not spaces).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a boxplot of the rainfall figures, and explain why the
values are reasonable. (A rainfall cannot be negative, and it is
unusual for a annual rainfall to exceed 60 inches.) A
<code>ggplot</code> boxplot needs <em>something</em> on the <span class="math inline">\(x\)</span>-axis: the
number 1 will do.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="simple-regression.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rains,<span class="fu">aes</span>(<span class="at">y=</span>rainfall,<span class="at">x=</span><span class="dv">1</span>))<span class="sc">+</span><span class="fu">geom_boxplot</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/calirain-3-1.png" width="672" /></p>
<p>There is only one rainfall over 60 inches, and the smallest one is
close to zero but positive, so that is good.</p>
<p>Another possible plot here is a histogram, since there is only one quantitative variable:</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="simple-regression.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rains, <span class="fu">aes</span>(<span class="at">x=</span>rainfall))<span class="sc">+</span><span class="fu">geom_histogram</span>(<span class="at">bins=</span><span class="dv">7</span>)</span></code></pre></div>
<p><img src="pasias_files/figure-html/calirain-4-1.png" width="672" /></p>
<p>This clearly shows the rainfall value above 60 inches, but some other things are less clear: are those two rainfall values around 50 inches above or below 50, and are those six rainfall values near zero actually above zero?
Extra: What stations have those extreme values? Should you wish to find out:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="simple-regression.html#cb124-1" aria-hidden="true" tabindex="-1"></a>rains <span class="sc">%&gt;%</span> <span class="fu">filter</span>(rainfall<span class="sc">&gt;</span><span class="dv">60</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 5
##   station      rainfall altitude latitude fromcoast
##   &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 CrescentCity     74.9       35     41.7         1</code></pre>
<p>This is a place right on the Pacific coast, almost up into Oregon (it’s almost
the northernmost of all the stations). So it makes sense that it would
have a high rainfall, if anywhere does. (If you know anything about
rainy places, you’ll probably think of Vancouver and Seattle, in the
Pacific Northwest.) Here it is:
<a href="https://www.google.ca/maps/place/Crescent+City,+CA,+USA/@41.7552589,-123.9652917,8.42z/data=!4m5!3m4!1s0x54d066375c6288db:0x76e89ab07375e62e!8m2!3d41.7557501!4d-124.2025913">link</a>.
Which station has less than 2 inches of annual rainfall?</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="simple-regression.html#cb126-1" aria-hidden="true" tabindex="-1"></a>rains <span class="sc">%&gt;%</span> <span class="fu">filter</span>(rainfall<span class="sc">&lt;</span><span class="dv">2</span>)  </span></code></pre></div>
<pre><code>## # A tibble: 1 × 5
##   station     rainfall altitude latitude fromcoast
##   &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 DeathValley     1.66     -178     36.5       194</code></pre>
<p>The name of the station is a clue: this one is in the desert. So you’d
expect very little rain. Its altitude is <em>negative</em>, so it’s
actually <em>below</em> sea level. This is correct. Here is where it is:
<a href="https://www.google.ca/maps/place/Death+Valley,+CA,+USA/@36.6341288,-118.2252974,7.75z/data=!4m5!3m4!1s0x80c739a21e8fffb1:0x1c897383d723dd25!8m2!3d36.5322649!4d-116.9325408">link</a>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Plot <code>rainfall</code> against each of the other quantitative
variables (that is, not <code>station</code>).</li>
</ol>
<p>Solution</p>
<p>That is, <code>altitude</code>, <code>latitude</code> and
<code>fromcoast</code>. The obvious way to do this (perfectly
acceptable) is one plot at a time:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="simple-regression.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rains,<span class="fu">aes</span>(<span class="at">y=</span>rainfall,<span class="at">x=</span>altitude))<span class="sc">+</span><span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/calirain-7-1.png" width="672" /></p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="simple-regression.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rains,<span class="fu">aes</span>(<span class="at">y=</span>rainfall,<span class="at">x=</span>latitude))<span class="sc">+</span><span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/calirain-8-1.png" width="672" /></p>
<p>and finally</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="simple-regression.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rains,<span class="fu">aes</span>(<span class="at">y=</span>rainfall,<span class="at">x=</span>fromcoast))<span class="sc">+</span><span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/calirain-9-1.png" width="672" /></p>
<p>You can add a smooth trend to these if you want. Up to you. Just the
points is fine with me.</p>
<p>Here is a funky way to get all three plots in one shot:</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="simple-regression.html#cb131-1" aria-hidden="true" tabindex="-1"></a>rains <span class="sc">%&gt;%</span> </span>
<span id="cb131-2"><a href="simple-regression.html#cb131-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(altitude<span class="sc">:</span>fromcoast, <span class="at">names_to=</span><span class="st">&quot;xname&quot;</span>,<span class="at">values_to=</span><span class="st">&quot;x&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb131-3"><a href="simple-regression.html#cb131-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>rainfall))<span class="sc">+</span><span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb131-4"><a href="simple-regression.html#cb131-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>xname,<span class="at">scales=</span><span class="st">&quot;free&quot;</span>)</span></code></pre></div>
<p><img src="pasias_files/figure-html/calirain-10-1.png" width="672" /></p>
<p>This always seems extraordinarily strange if you haven’t run into it
before. The strategy is to put <em>all</em> the <span class="math inline">\(x\)</span>-variables you want
to plot into <em>one</em> column and then plot your <span class="math inline">\(y\)</span> against the
<span class="math inline">\(x\)</span>-column. Thus: make a column of all the <span class="math inline">\(x\)</span>’s glued
together, labelled by which <span class="math inline">\(x\)</span> they are, then plot <span class="math inline">\(y\)</span> against <span class="math inline">\(x\)</span>
but make a different sub-plot or “facet” for each different
<span class="math inline">\(x\)</span>-name. The last thing is that each <span class="math inline">\(x\)</span> is measured on a different
scale, and unless we take steps, all the sub-plots will have the
<em>same</em> scale on each axis, which we don’t want.</p>
<p>I’m not sure I like how it came out, with three very tall
plots. <code>facet_wrap</code> can also take an <code>nrow</code> or an
<code>ncol</code>, which tells it how many rows or columns to use for the
display. Here, for example, two columns because I thought three was
too many:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="simple-regression.html#cb132-1" aria-hidden="true" tabindex="-1"></a>rains <span class="sc">%&gt;%</span> </span>
<span id="cb132-2"><a href="simple-regression.html#cb132-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(altitude<span class="sc">:</span>fromcoast, <span class="at">names_to=</span><span class="st">&quot;xname&quot;</span>,<span class="at">values_to=</span><span class="st">&quot;x&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb132-3"><a href="simple-regression.html#cb132-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>rainfall))<span class="sc">+</span><span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb132-4"><a href="simple-regression.html#cb132-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>xname,<span class="at">scales=</span><span class="st">&quot;free&quot;</span>,<span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="pasias_files/figure-html/calirain-11-1.png" width="672" /></p>
<p>Now, the three plots have come out about square, or at least “landscape”, which I like a lot better.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Look at the relationship of each other variable with
<code>rainfall</code>.
Justify the assertion that <code>latitude</code> seems most strongly
related with <code>rainfall</code>. Is that relationship positive or negative? linear? Explain
briefly.</li>
</ol>
<p>Solution</p>
<p>Let’s look at the three variables in turn:</p>
<ul>
<li><p><code>altitude</code>: not much of anything. The stations near
sea level have rainfall all over the place, though the three
highest-altitude stations have the three highest rainfalls apart
from Crescent City.</p></li>
<li><p><code>latitude</code>: there is a definite upward trend here, in
that stations further north (higher latitude) are likely to have
a higher rainfall. I’d call this trend linear (or, not obviously
curved), though the two most northerly stations have one higher
and one much lower rainfall than you’d expect.</p></li>
<li><p><code>fromcoast</code>: this is a weak downward trend, though
the trend is spoiled by those three stations about 150 miles
from the coast that have more than 40 inches of rainfall.</p></li>
</ul>
<p>Out of those, only <code>latitude</code> seems to have any meaningful
relationship with <code>rainfall</code>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Fit a regression with <code>rainfall</code> as the response
variable, and <code>latitude</code> as your explanatory variable. What
are the intercept, slope and R-squared values? Is there a
<em>significant</em> relationship between <code>rainfall</code> and your
explanatory variable? What does that mean?</li>
</ol>
<p>Solution</p>
<p>Save your <code>lm</code> into a
variable, since it will get used again later:</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="simple-regression.html#cb133-1" aria-hidden="true" tabindex="-1"></a>rainfall<span class="fl">.1</span><span class="ot">=</span><span class="fu">lm</span>(rainfall<span class="sc">~</span>latitude,<span class="at">data=</span>rains)</span>
<span id="cb133-2"><a href="simple-regression.html#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rainfall<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rainfall ~ latitude, data = rains)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -27.297  -7.956  -2.103   6.082  38.262 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -113.3028    35.7210  -3.172  0.00366 ** 
## latitude       3.5950     0.9623   3.736  0.00085 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 13.82 on 28 degrees of freedom
## Multiple R-squared:  0.3326, Adjusted R-squared:  0.3088 
## F-statistic: 13.96 on 1 and 28 DF,  p-value: 0.0008495</code></pre>
<p>My intercept is <span class="math inline">\(-113.3\)</span>, slope is <span class="math inline">\(3.6\)</span> and R-squared is <span class="math inline">\(0.33\)</span> or
33%. (I want you to pull these numbers out of the output and round
them off to something sensible.) The slope is significantly nonzero,
its P-value being 0.00085: rainfall really does depend on latitude, although
not strongly so.</p>
<p>Extra: Of course, I can easily do the others as well, though you don’t have to:</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="simple-regression.html#cb135-1" aria-hidden="true" tabindex="-1"></a>rainfall<span class="fl">.2</span><span class="ot">=</span><span class="fu">lm</span>(rainfall<span class="sc">~</span>fromcoast,<span class="at">data=</span>rains)</span>
<span id="cb135-2"><a href="simple-regression.html#cb135-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rainfall<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rainfall ~ fromcoast, data = rains)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.240  -9.431  -6.603   2.871  51.147 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 23.77306    4.61296   5.154 1.82e-05 ***
## fromcoast   -0.05039    0.04431  -1.137    0.265    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 16.54 on 28 degrees of freedom
## Multiple R-squared:  0.04414,    Adjusted R-squared:   0.01 
## F-statistic: 1.293 on 1 and 28 DF,  p-value: 0.2651</code></pre>
<p>Here, the intercept is 23.8, the slope is <span class="math inline">\(-0.05\)</span> and R-squared is a
dismal 0.04 (4%). This is a way of seeing that this relationship is
really weak, and it doesn’t even have a curve to the trend or anything
that would compensate for this. I looked at the scatterplot again and
saw that if it were not for the point bottom right which is furthest
from the coast and has almost no rainfall, there would be almost no
trend at all. The slope here is not significantly different from zero,
with a P-value of 0.265.</p>
<p>Finally:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="simple-regression.html#cb137-1" aria-hidden="true" tabindex="-1"></a>rainfall<span class="fl">.3</span><span class="ot">=</span><span class="fu">lm</span>(rainfall<span class="sc">~</span>altitude,<span class="at">data=</span>rains)</span>
<span id="cb137-2"><a href="simple-regression.html#cb137-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rainfall<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rainfall ~ altitude, data = rains)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -20.620  -8.479  -2.729   4.555  58.271 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 16.514799   3.539141   4.666  6.9e-05 ***
## altitude     0.002394   0.001428   1.676    0.105    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 16.13 on 28 degrees of freedom
## Multiple R-squared:  0.09121,    Adjusted R-squared:  0.05875 
## F-statistic:  2.81 on 1 and 28 DF,  p-value: 0.1048</code></pre>
<p>The intercept is 16.5, the slope is 0.002 and the R-squared is 0.09 or
9%, also terrible. The P-value is 0.105, which is not small enough to
be significant.</p>
<p>So it looks as if it’s only <code>latitude</code> that
has any impact at all. This is the only explanatory variable with a
significantly nonzero slope. On its own, at least.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Fit a multiple regression predicting <code>rainfall</code> from
all three of the other (quantitative) variables. Display the
results. Comment is coming up later.</li>
</ol>
<p>Solution</p>
<p>This, then:</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="simple-regression.html#cb139-1" aria-hidden="true" tabindex="-1"></a>rainfall<span class="fl">.4</span><span class="ot">=</span><span class="fu">lm</span>(rainfall<span class="sc">~</span>latitude<span class="sc">+</span>altitude<span class="sc">+</span>fromcoast,<span class="at">data=</span>rains)</span>
<span id="cb139-2"><a href="simple-regression.html#cb139-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(rainfall<span class="fl">.4</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rainfall ~ latitude + altitude + fromcoast, data = rains)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -28.722  -5.603  -0.531   3.510  33.317 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.024e+02  2.921e+01  -3.505 0.001676 ** 
## latitude     3.451e+00  7.949e-01   4.342 0.000191 ***
## altitude     4.091e-03  1.218e-03   3.358 0.002431 ** 
## fromcoast   -1.429e-01  3.634e-02  -3.931 0.000559 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 11.1 on 26 degrees of freedom
## Multiple R-squared:  0.6003, Adjusted R-squared:  0.5542 
## F-statistic: 13.02 on 3 and 26 DF,  p-value: 2.205e-05</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>What is the R-squared for the regression of the last part?
How does that compare with the R-squared of your regression in part (e)?</li>
</ol>
<p>Solution</p>
<p>The R-squared is 0.60 (60%), which is quite a bit bigger than the
R-squared of 0.33 (33%) we got back in (e).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>What do you conclude about the importance of the variables
that you did <em>not</em> include in your model in
(e)? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Both variables <code>altitude</code> and <code>fromcoast</code> are
significant in this regression, so they have <em>something to add</em> over and above <code>latitude</code> when it comes to
predicting rainfall, even though (and this seems odd) they have no
apparent relationship with <code>rainfall</code> on their own.
Another way to say this is that the three variables work together
as a team to predict rainfall, and together they do much better
than any one of them can do by themselves.<br />
This also goes to show that the scatterplots we began
with don’t get to the heart of multi-variable relationships,
because they are only looking at the variables two at a time.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol style="list-style-type: lower-roman">
<li>Make a suitable hypothesis test that the variables
<code>altitude</code> and <code>fromcoast</code> significantly improve the
prediction of <code>rainfall</code> over the use of <code>latitude</code>
alone. What do you conclude?</li>
</ol>
<p>Solution</p>
<p>This calls for <code>anova</code>. Feed this two fitted models,
smaller (fewer explanatory variables) first. The null hypothesis
is that the two models are equally good (so we should go with the
smaller); the alternative is that the larger model is better, so
that the extra complication is worth it:</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="simple-regression.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(rainfall<span class="fl">.1</span>,rainfall<span class="fl">.4</span>)  </span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: rainfall ~ latitude
## Model 2: rainfall ~ latitude + altitude + fromcoast
##   Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)   
## 1     28 5346.8                                
## 2     26 3202.3  2    2144.5 8.7057 0.001276 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The P-value is small, so we reject the null in favour of the
alternative: the regression with all three explanatory variables fits
better than the one with just <code>latitude</code>, so the bigger model
is the one we should go with.</p>
<p>If you have studied these things: this one is a
“multiple-partial <span class="math inline">\(F\)</span>-test”, for testing the combined significance of more than one <span class="math inline">\(x\)</span>
but less than all the <span class="math inline">\(x\)</span>’s.<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="carbon-monoxide-in-cigarettes-1" class="section level2 hasAnchor" number="18.16">
<h2><span class="header-section-number">18.16</span> Carbon monoxide in cigarettes<a href="simple-regression.html#carbon-monoxide-in-cigarettes-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The (US) Federal Trade Commission assesses cigarettes
according to their tar, nicotine and carbon monoxide contents. In a
particular year, 25 brands were assessed. For each brand, the tar,
nicotine and carbon monoxide (all in milligrams) were measured, along
with the weight in grams. Our aim is to predict carbon monoxide from
any or all of the other variables. The data are in
<a href="http://ritsokiguess.site/datafiles/ftccigar.txt">link</a>. These are
aligned by column (except for the variable names), with more than one
space between each column of data.</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R, and check that you have 25 observations
and 4 variables.</li>
</ol>
<p>Solution</p>
<p>This specification calls for <code>read_table2</code>:</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="simple-regression.html#cb143-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/ftccigar.txt&quot;</span></span>
<span id="cb143-2"><a href="simple-regression.html#cb143-2" aria-hidden="true" tabindex="-1"></a>cigs <span class="ot">&lt;-</span> <span class="fu">read_table2</span>(my_url)</span></code></pre></div>
<pre><code>## Warning: `read_table2()` was deprecated in readr 2.0.0.
## Please use `read_table()` instead.</code></pre>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   tar = col_double(),
##   nicotine = col_double(),
##   weight = col_double(),
##   co = col_double()
## )</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="simple-regression.html#cb146-1" aria-hidden="true" tabindex="-1"></a>cigs</span></code></pre></div>
<pre><code>## # A tibble: 25 × 4
##      tar nicotine weight    co
##    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
##  1  14.1     0.86  0.985  13.6
##  2  16       1.06  1.09   16.6
##  3  29.8     2.03  1.16   23.5
##  4   8       0.67  0.928  10.2
##  5   4.1     0.4   0.946   5.4
##  6  15       1.04  0.888  15  
##  7   8.8     0.76  1.03    9  
##  8  12.4     0.95  0.922  12.3
##  9  16.6     1.12  0.937  16.3
## 10  14.9     1.02  0.886  15.4
## # … with 15 more rows</code></pre>
<p>Yes, I have 25 observations on 4 variables indeed.</p>
<p><code>read_delim</code> won’t work (try it and see what happens), because
that would require the values to be separated by <em>exactly one</em> space.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Run a regression to predict carbon monoxide from the other
variables, and obtain a summary of the output.</li>
</ol>
<p>Solution</p>
<p>The word “summary” is meant to be a big clue that
<code>summary</code> is what you need:</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="simple-regression.html#cb148-1" aria-hidden="true" tabindex="-1"></a>cigs<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(co <span class="sc">~</span> tar <span class="sc">+</span> nicotine <span class="sc">+</span> weight, <span class="at">data =</span> cigs)</span>
<span id="cb148-2"><a href="simple-regression.html#cb148-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cigs<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = co ~ tar + nicotine + weight, data = cigs)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.89261 -0.78269  0.00428  0.92891  2.45082 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   3.2022     3.4618   0.925 0.365464    
## tar           0.9626     0.2422   3.974 0.000692 ***
## nicotine     -2.6317     3.9006  -0.675 0.507234    
## weight       -0.1305     3.8853  -0.034 0.973527    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.446 on 21 degrees of freedom
## Multiple R-squared:  0.9186, Adjusted R-squared:  0.907 
## F-statistic: 78.98 on 3 and 21 DF,  p-value: 1.329e-11</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Which one of your explanatory variables would you
remove from this regression? Explain (very) briefly. Go ahead and
fit the regression without it, and describe how the change in
R-squared from the regression in (b) was entirely predictable.</li>
</ol>
<p>Solution</p>
<p>First, the <span class="math inline">\(x\)</span>-variable to remove. The obvious candidate is
<code>weight</code>, since it has easily the highest, and clearly
non-significant, P-value. So, out it comes:</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="simple-regression.html#cb150-1" aria-hidden="true" tabindex="-1"></a>cigs<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(co <span class="sc">~</span> tar <span class="sc">+</span> nicotine, <span class="at">data =</span> cigs)</span>
<span id="cb150-2"><a href="simple-regression.html#cb150-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cigs<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = co ~ tar + nicotine, data = cigs)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.89941 -0.78470 -0.00144  0.91585  2.43064 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   3.0896     0.8438   3.662 0.001371 ** 
## tar           0.9625     0.2367   4.067 0.000512 ***
## nicotine     -2.6463     3.7872  -0.699 0.492035    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.413 on 22 degrees of freedom
## Multiple R-squared:  0.9186, Adjusted R-squared:  0.9112 
## F-statistic: 124.1 on 2 and 22 DF,  p-value: 1.042e-12</code></pre>
<p>R-squared has dropped from 0.9186 to 0.9186! That is, taking
out <code>weight</code> has not just had a minimal effect on R-squared;
it’s not changed R-squared at all. This is because <code>weight</code> was
so far from being significant: it literally had <em>nothing</em> to add.</p>
<p>Another way of achieving the same thing is via the function
<code>update</code>, which takes a fitted model object and describes the
<em>change</em> that you want to make:</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="simple-regression.html#cb152-1" aria-hidden="true" tabindex="-1"></a>cigs<span class="fl">.2</span>a <span class="ot">&lt;-</span> <span class="fu">update</span>(cigs<span class="fl">.1</span>, . <span class="sc">~</span> . <span class="sc">-</span> weight)</span>
<span id="cb152-2"><a href="simple-regression.html#cb152-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cigs<span class="fl">.2</span>a)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = co ~ tar + nicotine, data = cigs)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.89941 -0.78470 -0.00144  0.91585  2.43064 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   3.0896     0.8438   3.662 0.001371 ** 
## tar           0.9625     0.2367   4.067 0.000512 ***
## nicotine     -2.6463     3.7872  -0.699 0.492035    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.413 on 22 degrees of freedom
## Multiple R-squared:  0.9186, Adjusted R-squared:  0.9112 
## F-statistic: 124.1 on 2 and 22 DF,  p-value: 1.042e-12</code></pre>
<p>This can be shorter than describing the whole model again, as you do
with the <code>cigs.2</code> version of <code>lm</code>. The syntax is that
you first specify a “base” fitted model object that you’re going to
update. Because the model <code>cigs.1</code> contains all the information
about the kind of model it is, and which data frame the data come
from, R already knows that this is a linear
multiple regression and which <span class="math inline">\(x\)</span>’s it contains. The second thing to describe is the change from
the “base”. In this case, we want to use the same response variable
and all the same explanatory variables that we had before, except for
<code>weight</code>. This is specified by a special kind of model formula
where <code>.</code> means “whatever was there before”: in English,
“same response and same explanatories except take out <code>weight</code>”.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a regression predicting carbon monoxide from
<code>nicotine</code> <em>only</em>, and display the summary.</li>
</ol>
<p>Solution</p>
<p>As you would guess:</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="simple-regression.html#cb154-1" aria-hidden="true" tabindex="-1"></a>cigs<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(co <span class="sc">~</span> nicotine, <span class="at">data =</span> cigs)</span>
<span id="cb154-2"><a href="simple-regression.html#cb154-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(cigs<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = co ~ nicotine, data = cigs)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3273 -1.2228  0.2304  1.2700  3.9357 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1.6647     0.9936   1.675    0.107    
## nicotine     12.3954     1.0542  11.759 3.31e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.828 on 23 degrees of freedom
## Multiple R-squared:  0.8574, Adjusted R-squared:  0.8512 
## F-statistic: 138.3 on 1 and 23 DF,  p-value: 3.312e-11</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li><code>nicotine</code> was far from being significant in the model
of (c), and yet in the model of
(d), it was <em>strongly</em> significant, and the
R-squared value of (d) was almost as high as that
of (c). What does this say about the importance of
<code>nicotine</code> as an explanatory variable? Explain, as briefly as
you can manage.</li>
</ol>
<p>Solution</p>
<p>What this says is that you <em>cannot</em> say anything about the
“importance” of <code>nicotine</code> without also describing the
context that you’re talking about. <em>By itself</em>,
<code>nicotine</code> is important, but <em>when you have
<code>tar</code> in the model</em>, <code>nicotine</code> is not
important: precisely, it now has nothing to add over and above
the predictive value that <code>tar</code> has. You might guess that
this is because <code>tar</code> and <code>nicotine</code> are
“saying the same thing” in some fashion.
We’ll explore that in a moment.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Make a “pairs plot”: that is, scatter plots between all
pairs of variables. This can be done by feeding the whole data frame
into <code>plot</code>.<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a>
Do you see any strong relationships that do
<em>not</em> include <code>co</code>? Does that shed any light on the last
part? Explain briefly (or “at length” if that’s how it comes
out).</li>
</ol>
<p>Solution</p>
<p>Plot the entire data frame:</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="simple-regression.html#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cigs)</span></code></pre></div>
<p><img src="pasias_files/figure-html/ftccigar-6-1.png" width="672" /></p>
<p>We’re supposed to ignore <code>co</code>, but I comment that strong
relationships between <code>co</code> and <em>both</em> of <code>tar</code> and
<code>nicotine</code> show up here, along with <code>weight</code> being
at most weakly related to anything else.</p>
<p>That leaves the relationship of <code>tar</code> and <code>nicotine</code>
with each other. That also looks like a strong linear trend. When you
have correlations between explanatory variables, it is called
“multicollinearity”.</p>
<p>Having correlated <span class="math inline">\(x\)</span>’s is
trouble. Here is where we find out why. The problem is that when
<code>co</code> is large, <code>nicotine</code> is large, and a large value of
<code>tar</code> will come along with it. So we don’t know whether a large
value of <code>co</code> is caused by a large value of <code>tar</code> or a
large value of <code>nicotine</code>: there is no way to separate out
their effects because in effect they are “glued together”.</p>
<p>You might know of this effect (in an experimental design context) as
“confounding”: the effect of <code>tar</code> on <code>co</code> is
confounded with the effect of <code>nicotine</code> on <code>co</code>, and
you can’t tell which one deserves the credit for predicting <code>co</code>.</p>
<p>If you were able to design an experiment here, you could (in
principle) manufacture a bunch of cigarettes with high tar; some of
them would have high nicotine and some would have low. Likewise for
low tar. Then the
correlation between <code>nicotine</code> and <code>tar</code> would go away,
their effects on <code>co</code> would no longer be confounded, and you
could see unambiguously which one of the variables deserves credit for
predicting <code>co</code>. Or maybe it depends on both, genuinely, but at
least then you’d know.</p>
<p>We, however, have an observational study, so we have to make do with
the data we have. Confounding is one of the risks we take when we work
with observational data.</p>
<p>This was a “base graphics” plot. There is a way of doing a
<code>ggplot</code>-style “pairs plot”, as this is called, thus:</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="simple-regression.html#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb157-2"><a href="simple-regression.html#cb157-2" aria-hidden="true" tabindex="-1"></a>cigs <span class="sc">%&gt;%</span> <span class="fu">ggpairs</span>(<span class="at">progress =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="pasias_files/figure-html/tober-1.png" width="672" /></p>
<p>As ever, <code>install.packages</code> first, in the likely event that you
don’t have this package installed yet. Once you do, though, I think
this is a nicer way to get a pairs plot.</p>
<p>This plot is a bit more sophisticated: instead of just having the
scatterplots of the pairs of variables in the row and column, it uses
the diagonal to show a “kernel density” (a smoothed-out histogram),
and upper-right it shows the correlation between each pair of
variables. The three correlations between <code>co</code>, <code>tar</code>
and <code>nicotine</code> are clearly the highest.</p>
<p>If you want only some of the columns to appear in your pairs plot,
<code>select</code> them first, and then pass that data frame into
<code>ggpairs</code>. Here, we found that <code>weight</code> was not
correlated with anything much, so we can take it out and then make a
pairs plot of the other variables:</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="simple-regression.html#cb158-1" aria-hidden="true" tabindex="-1"></a>cigs <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>weight) <span class="sc">%&gt;%</span> <span class="fu">ggpairs</span>(<span class="at">progress =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="pasias_files/figure-html/ftccigar-7-1.png" width="672" /></p>
<p>The three correlations that remain are all very high, which is
entirely consistent with the strong linear relationships that you see
bottom left.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="maximal-oxygen-uptake-in-young-boys-1" class="section level2 hasAnchor" number="18.17">
<h2><span class="header-section-number">18.17</span> Maximal oxygen uptake in young boys<a href="simple-regression.html#maximal-oxygen-uptake-in-young-boys-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A physiologist wanted to understand the relationship between
physical characteristics of pre-adolescent boys and their maximal
oxygen uptake (millilitres of oxygen per kilogram of body weight). The
data are in
<a href="http://ritsokiguess.site/datafiles/youngboys.txt">link</a> for a
random sample of 10 pre-adolescent boys. The variables are (with
units):</p>
<ul>
<li><p><code>uptake</code>: Oxygen uptake (millitres of oxygen per kilogram
of body weight)</p></li>
<li><p><code>age</code>: boy’s age (years)</p></li>
<li><p><code>height</code>: boy’s height (cm)</p></li>
<li><p><code>weight</code>: boy’s weight (kg)</p></li>
<li><p><code>chest</code>: chest depth (cm).</p></li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R and confirm that you do indeed have
10 observations.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="simple-regression.html#cb159-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/youngboys.txt&quot;</span></span>
<span id="cb159-2"><a href="simple-regression.html#cb159-2" aria-hidden="true" tabindex="-1"></a>boys <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 10 Columns: 5
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot; &quot;
## dbl (5): uptake, age, height, weight, chest
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="simple-regression.html#cb161-1" aria-hidden="true" tabindex="-1"></a>boys</span></code></pre></div>
<pre><code>## # A tibble: 10 × 5
##    uptake   age height weight chest
##     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
##  1   1.54   8.4   132    29.1  14.4
##  2   1.74   8.7   136.   29.7  14.5
##  3   1.32   8.9   128.   28.4  14  
##  4   1.5    9.9   131.   28.8  14.2
##  5   1.46   9     130    25.9  13.6
##  6   1.35   7.7   128.   27.6  13.9
##  7   1.53   7.3   130.   29    14  
##  8   1.71   9.9   138.   33.6  14.6
##  9   1.27   9.3   127.   27.7  13.9
## 10   1.5    8.1   132.   30.8  14.5</code></pre>
<p>10 boys (rows) indeed.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Fit a regression predicting oxygen uptake from all the
other variables, and display the results.</li>
</ol>
<p>Solution</p>
<p>Fitting four explanatory variables with only ten observations is likely to be pretty shaky, but we
press ahead regardless:</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="simple-regression.html#cb163-1" aria-hidden="true" tabindex="-1"></a>boys<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(uptake <span class="sc">~</span> age <span class="sc">+</span> height <span class="sc">+</span> weight <span class="sc">+</span> chest, <span class="at">data =</span> boys)</span>
<span id="cb163-2"><a href="simple-regression.html#cb163-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(boys<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = uptake ~ age + height + weight + chest, data = boys)
## 
## Residuals:
##         1         2         3         4         5         6         7         8 
## -0.020697  0.019741 -0.003649  0.038470 -0.023639 -0.026026  0.050459 -0.014380 
##         9        10 
##  0.004294 -0.024573 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -4.774739   0.862818  -5.534 0.002643 ** 
## age         -0.035214   0.015386  -2.289 0.070769 .  
## height       0.051637   0.006215   8.308 0.000413 ***
## weight      -0.023417   0.013428  -1.744 0.141640    
## chest        0.034489   0.085239   0.405 0.702490    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.03721 on 5 degrees of freedom
## Multiple R-squared:  0.9675, Adjusted R-squared:  0.9415 
## F-statistic:  37.2 on 4 and 5 DF,  p-value: 0.0006513</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>(A one-mark question.) Would you say, on the evidence so
far, that the regression fits well or badly? Explain (very)
briefly.</li>
</ol>
<p>Solution</p>
<p>R-squared of 0.97 (97%) is very high, so I’d say this
regression fits very well. That’s all.
I said “on the evidence so far” to dissuade you from
overthinking this, or thinking that you needed to produce
some more evidence. That, plus the fact that this was only
one mark.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>It seems reasonable that an older boy should have a
greater oxygen uptake, all else being equal. Is this supported
by your output? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>If an older boy has greater oxygen uptake (the “all else equal” was a hint),
the slope of <code>age</code> should be
positive. It is not: it is <span class="math inline">\(-0.035\)</span>, so it is suggesting
(all else equal) that a greater age goes with a
<em>smaller</em> oxygen uptake.
The reason why this happens (which you didn’t need, but
you can include it if you like) is that <code>age</code> has a
non-small P-value of 0.07, so that the <code>age</code> slope
is not significantly different from zero. With all the
other variables, <code>age</code> has nothing to <em>add</em>
over and above them, and we could therefore remove it.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>It seems reasonable that a boy with larger weight
should have larger lungs and thus a <em>statistically
significantly</em> larger oxygen uptake. Is that what happens
here? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Look at the P-value for <code>weight</code>. This is 0.14,
not small, and so a boy with larger weight does not have
a significantly larger oxygen uptake, all else
equal. (The slope for <code>weight</code> is not
significantly different from zero either.)
I emphasized “statistically significant” to remind you
that this means to do a test and get a P-value.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Fit a model that contains only the significant
explanatory variables from your first regression. How do
the R-squared values from the two regressions compare?
(The last sentence asks for more or less the same thing as
the next part. Answer it either here or there. Either
place is good.)</li>
</ol>
<p>Solution</p>
<p>Only <code>height</code> is significant, so that’s the
only explanatory variable we need to keep. I would
just do the regression straight rather than using
<code>update</code> here:</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="simple-regression.html#cb165-1" aria-hidden="true" tabindex="-1"></a>boys<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(uptake <span class="sc">~</span> height, <span class="at">data =</span> boys)</span>
<span id="cb165-2"><a href="simple-regression.html#cb165-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(boys<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = uptake ~ height, data = boys)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.069879 -0.033144  0.001407  0.009581  0.084012 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.843326   0.609198  -6.309 0.000231 ***
## height       0.040718   0.004648   8.761 2.26e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.05013 on 8 degrees of freedom
## Multiple R-squared:  0.9056, Adjusted R-squared:  0.8938 
## F-statistic: 76.75 on 1 and 8 DF,  p-value: 2.258e-05</code></pre>
<p>If you want, you can use <code>update</code> here, which looks like this:</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="simple-regression.html#cb167-1" aria-hidden="true" tabindex="-1"></a>boys<span class="fl">.2</span>a <span class="ot">&lt;-</span> <span class="fu">update</span>(boys<span class="fl">.1</span>, . <span class="sc">~</span> . <span class="sc">-</span> age <span class="sc">-</span> weight <span class="sc">-</span> chest)</span>
<span id="cb167-2"><a href="simple-regression.html#cb167-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(boys<span class="fl">.2</span>a)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = uptake ~ height, data = boys)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.069879 -0.033144  0.001407  0.009581  0.084012 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -3.843326   0.609198  -6.309 0.000231 ***
## height       0.040718   0.004648   8.761 2.26e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.05013 on 8 degrees of freedom
## Multiple R-squared:  0.9056, Adjusted R-squared:  0.8938 
## F-statistic: 76.75 on 1 and 8 DF,  p-value: 2.258e-05</code></pre>
<p>This doesn’t go quite so smoothly here because there are three
variables being removed, and it’s a bit of work to type them all.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>How has R-squared changed between your two
regressions? Describe what you see in a few words.</li>
</ol>
<p>Solution</p>
<p>R-squared has dropped by a bit, from 97% to 91%. (Make your own
call: pull out the two R-squared numbers, and say a word or two about
how they compare. I don’t much mind what you say:
“R-squared has decreased (noticeably)”, “R-squared has hardly changed”. But say
something.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Carry out a test comparing the fit of your
two regression models. What do you conclude, and
therefore what recommendation would you make about the
regression that would be preferred?</li>
</ol>
<p>Solution</p>
<p>The word “test” again implies something that produces a P-value with a
null hypothesis that you might reject. In this case, the test that
compares two models differing by more than one <span class="math inline">\(x\)</span> uses
<code>anova</code>, testing the null hypothesis that the two regressions
are equally good, against the alternative that the bigger (first) one
is better. Feed <code>anova</code> two fitted model objects, smaller first:</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="simple-regression.html#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(boys<span class="fl">.2</span>, boys<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: uptake ~ height
## Model 2: uptake ~ age + height + weight + chest
##   Res.Df       RSS Df Sum of Sq      F Pr(&gt;F)
## 1      8 0.0201016                           
## 2      5 0.0069226  3  0.013179 3.1729  0.123</code></pre>
<p>This P-value of 0.123 is not small, so we do not reject the null
hypothesis. There is not a significant difference in fit between the
two models. Therefore, we should go with the smaller model
<code>boys.2</code> because it is simpler.</p>
<p>That drop in R-squared from 97% to 91% was, it turns out, <em>not</em>
significant: the three extra variables
could have produced a change in R-squared like that,
<em>even if they were worthless</em>.<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a></p>
<p>If you have learned about “adjusted R-squared”, you might recall
that this is supposed to go down <em>only</em> if the variables you took
out should not have been taken out. But adjusted R-squared goes down
here as well, from 94% to 89% (not quite as much, therefore). What
happens is that adjusted R-squared is rather more relaxed about
keeping variables than the <code>anova</code> <span class="math inline">\(F\)</span>-test is; if we had used
an <span class="math inline">\(\alpha\)</span> of something like 0.10, the decision between the two
models would have been a lot closer, and this is reflected in the
adjusted R-squared values.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol style="list-style-type: lower-roman">
<li>Obtain a table of correlations between all
the variables in the data frame. Do this by feeding
the whole data frame into <code>cor</code>.
We found that a regression predicting oxygen uptake
from just <code>height</code> was acceptably good. What
does your table of correlations say about why that
is? (Hint: look for all the correlations that are
<em>large</em>.)</li>
</ol>
<p>Solution</p>
<p>Correlations first:</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="simple-regression.html#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(boys)</span></code></pre></div>
<pre><code>##           uptake       age    height    weight     chest
## uptake 1.0000000 0.1361907 0.9516347 0.6576883 0.7182659
## age    0.1361907 1.0000000 0.3274830 0.2307403 0.1657523
## height 0.9516347 0.3274830 1.0000000 0.7898252 0.7909452
## weight 0.6576883 0.2307403 0.7898252 1.0000000 0.8809605
## chest  0.7182659 0.1657523 0.7909452 0.8809605 1.0000000</code></pre>
<p>The correlations with <code>age</code> are all on the low side, but all
the other correlations are high, not just between <code>uptake</code> and the
other variables, but between the explanatory variables as well.</p>
<p>Why is this helpful in understanding what’s going on? Well, imagine a
boy with large height (a tall one). The regression <code>boys.2</code>
says that this alone is enough to predict that such a boy’s oxygen
uptake is likely to be large, since the slope is positive. But the
correlations tell you more: a boy with large height is also (somewhat)
likely to be older (have large age), heavier (large weight) and to have
larger <code>chest</code> cavity. So oxygen uptake does depend on those other
variables as well, but once you know <code>height</code> you can make a
good guess at their values; you don’t need to know them.</p>
<p>Further remarks: <code>age</code> has a low correlation with
<code>uptake</code>, so its non-significance earlier appears to be
“real”: it really does have nothing extra to say, because the other
variables have a stronger link with <code>uptake</code> than
<code>age</code>. Height, however, seems to be the best way of relating
oxygen uptake to any of the other variables. I think the suppositions
from earlier about relating oxygen uptake to “bigness”<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> in some sense
are actually sound, but age and weight and <code>chest</code> capture
“bigness” worse than height does. Later, when you learn about
Principal Components, you will see that the first principal component,
the one that best captures how the variables vary together, is often
“bigness” in some sense.</p>
<p>Another way to think about these things is via pairwise
scatterplots. The nicest way to produce these is via <code>ggpairs</code>
from package <code>GGally</code>:</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="simple-regression.html#cb173-1" aria-hidden="true" tabindex="-1"></a>boys <span class="sc">%&gt;%</span> <span class="fu">ggpairs</span>(<span class="at">progress =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="pasias_files/figure-html/youngboys-7-1.png" width="672" /></p>
<p>A final remark: with five variables, we really ought to have more than
ten observations (something like 50 would be better). But with more
observations and the same correlation structure, the same issues would
come up again, so the question would not be materially changed.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="facebook-friends-and-grey-matter-1" class="section level2 hasAnchor" number="18.18">
<h2><span class="header-section-number">18.18</span> Facebook friends and grey matter<a href="simple-regression.html#facebook-friends-and-grey-matter-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Is there a relationship between the number
of Facebook friends a person has, and the density of grey matter in
the areas of the brain associated with social perception and
associative memory? To find out, a 2012 study measured both of these
variables for a sample of 40 students at City University in London
(England). The data are at
<a href="http://ritsokiguess.site/datafiles/facebook.txt">link</a>. The grey
matter density is on a <span class="math inline">\(z\)</span>-score standardized scale. The values are
separated by <em>tabs</em>.</p>
<p>The aim of this question is to produce an R Markdown report that
contains your answers to the questions below.</p>
<p>You should aim to make your report flow smoothly, so that it would be
pleasant for a grader to read, and can stand on its own as an analysis
(rather than just being the answer to a question that I set you).
Some suggestions: give your report a title and arrange it into
sections with an Introduction; add a small amount of additional text
here and there explaining what you are doing and why. I don’t expect
you to spend a large amount of time on this, but I <em>do</em> hope
you will make some effort. (My report came out to 4 Word pages.)</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data and make a scatterplot for predicting the
number of Facebook friends from the grey matter density. On your
scatterplot, add a smooth trend.</li>
</ol>
<p>Solution</p>
<p>Begin your document with a code chunk containing
<code>library(tidyverse)</code>. The data values are
separated by tabs, which you will need to take into account:</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="simple-regression.html#cb174-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/facebook.txt&quot;</span></span>
<span id="cb174-2"><a href="simple-regression.html#cb174-2" aria-hidden="true" tabindex="-1"></a>fb <span class="ot">&lt;-</span> <span class="fu">read_tsv</span>(my_url)</span></code></pre></div>
<pre><code>## Rows: 40 Columns: 2
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;\t&quot;
## dbl (2): GMdensity, FBfriends
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="simple-regression.html#cb176-1" aria-hidden="true" tabindex="-1"></a>fb</span></code></pre></div>
<pre><code>## # A tibble: 40 × 2
##    GMdensity FBfriends
##        &lt;dbl&gt;     &lt;dbl&gt;
##  1      -1.8        23
##  2       0.1        35
##  3      -1.2        80
##  4      -0.4       110
##  5      -0.9       120
##  6      -2.1       140
##  7      -1.5       168
##  8       0.5       132
##  9       0.6       154
## 10      -0.5       241
## # … with 30 more rows</code></pre>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="simple-regression.html#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fb, <span class="fu">aes</span>(<span class="at">x =</span> GMdensity, <span class="at">y =</span> FBfriends)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/fbfriends-1-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Describe what you see on your scatterplot: is there a
trend, and if so, what kind of trend is it? (Don’t get too taken in
by the exact shape of your smooth trend.) Think “form, direction, strength”.</li>
</ol>
<p>Solution</p>
<p>I’d say there seems to be a weak, upward, apparently linear
trend. The points are not especially close to the trend, so I
don’t think there’s any justification for calling this other
than “weak”. (If you think the trend is, let’s say,
“moderate”, you ought to say what makes you think that: for
example, that the people with a lot of Facebook friends also
tend to have a higher grey matter density. I can live with a
reasonably-justified “moderate”.)
The reason I said not to get taken in by the shape of the smooth
trend is that this has a “wiggle” in it: it goes down again
briefly in the middle. But this is likely a quirk of the data,
and the trend, if there is any, seems to be an upward one.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Fit a regression predicting the number of Facebook friends
from the grey matter density, and display the output.</li>
</ol>
<p>Solution</p>
<p>That looks like this. You can call the “fitted model object”
whatever you like, but you’ll need to get the capitalization of
the variable names correct:</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="simple-regression.html#cb180-1" aria-hidden="true" tabindex="-1"></a>fb<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(FBfriends <span class="sc">~</span> GMdensity, <span class="at">data =</span> fb)</span>
<span id="cb180-2"><a href="simple-regression.html#cb180-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fb<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = FBfriends ~ GMdensity, data = fb)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -339.89 -110.01   -5.12   99.80  303.64 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   366.64      26.35  13.916  &lt; 2e-16 ***
## GMdensity      82.45      27.58   2.989  0.00488 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 165.7 on 38 degrees of freedom
## Multiple R-squared:  0.1904, Adjusted R-squared:  0.1691 
## F-statistic: 8.936 on 1 and 38 DF,  p-value: 0.004882</code></pre>
<p>I observe, though I didn’t ask you to, that the R-squared is pretty
awful, going with a correlation of</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="simple-regression.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fl">0.1904</span>)</span></code></pre></div>
<pre><code>## [1] 0.4363485</code></pre>
<p>which <em>would</em> look
like as weak of a trend as we saw.<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Is the slope of your regression line significantly
different from zero? What does that mean, in the context of the
data?</li>
</ol>
<p>Solution</p>
<p>The P-value of the slope is 0.005, which is less than
0.05. Therefore the slope <em>is</em> significantly different from
zero. That means that the number of Facebook friends really does
depend on the grey matter density, for the whole population of
interest and not just the 40 students observed here (that were a
sample from that population). I don’t mind so much what you
think the population is, but it needs to be clear that the
relationship applies to a population.
Another way to approach this is to say that you would expect
this relationship to show up again in another similar
experiment. That also works, because it gets at the idea of
reproducibility.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Are you surprised by the results of
parts (b) and (d)? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>I <em>am</em> surprised, because I thought the trend on the
scatterplot was so weak that there would not be a significant
slope. I guess there was enough of an upward trend to be
significant, and with <span class="math inline">\(n=40\)</span> observations we were able to get a
significant slope out of that scatterplot. With this many
observations, even a weak correlation can be significantly
nonzero.
You can be surprised or not, but you need to have some kind of
consideration of the strength of the trend on the scatterplot as
against the significance of the slope. For example, if you
decided that the trend was “moderate” in strength, you would
be justified in being less surprised than I was.
Here, there is the usual issue that we have proved that the
slope is not zero (that the relationship is not flat), but we
may not have a very clear idea of what the slope actually
<em>is</em>. There are a couple of ways to get a confidence
interval. The obvious one is to use R as a calculator and go up
and down twice its standard error (to get a rough idea):</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="simple-regression.html#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fl">82.45</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fl">27.58</span> <span class="sc">*</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1]  27.29 137.61</code></pre>
<p>The <code>c()</code> thing is to get both confidence limits at once. The
smoother way is this:</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="simple-regression.html#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(fb<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>##                 2.5 %   97.5 %
## (Intercept) 313.30872 419.9810
## GMdensity    26.61391 138.2836</code></pre>
<p>Feed <code>confint</code> a “fitted model object” and it’ll give you
confidence intervals (by default 95%) for all the parameters in it.</p>
<p>The confidence interval for the slope goes from about 27 to about
138. That is to say, a one-unit increase in grey matter density goes
with an increase in Facebook friends of this much. This is not
especially insightful: it’s bigger than zero (the test was
significant), but other than that, it could be almost
anything. <em>This</em> is where the weakness of the trend comes back to
bite us. With this much scatter in our data, we need a <em>much</em>
larger sample size to estimate accurately how big an effect grey
matter density has.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Obtain a scatterplot with the regression line on it.</li>
</ol>
<p>Solution</p>
<p>Just a modification
of (a):</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="simple-regression.html#cb188-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fb, <span class="fu">aes</span>(<span class="at">x =</span> GMdensity, <span class="at">y =</span> FBfriends)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb188-2"><a href="simple-regression.html#cb188-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/fbfriends-6-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Obtain a plot of the residuals from the regression against
the fitted values, and comment briefly on it.</li>
</ol>
<p>Solution</p>
<p>This is, to my mind, the easiest way:</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="simple-regression.html#cb190-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fb<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/fbfriends-7-1.png" width="672" /></p>
<p>There is some “magic” here, since the fitted model object is not
actually a data frame, but it works this way.
That looks to me like a completely random scatter of
points. Thus, I am completely happy with the straight-line regression
that we fitted, and I see no need to improve it.</p>
<p>(You should make two points here: one, describe what you see, and two,
what it implies about whether or not your regression is satisfactory.)</p>
<p>Compare that residual plot with this one:</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="simple-regression.html#cb191-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fb<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span></span>
<span id="cb191-2"><a href="simple-regression.html#cb191-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/fbfriends-8-1.png" width="672" /></p>
<p>Now, why did I try adding a smooth trend, and why is it not
necessarily a good idea? The idea of a residual plot is that there
should be no trend, and so the smooth trend curve ought to go straight
across. The problem is that it will tend to wiggle, just by chance, as
here: it looks as if it goes up and down before flattening out. But if
you look at the points, <em>they</em> are all over the place, not close
to the smooth trend at all. So the smooth trend is rather
deceiving. Or, to put it another way, to indicate a real problem, the
smooth trend would have to be a <em>lot</em> farther from flat than this
one is. I’d call this one basically flat.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="endogenous-nitrogen-excretion-in-carp-1" class="section level2 hasAnchor" number="18.19">
<h2><span class="header-section-number">18.19</span> Endogenous nitrogen excretion in carp<a href="simple-regression.html#endogenous-nitrogen-excretion-in-carp-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A paper in Fisheries Science reported on variables that
affect “endogenous nitrogen excretion” or ENE in carp raised in
Japan. A number of carp were divided into groups based on body weight,
and each group was placed in a different tank. The mean body weight of
the carp placed in each tank was recorded. The carp were then fed a
protein-free diet three times daily for a period of 20 days. At the
end of the experiment, the amount of ENE in each tank was measured, in
milligrams of total fish body weight per day. (Thus it should not
matter that some of the tanks had more fish than others, because the
scaling is done properly.)</p>
<p>For this question, write a report in R Markdown that answers the
questions below and contains some narrative that describes your
analysis. Create an HTML document from your R Markdown.</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data in from
<a href="http://ritsokiguess.site/datafiles/carp.txt">link</a>. There are 10
tanks.</li>
</ol>
<p>Solution</p>
<p>Just this. Listing the data is up to you, but doing so and
commenting that the values appear to be correct will improve your report.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="simple-regression.html#cb193-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/carp.txt&quot;</span></span>
<span id="cb193-2"><a href="simple-regression.html#cb193-2" aria-hidden="true" tabindex="-1"></a>carp <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 10 Columns: 3
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot; &quot;
## dbl (3): tank, bodyweight, ENE
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="simple-regression.html#cb195-1" aria-hidden="true" tabindex="-1"></a>carp</span></code></pre></div>
<pre><code>## # A tibble: 10 × 3
##     tank bodyweight   ENE
##    &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;
##  1     1       11.7  15.3
##  2     2       25.3   9.3
##  3     3       90.2   6.5
##  4     4      213     6  
##  5     5       10.2  15.7
##  6     6       17.6  10  
##  7     7       32.6   8.6
##  8     8       81.3   6.4
##  9     9      142.    5.6
## 10    10      286.    6</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Create a scatterplot of ENE (response) against bodyweight
(explanatory). Add a smooth trend to your plot.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="simple-regression.html#cb197-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(carp, <span class="fu">aes</span>(<span class="at">x =</span> bodyweight, <span class="at">y =</span> ENE)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb197-2"><a href="simple-regression.html#cb197-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/marttis-1.png" width="672" /></p>
<p>This part is just about getting the plot. Comments are coming in a
minute. Note that <code>ENE</code> is capital letters, so that
<code>ene</code> will not work.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Is there an upward or downward trend (or neither)? Is the
relationship a line or a curve? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The trend is downward: as bodyweight increases, ENE
decreases. However, the decrease is rapid at first and then levels
off, so the relationship is nonlinear. I want some kind of
support for an assertion of non-linearity: anything that says that
the slope or rate of decrease is not constant is good.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a straight line to the data, and obtain the R-squared
for the regression.</li>
</ol>
<p>Solution</p>
<p><code>lm</code>. The first stage is to fit the straight line, saving
the result in a variable, and the second stage is to look at the
“fitted model object”, here via <code>summary</code>:</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="simple-regression.html#cb199-1" aria-hidden="true" tabindex="-1"></a>carp<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(ENE <span class="sc">~</span> bodyweight, <span class="at">data =</span> carp)</span>
<span id="cb199-2"><a href="simple-regression.html#cb199-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(carp<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ENE ~ bodyweight, data = carp)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -2.800 -1.957 -1.173  1.847  4.572 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 11.40393    1.31464   8.675 2.43e-05 ***
## bodyweight  -0.02710    0.01027  -2.640   0.0297 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.928 on 8 degrees of freedom
## Multiple R-squared:  0.4656, Adjusted R-squared:  0.3988 
## F-statistic: 6.971 on 1 and 8 DF,  p-value: 0.0297</code></pre>
<p>Finally, you need to give me a (suitably rounded) value for
R-squared: 46.6% or 47% or the equivalents as a decimal. I just
need the value at this point.
This kind of R-squared is actually pretty good for natural data, but
the issue is whether we can improve it by fitting a non-linear
model.<a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Obtain a residual plot (residuals against fitted values)
for this regression. Do you see any problems? If so, what does that
tell you about the relationship in the data?</li>
</ol>
<p>Solution</p>
<p>This is the easiest way: feed the output of the regression
straight into <code>ggplot</code>:</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="simple-regression.html#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(carp<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/goeslingerin-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Fit a parabola to the data (that is, including an
<span class="math inline">\(x\)</span>-squared term). Compare the R-squared values for the models in
this part and part (d). Does that suggest that the parabola
model is an improvement here over the linear model?</li>
</ol>
<p>Solution</p>
<p>Add bodyweight-squared to
the regression. Don’t forget the <code>I()</code>:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="simple-regression.html#cb202-1" aria-hidden="true" tabindex="-1"></a>carp<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(ENE <span class="sc">~</span> bodyweight <span class="sc">+</span> <span class="fu">I</span>(bodyweight<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> carp)</span>
<span id="cb202-2"><a href="simple-regression.html#cb202-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(carp<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ENE ~ bodyweight + I(bodyweight^2), data = carp)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.0834 -1.7388 -0.5464  1.3841  2.9976 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     13.7127373  1.3062494  10.498 1.55e-05 ***
## bodyweight      -0.1018390  0.0288109  -3.535  0.00954 ** 
## I(bodyweight^2)  0.0002735  0.0001016   2.692  0.03101 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.194 on 7 degrees of freedom
## Multiple R-squared:  0.7374, Adjusted R-squared:  0.6624 
## F-statistic: 9.829 on 2 and 7 DF,  p-value: 0.009277</code></pre>
<p>R-squared has gone up from 47% to 74%, a substantial
improvement. This suggests to me that the parabola model is a
substantial improvement.<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a></p>
<p>I try to avoid using the word “significant” in this context, since
we haven’t actually done a test of significance.</p>
<p>The reason for the <code>I()</code> is that the up-arrow has a special
meaning in <code>lm</code>, relating to interactions between factors (as
in ANOVA), that we don’t want here. Putting <code>I()</code> around it
means “use as is”, that is, raise bodyweight to power 2, rather than
using the special meaning of the up-arrow in <code>lm</code>.</p>
<p>Because it’s the up-arrow that is the problem, this applies whenever
you’re raising an explanatory variable to a power (or taking a
reciprocal or a square root, say).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Is the test for the slope coefficient for the squared term
significant? What does this mean?</li>
</ol>
<p>Solution</p>
<p>Look along the <code>bodyweight</code>-squared line to get a P-value
of 0.031. This is less than the default 0.05, so it <em>is</em>
significant.
This means, in short, that the quadratic model is a significant
<em>improvement</em> over the linear one.<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a>
Said longer: the null hypothesis being tested is that the slope
coefficient of the squared term is zero (that is, that the squared
term has nothing to add over the linear model). This is rejected,
so the squared term has <em>something</em> to add in terms of
quality of prediction.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Make the scatterplot of part (b), but add
the fitted curve. Describe any way in which the curve fails to fit well.</li>
</ol>
<p>Solution</p>
<p>This is a bit slippery, because the points to plot and the
fitted curve are from different data frames. What you do in this
case is to put a <code>data=</code> in one of the <code>geom</code>s,
which says “don’t use the data frame that was in the <code>ggplot</code>, but use this one instead”.
I would think about
starting with the regression object <code>carp.2</code> as my base
data frame, since we want (or I want) to do two things with
that: plot the fitted values and join them with lines. Then I
want to add the original data, just the points:</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="simple-regression.html#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(carp<span class="fl">.2</span>, <span class="fu">aes</span>(<span class="at">x =</span> carp<span class="sc">$</span>bodyweight, <span class="at">y =</span> .fitted), <span class="at">colour =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span></span>
<span id="cb204-2"><a href="simple-regression.html#cb204-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">colour =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span></span>
<span id="cb204-3"><a href="simple-regression.html#cb204-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> carp, <span class="fu">aes</span>(<span class="at">x =</span> bodyweight, <span class="at">y =</span> ENE))</span></code></pre></div>
<p><img src="pasias_files/figure-html/bletz-1.png" width="672" /></p>
<p>This works, but is not very aesthetic, because the bodyweight that is
plotted against the fitted values is in the wrong data frame, and so
we have to use the dollar-sign thing to get it from the right one.</p>
<p>A better way around this is “augment” the data with output from the regression object.
This is done using <code>augment</code> from
package <code>broom</code>:</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="simple-regression.html#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb205-2"><a href="simple-regression.html#cb205-2" aria-hidden="true" tabindex="-1"></a>carp<span class="fl">.2</span>a <span class="ot">&lt;-</span> <span class="fu">augment</span>(carp<span class="fl">.2</span>, carp)</span>
<span id="cb205-3"><a href="simple-regression.html#cb205-3" aria-hidden="true" tabindex="-1"></a>carp<span class="fl">.2</span>a</span></code></pre></div>
<pre><code>## # A tibble: 10 × 9
##     tank bodyweight   ENE .fitted .resid  .hat .sigma .cooksd .std.resid
##    &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;
##  1     1       11.7  15.3   12.6   2.74  0.239   1.99 0.215        1.43 
##  2     2       25.3   9.3   11.3  -2.01  0.163   2.19 0.0651      -1.00 
##  3     3       90.2   6.5    6.75 -0.252 0.240   2.37 0.00182     -0.132
##  4     4      213     6      4.43  1.57  0.325   2.24 0.122        0.871
##  5     5       10.2  15.7   12.7   3.00  0.251   1.90 0.279        1.58 
##  6     6       17.6  10     12.0  -2.01  0.199   2.19 0.0866      -1.02 
##  7     7       32.6   8.6   10.7  -2.08  0.143   2.18 0.0583      -1.03 
##  8     8       81.3   6.4    7.24 -0.841 0.211   2.34 0.0166      -0.431
##  9     9      142.    5.6    4.78  0.822 0.355   2.33 0.0398       0.466
## 10    10      286.    6      6.94 -0.940 0.875   2.11 3.40        -1.21</code></pre>
<p>so now you see what <code>carp.2a</code> has in it, and then:</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="simple-regression.html#cb207-1" aria-hidden="true" tabindex="-1"></a>g <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(carp<span class="fl">.2</span>a, <span class="fu">aes</span>(<span class="at">x =</span> bodyweight, <span class="at">y =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb207-2"><a href="simple-regression.html#cb207-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">colour =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span></span>
<span id="cb207-3"><a href="simple-regression.html#cb207-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> ENE))</span></code></pre></div>
<p>This is easier coding: there are only two non-standard things. The
first is that the fitted-value lines should be a distinct colour like
blue so that you can tell them from the data points. The second thing
is that for the second <code>geom_point</code>, the one that plots the data,
the <span class="math inline">\(x\)</span> coordinate <code>bodyweight</code> is correct so that we don’t
have to change that; we only have to change the <span class="math inline">\(y\)</span>-coordinate, which
is <code>ENE</code>. The plot is this:</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="simple-regression.html#cb208-1" aria-hidden="true" tabindex="-1"></a>g</span></code></pre></div>
<p><img src="pasias_files/figure-html/carp-4-1.png" width="672" /></p>
<p>Concerning interpretation, you have a number of possibilities
here. The simplest is that the points in the middle are above the
curve, and the points at the ends are below. (That is, negative
residuals at the ends, and positive ones in the middle, which gives
you a hint for the next part.) Another is that the parabola curve
fails to capture the <em>shape</em> of the relationship; for example, I
see nothing much in the data suggesting that the relationship should go
back up, and even given that, the fitted curve doesn’t go especially
near any of the points.</p>
<p>I was thinking that the data should be fit better by something like
the left half of an upward-opening parabola, but I guess the curvature
on the left half of the plot suggests that it needs most of the left
half of the parabola just to cover the left half of the plot.</p>
<p>The moral of the story, as we see in the next part, is that the
parabola is the wrong curve for the job.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol style="list-style-type: lower-roman">
<li>Obtain a residual plot for the parabola model. Do you see
any problems with it? (If you do, I’m not asking you to do anything
about them in this question, but I will.)</li>
</ol>
<p><span class="math inline">\(\blacksquare\)</span></p>
<p>The same idea as before for the other residual plot. Use the
fitted model object <code>carp.2</code> as your data frame for the
<code>ggplot</code>:</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="simple-regression.html#cb209-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(carp<span class="fl">.2</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/ohem-1.png" width="672" /></p>
<p>I think this is <em>still</em> a curve (or, it goes down and then
sharply up at the end). Either way, there is still a pattern.</p>
<p>That was all I needed, but as to what this means: our parabola was a
curve all right, but it appears not to be the right <em>kind</em> of
curve. I think the original data looks more like a hyperbola (a curve
like <span class="math inline">\(y=1/x\)</span>) than a parabola, in that it seems to decrease fast and
then gradually to a limit, and <em>that</em> suggests, as in the class
example, that we should try an asymptote model. Note how I specify it,
with the <code>I()</code> thing again, since <code>/</code> has a special meaning
to <code>lm</code> in the same way that
<code>^</code> does:</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="simple-regression.html#cb210-1" aria-hidden="true" tabindex="-1"></a>carp<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(ENE <span class="sc">~</span> <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">/</span> bodyweight), <span class="at">data =</span> carp)</span>
<span id="cb210-2"><a href="simple-regression.html#cb210-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(carp<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ENE ~ I(1/bodyweight), data = carp)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.29801 -0.12830  0.04029  0.26702  0.91707 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       5.1804     0.2823   18.35 8.01e-08 ***
## I(1/bodyweight) 107.6690     5.8860   18.29 8.21e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6121 on 8 degrees of freedom
## Multiple R-squared:  0.9766, Adjusted R-squared:  0.9737 
## F-statistic: 334.6 on 1 and 8 DF,  p-value: 8.205e-08</code></pre>
<p>That fits <em>extraordinarily</em> well, with an R-squared up near
98%. The intercept is the asymptote, which suggests a (lower) limit
of about 5.2 for <code>ENE</code> (in the limit for large bodyweight). We
would have to ask the fisheries scientist whether this kind of thing
is a reasonable biological mechanism. It says that a carp always has
some ENE, no matter how big it gets, but a smaller carp will have a
lot more.</p>
<p>Does the fitted value plot look reasonable now? This is <code>augment</code> again since the fitted values and observed data come from different data frames:</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="simple-regression.html#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb212-2"><a href="simple-regression.html#cb212-2" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(carp<span class="fl">.3</span>, carp) <span class="sc">%&gt;%</span></span>
<span id="cb212-3"><a href="simple-regression.html#cb212-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> bodyweight, <span class="at">y =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb212-4"><a href="simple-regression.html#cb212-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">colour =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span></span>
<span id="cb212-5"><a href="simple-regression.html#cb212-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> ENE))</span></code></pre></div>
<p><img src="pasias_files/figure-html/augment2-1.png" width="672" /></p>
<p>I’d say that does a really nice job of fitting the data. But it would
be nice to have a few more tanks with large-bodyweight fish, to
convince us that we have the shape of the trend right.</p>
<p>And, as ever, the residual plot. That’s a lot easier than the plot we
just did:</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="simple-regression.html#cb213-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(carp<span class="fl">.3</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/sailer-1.png" width="672" /></p>
<p>All in all, that looks pretty good (and certainly a vast improvement
over the ones you got before).</p>
<p>When you write up your report, you can make it flow better by writing
it in a way that suggests that each thing was the obvious thing to do
next: that is, that <em>you</em> would have thought to do it next,
rather than me telling you what to do.</p>
<p>My report (as an R Markdown file) is at
<a href="http://ritsokiguess.site/datafiles/carp.Rmd">link</a>. Download it,
knit it, play with it.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="salaries-of-social-workers-1" class="section level2 hasAnchor" number="18.20">
<h2><span class="header-section-number">18.20</span> Salaries of social workers<a href="simple-regression.html#salaries-of-social-workers-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Another salary-prediction question: does the number of years
of work experience that a social worker has help to predict their
salary? Data for 50 social workers are in
<a href="http://ritsokiguess.site/datafiles/socwork.txt">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R. Check that you have 50 observations on
two variables. Also do something to check that the years of
experience and annual salary figures look reasonable overall.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="simple-regression.html#cb214-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/socwork.txt&quot;</span></span>
<span id="cb214-2"><a href="simple-regression.html#cb214-2" aria-hidden="true" tabindex="-1"></a>soc <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 50 Columns: 2
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot; &quot;
## dbl (2): experience, salary
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="simple-regression.html#cb216-1" aria-hidden="true" tabindex="-1"></a>soc</span></code></pre></div>
<pre><code>## # A tibble: 50 × 2
##    experience salary
##         &lt;dbl&gt;  &lt;dbl&gt;
##  1          7  26075
##  2         28  79370
##  3         23  65726
##  4         18  41983
##  5         19  62308
##  6         15  41154
##  7         24  53610
##  8         13  33697
##  9          2  22444
## 10          8  32562
## # … with 40 more rows</code></pre>
<p>That checks that we have the right <em>number</em> of observations; to
check that we have sensible <em>values</em>, something like
<code>summary</code> is called for:</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="simple-regression.html#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(soc)</span></code></pre></div>
<pre><code>##    experience        salary     
##  Min.   : 1.00   Min.   :16105  
##  1st Qu.:13.50   1st Qu.:36990  
##  Median :20.00   Median :50948  
##  Mean   :18.12   Mean   :50171  
##  3rd Qu.:24.75   3rd Qu.:65204  
##  Max.   :28.00   Max.   :99139</code></pre>
<p>A person working in any field cannot have a negative number of years
of experience, and cannot have more than about 40 years of experience
(or else they would have retired). Our experience numbers fit
that. Salaries had better be five or six figures, and salaries for
social workers are not generally all that high, so these figures look
reasonable.</p>
<p>A rather more <code>tidyverse</code> way is this:</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="simple-regression.html#cb220-1" aria-hidden="true" tabindex="-1"></a>soc <span class="sc">%&gt;%</span> </span>
<span id="cb220-2"><a href="simple-regression.html#cb220-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="fu">list</span>(<span class="at">min =</span> <span class="sc">~</span><span class="fu">min</span>(.),  <span class="at">max =</span> <span class="sc">~</span><span class="fu">max</span>(.))))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   experience_min experience_max salary_min salary_max
##            &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1              1             28      16105      99139</code></pre>
<p>This gets the minimum and maximum of all the variables. I would have
liked them arranged in a nice rectangle (<code>min</code> and <code>max</code>
as rows, the variables as columns), but that’s not how this came out.</p>
<p>The code so far uses <code>across</code>. This means to do something across multiple columns. In this case, we want to do the calculation on <em>all</em> the columns, so we use the select-helper <code>everything</code>. You can use any of the other select-helpers like <code>starts_with</code>, or you could do something like <code>where(is.numeric)</code> to do your summaries only on the quantitative columns (which would also work here). The dots inside <code>min</code> and <code>max</code> mean “the variable we are looking at at the moment”, and the squiggles before <code>min</code> and <code>max</code> mean “calculate”, so you read the above code as “for each column, work out the smallest and largest value of it”.</p>
<p>What, you want a nice rectangle? This is a pivot-longer, but the fancy version because the column names encode two kinds of things, a variable and a statistic:</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="simple-regression.html#cb222-1" aria-hidden="true" tabindex="-1"></a>soc <span class="sc">%&gt;%</span> </span>
<span id="cb222-2"><a href="simple-regression.html#cb222-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="fu">list</span>(<span class="at">min =</span> <span class="sc">~</span><span class="fu">min</span>(.),  <span class="at">max =</span> <span class="sc">~</span><span class="fu">max</span>(.)))) <span class="sc">%&gt;%</span> </span>
<span id="cb222-3"><a href="simple-regression.html#cb222-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>(), </span>
<span id="cb222-4"><a href="simple-regression.html#cb222-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="fu">c</span>(<span class="st">&quot;variable&quot;</span>, <span class="st">&quot;statistic&quot;</span>), </span>
<span id="cb222-5"><a href="simple-regression.html#cb222-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_sep =</span> <span class="st">&quot;_&quot;</span>,</span>
<span id="cb222-6"><a href="simple-regression.html#cb222-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">&quot;value&quot;</span></span>
<span id="cb222-7"><a href="simple-regression.html#cb222-7" aria-hidden="true" tabindex="-1"></a>               )</span></code></pre></div>
<pre><code>## # A tibble: 4 × 3
##   variable   statistic value
##   &lt;chr&gt;      &lt;chr&gt;     &lt;dbl&gt;
## 1 experience min           1
## 2 experience max          28
## 3 salary     min       16105
## 4 salary     max       99139</code></pre>
<p>and then</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="simple-regression.html#cb224-1" aria-hidden="true" tabindex="-1"></a>soc <span class="sc">%&gt;%</span> </span>
<span id="cb224-2"><a href="simple-regression.html#cb224-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="fu">list</span>(<span class="at">min =</span> <span class="sc">~</span><span class="fu">min</span>(.),  <span class="at">max =</span> <span class="sc">~</span><span class="fu">max</span>(.)))) <span class="sc">%&gt;%</span> </span>
<span id="cb224-3"><a href="simple-regression.html#cb224-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>(), </span>
<span id="cb224-4"><a href="simple-regression.html#cb224-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="fu">c</span>(<span class="st">&quot;variable&quot;</span>, <span class="st">&quot;statistic&quot;</span>), </span>
<span id="cb224-5"><a href="simple-regression.html#cb224-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_sep =</span> <span class="st">&quot;_&quot;</span>,</span>
<span id="cb224-6"><a href="simple-regression.html#cb224-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">&quot;value&quot;</span></span>
<span id="cb224-7"><a href="simple-regression.html#cb224-7" aria-hidden="true" tabindex="-1"></a>               ) <span class="sc">%&gt;%</span> </span>
<span id="cb224-8"><a href="simple-regression.html#cb224-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> statistic, <span class="at">values_from =</span> value)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   variable     min   max
##   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;
## 1 experience     1    28
## 2 salary     16105 99139</code></pre>
<p>Note the strategy: make it longer first, then figure out what to do next. This is different from <code>rowwise</code>; in fact, we are working “columnwise”, doing something for each column, no matter how many there are. My go-to for this stuff is <a href="https://dplyr.tidyverse.org/articles/colwise.html">here</a>.</p>
<p>Another way to work is with the five-number summary. This gives a more nuanced picture of the data values we have.<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a></p>
<p>The base-R five-number summary looks like this:</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="simple-regression.html#cb226-1" aria-hidden="true" tabindex="-1"></a>qq <span class="ot">&lt;-</span> <span class="fu">quantile</span>(soc<span class="sc">$</span>experience)</span>
<span id="cb226-2"><a href="simple-regression.html#cb226-2" aria-hidden="true" tabindex="-1"></a>qq</span></code></pre></div>
<pre><code>##    0%   25%   50%   75%  100% 
##  1.00 13.50 20.00 24.75 28.00</code></pre>
<p>This is what’s known as a “named vector”. The numbers on the bottom are the summaries themselves, and the names above say which percentile you are looking at. Unfortunately, the <code>tidyverse</code> doesn’t like names, so modelling after the above doesn’t quite work:</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="simple-regression.html#cb228-1" aria-hidden="true" tabindex="-1"></a>soc <span class="sc">%&gt;%</span> </span>
<span id="cb228-2"><a href="simple-regression.html#cb228-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="fu">list</span>(<span class="at">q =</span> <span class="sc">~</span><span class="fu">quantile</span>(.))))</span></code></pre></div>
<pre><code>## # A tibble: 5 × 2
##   experience_q salary_q
##          &lt;dbl&gt;    &lt;dbl&gt;
## 1          1     16105 
## 2         13.5   36990.
## 3         20     50948.
## 4         24.8   65204.
## 5         28     99139</code></pre>
<p>You can guess which percentile is which (they have to be in order), but this is not completely satisfactory. A workaround is to get hold of the <code>names</code> and add them to the result:</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="simple-regression.html#cb230-1" aria-hidden="true" tabindex="-1"></a>soc <span class="sc">%&gt;%</span> </span>
<span id="cb230-2"><a href="simple-regression.html#cb230-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="fu">across</span>(<span class="fu">everything</span>(), <span class="fu">list</span>(<span class="at">q =</span> <span class="sc">~</span><span class="fu">quantile</span>(.)))) <span class="sc">%&gt;%</span> </span>
<span id="cb230-3"><a href="simple-regression.html#cb230-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pct =</span> <span class="fu">names</span>(qq))</span></code></pre></div>
<pre><code>## # A tibble: 5 × 3
##   experience_q salary_q pct  
##          &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;
## 1          1     16105  0%   
## 2         13.5   36990. 25%  
## 3         20     50948. 50%  
## 4         24.8   65204. 75%  
## 5         28     99139  100%</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a scatterplot showing how salary depends on
experience. Does the nature of the trend make sense?</li>
</ol>
<p>Solution</p>
<p>The usual:</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="simple-regression.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(soc, <span class="fu">aes</span>(<span class="at">x =</span> experience, <span class="at">y =</span> salary)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/socwork-9-1.png" width="672" /></p>
<p>As experience goes up, salary also goes up, as you would expect. Also,
the trend seems more or less straight.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Fit a regression predicting salary from experience, and
display the results. Is the slope positive or negative? Does that
make sense?</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="simple-regression.html#cb233-1" aria-hidden="true" tabindex="-1"></a>soc<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(salary <span class="sc">~</span> experience, <span class="at">data =</span> soc)</span>
<span id="cb233-2"><a href="simple-regression.html#cb233-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(soc<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = salary ~ experience, data = soc)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -17666.3  -5498.2   -726.7   4667.7  27811.6 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  11368.7     3160.3   3.597 0.000758 ***
## experience    2141.4      160.8  13.314  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8642 on 48 degrees of freedom
## Multiple R-squared:  0.7869, Adjusted R-squared:  0.7825 
## F-statistic: 177.3 on 1 and 48 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The slope is (significantly) positive, which squares with our guess
(more experience goes with greater salary), and also the upward trend
on the scatterplot. The value of the slope is about 2,000; this means
that one more year of experience goes with about a $2,000 increase in
salary.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Obtain and plot the residuals against the fitted values. What
problem do you see?</li>
</ol>
<p>Solution</p>
<p>The easiest way to do this with <code>ggplot</code> is to plot the
<em>regression object</em> (even though it is not actually a data
frame), and plot the <code>.fitted</code> and <code>.resid</code>
columns in it, not forgetting the initial dots:</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="simple-regression.html#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(soc<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/socwork-11-1.png" width="672" /></p>
<p>I see a “fanning-out”: the residuals are getting bigger <em>in size</em>
(further away from zero) as the fitted values get bigger. That
is, when the (estimated) salary gets larger, it also gets more
variable.</p>
<p>Fanning-out is sometimes hard to see. What you can do if you suspect
that it might have happened is to plot the <em>absolute value</em> of
the residuals against the fitted values. The absolute value is the
residual without its plus or minus sign, so if the residuals are
getting bigger in size, their absolute values are getting bigger. That
would look like this:</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="simple-regression.html#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(soc<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> <span class="fu">abs</span>(.resid))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/socwork-12-1.png" width="672" /></p>
<p>I added a smooth trend to this to help us judge whether the
absolute-value-residuals are getting bigger as the fitted values get
bigger. It looks to me as if the overall trend is an increasing one,
apart from those few small fitted values that have larger-sized
residuals. Don’t get thrown off by the kinks in the smooth trend. Here
is a smoother version:</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="simple-regression.html#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(soc<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> <span class="fu">abs</span>(.resid))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">span =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/socwork-13-1.png" width="672" /></p>
<p>The larger fitted values, according to this, have residuals larger in size.</p>
<p>The thing that controls the smoothness of the smooth trend is the
value of <code>span</code> in <code>geom_smooth</code>. The default is
0.75. The larger the value you use, the smoother the trend; the
smaller, the more wiggly. I’m inclined to think that the default value
is a bit too small. Possibly this value is too big, but it shows you
the idea.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>The problem you unearthed in the previous part is often helped
by a transformation. Run Box-Cox on your data to find a suitable
transformation. What transformation is suggested?</li>
</ol>
<p>Solution</p>
<p>You’ll need to call in (and install if necessary) the package
<code>MASS</code> that contains <code>boxcox</code>:</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="simple-regression.html#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span></code></pre></div>
<p>I explain that “masked” thing below.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="simple-regression.html#cb241-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxcox</span>(salary <span class="sc">~</span> experience, <span class="at">data =</span> soc)</span></code></pre></div>
<p><img src="pasias_files/figure-html/socwork-15-1.png" width="672" /></p>
<p>That one looks like <span class="math inline">\(\lambda=0\)</span> or log. You could probably also
justify fourth root (power 0.25), but log is a very common
transformation, which people won’t need much persuasion to accept.</p>
<p>There’s one annoyance with <code>MASS</code>: it has a <code>select</code>
(which I have never used), and if you load <code>tidyverse</code> first
and <code>MASS</code> second, as I have done here, when you mean to run
the column-selection <code>select</code>, it will actually run the
<code>select</code> that comes from <code>MASS</code>, and give you an error
that you will have a terrible time debugging. That’s what that
“masked” message was when you loaded <code>MASS</code>. This is a great place to learn about the <code>conflicted</code> package. See <a href="https://github.com/r-lib/conflicted">here</a> for how it works. (Scroll down to under the list of files.)</p>
<p>If you want to insist on something like “the <code>select</code> that lives in <code>dplyr</code>”,
you can do that by saying
<code>dplyr::select</code>. But this is kind of cumbersome if you don’t
need to do it.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Calculate a new variable as suggested by your
transformation. Use your transformed response in a regression,
showing the summary.</li>
</ol>
<p>Solution</p>
<p>The best way is to add the new variable to the data frame using
<code>mutate</code>, and save that new data frame. That goes like this:</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="simple-regression.html#cb242-1" aria-hidden="true" tabindex="-1"></a>soc<span class="fl">.2</span> <span class="ot">&lt;-</span> soc <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">log_salary =</span> <span class="fu">log</span>(salary))</span></code></pre></div>
<p>and then</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="simple-regression.html#cb243-1" aria-hidden="true" tabindex="-1"></a>soc<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(log_salary <span class="sc">~</span> experience, <span class="at">data =</span> soc<span class="fl">.2</span>)</span>
<span id="cb243-2"><a href="simple-regression.html#cb243-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(soc<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_salary ~ experience, data = soc.2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.35435 -0.09046 -0.01725  0.09739  0.26355 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 9.841315   0.056356  174.63   &lt;2e-16 ***
## experience  0.049979   0.002868   17.43   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1541 on 48 degrees of freedom
## Multiple R-squared:  0.8635, Adjusted R-squared:  0.8607 
## F-statistic: 303.7 on 1 and 48 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>I think it’s best to save the data frame with <code>log_salary</code> in
it, since we’ll be doing a couple of things with it, and it’s best to
be able to start from <code>soc.2</code>. But you can also do this:</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="simple-regression.html#cb245-1" aria-hidden="true" tabindex="-1"></a>soc <span class="sc">%&gt;%</span></span>
<span id="cb245-2"><a href="simple-regression.html#cb245-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">log_salary =</span> <span class="fu">log</span>(salary)) <span class="sc">%&gt;%</span></span>
<span id="cb245-3"><a href="simple-regression.html#cb245-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(log_salary <span class="sc">~</span> experience, <span class="at">data =</span> .) <span class="sc">%&gt;%</span></span>
<span id="cb245-4"><a href="simple-regression.html#cb245-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_salary ~ experience, data = .)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.35435 -0.09046 -0.01725  0.09739  0.26355 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 9.841315   0.056356  174.63   &lt;2e-16 ***
## experience  0.049979   0.002868   17.43   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1541 on 48 degrees of freedom
## Multiple R-squared:  0.8635, Adjusted R-squared:  0.8607 
## F-statistic: 303.7 on 1 and 48 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The second line is where the fun starts: <code>lm</code> wants the data
frame as a <code>data=</code> at the end. So, to specify a data frame in
something like <code>lm</code>, we have to use the special symbol
<code>.</code>, which is another way to say
“the data frame that came out of the previous step”.</p>
<p>Got that? All right. The last line is a piece of cake in
comparison. Normally <code>summary</code> would require a data frame or a
fitted model object, but the second line produces one (a fitted model
object) as output, which goes into <code>summary</code> as the first
(and only) thing, so all is good and we get the regression output.</p>
<p>What we lose by doing this is that if we need something later from this
fitted model object, we are out of luck since we didn’t save
it. That’s why I created <code>soc.2</code> and <code>soc.3</code> above.</p>
<p>You can also put functions of things directly into <code>lm</code>:</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="simple-regression.html#cb247-1" aria-hidden="true" tabindex="-1"></a>soc<span class="fl">.1</span>a <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(salary) <span class="sc">~</span> experience, <span class="at">data =</span> soc)</span>
<span id="cb247-2"><a href="simple-regression.html#cb247-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(soc<span class="fl">.1</span>a)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(salary) ~ experience, data = soc)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.35435 -0.09046 -0.01725  0.09739  0.26355 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 9.841315   0.056356  174.63   &lt;2e-16 ***
## experience  0.049979   0.002868   17.43   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1541 on 48 degrees of freedom
## Multiple R-squared:  0.8635, Adjusted R-squared:  0.8607 
## F-statistic: 303.7 on 1 and 48 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Obtain and plot the residuals against the fitted values for
this regression. Do you seem to have solved the problem with the
previous residual plot?</li>
</ol>
<p>Solution</p>
<p>As we did before, treating the regression object as if it were a
data frame:</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="simple-regression.html#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(soc<span class="fl">.3</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/socwork-20-1.png" width="672" /></p>
<p>That, to my mind, is a horizontal band of points, so I would say yes,
I have solved the fanning out.</p>
<p>One concern I have about the residuals is that there seem to be a
couple of very negative values: that is, are the residuals normally
distributed as they should be? Well, that’s easy enough to check:</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="simple-regression.html#cb250-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(soc<span class="fl">.3</span>, <span class="fu">aes</span>(<span class="at">sample =</span> .resid)) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/socwork-21-1.png" width="672" /></p>
<p>The issues here are that those bottom two values are a bit too low,
and the top few values are a bit bunched up (that curve at the top).
It is really not bad, though, so I am making the call that I don’t
think I needed to worry.
Note that the transformation we found here is the same as the
log-salary used by the management consultants in the
backward-elimination question, and with the same effect: an extra year
of experience goes with a <em>percent</em> increase in salary.</p>
<p>What increase? Well, the slope is about 0.05, so adding a year of
experience is predicted to increase log-salary by 0.05, or to
multiply actual salary by</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="simple-regression.html#cb251-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fl">0.05</span>)</span></code></pre></div>
<pre><code>## [1] 1.051271</code></pre>
<p>or to increase salary by about 5%.<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="predicting-volume-of-wood-in-pine-trees-1" class="section level2 hasAnchor" number="18.21">
<h2><span class="header-section-number">18.21</span> Predicting volume of wood in pine trees<a href="simple-regression.html#predicting-volume-of-wood-in-pine-trees-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In forestry, the financial value of a tree
is the volume of wood that it contains. This is difficult to estimate
while the tree is still standing, but the diameter is easy to measure
with a tape measure (to measure the circumference) and a calculation
involving <span class="math inline">\(\pi\)</span>, assuming that the cross-section of the tree is at
least approximately circular. The standard measurement is
“diameter at breast height”
(that is, at the height of a human breast or
chest), defined as being 4.5 feet above the ground.</p>
<p>Several pine trees had their diameter measured shortly before being
cut down, and for each tree, the volume of wood was recorded. The data
are in
<a href="http://ritsokiguess.site/datafiles/pinetrees.txt">link</a>. The
diameter is in inches and the volume is in cubic inches. Is it
possible to predict the volume of wood from the diameter?</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R and display the values (there are not
very many).</li>
</ol>
<p>Solution</p>
<p>Observe that the data values are separated by spaces, and therefore
that <code>read_delim</code> will do it:</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="simple-regression.html#cb253-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/pinetrees.txt&quot;</span></span>
<span id="cb253-2"><a href="simple-regression.html#cb253-2" aria-hidden="true" tabindex="-1"></a>trees <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 10 Columns: 2
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot; &quot;
## dbl (2): diameter, volume
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="simple-regression.html#cb255-1" aria-hidden="true" tabindex="-1"></a>trees</span></code></pre></div>
<pre><code>## # A tibble: 10 × 2
##    diameter volume
##       &lt;dbl&gt;  &lt;dbl&gt;
##  1       32    185
##  2       29    109
##  3       24     95
##  4       45    300
##  5       20     30
##  6       30    125
##  7       26     55
##  8       40    246
##  9       24     60
## 10       18     15</code></pre>
<p>That looks like the data file.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a suitable plot.</li>
</ol>
<p>Solution</p>
<p>No clues this time. You need to recognize that you have two
quantitative variables, so that a scatterplot is called
for. Also, the volume is the response, so that should go on the <span class="math inline">\(y\)</span>-axis:</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="simple-regression.html#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(trees, <span class="fu">aes</span>(<span class="at">x =</span> diameter, <span class="at">y =</span> volume)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/pinetrees-2-1.png" width="672" /></p>
<p>You can put a smooth trend on it if you like, which would
look like this:</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="simple-regression.html#cb258-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(trees, <span class="fu">aes</span>(<span class="at">x =</span> diameter, <span class="at">y =</span> volume)) <span class="sc">+</span></span>
<span id="cb258-2"><a href="simple-regression.html#cb258-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/pinetrees-3-1.png" width="672" /></p>
<p>I’ll take either of those for this part, though I think the smooth
trend actually obscures the issue here (because there is not so much
data).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Describe what you learn from your plot about the
relationship between diameter and volume, if anything.</li>
</ol>
<p>Solution</p>
<p>The word “relationship” offers a clue that a scatterplot would
have been a good idea, if you hadn’t realized by now.
I am guided by “form, direction, strength” in looking at a scatterplot:</p>
<ul>
<li><p>Form: it is an apparently linear relationship.</p></li>
<li><p>Direction: it is an upward trend: that is, a tree with a larger diameter also has a larger volume of wood. (This is not very surprising.)</p></li>
<li><p>Strength: I’d call this a strong (or moderate-to-strong) relationship. (We’ll see in a minute what the R-squared is.)</p></li>
</ul>
<p>You don’t need to be as formal as this, but you <em>do</em> need
to get at the idea that it is an upward trend, apparently
linear, and at least fairly strong.<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a (linear) regression, predicting volume from diameter,
and obtain the <code>summary</code>. How would you describe the R-squared?</li>
</ol>
<p>Solution</p>
<p>My naming convention is (usually) to call the fitted model
object by the name of the response variable and a number. (I
have always used dots, but in the spirit of the
<code>tidyverse</code> I suppose I should use underscores.)</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="simple-regression.html#cb260-1" aria-hidden="true" tabindex="-1"></a>volume<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(volume <span class="sc">~</span> diameter, <span class="at">data =</span> trees)</span>
<span id="cb260-2"><a href="simple-regression.html#cb260-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(volume<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = volume ~ diameter, data = trees)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -36.497  -9.982   1.751   8.959  28.139 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -191.749     23.954  -8.005 4.35e-05 ***
## diameter      10.894      0.801  13.600 8.22e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 20.38 on 8 degrees of freedom
## Multiple R-squared:  0.9585, Adjusted R-squared:  0.9534 
## F-statistic:   185 on 1 and 8 DF,  p-value: 8.217e-07</code></pre>
<p>R-squared is nearly 96%, so the relationship is definitely a strong one.</p>
<p>I also wanted to mention the <code>broom</code> package, which was
installed with the <code>tidyverse</code> but which you need to load
separately. It provides two handy ways to summarize a fitted model
(regression, analysis of variance or whatever):</p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="simple-regression.html#cb262-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb262-2"><a href="simple-regression.html#cb262-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(volume<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.959         0.953  20.4      185. 0.000000822     1  -43.2  92.4  93.4
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<p>This gives a one-line summary of a model, including things like
R-squared. This is handy if you’re fitting more than one model,
because you can collect the one-line summaries together into a data
frame and eyeball them.</p>
<p>The other summary is this one:</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="simple-regression.html#cb264-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(volume<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 5
##   term        estimate std.error statistic     p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
## 1 (Intercept)   -192.     24.0       -8.01 0.0000435  
## 2 diameter        10.9     0.801     13.6  0.000000822</code></pre>
<p>This gives a table of intercepts, slopes and their P-values, but the
value to this one is that it is a <em>data frame</em>, so if you want to
pull anything out of it, you know how to do that:<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a></p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="simple-regression.html#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(volume<span class="fl">.1</span>) <span class="sc">%&gt;%</span> <span class="fu">filter</span>(term <span class="sc">==</span> <span class="st">&quot;diameter&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 5
##   term     estimate std.error statistic     p.value
##   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
## 1 diameter     10.9     0.801      13.6 0.000000822</code></pre>
<p>This gets the estimated slope and its P-value, without worrying about
the corresponding things for the intercept, which are usually of less
interest anyway.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Draw a graph that will help you decide whether you trust
the linearity of this regression. What do you conclude? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The thing I’m fishing for is a residual plot (of the residuals
against the fitted values), and on it you are looking for a
random mess of nothingness:</p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="simple-regression.html#cb268-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(volume<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/pinetrees-8-1.png" width="672" /></p>
<p>Make a call. You could say that there’s no discernible pattern,
especially with such a small data set, and
therefore that the regression is fine. Or you could say that there is
fanning-in: the two points on the right have residuals close to 0
while the points on the left have residuals larger in size. Say
something.</p>
<p>I don’t think you can justify a curve or a trend, because
the residuals on the left are both positive and negative.</p>
<p>My feeling is that the residuals on the right are close to 0 because
these points have noticeably larger diameter than the others, and they
are <em>influential</em> points in the regression that will pull the
line closer to themselves. This is why their residuals are close to
zero. But I am happy with either of the points made in the paragraph
under the plot.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>What would you guess would be the volume of a tree of
diameter zero? Is that what the regression predicts? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Logically, a tree that has diameter zero is a non-existent tree,
so its volume should be zero as well.
In the regression, the quantity that says what volume is when
diameter is zero is the <em>intercept</em>. Here the intercept is
<span class="math inline">\(-192\)</span>, which is definitely not zero. In fact, if you look at
the P-value, the intercept is significantly <em>less</em> than
zero. Thus, the model makes no logical sense for trees of small
diameter. The smallest tree in the data set has diameter 18,
which is not really small, I suppose, but it is a little
disconcerting to have a model that makes no logical sense.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>A simple way of modelling a tree’s shape is to pretend it is a
cone, like this, but probably taller and skinnier:</li>
</ol>
<p><img src="/home/ken/Pictures/conebnw.png" /></p>
<p>with its base on the ground. What is the relationship between the
<em>diameter</em> (at the base) and volume of a cone? (If you don’t
remember, look it up. You’ll probably get a formula in terms of the
radius, which you’ll have to convert.
Cite the website you used.)</p>
<p>Solution</p>
<p>According to
<a href="http://www.web-formulas.com/Math_Formulas/Geometry_Volume_of_Cone.aspx">link</a>,
the volume of a cone is <span class="math inline">\(V=\pi r^2h/3\)</span>, where <span class="math inline">\(V\)</span> is the volume,
<span class="math inline">\(r\)</span> is the radius (at the bottom of the cone) and <span class="math inline">\(h\)</span> is the
height. The diameter is twice the radius, so replace <span class="math inline">\(r\)</span> by
<span class="math inline">\(d/2\)</span>, <span class="math inline">\(d\)</span> being the diameter. A little algebra gives
<span class="math display">\[ V = \pi d^2 h / 12.\]</span></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Fit a regression model that predicts volume from diameter
according to the formula you obtained in the previous part. You can
assume that the trees in this data set are of similar heights, so
that the height can be treated as a constant.<br />
Display the
results.</li>
</ol>
<p>Solution</p>
<p>According to my formula, the volume depends on the diameter
squared, which I include in the model thus:</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="simple-regression.html#cb269-1" aria-hidden="true" tabindex="-1"></a>volume<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(volume <span class="sc">~</span> <span class="fu">I</span>(diameter<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> trees)</span>
<span id="cb269-2"><a href="simple-regression.html#cb269-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(volume<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = volume ~ I(diameter^2), data = trees)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -29.708  -9.065  -5.722   3.032  40.816 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -30.82634   13.82243   -2.23   0.0563 .  
## I(diameter^2)   0.17091    0.01342   12.74 1.36e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 21.7 on 8 degrees of freedom
## Multiple R-squared:  0.953,  Adjusted R-squared:  0.9471 
## F-statistic: 162.2 on 1 and 8 DF,  p-value: 1.359e-06</code></pre>
<p>This adds an intercept as well, which is fine (there are technical
difficulties around removing the intercept).</p>
<p>That’s as far as I wanted you to go, but (of course) I have a few
comments.</p>
<p>The intercept here is still negative, but not significantly different
from zero, which is a step forward. The R-squared for this regression
is very similar to that from our linear model (the one for which the
intercept made no sense). So, from that point of view, either model
predicts the data well. I should look at the residuals from this one:</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="simple-regression.html#cb271-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(volume<span class="fl">.2</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/pinetrees-10-1.png" width="672" /></p>
<p>I really don’t think there are any problems there.</p>
<p>Now, I said to assume that the trees are all of similar height. This
seems entirely questionable, since the trees vary quite a bit in
diameter, and you would guess that trees with bigger diameter would
also be taller. It seems more plausible that the same kind of trees
(pine trees in this case) would have the same “shape”, so that if
you knew the diameter you could <em>predict</em> the height, with
larger-diameter trees being taller. Except that we don’t have the
heights here, so we can’t build a model for that.</p>
<p>So I went looking in the literature. I found this paper:
<a href="https://pdfs.semanticscholar.org/5497/3d02d63428e3dfed6645acfdba874ad80822.pdf">link</a>. This
gives several models for relationships between volume, diameter and height. In
the formulas below, there is an implied “plus error” on the right,
and the <span class="math inline">\(\alpha_i\)</span> are parameters to be estimated.</p>
<p>For predicting height from diameter (equation 1 in paper):</p>
<p><span class="math display">\[  h = \exp(\alpha_1+\alpha_2 d^{\alpha_3}) \]</span></p>
<p>For predicting volume from height and diameter (equation 6):</p>
<p><span class="math display">\[  V = \alpha_1 d^{\alpha_2} h^{\alpha_3} \]</span></p>
<p>This is a take-off on our assumption that the trees were cone-shaped,
with cone-shaped trees having <span class="math inline">\(\alpha_1=\pi/12\)</span>, <span class="math inline">\(\alpha_2=2\)</span> and
<span class="math inline">\(\alpha_3=1\)</span>. The paper uses different units, so <span class="math inline">\(\alpha_1\)</span> is not
comparable, but <span class="math inline">\(\alpha_2\)</span> and <span class="math inline">\(\alpha_3\)</span> are (as estimated from the
data in the paper, which were for longleaf pine) quite close to 2 and
1.</p>
<p>Last, the actual relationship that helps us: predicting volume from
just diameter (equation 5):</p>
<p><span class="math display">\[  V = \alpha_1 d^{\alpha_2}\]</span></p>
<p>This is a power law type of relationship. For example, if you were
willing to pretend that a tree was a cone with height proportional to
diameter (one way of getting at the idea of a bigger tree typically
being taller, instead of assuming constant height as we did), that
would imply <span class="math inline">\(\alpha_2=3\)</span> here.</p>
<p>This is non-linear as it stands, but we can bash it into shape by taking
logs:</p>
<p><span class="math display">\[
\ln V = \ln \alpha_1 + \alpha_2 \ln d
\]</span></p>
<p>so that log-volume has a linear relationship with log-diameter and we
can go ahead and estimate it:</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="simple-regression.html#cb272-1" aria-hidden="true" tabindex="-1"></a>volume<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(volume) <span class="sc">~</span> <span class="fu">log</span>(diameter), <span class="at">data =</span> trees)</span>
<span id="cb272-2"><a href="simple-regression.html#cb272-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(volume<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(volume) ~ log(diameter), data = trees)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.40989 -0.22341  0.01504  0.10459  0.53596 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    -5.9243     1.1759  -5.038    0.001 ** 
## log(diameter)   3.1284     0.3527   8.870 2.06e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.3027 on 8 degrees of freedom
## Multiple R-squared:  0.9077, Adjusted R-squared:  0.8962 
## F-statistic: 78.68 on 1 and 8 DF,  p-value: 2.061e-05</code></pre>
<p>The parameter that I called <span class="math inline">\(\alpha_2\)</span> above is the slope of this
model, 3.13. This is a bit different from the figure in the paper,
which was 2.19. I think these are comparable even though the other
parameter is not (again, measurements in different units, plus, this
time we need to take the log of it). I think the “slopes” are
comparable because we haven’t estimated our slope all that accurately:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="simple-regression.html#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(volume<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>##                   2.5 %    97.5 %
## (Intercept)   -8.635791 -3.212752
## log(diameter)  2.315115  3.941665</code></pre>
<p>From 2.3 to 3.9. It is definitely not zero, but we are rather less
sure about what it is, and 2.19 is not completely implausible.</p>
<p>The R-squared here, though it is less than the other ones we
got, is still high. The residuals are these:</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="simple-regression.html#cb276-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(volume<span class="fl">.3</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/pinetrees-13-1.png" width="672" /></p>
<p>which again seem to show no problems. The residuals are smaller in
size now because of the log transformation: the actual and predicted
log-volumes are smaller numbers than the actual and predicted volumes,
so the residuals are now closer to zero.</p>
<p>Does this model behave itself at zero? Well, roughly at least: if the
diameter is very small, its log is very negative, and the predicted
log-volume is also very negative (the slope is positive). So the
predicted actual volume will be close to zero. If you want to make
that mathematically rigorous, you can take limits, but that’s the
intuition. We can also do some predictions: set up a data frame that has a column called <code>diameter</code> with some diameters to predict for:</p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="simple-regression.html#cb277-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">diameter =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="fu">seq</span>(<span class="dv">5</span>, <span class="dv">50</span>, <span class="dv">5</span>)))</span>
<span id="cb277-2"><a href="simple-regression.html#cb277-2" aria-hidden="true" tabindex="-1"></a>d</span></code></pre></div>
<pre><code>## # A tibble: 12 × 1
##    diameter
##       &lt;dbl&gt;
##  1        1
##  2        2
##  3        5
##  4       10
##  5       15
##  6       20
##  7       25
##  8       30
##  9       35
## 10       40
## 11       45
## 12       50</code></pre>
<p>and then feed that into <code>predict</code>:</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="simple-regression.html#cb279-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predictions</span>(volume<span class="fl">.3</span>, <span class="at">newdata =</span> d) <span class="ot">-&gt;</span> p</span>
<span id="cb279-2"><a href="simple-regression.html#cb279-2" aria-hidden="true" tabindex="-1"></a>p</span></code></pre></div>
<pre><code>##    rowid     type  predicted  std.error   conf.low  conf.high diameter
## 1      1 response -5.9242712 1.17585198 -8.6357907 -3.2127517        1
## 2      2 response -3.7558365 0.93241870 -5.9059979 -1.6056752        2
## 3      3 response -0.8893218 0.61187164 -2.3003004  0.5216567        5
## 4      4 response  1.2791128 0.37239393  0.4203709  2.1378548       10
## 5      5 response  2.5475658 0.23706829  2.0008853  3.0942463       15
## 6      6 response  3.4475475 0.14995389  3.1017532  3.7933418       20
## 7      7 response  4.1456275 0.10253054  3.9091917  4.3820634       25
## 8      8 response  4.7160005 0.09962028  4.4862757  4.9457252       30
## 9      9 response  5.1982439 0.12600841  4.9076680  5.4888198       35
## 10    10 response  5.6159822 0.16066639  5.2454848  5.9864795       40
## 11    11 response  5.9844534 0.19559969  5.5333997  6.4355071       45
## 12    12 response  6.3140622 0.22872784  5.7866149  6.8415096       50</code></pre>
<p>These are predicted log-volumes, so we’d better anti-log them. <code>log</code> in R is natural logs, so this is inverted using <code>exp</code>:</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="simple-regression.html#cb281-1" aria-hidden="true" tabindex="-1"></a>p <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">exp_pred =</span> <span class="fu">exp</span>(predicted))</span></code></pre></div>
<pre><code>##    rowid     type  predicted  std.error   conf.low  conf.high diameter
## 1      1 response -5.9242712 1.17585198 -8.6357907 -3.2127517        1
## 2      2 response -3.7558365 0.93241870 -5.9059979 -1.6056752        2
## 3      3 response -0.8893218 0.61187164 -2.3003004  0.5216567        5
## 4      4 response  1.2791128 0.37239393  0.4203709  2.1378548       10
## 5      5 response  2.5475658 0.23706829  2.0008853  3.0942463       15
## 6      6 response  3.4475475 0.14995389  3.1017532  3.7933418       20
## 7      7 response  4.1456275 0.10253054  3.9091917  4.3820634       25
## 8      8 response  4.7160005 0.09962028  4.4862757  4.9457252       30
## 9      9 response  5.1982439 0.12600841  4.9076680  5.4888198       35
## 10    10 response  5.6159822 0.16066639  5.2454848  5.9864795       40
## 11    11 response  5.9844534 0.19559969  5.5333997  6.4355071       45
## 12    12 response  6.3140622 0.22872784  5.7866149  6.8415096       50
##        exp_pred
## 1  2.673756e-03
## 2  2.338088e-02
## 3  4.109343e-01
## 4  3.593450e+00
## 5  1.277597e+01
## 6  3.142323e+01
## 7  6.315724e+01
## 8  1.117205e+02
## 9  1.809542e+02
## 10 2.747831e+02
## 11 3.972054e+02
## 12 5.522839e+02</code></pre>
<p>For a diameter near zero, the predicted volume appears to be near zero as well.</p>
<p><br></p>
<p>I mentioned <code>broom</code> earlier. We can make a data frame out of
the one-line summaries of our three models:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="simple-regression.html#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_rows</span>(<span class="fu">glance</span>(volume<span class="fl">.1</span>), <span class="fu">glance</span>(volume<span class="fl">.2</span>), <span class="fu">glance</span>(volume<span class="fl">.3</span>))</span></code></pre></div>
<pre><code>## # A tibble: 3 × 12
##   r.squared adj.r.squared  sigma statistic     p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.959         0.953 20.4       185.  0.000000822     1 -43.2  92.4  93.4 
## 2     0.953         0.947 21.7       162.  0.00000136      1 -43.8  93.7  94.6 
## 3     0.908         0.896  0.303      78.7 0.0000206       1  -1.12  8.25  9.16
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<p>(I mistakenly put <code>glimpse</code> instead of <code>glance</code> there
the first time. The former is for a quick look at a <em>data frame</em>,
while the latter is for a quick look at a <em>model</em>.)</p>
<p>The three R-squareds are all high, with the one from the third model
being a bit lower as we saw before.</p>
<p>My code is rather repetitious. There has to be a way to streamline
it. I was determined to find out how. My solution involves putting the
three models in a list-column, and then using <code>rowwise</code> to
get the <code>glance</code> output for each one.</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="simple-regression.html#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">i =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">model =</span> <span class="fu">list</span>(volume<span class="fl">.1</span>, volume<span class="fl">.2</span>, volume<span class="fl">.3</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb285-2"><a href="simple-regression.html#cb285-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb285-3"><a href="simple-regression.html#cb285-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">glances =</span> <span class="fu">list</span>(<span class="fu">glance</span>(model))) <span class="sc">%&gt;%</span> </span>
<span id="cb285-4"><a href="simple-regression.html#cb285-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(glances)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 14
##       i model  r.squared adj.r.squared  sigma statistic     p.value    df logLik
##   &lt;int&gt; &lt;list&gt;     &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     1 &lt;lm&gt;       0.959         0.953 20.4       185.  0.000000822     1 -43.2 
## 2     2 &lt;lm&gt;       0.953         0.947 21.7       162.  0.00000136      1 -43.8 
## 3     3 &lt;lm&gt;       0.908         0.896  0.303      78.7 0.0000206       1  -1.12
## # … with 5 more variables: AIC &lt;dbl&gt;, BIC &lt;dbl&gt;, deviance &lt;dbl&gt;,
## #   df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<p>I almost got caught by forgetting the <code>list</code> on the definition of <code>glances</code>. I certainly need it, because the output from <code>glance</code> is a (one-row) dataframe, not a single number.</p>
<p>It works. You see the three R-squared values in the first column of numbers. The
third model is otherwise a lot different from the others because it
has a different response variable.</p>
<p>Other thoughts:</p>
<p>How might you measure or estimate the height of a
tree (other than by climbing it and dropping a tape measure down)? One
way, that works if the tree is fairly isolated, is to walk away from
its base. Periodically, you point at the top of the tree, and when the
angle between your arm and the ground reaches 45 degrees, you stop
walking. (If it’s greater than 45 degrees, you walk further away, and
if it’s less, you walk back towards the tree.) The distance between
you and the base of the tree is then equal to the height of the tree,
and if you have a long enough tape measure you can measure it.</p>
<p>The above works because the tangent of 45 degrees is 1. If you have a
device that will measure the actual angle,<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a>
you
can be any distance away from the tree, point the device at the top,
record the angle, and do some trigonometry to estimate the height of
the tree (to which you add the height of your eyes).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="tortoise-shells-and-eggs-1" class="section level2 hasAnchor" number="18.22">
<h2><span class="header-section-number">18.22</span> Tortoise shells and eggs<a href="simple-regression.html#tortoise-shells-and-eggs-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A biologist measured the length of the carapace (shell) of
female tortoises, and then x-rayed the tortoises to count how many
eggs they were carrying. The length is measured in millimetres. The
data are in
<a href="http://ritsokiguess.site/datafiles/tortoise-eggs.txt">link</a>. The
biologist is wondering what kind of relationship, if any, there is
between the carapace length (as an explanatory variable) and the
number of eggs (as a response variable).</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data, and check that your values look
reasonable.</li>
</ol>
<p>Solution</p>
<p>Look at the data first. The columns are aligned and separated by
more than one space, so it’s <code>read_table</code>:</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="simple-regression.html#cb287-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/tortoise-eggs.txt&quot;</span></span>
<span id="cb287-2"><a href="simple-regression.html#cb287-2" aria-hidden="true" tabindex="-1"></a>tortoises <span class="ot">&lt;-</span> <span class="fu">read_table</span>(my_url)</span></code></pre></div>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   length = col_double(),
##   eggs = col_double()
## )</code></pre>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="simple-regression.html#cb289-1" aria-hidden="true" tabindex="-1"></a>tortoises</span></code></pre></div>
<pre><code>## # A tibble: 18 × 2
##    length  eggs
##     &lt;dbl&gt; &lt;dbl&gt;
##  1    284     3
##  2    290     2
##  3    290     7
##  4    290     7
##  5    298    11
##  6    299    12
##  7    302    10
##  8    306     8
##  9    306     8
## 10    309     9
## 11    310    10
## 12    311    13
## 13    317     7
## 14    317     9
## 15    320     6
## 16    323    13
## 17    334     2
## 18    334     8</code></pre>
<p>Those look the same as the values in the data file. (<em>Some</em>
comment is needed here. I don’t much mind what, but something that
suggests that you have eyeballed the data and there are no obvious
problems: that is what I am looking for.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Obtain a scatterplot, with a smooth trend, of the data.</li>
</ol>
<p>Solution</p>
<p>Something like this:</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="simple-regression.html#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(tortoises, <span class="fu">aes</span>(<span class="at">x =</span> length, <span class="at">y =</span> eggs)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/looe-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>The biologist expected that a larger tortoise would be able
to carry more eggs. Is that what the scatterplot is suggesting?
Explain briefly why or why not.</li>
</ol>
<p>Solution</p>
<p>The biologist’s expectation is of an upward trend. But it looks as
if the trend on the scatterplot is up, then down, ie. a curve
rather than a straight line. So this is not what the biologist was
expecting.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a straight-line relationship and display the summary.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="simple-regression.html#cb293-1" aria-hidden="true" tabindex="-1"></a>tortoises<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(eggs <span class="sc">~</span> length, <span class="at">data =</span> tortoises)</span>
<span id="cb293-2"><a href="simple-regression.html#cb293-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tortoises<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = eggs ~ length, data = tortoises)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.7790 -1.1772 -0.0065  2.0487  4.8556 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -0.43532   17.34992  -0.025    0.980
## length       0.02759    0.05631   0.490    0.631
## 
## Residual standard error: 3.411 on 16 degrees of freedom
## Multiple R-squared:  0.01478,    Adjusted R-squared:  -0.0468 
## F-statistic:  0.24 on 1 and 16 DF,  p-value: 0.6308</code></pre>
<p>I didn’t ask for a comment, but feel free to observe that this
regression is truly awful, with an R-squared of less than 2% and a
non-significant effect of <code>length</code>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Add a squared term to your regression, fit that and display
the summary.</li>
</ol>
<p>Solution</p>
<p>The <code>I()</code> is needed because the raise-to-a-power symbol has
a special meaning in a model formula, and we want to <em>not</em>
use that special meaning:</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="simple-regression.html#cb295-1" aria-hidden="true" tabindex="-1"></a>tortoises<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(eggs <span class="sc">~</span> length <span class="sc">+</span> <span class="fu">I</span>(length<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> tortoises)</span>
<span id="cb295-2"><a href="simple-regression.html#cb295-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tortoises<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = eggs ~ length + I(length^2), data = tortoises)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.0091 -1.8480 -0.1896  2.0989  4.3605 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept) -8.999e+02  2.703e+02  -3.329  0.00457 **
## length       5.857e+00  1.750e+00   3.347  0.00441 **
## I(length^2) -9.425e-03  2.829e-03  -3.332  0.00455 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.671 on 15 degrees of freedom
## Multiple R-squared:  0.4338, Adjusted R-squared:  0.3583 
## F-statistic: 5.747 on 2 and 15 DF,  p-value: 0.01403</code></pre>
<p>Another way is to use <code>update</code>:</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="simple-regression.html#cb297-1" aria-hidden="true" tabindex="-1"></a>tortoises<span class="fl">.2</span>a <span class="ot">&lt;-</span> <span class="fu">update</span>(tortoises<span class="fl">.1</span>, . <span class="sc">~</span> . <span class="sc">+</span> <span class="fu">I</span>(length<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb297-2"><a href="simple-regression.html#cb297-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(tortoises<span class="fl">.2</span>a)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = eggs ~ length + I(length^2), data = tortoises)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.0091 -1.8480 -0.1896  2.0989  4.3605 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept) -8.999e+02  2.703e+02  -3.329  0.00457 **
## length       5.857e+00  1.750e+00   3.347  0.00441 **
## I(length^2) -9.425e-03  2.829e-03  -3.332  0.00455 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.671 on 15 degrees of freedom
## Multiple R-squared:  0.4338, Adjusted R-squared:  0.3583 
## F-statistic: 5.747 on 2 and 15 DF,  p-value: 0.01403</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Is a curve better than a line for these data? Justify your
answer in two ways: by comparing a measure of fit, and by doing a
suitable test of significance.</li>
</ol>
<p>Solution</p>
<p>An appropriate measure of fit is R-squared. For the straight line,
this is about 0.01, and for the regression with the squared term it
is about 0.43. This tells us that a straight line fits appallingly
badly, and that a curve fits a <em>lot</em> better.
This doesn’t do a test, though. For that, look at the slope of the
length-squared term in the second regression; in particular,
look at its P-value. This is 0.0045, which is small: the squared
term is necessary, and taking it out would be a mistake. The
relationship really is curved, and trying to describe it with a
straight line would be a big mistake.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Make a residual plot for the straight line model: that is, plot
the residuals against the fitted values.
Does this echo
your conclusions of the previous part? In what way? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Plot the things called <code>.fitted</code> and <code>.resid</code> from the
regression object, which is not a data frame but you can treat it as
if it is for this:</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="simple-regression.html#cb299-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(tortoises<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/tortoise-5-1.png" width="672" /></p>
<p>Up to you whether you put a smooth trend on it or not:</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="simple-regression.html#cb300-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(tortoises<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb300-2"><a href="simple-regression.html#cb300-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/tortoise-6-1.png" width="672" /></p>
<p>Looking at the plot, you see a curve, up and down. The most
negative residuals go with small or large fitted values; when the
fitted value is in the middle, the residual is usually positive. A
curve on the residual plot indicates a curve in the actual
relationship. We just found above that a curve does fit a lot
better, so this is all consistent.</p>
<p>Aside: the grey “envelope” is wide, so there is a lot of scatter on the
residual plot. The grey envelope almost contains zero all the way
across, so the evidence for a curve (or any other kind of trend) is
not all that strong, based on this plot. This is in great contrast to
the regression with length-squared, where the length-squared term is
<em>definitely</em> necessary.</p>
<p>That was all I wanted, but you can certainly look at other
plots. Normal quantile plot of the residuals:</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="simple-regression.html#cb302-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(tortoises<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">sample =</span> .resid)) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/tortoise-7-1.png" width="672" /></p>
<p>This is not the best: the low values are a bit too low, so that the
whole picture is (a little) skewed to the left.<a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a></p>
<p>Another plot you can make is to assess fan-out: you plot the
<em>absolute value</em><a href="#fn39" class="footnote-ref" id="fnref39"><sup>39</sup></a> of the residuals against the fitted values. The idea
is that if there is fan-out, the absolute value of the residuals will
get bigger:</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="simple-regression.html#cb303-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(tortoises<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> <span class="fu">abs</span>(.resid))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb303-2"><a href="simple-regression.html#cb303-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/tortoise-8-1.png" width="672" /></p>
<p>I put the smooth curve on as a kind of warning: it looks as if the
size of the residuals goes down and then up again as the fitted values
increase. But the width of the grey “envelope” and the general
scatter of the points suggests that there is really not much happening
here at all. On a plot of residuals, the grey envelope is really more
informative than the blue smooth trend. On this one, there is no
evidence of any fan-out (or fan-in).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="roller-coasters-1" class="section level2 hasAnchor" number="18.23">
<h2><span class="header-section-number">18.23</span> Roller coasters<a href="simple-regression.html#roller-coasters-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A poll on the Discovery Channel asked people to nominate the
best roller-coasters in the United States. We will examine the 10
roller-coasters that received the most votes. Two features of a
roller-coaster that are of interest are the distance it drops from
start to finish, measured here in feet<a href="#fn40" class="footnote-ref" id="fnref40"><sup>40</sup></a> and the duration of the ride,
measured in seconds. Is it true that roller-coasters with a bigger
drop also tend to have a longer ride? The data are at
<a href="http://ritsokiguess.site/datafiles/coasters.csv">link</a>.<a href="#fn41" class="footnote-ref" id="fnref41"><sup>41</sup></a></p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R and verify that you have a sensible
number of rows and columns.</li>
</ol>
<p>Solution</p>
<p>A <code>.csv</code>, so the usual for that:</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="simple-regression.html#cb305-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/coasters.csv&quot;</span></span>
<span id="cb305-2"><a href="simple-regression.html#cb305-2" aria-hidden="true" tabindex="-1"></a>coasters <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(my_url)</span></code></pre></div>
<pre><code>## Rows: 10 Columns: 4
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## chr (2): coaster_name, state
## dbl (2): drop, duration
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="simple-regression.html#cb307-1" aria-hidden="true" tabindex="-1"></a>coasters</span></code></pre></div>
<pre><code>## # A tibble: 10 × 4
##    coaster_name     state         drop duration
##    &lt;chr&gt;            &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;
##  1 Incredible Hulk  Florida        105      135
##  2 Millennium Force Ohio           300      105
##  3 Goliath          California     255      180
##  4 Nitro            New Jersey     215      240
##  5 Magnum XL-2000   Ohio           195      120
##  6 The Beast        Ohio           141       65
##  7 Son of Beast     Ohio           214      140
##  8 Thunderbolt      Pennsylvania    95       90
##  9 Ghost Rider      California     108      160
## 10 Raven            Indiana         86       90</code></pre>
<p>The number of marks for this kind of thing has been decreasing through
the course, since by now you ought to have figured out how to do it
without looking it up.</p>
<p>There are 10 rows for the promised 10 roller-coasters, and there are
several columns: the drop for each roller-coaster and the duration of
its ride, as promised, as well as the name of each roller-coaster and the state
that it is in. (A lot of them seem to be in Ohio, for some reason that
I don’t know.) So this all looks good.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a scatterplot of duration (response) against drop
(explanatory), labelling each roller-coaster with its name in such a
way that the labels do not overlap. Add a regression line to your plot.</li>
</ol>
<p>Solution</p>
<p>The last part, about the labels not overlapping, is an
invitation to use <code>ggrepel</code>, which is the way I’d
recommend doing this. (If not, you have to do potentially lots
of work organizing where the labels sit relative to the points,
which is time you probably don’t want to spend.) Thus:</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="simple-regression.html#cb309-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggrepel)</span>
<span id="cb309-2"><a href="simple-regression.html#cb309-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(coasters, <span class="fu">aes</span>(<span class="at">x =</span> drop, <span class="at">y =</span> duration, <span class="at">label =</span> coaster_name)) <span class="sc">+</span></span>
<span id="cb309-3"><a href="simple-regression.html#cb309-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_text_repel</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/coasters-2-1.png" width="672" /></p>
<p>The <code>se=F</code> at the end is optional; if you omit it, you get that
“envelope” around the line, which is fine here.</p>
<p>Note that with the labelling done this way, you can easily identify
which roller-coaster is which.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Would you say that roller-coasters with a larger drop tend
to have a longer ride? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>I think there are two good answers here: “yes” and “kind of”.
Supporting “yes” is the fact that the regression line does go
uphill, so that overall, or on average, roller-coasters with a
larger drop do tend to have a longer duration of ride as well.
Supporting “kind of” is the fact that, though the regression
line goes uphill, there are a lot of roller-coasters that are
some way off the trend, far from the regression line.
I am happy to go with either of those. I could also go with
“not really” and the same discussion that I attached to
“kind of”.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Find a roller-coaster that is unusual compared to the
others. What about its combination of <code>drop</code> and
<code>duration</code> is unusual?</li>
</ol>
<p>Solution</p>
<p>This is an invitation to find a point that is a long way off the
line. I think the obvious choice is my first one below, but I
would take either of the others as well:</p>
<ul>
<li><p>“Nitro” is a long way above the line. That means it has
a long duration, relative to its drop. There are two other
roller-coasters that have a larger drop but not as long a
duration. In other words, this roller-coaster drops slowly,
presumably by doing a lot of twisting, loop-the-loop and so on.</p></li>
<li><p>“The Beast” is a long way below the line, so it has a
short duration relative to its drop. It is actually the
shortest ride of all, but is only a bit below average in terms
of drop. This suggests that The Beast is one of those rides
that drops a long way quickly.</p></li>
<li><p>“Millennium Force” has the biggest drop of all, but a
shorter-than-average duration. This looks like another ride
with a big drop in it.</p></li>
</ul>
<p>A roller-coaster that is “unusual” will have a residual that
is large in size (either positive, like Nitro, or negative, like
the other two). I didn’t ask you to find the residuals, but if
you want to, <code>augment</code> from <code>broom</code> is the
smoothest way to go:</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="simple-regression.html#cb311-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb311-2"><a href="simple-regression.html#cb311-2" aria-hidden="true" tabindex="-1"></a>duration<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(duration <span class="sc">~</span> drop, <span class="at">data =</span> coasters)</span>
<span id="cb311-3"><a href="simple-regression.html#cb311-3" aria-hidden="true" tabindex="-1"></a><span class="fu">augment</span>(duration<span class="fl">.1</span>, coasters) <span class="sc">%&gt;%</span></span>
<span id="cb311-4"><a href="simple-regression.html#cb311-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(coaster_name, duration, drop, .resid) <span class="sc">%&gt;%</span></span>
<span id="cb311-5"><a href="simple-regression.html#cb311-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(<span class="fu">abs</span>(.resid)))</span></code></pre></div>
<pre><code>## # A tibble: 10 × 4
##    coaster_name     duration  drop .resid
##    &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
##  1 Nitro                 240   215  97.0 
##  2 The Beast              65   141 -60.1 
##  3 Millennium Force      105   300 -58.6 
##  4 Ghost Rider           160   108  42.8 
##  5 Goliath               180   255  27.3 
##  6 Thunderbolt            90    95 -24.0 
##  7 Raven                  90    86 -21.8 
##  8 Incredible Hulk       135   105  18.6 
##  9 Magnum XL-2000        120   195 -18.2 
## 10 Son of Beast          140   214  -2.81</code></pre>
<p><code>augment</code> produces a data frame (of the original data frame
with some new columns that come from the regression), so I can feed it
into a pipe to do things with it, like only displaying the columns I
want, and arranging them in order by absolute value of residual, so
that the roller-coasters further from the line come out first. This
identifies the three that we found above. The fourth one, “Ghost Rider”,
is like Nitro in that it takes a (relatively) long time to
fall not very far.
You can also put <code>augment</code> in the <em>middle</em> of a pipe. What
you may have to do then is supply the <em>original</em> data frame name
to <code>augment</code> so that you have everything:</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="simple-regression.html#cb313-1" aria-hidden="true" tabindex="-1"></a>coasters <span class="sc">%&gt;%</span></span>
<span id="cb313-2"><a href="simple-regression.html#cb313-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(duration <span class="sc">~</span> drop, <span class="at">data =</span> .) <span class="sc">%&gt;%</span></span>
<span id="cb313-3"><a href="simple-regression.html#cb313-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(coasters) <span class="sc">%&gt;%</span></span>
<span id="cb313-4"><a href="simple-regression.html#cb313-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(<span class="fu">abs</span>(.resid)))</span></code></pre></div>
<pre><code>## # A tibble: 10 × 10
##    coaster_name     state      drop duration .fitted .resid  .hat .sigma .cooksd
##    &lt;chr&gt;            &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1 Nitro            New Jers…   215      240    143.  97.0  0.138   37.5 3.36e-1
##  2 The Beast        Ohio        141       65    125. -60.1  0.118   48.8 1.06e-1
##  3 Millennium Force Ohio        300      105    164. -58.6  0.429   45.9 8.70e-1
##  4 Ghost Rider      Californ…   108      160    117.  42.8  0.180   51.5 9.46e-2
##  5 Goliath          Californ…   255      180    153.  27.3  0.239   53.2 5.91e-2
##  6 Thunderbolt      Pennsylv…    95       90    114. -24.0  0.216   53.5 3.91e-2
##  7 Raven            Indiana      86       90    112. -21.8  0.245   53.6 3.95e-2
##  8 Incredible Hulk  Florida     105      135    116.  18.6  0.188   53.9 1.89e-2
##  9 Magnum XL-2000   Ohio        195      120    138. -18.2  0.111   54.0 8.98e-3
## 10 Son of Beast     Ohio        214      140    143.  -2.81 0.136   54.5 2.77e-4
## # … with 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<p>I wanted to hang on to the roller-coaster names, so I added the data
frame name to <code>augment</code>. If you don’t (that is, you just put
<code>augment()</code> in the middle of a pipe), then <code>augment</code>
“attempts to reconstruct the data from the model”.<a href="#fn42" class="footnote-ref" id="fnref42"><sup>42</sup></a> That means you wouldn’t get
<em>everything</em> from the original data frame; you would just get the
things that were in the regression. In this case, that means you would lose
the coaster names.</p>
<p>A technicality (but one that you should probably care about):
<code>augment</code> takes up to <em>two</em> inputs: a fitted model object
like my <code>duration.1</code>, and an optional data frame to include
other things from, like the coaster names. I had only one input to it
in the pipe because the implied first input was the output from the
<code>lm</code>, which doesn’t have a name; the input <code>coasters</code> in
the pipe was what would normally be the <em>second</em> input to
<code>augment</code>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="running-and-blood-sugar-1" class="section level2 hasAnchor" number="18.24">
<h2><span class="header-section-number">18.24</span> Running and blood sugar<a href="simple-regression.html#running-and-blood-sugar-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A diabetic wants to know how aerobic exercise affects his
blood sugar. When his blood sugar reaches 170 (mg/dl), he goes out for
a run at a pace of 10 minutes per mile. He runs different distances on
different days. Each time he runs, he measures his blood sugar after
the run. (The preferred blood sugar level is between 80 and 120 on
this scale.) The data are in the file
<a href="http://ritsokiguess.site/datafiles/runner.txt">link</a>. Our aim is
to predict blood sugar from distance.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data and display the data frame that you read
in.</li>
</ol>
<p>Solution</p>
<p>From the URL is easiest. These are delimited by one space, as
you can tell by looking at the file:</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="simple-regression.html#cb315-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/runner.txt&quot;</span></span>
<span id="cb315-2"><a href="simple-regression.html#cb315-2" aria-hidden="true" tabindex="-1"></a>runs <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 12 Columns: 2
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot; &quot;
## dbl (2): distance, blood_sugar
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="simple-regression.html#cb317-1" aria-hidden="true" tabindex="-1"></a>runs</span></code></pre></div>
<pre><code>## # A tibble: 12 × 2
##    distance blood_sugar
##       &lt;dbl&gt;       &lt;dbl&gt;
##  1      2           136
##  2      2           146
##  3      2.5         131
##  4      2.5         125
##  5      3           120
##  6      3           116
##  7      3.5         104
##  8      3.5          95
##  9      4            85
## 10      4            94
## 11      4.5          83
## 12      4.5          75</code></pre>
<p>That looks like my data file.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a scatterplot and add a smooth trend to it.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="simple-regression.html#cb319-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(runs, <span class="fu">aes</span>(<span class="at">x =</span> distance, <span class="at">y =</span> blood_sugar)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb319-2"><a href="simple-regression.html#cb319-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/plymouth-1.png" width="672" /></p>
<p><code>blood_sugar</code> should be on the vertical axis, since this is
what we are trying to predict. Getting the <code>x</code> and the
<code>y</code> right is easy on these, because they are the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>
for your plot.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Would you say that the relationship between blood sugar and
running distance is approximately linear, or not? It is therefore
reasonable to use a regression of blood sugar on distance? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>I’d say that this is about as linear as you could ever wish
for. Neither the pattern of points nor the smooth trend have any
kind of noticeable bend in them. (Observing a lack of curvature in
either the points or the smooth trend is enough.) The trend
is a linear one, so using a regression will be just fine. (If it
weren’t, the rest of the question would be kind of dumb.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a suitable regression, and obtain the regression output.</li>
</ol>
<p>Solution</p>
<p>Two steps: <code>lm</code> and then <code>summary</code>:</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="simple-regression.html#cb321-1" aria-hidden="true" tabindex="-1"></a>runs<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(blood_sugar <span class="sc">~</span> distance, <span class="at">data =</span> runs)</span>
<span id="cb321-2"><a href="simple-regression.html#cb321-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(runs<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = blood_sugar ~ distance, data = runs)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.8238 -3.6167  0.8333  4.0190  5.5476 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  191.624      5.439   35.23 8.05e-12 ***
## distance     -25.371      1.618  -15.68 2.29e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.788 on 10 degrees of freedom
## Multiple R-squared:  0.9609, Adjusted R-squared:  0.957 
## F-statistic: 245.7 on 1 and 10 DF,  p-value: 2.287e-08</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>How would you <em>interpret</em> the slope? That is, what is
the slope, and what does that mean about blood sugar and running distance?</li>
</ol>
<p>Solution</p>
<p>The slope is <span class="math inline">\(-25.37\)</span>. This means that for each additional mile run,
the runner’s blood sugar will decrease on average by about 25 units.</p>
<p>You can check this from the scatterplot. For example, from 2 to 3
miles, average blood sugar decreases from about 140 to about 115, a
drop of 25.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Is there a (statistically) significant relationship between
running distance and blood sugar? How do you know? Do you find this
surprising, given what you have seen so far? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Look at the P-value either on the <code>distance</code> line (for its
<span class="math inline">\(t\)</span>-test) or for the <span class="math inline">\(F\)</span>-statistic on the bottom line. These are
the same: 0.000000023. (They will be the same any time there is
one <span class="math inline">\(x\)</span>-variable.) This P-value is <em>way</em> smaller than 0.05,
so there <em>is</em> a significant relationship between running distance
and blood sugar. This does not surprise me in the slightest,
because the trend on the scatterplot is <em>so</em> clear, there’s
no way it could have happened by chance if in fact there were no
relationship between running distance and blood sugar.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>This diabetic is planning to go for a 3-mile run tomorrow
and a 5-mile run the day after. Obtain suitable 95% intervals that
say what his blood sugar might be after each of these runs.</li>
</ol>
<p>Solution</p>
<p>This is a prediction interval, in each case, since we are talking about
<em>individual</em> runs of 3 miles and 5 miles (not the mean blood
sugar after <em>all</em> runs of 3 miles, which is what a confidence
interval for the mean response would be).
The procedure is to set up a data frame with the two
<code>distance</code> values in it, and then feed that and the
regression object into <code>predict</code>, coming up in a moment.</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="simple-regression.html#cb323-1" aria-hidden="true" tabindex="-1"></a>dists <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">5</span>)</span>
<span id="cb323-2"><a href="simple-regression.html#cb323-2" aria-hidden="true" tabindex="-1"></a>new <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">distance =</span> dists)</span>
<span id="cb323-3"><a href="simple-regression.html#cb323-3" aria-hidden="true" tabindex="-1"></a>new</span></code></pre></div>
<pre><code>## # A tibble: 2 × 1
##   distance
##      &lt;dbl&gt;
## 1        3
## 2        5</code></pre>
<p>The important thing is that the name of the column of the new data
frame must be <em>exactly</em> the same as the name of the explanatory
variable in the regression. If they don’t match, <code>predict</code>
won’t work. At least, it won’t work properly.<a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a></p>
<p>If your first thought is <code>datagrid</code>, well, that will also work:</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="simple-regression.html#cb325-1" aria-hidden="true" tabindex="-1"></a>new2 <span class="ot">&lt;-</span> <span class="fu">datagrid</span>(<span class="at">model =</span> runs<span class="fl">.1</span>, <span class="at">distance =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">10</span>))</span>
<span id="cb325-2"><a href="simple-regression.html#cb325-2" aria-hidden="true" tabindex="-1"></a>new2</span></code></pre></div>
<pre><code>##    distance
## 1:        5
## 2:       10</code></pre>
<p>Use whichever of these methods comes to your mind.</p>
<p>Then, <code>predict</code>, because you want prediction intervals rather than confidence intervals for the mean response (which is what <code>marginaleffects</code> gives you):</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="simple-regression.html#cb327-1" aria-hidden="true" tabindex="-1"></a>pp <span class="ot">&lt;-</span> <span class="fu">predict</span>(runs<span class="fl">.1</span>, new, <span class="at">interval =</span> <span class="st">&quot;p&quot;</span>)</span>
<span id="cb327-2"><a href="simple-regression.html#cb327-2" aria-hidden="true" tabindex="-1"></a>pp</span></code></pre></div>
<pre><code>##         fit       lwr       upr
## 1 115.50952 104.37000 126.64905
## 2  64.76667  51.99545  77.53788</code></pre>
<p>and display this with the distances by the side:</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="simple-regression.html#cb329-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(new, pp)</span></code></pre></div>
<pre><code>##   distance       fit       lwr       upr
## 1        3 115.50952 104.37000 126.64905
## 2        5  64.76667  51.99545  77.53788</code></pre>
<p>or</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="simple-regression.html#cb331-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(new, pp)</span></code></pre></div>
<pre><code>##   distance       fit       lwr       upr
## 1        3 115.50952 104.37000 126.64905
## 2        5  64.76667  51.99545  77.53788</code></pre>
<p>Blood sugar after a 3-mile run is predicted to be between 104 and 127;
after a 5-mile run it is predicted to be between 52 and 77.5.</p>
<p>Extra: both <code>cbind</code> and <code>data.frame</code> are “base R” ways of
combining a data frame with something else to make a new data
frame. They are not from the <code>tidyverse</code>. The
<code>tidyverse</code> way is via <code>tibble</code> or <code>bind_cols</code>,
but they are a bit more particular about what they will take:
<code>tibble</code> takes vectors (single variables) and
<code>bind_cols</code> takes vectors or data frames. The problem here is
that <code>pp</code> is not either of those:</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="simple-regression.html#cb333-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(pp)</span></code></pre></div>
<pre><code>## [1] &quot;matrix&quot; &quot;array&quot;</code></pre>
<p>so that we have to use <code>as_tibble</code> first to turn it into a
data frame, and thus:</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="simple-regression.html#cb335-1" aria-hidden="true" tabindex="-1"></a>pp <span class="sc">%&gt;%</span> <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> <span class="fu">bind_cols</span>(new)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
##     fit   lwr   upr distance
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
## 1 116.  104.  127.         3
## 2  64.8  52.0  77.5        5</code></pre>
<p>which puts things backwards, unless you do it like this:</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="simple-regression.html#cb337-1" aria-hidden="true" tabindex="-1"></a>new <span class="sc">%&gt;%</span> <span class="fu">bind_cols</span>(<span class="fu">as_tibble</span>(pp))</span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
##   distance   fit   lwr   upr
##      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1        3 116.  104.  127. 
## 2        5  64.8  52.0  77.5</code></pre>
<p>which is a pretty result from very ugly code.</p>
<p>I also remembered that if you finish with a <code>select</code>, you get the columns in the order they were in the <code>select</code>:</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="simple-regression.html#cb339-1" aria-hidden="true" tabindex="-1"></a>pp <span class="sc">%&gt;%</span></span>
<span id="cb339-2"><a href="simple-regression.html#cb339-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span></span>
<span id="cb339-3"><a href="simple-regression.html#cb339-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(new) <span class="sc">%&gt;%</span></span>
<span id="cb339-4"><a href="simple-regression.html#cb339-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">c</span>(distance, <span class="fu">everything</span>()))</span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
##   distance   fit   lwr   upr
##      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1        3 116.  104.  127. 
## 2        5  64.8  52.0  77.5</code></pre>
<p><code>everything</code> is a so-called “select helper”. It means
“everything except any columns you already named”, so this whole thing has the effect of listing the columns
with <code>distance</code> first and all the other columns afterwards, in the order that they were in before.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Which of your two intervals is longer? Does this make
sense? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The intervals are about 22.25 and 25.5 units long. The one for a
5-mile run is a bit longer. I think this makes sense because 3
miles is close to the average run distance, so there is a lot of
“nearby” data. 5 miles is actually longer than any of the runs
that were actually done (and therefore we are actually
extrapolating), but the important point for the prediction
interval is that there is less nearby data: those 2-mile runs
don’t help so much in predicting blood sugar after a 5-mile
run. (They help <em>some</em>, because the trend is so linear. This
is why the 5-mile interval is not <em>so</em> much longer. If the
trend were less clear, the 5-mile interval would be more
noticeably worse.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="calories-and-fat-in-pizza-1" class="section level2 hasAnchor" number="18.25">
<h2><span class="header-section-number">18.25</span> Calories and fat in pizza<a href="simple-regression.html#calories-and-fat-in-pizza-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The file at
<a href="http://ritsokiguess.site/datafiles/Pizza.csv">link</a>
came from a spreadsheet of information about 24 brands
of pizza: specifically, per 5-ounce serving, the number of calories,
the grams of fat, and the cost (in US dollars). The names of the pizza
brands are quite long. This file may open in a spreadsheet when you
browse to the link, depending on your computer’s setup.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data and display at least some of the data
frame. Are the variables of the right types? (In particular, why is
the number of calories labelled one way and the cost labelled a
different way?)</li>
</ol>
<p>Solution</p>
<p><code>read_csv</code> is the thing this time:</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="simple-regression.html#cb341-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/Pizza.csv&quot;</span></span>
<span id="cb341-2"><a href="simple-regression.html#cb341-2" aria-hidden="true" tabindex="-1"></a>pizza <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(my_url)</span></code></pre></div>
<pre><code>## Rows: 24 Columns: 4
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## chr (1): Type
## dbl (3): Calories, Fat, Cost
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="simple-regression.html#cb343-1" aria-hidden="true" tabindex="-1"></a>pizza</span></code></pre></div>
<pre><code>## # A tibble: 24 × 4
##    Type                                                  Calories   Fat  Cost
##    &lt;chr&gt;                                                    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 Domino&#39;s Deep Dish with Pepperoni                          385  19.5  1.87
##  2 Pizza Hut&#39;s Stuffed Crust with Pepperoni                   370  15    1.83
##  3 Pizza Hut&#39;s Pan Pizza with Pepperoni                       280  14    1.83
##  4 Domino&#39;s Hand-Tossed with Pepperoni                        305  12    1.67
##  5 Pizza Hut&#39;s Hand-Tossed with Pepperoni                     230   9    1.63
##  6 Little Caesars&#39; Deep Dish with Pepperoni                   350  14.2  1.06
##  7 Little Caesars&#39; Original Round with Pepperoni              230   8    0.81
##  8 Freschetta Bakes &amp; Rises  4-Cheese                         364  15    0.98
##  9 Freschetta Bakes &amp; Rises Sauce Stuffed Crust 4-Cheese      334  11    1.23
## 10 DiGiorno Rising Crust Four Cheese                          332  12    0.94
## # … with 14 more rows</code></pre>
<p>The four variables are: the brand of pizza, which got read in as text,
the number of calories (an integer), and the fat and cost, which are
both decimal numbers so they get labelled <code>dbl</code>, which is short for
“double-precision floating point number”.</p>
<p>Anyway, these are apparently the right thing.</p>
<p>Extra: I wanted to mention something else that I discovered
yesterday.<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a>
There is a package called <code>rio</code> that will
read (and write) data in a whole bunch of different formats in a
unified way.<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a> Anyway, the usual installation thing, done once:</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="simple-regression.html#cb345-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;rio&quot;</span>)</span></code></pre></div>
<p>which takes a moment since it probably has to install some other
packages too, and then you read in a file like this:</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="simple-regression.html#cb346-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rio)</span>
<span id="cb346-2"><a href="simple-regression.html#cb346-2" aria-hidden="true" tabindex="-1"></a>pizza3 <span class="ot">&lt;-</span> <span class="fu">import</span>(my_url)</span>
<span id="cb346-3"><a href="simple-regression.html#cb346-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(pizza3)</span></code></pre></div>
<pre><code>##                                       Type Calories  Fat Cost
## 1        Domino&#39;s Deep Dish with Pepperoni      385 19.5 1.87
## 2 Pizza Hut&#39;s Stuffed Crust with Pepperoni      370 15.0 1.83
## 3     Pizza Hut&#39;s Pan Pizza with Pepperoni      280 14.0 1.83
## 4      Domino&#39;s Hand-Tossed with Pepperoni      305 12.0 1.67
## 5   Pizza Hut&#39;s Hand-Tossed with Pepperoni      230  9.0 1.63
## 6 Little Caesars&#39; Deep Dish with Pepperoni      350 14.2 1.06</code></pre>
<p><code>import</code> figures that you have a <code>.csv</code> file, so it
calls up <code>read_csv</code> or similar.</p>
<p>Technical note: <code>rio</code> does not use the <code>read_</code>
functions, so what it gives you is actually a <code>data.frame</code>
rather than a <code>tibble</code>, so that when you display it, you get
the whole thing even if it is long. Hence the <code>head</code> here and
below to display the first six lines.</p>
<p>I originally had the data as an Excel spreadsheet, but <code>import</code>
will gobble up that pizza too:</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="simple-regression.html#cb348-1" aria-hidden="true" tabindex="-1"></a>my_other_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/Pizza_E29.xls&quot;</span></span>
<span id="cb348-2"><a href="simple-regression.html#cb348-2" aria-hidden="true" tabindex="-1"></a>pizza4 <span class="ot">&lt;-</span> <span class="fu">import</span>(my_other_url)</span>
<span id="cb348-3"><a href="simple-regression.html#cb348-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(pizza4)</span></code></pre></div>
<pre><code>##                                       Type Calories Fat (g) Cost ($)
## 1        Domino&#39;s Deep Dish with Pepperoni      385    19.5     1.87
## 2 Pizza Hut&#39;s Stuffed Crust with Pepperoni      370    15.0     1.83
## 3     Pizza Hut&#39;s Pan Pizza with Pepperoni      280    14.0     1.83
## 4      Domino&#39;s Hand-Tossed with Pepperoni      305    12.0     1.67
## 5   Pizza Hut&#39;s Hand-Tossed with Pepperoni      230     9.0     1.63
## 6 Little Caesars&#39; Deep Dish with Pepperoni      350    14.2     1.06</code></pre>
<p>The corresponding function for writing a data frame to a file in the
right format is, predictably enough, called <code>export</code>.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a scatterplot for predicting calories from the number
of grams of fat. Add a smooth trend. What kind of relationship do
you see, if any?</li>
</ol>
<p>Solution</p>
<p>All the variable names start with Capital Letters:</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="simple-regression.html#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(pizza, <span class="fu">aes</span>(<span class="at">x =</span> Fat, <span class="at">y =</span> Calories)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb350-2"><a href="simple-regression.html#cb350-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/alskhslafkhlksfhsasvvvv-1.png" width="672" /></p>
<p>There is definitely an upward trend: the more fat, the more
calories. The trend is more or less linear (or, a little bit curved:
say what you like, as long as it’s not obviously crazy). <em>I</em>
think, with this much scatter, there’s no real justification for
fitting a curve.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Fit a straight-line relationship, and display the intercept,
slope, R-squared, etc. Is there a real relationship between the two
variables, or is any apparent trend just chance?</li>
</ol>
<p>Solution</p>
<p><code>lm</code>, with <code>summary</code>:</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="simple-regression.html#cb352-1" aria-hidden="true" tabindex="-1"></a>pizza<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(Calories <span class="sc">~</span> Fat, <span class="at">data =</span> pizza)</span>
<span id="cb352-2"><a href="simple-regression.html#cb352-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pizza<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Calories ~ Fat, data = pizza)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -55.44 -11.67   6.18  17.87  41.61 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  194.747     21.605   9.014 7.71e-09 ***
## Fat           10.050      1.558   6.449 1.73e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 25.79 on 22 degrees of freedom
## Multiple R-squared:  0.654,  Adjusted R-squared:  0.6383 
## F-statistic: 41.59 on 1 and 22 DF,  p-value: 1.731e-06</code></pre>
<p>To assess whether this trend is real or just chance, look at the
P-value on the end of the <code>Fat</code> line, or on the bottom line
where the <span class="math inline">\(F\)</span>-statistic is (they are the same value of <span class="math inline">\(1.73\times 10^{-6}\)</span> or 0.0000017, so you can pick either). This P-value is
really small, so the slope is definitely <em>not</em> zero, and
therefore there really is a relationship between the two variables.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Obtain a plot of the residuals against the fitted values
for this regression. Does this indicate that there are any problems
with this regression, or not? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Use the regression object <code>pizza.1</code>:</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="simple-regression.html#cb354-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(pizza<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/pizza-6-1.png" width="672" /></p>
<p>On my residual plot, I see a slight curve in the smooth trend,
but I am not worried about that because the residuals on the plot are
all over the place in a seemingly random pattern (the grey envelope is
wide and that is pretty close to going straight across). So I think a
straight line model is satisfactory.</p>
<p>That’s all you needed, but it is also worth looking at a normal
quantile plot of the residuals:</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="simple-regression.html#cb356-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(pizza<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">sample =</span> .resid)) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/pizza-7-1.png" width="672" /></p>
<p>A bit skewed to the left (the low ones are too low).</p>
<p>Also a plot of the absolute residuals, for assessing fan-out:</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="simple-regression.html#cb357-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(pizza<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> <span class="fu">abs</span>(.resid))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/pizza-8-1.png" width="672" /></p>
<p>A tiny bit of fan-in (residuals getting <em>smaller</em> in size as the
fitted value gets bigger), but nothing much, I think.</p>
<p>Another way of assessing curvedness is to fit a squared term anyway,
and see whether it is significant:</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="simple-regression.html#cb359-1" aria-hidden="true" tabindex="-1"></a>pizza<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">update</span>(pizza<span class="fl">.1</span>, . <span class="sc">~</span> . <span class="sc">+</span> <span class="fu">I</span>(Fat<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb359-2"><a href="simple-regression.html#cb359-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(pizza<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Calories ~ Fat + I(Fat^2), data = pizza)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -62.103 -14.280   5.513  15.423  35.474 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)  90.2544    77.8156   1.160   0.2591  
## Fat          25.9717    11.5121   2.256   0.0349 *
## I(Fat^2)     -0.5702     0.4086  -1.395   0.1775  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 25.25 on 21 degrees of freedom
## Multiple R-squared:  0.6834, Adjusted R-squared:  0.6532 
## F-statistic: 22.66 on 2 and 21 DF,  p-value: 5.698e-06</code></pre>
<p>The fat-squared term is not significant, so that curve on the smooth trend
in the (first) residual plot was indeed nothing to get excited about.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>The research assistant in this study returns with two
new brands of pizza (ones that were not in the original data). The
fat content of a 5-ounce serving was 12 grams for the first brand
and 20 grams for the second brand. For each of these brands of
pizza, obtain a suitable 95% interval for the number of calories
contained in a 5-ounce serving.</li>
</ol>
<p>Solution</p>
<p>The suitable interval here is a prediction interval, because we
are interested in each case in the calorie content of the
<em>particular</em> pizza brands that the research assistant
returned with (and not, for example, in the mean calorie content
for <em>all</em> brands of pizza that have 12 grams of fat per
serving). Thus:</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="simple-regression.html#cb361-1" aria-hidden="true" tabindex="-1"></a>newfat <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">12</span>, <span class="dv">20</span>)</span>
<span id="cb361-2"><a href="simple-regression.html#cb361-2" aria-hidden="true" tabindex="-1"></a>new <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Fat =</span> newfat)</span>
<span id="cb361-3"><a href="simple-regression.html#cb361-3" aria-hidden="true" tabindex="-1"></a>new</span></code></pre></div>
<pre><code>## # A tibble: 2 × 1
##     Fat
##   &lt;dbl&gt;
## 1    12
## 2    20</code></pre>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="simple-regression.html#cb363-1" aria-hidden="true" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(pizza<span class="fl">.1</span>, new, <span class="at">interval =</span> <span class="st">&quot;p&quot;</span>)</span>
<span id="cb363-2"><a href="simple-regression.html#cb363-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(new, preds)</span></code></pre></div>
<pre><code>##   Fat      fit      lwr      upr
## 1  12 315.3447 260.5524 370.1369
## 2  20 395.7431 337.1850 454.3011</code></pre>
<p>Use <code>datagrid</code> to make <code>new</code> if you like, but it is a very simple dataframe, so there is no obligation to do it that way.</p>
<p>Or, if you like:</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="simple-regression.html#cb365-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as_tibble</span>(preds) <span class="sc">%&gt;%</span> <span class="fu">bind_cols</span>(new) <span class="sc">%&gt;%</span> <span class="fu">select</span>(Fat, <span class="fu">everything</span>())</span></code></pre></div>
<pre><code>## # A tibble: 2 × 4
##     Fat   fit   lwr   upr
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    12  315.  261.  370.
## 2    20  396.  337.  454.</code></pre>
<p>For the pizza with 12 grams of fat, the predicted calories are between
261 and 370 with 95% confidence, and for the pizza with 20 grams of
fat, the calories are predicted to be between 337 and 454. (You should
write down what these intervals are, and not leave the reader to find
them in the output.)</p>
<p>(Remember the steps: create a new data frame containing the values to
predict for, and then feed that into <code>predict</code> along with the
model that you want to use to predict with. The variable in the data
frame has to be called <em>precisely</em> <code>Fat</code> with a capital F,
otherwise it won’t work.)</p>
<p>These intervals are both pretty awful: you get a very weak picture of
how many calories per serving the pizza brands in question might
contain. This is for two reasons: (i) there was a fair bit of scatter
in the original relationship, R-squared being around 65%, and (ii)
even if we knew perfectly where the line went (which we don’t),
there’s no guarantee that individual brands of pizza would be on it
anyway. (Prediction intervals are always hit by this double whammy, in
that individual observations suffer from variability in where the line
goes <em>and</em> variability around whatever the line is.)</p>
<p>I was expecting, when I put together this question, that the
20-grams-of-fat interval would be noticeably worse, because 20 is
farther away from the mean fat content of all the brands. But there
isn’t much to choose. For the confidence intervals for the mean
calories of <em>all</em> brands with these fat contents, the picture is clearer:</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="simple-regression.html#cb367-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_cap</span>(pizza<span class="fl">.1</span>, <span class="at">condition =</span> <span class="st">&quot;Fat&quot;</span>)</span></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>A <code>fat</code> value of 12 is close to the middle of the data, so the interval is shorter, but a value of 20 is out near the extreme and the interval is noticeably longer.</p>
<p>This part was a fair bit of work for 3 points, so I’m not insisting that you explain
your choice of a prediction interval over a confidence interval, but I
think it is still a smart thing to do, even purely from a marks point
of view, because if you get it wrong for a semi-plausible reason, you
might pick up some partial credit. Not pulling out your prediction
intervals from your output is a sure way to lose a point, however.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="where-should-the-fire-stations-be-1" class="section level2 hasAnchor" number="18.26">
<h2><span class="header-section-number">18.26</span> Where should the fire stations be?<a href="simple-regression.html#where-should-the-fire-stations-be-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In city planning, one major issue is where to locate fire
stations. If a city has too many fire stations, it will spend too much
on running them, but if it has too few, there may be unnecessary fire
damage because the fire trucks take too long to get to the fire.</p>
<p>The first part of a study of this kind of issue is to understand the
relationship between the distance from the fire station (measured in
miles in our data set) and the amount of fire damage caused (measured
in thousands of dollars). A city recorded the fire damage and distance
from fire station for 15 residential fires (which you can take as a
sample of “all possible residential fires in that city”). The data
are in <a href="http://ritsokiguess.site/datafiles/fire_damage.txt">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display the data, verifying that you have the
right number of rows and the right columns.</li>
</ol>
<p>Solution</p>
<p>A quick check of the data reveals that the data values are
separated by exactly one space, so:</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="simple-regression.html#cb368-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/fire_damage.txt&quot;</span></span>
<span id="cb368-2"><a href="simple-regression.html#cb368-2" aria-hidden="true" tabindex="-1"></a>fire <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 15 Columns: 2
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot; &quot;
## dbl (2): distance, damage
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="simple-regression.html#cb370-1" aria-hidden="true" tabindex="-1"></a>fire</span></code></pre></div>
<pre><code>## # A tibble: 15 × 2
##    distance damage
##       &lt;dbl&gt;  &lt;dbl&gt;
##  1      3.4   26.2
##  2      1.8   17.8
##  3      4.6   31.3
##  4      2.3   23.1
##  5      3.1   27.5
##  6      5.5   36  
##  7      0.7   14.1
##  8      3     22.3
##  9      2.6   19.6
## 10      4.3   31.3
## 11      2.1   24  
## 12      1.1   17.3
## 13      6.1   43.2
## 14      4.8   36.4
## 15      3.8   26.1</code></pre>
<p>15 observations (rows), and promised, and a column each of distances
and amounts of fire damage, also as promised.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li><a name="part:ttest">*</a> Obtain a 95% confidence interval for the
mean fire damage. (There is nothing here from STAD29, and your
answer should have nothing to do with distance.)</li>
</ol>
<p>Solution</p>
<p>I wanted to dissuade you from thinking too hard here. It’s just
an ordinary one-sample <span class="math inline">\(t\)</span>-test, extracting the interval from it:</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="simple-regression.html#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(fire<span class="sc">$</span>damage)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  fire$damage
## t = 12.678, df = 14, p-value = 4.605e-09
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  21.94488 30.88178
## sample estimates:
## mean of x 
##  26.41333</code></pre>
<p>Or</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="simple-regression.html#cb374-1" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(fire, <span class="fu">t.test</span>(damage))</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  damage
## t = 12.678, df = 14, p-value = 4.605e-09
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  21.94488 30.88178
## sample estimates:
## mean of x 
##  26.41333</code></pre>
<p>Ignore the P-value (it’s testing that the mean is the default
<em>zero</em>, which makes no sense). The confidence interval either way
goes from 21.9 to 30.9 (thousand dollars).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Draw a scatterplot for predicting the amount of fire damage
from the distance from the fire station. Add a smooth trend to your
plot.</li>
</ol>
<p>Solution</p>
<p>We are predicting fire damage, so that goes on the <span class="math inline">\(y\)</span>-axis:</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="simple-regression.html#cb376-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fire, <span class="fu">aes</span>(<span class="at">x =</span> distance, <span class="at">y =</span> damage)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/riemer-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li><a name="part:howgood">*</a> Is there a relationship between distance from fire station
and fire damage? Is it linear or definitely curved? How strong is
it? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>When the distance is larger, the fire damage is definitely larger,
so there is clearly a relationship. I would call this one
approximately linear: it wiggles a bit, but it is not to my mind
obviously curved. I would also call it a strong relationship,
since the points are close to the smooth trend.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Fit a regression predicting fire damage from distance. How
is the R-squared consistent (or inconsistent) with your answer from
part~(<a href="#part:howgood">here</a>)?</li>
</ol>
<p>Solution</p>
<p>The regression is an ordinary <code>lm</code>:</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="simple-regression.html#cb378-1" aria-hidden="true" tabindex="-1"></a>damage<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(damage <span class="sc">~</span> distance, <span class="at">data =</span> fire)</span>
<span id="cb378-2"><a href="simple-regression.html#cb378-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(damage<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = damage ~ distance, data = fire)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4682 -1.4705 -0.1311  1.7915  3.3915 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  10.2779     1.4203   7.237 6.59e-06 ***
## distance      4.9193     0.3927  12.525 1.25e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.316 on 13 degrees of freedom
## Multiple R-squared:  0.9235, Adjusted R-squared:  0.9176 
## F-statistic: 156.9 on 1 and 13 DF,  p-value: 1.248e-08</code></pre>
<p>We need to display the results, since we need to see the R-squared in
order to say something about it.</p>
<p>R-squared is about 92%, high, indicating a strong and linear
relationship. Back in part~(<a href="#part:howgood">here</a>), I said that the
relationship is linear and strong, which is entirely consistent with
such an R-squared. (If you said something different previously, say
how it does or doesn’t square with this kind of R-squared value.)</p>
<p>Points: one for fitting the regression, one for displaying it, and two
(at the grader’s discretion) for saying what the R-squared is and how
it’s consistent (or not) with part~(<a href="#part:howgood">here</a>).</p>
<p>Extra: if you thought the trend was “definitely curved”, you would
find that a parabola (or some other kind of curve) was definitely
better than a straight line. Here’s the parabola:</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="simple-regression.html#cb380-1" aria-hidden="true" tabindex="-1"></a>damage<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(damage <span class="sc">~</span> distance <span class="sc">+</span> <span class="fu">I</span>(distance<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> fire)</span>
<span id="cb380-2"><a href="simple-regression.html#cb380-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(damage<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = damage ~ distance + I(distance^2), data = fire)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8856 -1.6915 -0.0179  1.5490  3.6278 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    13.3395     2.5303   5.272 0.000197 ***
## distance        2.6400     1.6302   1.619 0.131327    
## I(distance^2)   0.3376     0.2349   1.437 0.176215    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.227 on 12 degrees of freedom
## Multiple R-squared:  0.9347, Adjusted R-squared:  0.9238 
## F-statistic: 85.91 on 2 and 12 DF,  p-value: 7.742e-08</code></pre>
<p>There’s no evidence here that a quadratic is better.</p>
<p>Or you might even have thought from the wiggles that it was more like cubic:</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="simple-regression.html#cb382-1" aria-hidden="true" tabindex="-1"></a>damage<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">update</span>(damage<span class="fl">.2</span>, . <span class="sc">~</span> . <span class="sc">+</span> <span class="fu">I</span>(distance<span class="sc">^</span><span class="dv">3</span>))</span>
<span id="cb382-2"><a href="simple-regression.html#cb382-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(damage<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = damage ~ distance + I(distance^2) + I(distance^3), 
##     data = fire)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.2325 -1.8377  0.0322  1.1512  3.1806 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)    10.8466     4.3618   2.487   0.0302 *
## distance        5.9555     4.9610   1.200   0.2552  
## I(distance^2)  -0.8141     1.6409  -0.496   0.6296  
## I(distance^3)   0.1141     0.1608   0.709   0.4928  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.274 on 11 degrees of freedom
## Multiple R-squared:  0.9376, Adjusted R-squared:  0.9205 
## F-statistic: 55.07 on 3 and 11 DF,  p-value: 6.507e-07</code></pre>
<p>No evidence that a cubic is better; that increase in R-squared up to
about 94% is just chance (bearing in mind that adding <em>any</em> <span class="math inline">\(x\)</span>,
even a useless one, will increase R-squared).</p>
<p>How bendy is the cubic?</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="simple-regression.html#cb384-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(fire, <span class="fu">aes</span>(<span class="at">x =</span> distance, <span class="at">y =</span> damage)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb384-2"><a href="simple-regression.html#cb384-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb384-3"><a href="simple-regression.html#cb384-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> damage<span class="fl">.3</span>, <span class="fu">aes</span>(<span class="at">y =</span> .fitted), <span class="at">colour =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/ganter-1.png" width="672" /></p>
<p>The cubic, in red, does bend a little, but it doesn’t do an obvious
job of going through the points better than the straight line does. It
seems to be mostly swayed by that one observation with damage over 40,
and choosing a relationship by how well it fits one point is flimsy at
the best of times. So, by Occam’s Razor, we go with the line rather
than the cubic because it (i) fits equally well, (ii) is simpler.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li><a name="part:cim"><em></a> Obtain a 95% confidence interval for the mean fire damage
</em>for a residence that is 4 miles from the nearest fire station*.
(Note the contrast with part~(<a href="#part:ttest">here</a>).)</li>
</ol>
<p>Solution</p>
<p>This is a confidence interval for a mean response at a given value
of the explanatory variable. This is as opposed to
part~(<a href="#part:ttest">here</a>), which is averaged over <em>all</em> distances.
So, follow the steps. Make a tiny data frame with this one value
of <code>distance</code>:</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="simple-regression.html#cb386-1" aria-hidden="true" tabindex="-1"></a>new <span class="ot">&lt;-</span> <span class="fu">datagrid</span>(<span class="at">model =</span> damage<span class="fl">.1</span>, <span class="at">distance =</span> <span class="dv">4</span>)</span>
<span id="cb386-2"><a href="simple-regression.html#cb386-2" aria-hidden="true" tabindex="-1"></a>new</span></code></pre></div>
<pre><code>##    distance
## 1:        4</code></pre>
<p>and then</p>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="simple-regression.html#cb388-1" aria-hidden="true" tabindex="-1"></a>pp <span class="ot">&lt;-</span> <span class="fu">predictions</span>(damage<span class="fl">.1</span>, <span class="at">newdata =</span> new)</span>
<span id="cb388-2"><a href="simple-regression.html#cb388-2" aria-hidden="true" tabindex="-1"></a>pp</span></code></pre></div>
<pre><code>##   rowid     type predicted std.error conf.low conf.high distance
## 1     1 response  29.95525 0.6615595 28.52604  31.38446        4</code></pre>
<p>28.5 to 31.4 (thousand dollars).</p>
<p>(I saved this one because I want to refer to it again later.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Compare the confidence intervals of parts
(<a href="#part:ttest">here</a>) and (<a href="#part:cim">here</a>). Specifically, compare their
centres and their lengths, and explain briefly why the results
make sense.</li>
</ol>
<p>Solution</p>
<p>Let me just put them side by side for ease of comparison:
part~(<a href="#part:ttest">here</a>) is:</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="simple-regression.html#cb390-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(fire<span class="sc">$</span>damage)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  fire$damage
## t = 12.678, df = 14, p-value = 4.605e-09
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  21.94488 30.88178
## sample estimates:
## mean of x 
##  26.41333</code></pre>
<p>and part~(<a href="#part:cim">here</a>)’s is</p>
<div class="sourceCode" id="cb392"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb392-1"><a href="simple-regression.html#cb392-1" aria-hidden="true" tabindex="-1"></a>pp</span></code></pre></div>
<pre><code>##   rowid     type predicted std.error conf.low conf.high distance
## 1     1 response  29.95525 0.6615595 28.52604  31.38446        4</code></pre>
<p>The centre of the interval is higher for the mean damage when the
distance is 4. This is because the mean distance is a bit less than 4:</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="simple-regression.html#cb394-1" aria-hidden="true" tabindex="-1"></a>fire <span class="sc">%&gt;%</span> <span class="fu">summarize</span>(<span class="at">m =</span> <span class="fu">mean</span>(distance))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 1
##       m
##   &lt;dbl&gt;
## 1  3.28</code></pre>
<p>We know it’s an upward trend, so our best guess at the mean damage is
higher if the mean distance is higher (in (<a href="#part:cim">here</a>), the
distance is <em>always</em> 4: we’re looking at the mean fire damage for
<em>all</em> residences that are 4 miles from a fire station.)</p>
<p>What about the lengths of the intervals? The one in (<a href="#part:ttest">here</a>)
is about <span class="math inline">\(30.9-21.9=9\)</span> (thousand dollars) long, but the one in
(<a href="#part:cim">here</a>) is only <span class="math inline">\(31.4-28.5=2.9\)</span> long, much shorter. This
makes sense because the relationship is a strong one: knowing the
distance from the fire station is very useful, because the bigger it
is, the bigger the damage going to be, with near certainty. Said
differently, if you know the distance, you can estimate the damage
accurately. If you don’t know the distance (as is the case in
(<a href="#part:ttest">here</a>)), you’re averaging over a lot of different
distances and thus there is a lot of uncertainty in the amount of fire
damage also.</p>
<p>If you have some reasonable discussion of the reason why the centres
and lengths of the intervals differ, I’m happy. It doesn’t have to be
the same as mine.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="making-it-stop-1" class="section level2 hasAnchor" number="18.27">
<h2><span class="header-section-number">18.27</span> Making it stop<a href="simple-regression.html#making-it-stop-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If you are driving, and you hit the brakes, how far do you travel before coming to a complete stop?
Presumably this depends on how fast you are going.
Knowing this relationship is important in setting speed limits on roads. For example, on a very bendy road, the speed limit needs to be low, because you cannot see very far ahead, and there could be something just
out of sight that you need to stop for.</p>
<p>Data were collected for a typical car and driver, as shown in <a href="http://ritsokiguess.site/datafiles/stopping.csv">http://ritsokiguess.site/datafiles/stopping.csv</a>. These are American data, so the speeds are miles per hour and the stopping distances are in feet.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display (probably all of) the data.</li>
</ol>
<p>Solution</p>
<p>The usual:</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="simple-regression.html#cb396-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/stopping.csv&quot;</span></span>
<span id="cb396-2"><a href="simple-regression.html#cb396-2" aria-hidden="true" tabindex="-1"></a>stopping <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(my_url)</span></code></pre></div>
<pre><code>## Rows: 8 Columns: 2
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## dbl (2): speed, distance
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="simple-regression.html#cb398-1" aria-hidden="true" tabindex="-1"></a>stopping</span></code></pre></div>
<pre><code>## # A tibble: 8 × 2
##   speed distance
##   &lt;dbl&gt;    &lt;dbl&gt;
## 1     0        0
## 2    10       20
## 3    20       50
## 4    30       95
## 5    40      150
## 6    50      220
## 7    60      300
## 8    70      400</code></pre>
<p>There are only eight observations.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a suitable plot of the data.</li>
</ol>
<p>Solution</p>
<p>Two quantitative variables means a scatterplot. Stopping distance is the outcome, so that goes on the <span class="math inline">\(y\)</span>-axis:</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="simple-regression.html#cb400-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(stopping, <span class="fu">aes</span>(<span class="at">x=</span>speed, <span class="at">y=</span>distance)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/braking-2-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Describe any trend you see in your graph.</li>
</ol>
<p>Solution</p>
<p>It’s an upward trend, but not linear: the stopping distance seems to increase faster at higher speeds.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a linear regression predicting stopping distance from speed. (You might have some misgivings about doing this, but do it anyway.)</li>
</ol>
<p>Solution</p>
<p>Having observed a curved relationship, it seems odd to fit a straight line. But we are going to do it anyway and then critique what we have:</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="simple-regression.html#cb401-1" aria-hidden="true" tabindex="-1"></a>stopping<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance<span class="sc">~</span>speed, <span class="at">data=</span>stopping)</span>
<span id="cb401-2"><a href="simple-regression.html#cb401-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(stopping<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = distance ~ speed, data = stopping)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -32.738 -22.351  -7.738  16.622  47.083 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -44.1667    22.0821   -2.00   0.0924 .  
## speed         5.6726     0.5279   10.75 3.84e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 34.21 on 6 degrees of freedom
## Multiple R-squared:  0.9506, Adjusted R-squared:  0.9424 
## F-statistic: 115.5 on 1 and 6 DF,  p-value: 3.837e-05</code></pre>
<p>Extra: note that R-squared is actually really high. We come back to that later.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Plot the residuals against the fitted values for this regression.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="simple-regression.html#cb403-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(stopping<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/braking-4-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>What do you learn from the residual plot? Does that surprise you? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The points on the residual plot form a (perfect) curve, so the original relationship was a curve. This is exactly what we saw on the scatterplot, so to me at least, this is no surprise.</p>
<p>(Make sure you say <em>how you know</em> that the original relationship was a curve from looking at the residual plot. Joined-up thinking.
There are <em>two</em> ways we know that the relationship is a curve. Get them both.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>What is the actual relationship between stopping distance and speed, according to the physics? See if you can find out. Cite any books or websites that you use: that is, include a link to a website, or give enough information about a book that the grader could find it.</li>
</ol>
<p>Solution</p>
<p>I searched for “braking distance and speed” and found the first two things below, that seemed to be useful. Later, I was thinking about the fourth point (which came out of my head) and while searching for other things about that, I found the third thing:</p>
<ul>
<li>a <a href="https://www.brake.org.uk/info-and-resources/facts-advice-research/road-safety-facts/15-facts-a-resources/facts/1255-speed">British road safety website</a>, that says “The braking distance depends on how fast the vehicle was travelling before the brakes were applied, and is proportional to the square of the initial speed.”</li>
<li>the <a href="https://en.wikipedia.org/wiki/Braking_distance">Wikipedia article on braking distance</a>, which gives the actual formula. This is the velocity squared, divided by a constant that depends on the coefficient of friction. (That is why your driving instructor tells you to leave a bigger gap behind the vehicle in front if it is raining, and an even bigger gap if it is icy.)</li>
<li>an <a href="http://www.amsi.org.au/teacher_modules/pdfs/Maths_delivers/Braking5.pdf">Australian math booklet</a> that talks specifically about braking distance and derives the formula (and the other equations of motion).</li>
<li>also, if you have done physics, you might remember the equation of motion <span class="math inline">\(v^2 = u^2 + 2as\)</span>, where <span class="math inline">\(u\)</span> is the initial velocity, <span class="math inline">\(v\)</span> is the final velocity, <span class="math inline">\(a\)</span> is the acceleration and <span class="math inline">\(s\)</span> is the distance covered. In this case, <span class="math inline">\(v=0\)</span> (the car is stationary at the end), and so <span class="math inline">\(-u^2/2a = s\)</span>. The acceleration is negative (the car is slowing down), so the left side is, despite appearances, positive. There seems to be a standard assumption that deceleration due to braking is constant (the same for all speeds), at least if you are trying to stop a car in a hurry.</li>
</ul>
<p>These are all saying that we should add a speed-squared term to our regression, and then we will have the relationship exactly right, according to the physics.</p>
<p>Extra: Another way to measure how far you are behind the vehicle in front is time.
Many of the British “motorways” (think 400-series highways) were built when I was young, and I remember <a href="https://www.youtube.com/watch?v=mf5d2DP4Pp0">a TV commercial</a> that said “Only a Fool Breaks the Two Second Rule”.<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a> In those days (the linked one is from the 1970s),<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a> a lot of British drivers were not used to going that fast, or on roads that straight, so this was a way to know how big a gap to leave, so that you had time to take evasive action if needed. The value of the two-second rule is that it works for any speed, and you don’t have to remember a bunch of stopping distances. (When I did my (Canadian) driving theory test, I think I worked out and learned a formula for the stopping distances that I could calculate in my head. I didn’t have to get very close since the test was multiple-choice.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Fit the relationship that your research indicated (in the previous part) and display the results. Comment briefly on the R-squared value.</li>
</ol>
<p>Solution</p>
<p>Add a squared term in <code>speed</code>:</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="simple-regression.html#cb404-1" aria-hidden="true" tabindex="-1"></a>stopping<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance<span class="sc">~</span>speed<span class="sc">+</span><span class="fu">I</span>(speed<span class="sc">^</span><span class="dv">2</span>), <span class="at">data=</span>stopping)</span>
<span id="cb404-2"><a href="simple-regression.html#cb404-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(stopping<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = distance ~ speed + I(speed^2), data = stopping)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
## -1.04167  0.98214  0.08929  1.27976 -0.44643 -0.08929 -2.64881  1.87500 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 1.041667   1.429997   0.728    0.499    
## speed       1.151786   0.095433  12.069 6.89e-05 ***
## I(speed^2)  0.064583   0.001311  49.267 6.51e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.699 on 5 degrees of freedom
## Multiple R-squared:  0.9999, Adjusted R-squared:  0.9999 
## F-statistic: 2.462e+04 on 2 and 5 DF,  p-value: 1.039e-10</code></pre>
<p>The R-squared now is basically 1, so that the model fits very close to perfectly.</p>
<p>Extra: you probably found in your research that the distance should be just something times speed squared, with no constant or linear term. Here, though, we have a significant linear term as well.
That is probably just chance, since the distances in the data look as if they have been rounded off. With more accurate values, I think the linear term would have been closer to zero.</p>
<p>If you want to go literally for the something-times-speed-squared, you can do that. This doesn’t quite work:</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="simple-regression.html#cb406-1" aria-hidden="true" tabindex="-1"></a>stopping<span class="fl">.3</span>x <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance<span class="sc">~</span><span class="fu">I</span>(speed<span class="sc">^</span><span class="dv">2</span>), <span class="at">data=</span>stopping)</span>
<span id="cb406-2"><a href="simple-regression.html#cb406-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(stopping<span class="fl">.3</span>x)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = distance ~ I(speed^2), data = stopping)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.7327  -3.4670   0.6761   6.2323   8.4513 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 14.732704   4.362859   3.377   0.0149 *  
## I(speed^2)   0.079796   0.001805  44.218 8.96e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 8.514 on 6 degrees of freedom
## Multiple R-squared:  0.9969, Adjusted R-squared:  0.9964 
## F-statistic:  1955 on 1 and 6 DF,  p-value: 8.958e-09</code></pre>
<p>because it still has an intercept in it. In R, the intercept is denoted by <code>1</code>. It is always included, unless you explicitly remove it. Some odd things start to happen if you remove the intercept, so it is not a good thing to do unless you know what you are doing. The answers <a href="https://stats.stackexchange.com/questions/7948/when-is-it-ok-to-remove-the-intercept-in-a-linear-regression-model">here</a> have some good discussion. Having decided that you <em>are</em> going to remove the intercept,
you can remove it the same way as anything else (see <code>update</code> in the multiple regression lecture) with “minus”. I haven’t shown you this, so if you do it, you will need to cite your source: that is, say where you learned what to do:</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="simple-regression.html#cb408-1" aria-hidden="true" tabindex="-1"></a>stopping<span class="fl">.3</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(distance<span class="sc">~</span><span class="fu">I</span>(speed<span class="sc">^</span><span class="dv">2</span>)<span class="sc">-</span><span class="dv">1</span>, <span class="at">data=</span>stopping)</span>
<span id="cb408-2"><a href="simple-regression.html#cb408-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(stopping<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = distance ~ I(speed^2) - 1, data = stopping)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.6123  -0.7859  10.5314  15.5314  19.2141 
## 
## Coefficients:
##            Estimate Std. Error t value Pr(&gt;|t|)    
## I(speed^2) 0.084207   0.001963   42.89 9.77e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 13.42 on 7 degrees of freedom
## Multiple R-squared:  0.9962, Adjusted R-squared:  0.9957 
## F-statistic:  1840 on 1 and 7 DF,  p-value: 9.772e-10</code></pre>
<p>The R-squared is still extremely high, much higher than for the straight line. The coefficient value, as I said earlier (citing Wikipedia), depends on the coefficient of friction; the stopping distances you see typically are based on a dry road, so you have to allow extra distance (or time: see above) if the road is not dry.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol style="list-style-type: lower-roman">
<li>Somebody says to you “if you have a regression with a high R-squared, like 95%, there is no need to look for a better model.” How do you respond to this? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>An example of a regression with an R-squared of 95% is the straight-line fit from earlier in this question. This is an example of a regression that fits well but is not appropriate because it doesn’t capture the form of the relationship.</p>
<p>In general, we are saying that no matter how high R-squared is, we might still be able to improve on the model we have. The flip side is that we might not be able to do any better (with another data set) than an R-squared of, say, 30%, because there is a lot of variability that is, as best as we can assess it, random and not explainable by anything.</p>
<p>Using R-squared as a measure of absolute model quality is, thus, a mistake. Or, to say it perhaps more clearly, asking “how high does R-squared have to be to indicate a good fit?” is asking the wrong question.
The right thing to do is to concentrate on getting the form of the model right, and thereby get the R-squared as high as we can for that data set (which might be very high, as here, or not high at all).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="predicting-height-from-foot-length-1" class="section level2 hasAnchor" number="18.28">
<h2><span class="header-section-number">18.28</span> Predicting height from foot length<a href="simple-regression.html#predicting-height-from-foot-length-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Is it possible to estimate the height of a person from the length of their foot? To find out, 33 (male) students had their height and foot length measured. The data are in
<a href="http://ritsokiguess.site/datafiles/heightfoot.csv">http://ritsokiguess.site/datafiles/heightfoot.csv</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display (some of) the data. (If you are having trouble, make sure you have <em>exactly</em> the right URL. The correct URL has no spaces or other strange characters in it.)</li>
</ol>
<p>Solution</p>
<p>The usual:</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="simple-regression.html#cb410-1" aria-hidden="true" tabindex="-1"></a>my_url <span class="ot">&lt;-</span> <span class="st">&quot;http://ritsokiguess.site/datafiles/heightfoot.csv&quot;</span></span>
<span id="cb410-2"><a href="simple-regression.html#cb410-2" aria-hidden="true" tabindex="-1"></a>hf <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(my_url)</span></code></pre></div>
<pre><code>## Rows: 33 Columns: 2
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## dbl (2): height, foot
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="simple-regression.html#cb412-1" aria-hidden="true" tabindex="-1"></a>hf</span></code></pre></div>
<pre><code>## # A tibble: 33 × 2
##    height  foot
##     &lt;dbl&gt; &lt;dbl&gt;
##  1   66.5  27  
##  2   73.5  29  
##  3   70    25.5
##  4   71    27.9
##  5   73    27  
##  6   71    26  
##  7   71    29  
##  8   69.5  27  
##  9   73    29  
## 10   71    27  
## # … with 23 more rows</code></pre>
<p>Call the data frame whatever you like, but keeping away from the names <code>height</code> and <code>foot</code> is probably wise, since those are the names of the columns.</p>
<p>There are indeed 33 rows as promised.</p>
<p>Extra: my comment in the question was to help you if you copy-pasted the file URL into R Studio. Depending on your setup, this might have gotten pasted with a space in it, at the point where it is split over two lines. The <em>best</em> way to proceed, one that won’t run into this problem, is to <em>right</em>-click on the URL and select Copy Link Address (or the equivalent on your system), and then it will put the whole URL on the clipboard in one piece, even if it is split over two lines in the original document, so that pasting it will work without problems.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a suitable plot of the two variables in the data frame.</li>
</ol>
<p>Solution</p>
<p>They are both quantitative, so a scatter plot is called for:</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="simple-regression.html#cb414-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hf, <span class="fu">aes</span>(<span class="at">y=</span>height, <span class="at">x=</span>foot)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/heightfoot-2-1.png" width="672" /></p>
<p>I added a smooth trend, or you could just plot the points. (This is better than plotting a regression line at this stage, because we haven’t yet thought about whether the trend is straight.)</p>
<p>Now that we’ve seen the scatterplot, the trend looks more or less straight (but you should take a look at the scatterplot first, with or without smooth trend, before you put a regression line on it). That point top left is a concern, though, which brings us to…</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Are there any observations not on the trend of the other points? What is unusual about those observations?</li>
</ol>
<p>Solution</p>
<p>The observation with height greater than 80 at the top of the graph looks like an outlier and does not follow the trend of the rest of the points. Or, this individual is much taller than you would expect for someone with a foot length of 27 inches. Or, this person is over 7 feet tall, which makes little sense as a height. Say something about what makes this person be off the trend.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a regression predicting height from foot length, <em>including</em> any observations that you identified in the previous part. For that regression, plot the residuals against the fitted values and make a normal quantile plot of the residuals.</li>
</ol>
<p>Solution</p>
<p>These things. Displaying the <code>summary</code> of the regression is optional, but gives the grader an opportunity to check that your work is all right so far.</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="simple-regression.html#cb416-1" aria-hidden="true" tabindex="-1"></a>hf<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(height<span class="sc">~</span>foot, <span class="at">data=</span>hf)</span>
<span id="cb416-2"><a href="simple-regression.html#cb416-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hf<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = height ~ foot, data = hf)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.7491 -1.3901 -0.0310  0.8918 12.9690 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  34.3363     9.9541   3.449 0.001640 ** 
## foot          1.3591     0.3581   3.795 0.000643 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.102 on 31 degrees of freedom
## Multiple R-squared:  0.3173, Adjusted R-squared:  0.2952 
## F-statistic: 14.41 on 1 and 31 DF,  p-value: 0.0006428</code></pre>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="simple-regression.html#cb418-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hf<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/heightfoot-3-1.png" width="672" /></p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="simple-regression.html#cb419-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hf<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">sample=</span>.resid)) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/heightfoot-3-2.png" width="672" /></p>
<p>Note that we did not exclude the off-trend point. Removing points <em>because they are outliers</em> is a <strong>bad</strong> idea. <a href="https://statisticsbyjim.com/basics/remove-outliers/">This</a> is a good discussion of the issues.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Earlier, you identified one or more observations that were off the trend. How does this point or points show up on each of the plots you drew in the previous part?</li>
</ol>
<p>Solution</p>
<p>On its own at the top in both cases; the large positive residual on the first plot, and the unusually large value at the top right of the normal quantile plot. (You need to say one thing about each graph, or say as I did that the same kind of thing happens on both graphs.)</p>
<p>Extra: in the residuals vs. fitted values, the other residuals show a slight upward trend. This is because the regression line for these data, with the outlier, is pulled (slightly) closer to the outlier and thus slightly further away from the other points, particularly the ones on the left, compared to the same data but with the outlier removed (which you will be seeing shortly). If the unusual point had happened to have an extreme <span class="math inline">\(x\)</span> (foot length) as well, the effect would have been more pronounced.</p>
<p>This is the kind of thing I mean (made-up data):</p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="simple-regression.html#cb420-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb420-2"><a href="simple-regression.html#cb420-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">10</span><span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>x, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb420-3"><a href="simple-regression.html#cb420-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">ifelse</span>(x <span class="sc">==</span> <span class="dv">9</span>, <span class="dv">40</span>, y)) <span class="ot">-&gt;</span> madeup</span>
<span id="cb420-4"><a href="simple-regression.html#cb420-4" aria-hidden="true" tabindex="-1"></a>madeup</span></code></pre></div>
<pre><code>## # A tibble: 10 × 2
##        x     y
##    &lt;int&gt; &lt;dbl&gt;
##  1     1  13.6
##  2     2  13.3
##  3     3  15.7
##  4     4  17.3
##  5     5  20.2
##  6     6  22.7
##  7     7  22.9
##  8     8  26.8
##  9     9  40  
## 10    10  31.1</code></pre>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="simple-regression.html#cb422-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(madeup, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/heightfoot-6-1.png" width="672" /></p>
<p>The second-last point is off a clearly linear trend otherwise (the smooth gets “distracted” by the outlying off-trend point). Fitting a regression anyway and looking at the residual plot gives this:</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="simple-regression.html#cb424-1" aria-hidden="true" tabindex="-1"></a>madeup<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>x, <span class="at">data =</span> madeup)</span>
<span id="cb424-2"><a href="simple-regression.html#cb424-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(madeup<span class="fl">.1</span>, <span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/heightfoot-7-1.png" width="672" /></p>
<p>This time you see a rather more obvious downward trend in the other residuals. The problem is not with them, but with the one very positive residual, corresponding to the outlier that is way off the trend on the scatterplot.</p>
<p>The residuals in a regression have to add up to zero. If one of them is very positive (as in the one you did and the example I just showed you), at least some of the other residuals have to become more negative to compensate – the ones on the right just above and the ones on the left in the one you did. If you have done STAC67, you will have some kind of sense of why that is: think about the two equations you have to solve to get the estimates of intercept and slope, and how they are related to the residuals. Slide 6 of <a href="https://statweb.stanford.edu/~jtaylo/courses/stats203/notes/introduction.pdf">this</a> shows them; at the least squares estimates, these two partial derivatives both have to be zero, and the things inside the brackets are the residuals.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Any data points that concerned you earlier were actually errors.
Create and save a new data frame that does not contain any of those data points.</li>
</ol>
<p>Solution</p>
<p>Find a way to not pick that outlying point. For example, you can choose the observations with height less than 80:</p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="simple-regression.html#cb425-1" aria-hidden="true" tabindex="-1"></a>hf <span class="sc">%&gt;%</span> <span class="fu">filter</span>(height<span class="sc">&lt;</span><span class="dv">80</span>) <span class="ot">-&gt;</span> hfx</span>
<span id="cb425-2"><a href="simple-regression.html#cb425-2" aria-hidden="true" tabindex="-1"></a>hfx</span></code></pre></div>
<pre><code>## # A tibble: 32 × 2
##    height  foot
##     &lt;dbl&gt; &lt;dbl&gt;
##  1   66.5  27  
##  2   73.5  29  
##  3   70    25.5
##  4   71    27.9
##  5   73    27  
##  6   71    26  
##  7   71    29  
##  8   69.5  27  
##  9   73    29  
## 10   71    27  
## # … with 22 more rows</code></pre>
<p>Only 32 rows left.</p>
<p>There are many other possibilities. Find one.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Run a regression predicting height from foot length for your data set without errors. Obtain a plot of the residuals against fitted values and a normal quantile plot of the residuals for this regression.</li>
</ol>
<p>Solution</p>
<p>Code-wise, the same as before, but with the new data set:</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="simple-regression.html#cb427-1" aria-hidden="true" tabindex="-1"></a>hf<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>(height<span class="sc">~</span>foot, <span class="at">data=</span>hfx)</span>
<span id="cb427-2"><a href="simple-regression.html#cb427-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hf<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = height ~ foot, data = hfx)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5097 -1.0158  0.4757  1.1141  3.9951 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  30.1502     6.5411   4.609 7.00e-05 ***
## foot          1.4952     0.2351   6.360 5.12e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.029 on 30 degrees of freedom
## Multiple R-squared:  0.5741, Adjusted R-squared:  0.5599 
## F-statistic: 40.45 on 1 and 30 DF,  p-value: 5.124e-07</code></pre>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="simple-regression.html#cb429-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hf<span class="fl">.2</span>, <span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/heightfoot-9-1.png" width="672" /></p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="simple-regression.html#cb430-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hf<span class="fl">.2</span>, <span class="fu">aes</span>(<span class="at">sample=</span>.resid)) <span class="sc">+</span> <span class="fu">stat_qq</span>() <span class="sc">+</span> <span class="fu">stat_qq_line</span>()</span></code></pre></div>
<p><img src="pasias_files/figure-html/heightfoot-9-2.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Do you see any problems on the plots you drew in the previous part? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>For myself, I see a random scatter of points on the first plot, and points close to the line on the second one. Thus I don’t see any problems at all. I would declare myself happy with the second regression, after removing the outlier. (Remember that we removed the outlier <em>because it was an error</em>, not just because it was an outlier. Outliers can be perfectly correct data points, and if they are, they have to be included in the modelling.)</p>
<p>You might have a different point of view, in which case you need to make the case for it. You might see a (very mild) case of fanning out in the first plot, or the two most negative residuals might be a bit too low. These are not really outliers, though, not at least in comparison to what we had before.</p>
<p>Extra: a standard diagnostic for fanning-out is to plot the <em>absolute values</em> of the residuals against the fitted values, with a smooth trend. If this looks like an increasing trend, there is fanning-out; a decreasing trend shows fanning-in. The idea is that we want to see whether the residuals are changing in <em>size</em> (for example, getting more positive <em>and</em> more negative both):</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="simple-regression.html#cb431-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hf<span class="fl">.2</span>, <span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span><span class="fu">abs</span>(.resid))) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/heightfoot-10-1.png" width="672" /></p>
<p>No evidence of fanning-out at all. In fact, the residuals seem to be smallest in size <em>in the middle</em>.</p>
<p>Another thing you might think of is to try Box-Cox:</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="simple-regression.html#cb433-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxcox</span>(height<span class="sc">~</span>foot, <span class="at">data=</span>hfx)</span></code></pre></div>
<p><img src="pasias_files/figure-html/heightfoot-11-1.png" width="672" /></p>
<p>It looks as if the best <span class="math inline">\(\lambda\)</span> is <span class="math inline">\(-1\)</span>, and we should predict one over height from foot length. But this plot is deceiving, since it doesn’t even show the whole confidence interval for <span class="math inline">\(\lambda\)</span>!
We should zoom out (a lot) more:</p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="simple-regression.html#cb434-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxcox</span>(height<span class="sc">~</span>foot, <span class="at">data=</span>hfx, <span class="at">lambda =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">8</span>, <span class="dv">8</span>, <span class="fl">0.1</span>))</span></code></pre></div>
<p><img src="pasias_files/figure-html/heightfoot-12-1.png" width="672" /></p>
<p>This shows that the confidence interval for <span class="math inline">\(\lambda\)</span> goes from about <span class="math inline">\(-7\)</span> to almost 5: that is, <em>any</em> value of <span class="math inline">\(\lambda\)</span> in that interval is supported by the data! This very definitely includes the do-nothing <span class="math inline">\(\lambda=1\)</span>, so there is really no support for any kind of transformation.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol style="list-style-type: lower-roman">
<li>Find a way to plot the data and <em>both</em> regression lines on the same plot, in such a way that you can see which regression line is which. If you get help from anything outside the course materials, cite your source(s).</li>
</ol>
<p>Solution</p>
<p>This is the same idea as with <a href="http://ritsokiguess.site/STAC33/windmill_slides.pdf">the windmill data</a>, page 22, though this one is a bit easier since everything is linear (no curves).</p>
<p>The easiest way is to use <code>geom_smooth</code> twice, once with the original data set, and then on the one with the outlier removed:</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="simple-regression.html#cb435-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hf, <span class="fu">aes</span>(<span class="at">y=</span>height, <span class="at">x=</span>foot)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se=</span>F) <span class="sc">+</span></span>
<span id="cb435-2"><a href="simple-regression.html#cb435-2" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_smooth</span>(<span class="at">data=</span>hfx, <span class="at">method=</span><span class="st">&quot;lm&quot;</span>, <span class="at">colour=</span><span class="st">&quot;red&quot;</span>, <span class="at">se=</span>F)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;
## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/heightfoot-13-1.png" width="672" /></p>
<p>I would use the original data set as the “base”, since we want to plot its points (including the outlier) as well as its line.
Then we want to plot just the line for the second data set. This entails using a <code>data=</code> in the second <code>geom_smooth</code>, to say that we want to get <em>this</em> regression line from a different data set, and also
entails drawing this line in a different colour (or in some way distinguishing it from the first one). Putting the <code>colour</code> <em>outside</em> an <code>aes</code> is a way to make the <em>whole line</em> red. (Compare how you make points different colours according to their value on a third variable.)</p>
<p>This is, I think, the best way to do it. You can mimic the idea that I used for the windmill data:</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="simple-regression.html#cb437-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(hf, <span class="fu">aes</span>(<span class="at">y=</span>height, <span class="at">x=</span>foot)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se=</span>F) <span class="sc">+</span></span>
<span id="cb437-2"><a href="simple-regression.html#cb437-2" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_line</span>(<span class="at">data=</span>hf<span class="fl">.2</span>, <span class="fu">aes</span>(<span class="at">y =</span> .fitted))</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/heightfoot-14-1.png" width="672" /></p>
<p>but this is not as good, because you don’t need to use the trickery with <code>geom_line</code>: the second trend is another regression line not a curve, and we know how to draw regression lines with <code>geom_smooth</code> without having to actually fit them. (Doing it this way reveals that you are copying without thinking, instead of wondering whether there is a better way to do it.)</p>
<p>The idea of using a different data set in different “layers” of a plot is quite well-known. For example, the idea is the one in <a href="https://bookdown.org/yih_huynh/Guide-to-R-Book/graphing-with-different-datasets.html">here</a>, though used for a different purpose there (plotting different sets of points instead of different lines).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="10" style="list-style-type: lower-alpha">
<li>Discuss briefly how removing the observation(s) that were errors has changed where the regression line goes, and whether that is what you expected.</li>
</ol>
<p>Solution</p>
<p>The regression line for the original data (my blue line) is pulled up compared to the one with outliers removed (red).</p>
<p>This is not very surprising, because we know that regression lines tend to get pulled towards outliers. What was surprising to me was that the difference wasn’t very big. Even at the low end, where the lines differ the most, the difference in predicted height is only about one inch.
Since regression lines are based on means, I would have expected a big outlier to have moved the line a lot more.</p>
<p>Say something about what you expected, and say something insightful about whether that was what you saw.</p>
<p>Extra: the regression lines are very similar, but their R-squared values are not: 32% and 57% respectively. Having a point far from the line has a big (downward) impact on R-squared.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="22">
<li id="fn22"><p>This is a base graphics graph rather than a <code>ggplot</code> one, but it will do for our purposes.<a href="simple-regression.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>Roller-coasters work by gravity, so there must be some drop.<a href="simple-regression.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>These are not to be confused with what your mom insists that you place between your coffee mug and the table.<a href="simple-regression.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>If you had just one <span class="math inline">\(x\)</span>, you’d use a <span class="math inline">\(t\)</span>-test for its slope, and if you were testing all the <span class="math inline">\(x\)</span>’s, you’d use the global <span class="math inline">\(F\)</span>-test that appears in the regression output.<a href="simple-regression.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>This is a base graphics graph rather than a <code>ggplot</code> one, but it will do for our purposes.<a href="simple-regression.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>Recall that adding <span class="math inline">\(x\)</span>-variables to a regression will always make R-squared go up, even if they are just random noise.<a href="simple-regression.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>This is not, I don’t think, a real word, but I mean size emphasizing how big a boy is generally, rather than how small.<a href="simple-regression.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>Correlations have to go up beyond 0.50 before they start looking at all interesting.<a href="simple-regression.html#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>The suspicion being that we can, since the scatterplot suggested serious non-linearity.<a href="simple-regression.html#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p>Again, not a surprise, given our initial scatterplot.<a href="simple-regression.html#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p>Now we can use that word <em>significant</em>.<a href="simple-regression.html#fnref32" class="footnote-back">↩︎</a></p></li>
<li id="fn33"><p>This might be overkill at this point, since we really only care about whether our data values are reasonable, and often just looking at the highest and lowest values will tell us that.<a href="simple-regression.html#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>Mathematically, <span class="math inline">\(e^x\)</span> is approximately <span class="math inline">\(1+x\)</span> for small <span class="math inline">\(x\)</span>, which winds up meaning that the slope in a model like this, if it is small, indicates about the percent increase in the response associated with a 1-unit change in the explanatory variable. Note that this only works with <span class="math inline">\(e^x\)</span> and natural logs, not base 10 logs or anything like that.<a href="simple-regression.html#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>When this was graded, it was 3 marks, to clue you in that there are three things to say.<a href="simple-regression.html#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p>The <code>summary</code> output is more designed for looking at than for extracting things from.<a href="simple-regression.html#fnref36" class="footnote-back">↩︎</a></p></li>
<li id="fn37"><p>These days, there are apps that will let you do this with your phone. I found one called Clinometer. See also <a href="https://gabrielhemery.com/how-to-calculate-tree-height-using-a-smartphone/">link</a>.<a href="simple-regression.html#fnref37" class="footnote-back">↩︎</a></p></li>
<li id="fn38"><p>The very negative residuals are at the left and right of the residual plot; they are there because the relationship is a curve. If you were to look at the residuals from the model with length-squared, you probably wouldn’t see this.<a href="simple-regression.html#fnref38" class="footnote-back">↩︎</a></p></li>
<li id="fn39"><p>The value, but throw away the minus sign if it has one.<a href="simple-regression.html#fnref39" class="footnote-back">↩︎</a></p></li>
<li id="fn40"><p>Roller-coasters work by gravity, so there must be some drop.<a href="simple-regression.html#fnref40" class="footnote-back">↩︎</a></p></li>
<li id="fn41"><p>These are not to be confused with what your mom insists that you place between your coffee mug and the table.<a href="simple-regression.html#fnref41" class="footnote-back">↩︎</a></p></li>
<li id="fn42"><p>A quote from the package vignette.<a href="simple-regression.html#fnref42" class="footnote-back">↩︎</a></p></li>
<li id="fn43"><p>It won’t give you an error, but it will go back to the <em>original</em> data frame to get distances to predict from, and you will get very confused. This is another example of (base) R trying to make life easier for you, but when it fails, it <em>fails</em>.<a href="simple-regression.html#fnref43" class="footnote-back">↩︎</a></p></li>
<li id="fn44"><p>R is like that: sometimes it seems as if it has infinite depth.<a href="simple-regression.html#fnref44" class="footnote-back">↩︎</a></p></li>
<li id="fn45"><p>It does this by figuring what kind of thing you have, from the extension to its filename, and then calling an appropriate function to read in or write out the data. This is an excellent example of “standing on the shoulders of giants” to make our lives easier. The software does the hard work of figuring out what kind of thing you have and how to read it in; all we do is say <code>import</code>.<a href="simple-regression.html#fnref45" class="footnote-back">↩︎</a></p></li>
<li id="fn46"><p>This is perhaps not a commercial so much as a public safety message.<a href="simple-regression.html#fnref46" class="footnote-back">↩︎</a></p></li>
<li id="fn47"><p>There are some typical British cars of the era in the commercial.<a href="simple-regression.html#fnref47" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tidying-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["pasias.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
