<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 18 Logistic regression | Problems and Solutions in Applied Statistics" />
<meta property="og:type" content="book" />
<meta property="og:url" content="http://ritsokiguess.site/pasias" />

<meta property="og:description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
<meta name="github-repo" content="nxskok/pasias" />

<meta name="author" content="Ken Butler" />

<meta name="date" content="2019-01-07" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<meta name="description" content="A set of problems and solutions, in R, on various parts of applied statistics">

<title>Chapter 18 Logistic regression | Problems and Solutions in Applied Statistics</title>

<script src="libs/header-attrs-2.4/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="packages-used-somewhere-in-this-book.html#packages-used-somewhere-in-this-book"><span class="toc-section-number">2</span> Packages used somewhere in this book</a></li>
<li><a href="getting-used-to-r-and-r-studio.html#getting-used-to-r-and-r-studio"><span class="toc-section-number">3</span> Getting used to R and R Studio</a>
<ul>
<li><a href="getting-used-to-r-and-r-studio.html#getting-an-r-studio-cloud-account"><span class="toc-section-number">3.1</span> Getting an R Studio Cloud account</a></li>
<li><a href="getting-used-to-r-and-r-studio.html#getting-started"><span class="toc-section-number">3.2</span> Getting started</a></li>
<li><a href="getting-used-to-r-and-r-studio.html#reading-data-from-a-file"><span class="toc-section-number">3.3</span> Reading data from a file</a></li>
<li><a href="getting-used-to-r-and-r-studio.html#reading-files-different-ways"><span class="toc-section-number">3.4</span> Reading files different ways</a></li>
</ul></li>
<li><a href="reading-in-data-and-drawing-some-graphs.html#reading-in-data-and-drawing-some-graphs"><span class="toc-section-number">4</span> Reading in data and drawing some graphs</a>
<ul>
<li><a href="reading-in-data-and-drawing-some-graphs.html#orange-juice"><span class="toc-section-number">4.1</span> Orange juice</a></li>
<li><a href="reading-in-data-and-drawing-some-graphs.html#making-soap"><span class="toc-section-number">4.2</span> Making soap</a></li>
<li><a href="reading-in-data-and-drawing-some-graphs.html#handling-shipments"><span class="toc-section-number">4.3</span> Handling shipments</a></li>
</ul></li>
<li><a href="data-exploration.html#data-exploration"><span class="toc-section-number">5</span> Data exploration</a>
<ul>
<li><a href="data-exploration.html#north-carolina-births"><span class="toc-section-number">5.1</span> North Carolina births</a></li>
<li><a href="data-exploration.html#more-about-the-nc-births"><span class="toc-section-number">5.2</span> More about the NC births</a></li>
<li><a href="data-exploration.html#nenana-alaska"><span class="toc-section-number">5.3</span> Nenana, Alaska</a></li>
<li><a href="data-exploration.html#computerized-accounting"><span class="toc-section-number">5.4</span> Computerized accounting</a></li>
<li><a href="data-exploration.html#test-scores-in-two-classes"><span class="toc-section-number">5.5</span> Test scores in two classes</a></li>
</ul></li>
<li><a href="one-sample-inference.html#one-sample-inference"><span class="toc-section-number">6</span> One-sample inference</a>
<ul>
<li><a href="one-sample-inference.html#hunter-gatherers-in-australia"><span class="toc-section-number">6.1</span> Hunter-gatherers in Australia</a></li>
<li><a href="one-sample-inference.html#buses-to-boulder"><span class="toc-section-number">6.2</span> Buses to Boulder</a></li>
<li><a href="one-sample-inference.html#length-of-gestation-in-north-carolina"><span class="toc-section-number">6.3</span> Length of gestation in North Carolina</a></li>
<li><a href="one-sample-inference.html#inferring-ice-break-up-in-nenana"><span class="toc-section-number">6.4</span> Inferring ice break-up in Nenana</a></li>
</ul></li>
<li><a href="two-sample-inference.html#two-sample-inference"><span class="toc-section-number">7</span> Two-sample inference</a>
<ul>
<li><a href="two-sample-inference.html#children-and-electronic-devices"><span class="toc-section-number">7.1</span> Children and electronic devices</a></li>
<li><a href="two-sample-inference.html#parking-close-to-the-curb"><span class="toc-section-number">7.2</span> Parking close to the curb</a></li>
<li><a href="two-sample-inference.html#bell-peppers-and-too-much-water"><span class="toc-section-number">7.3</span> Bell peppers and too much water</a></li>
<li><a href="two-sample-inference.html#exercise-and-anxiety-and-bullying-mice"><span class="toc-section-number">7.4</span> Exercise and anxiety and bullying mice</a></li>
<li><a href="two-sample-inference.html#diet-and-growth-in-boys"><span class="toc-section-number">7.5</span> Diet and growth in boys</a></li>
</ul></li>
<li><a href="power-and-sample-size.html#power-and-sample-size"><span class="toc-section-number">8</span> Power and sample size</a>
<ul>
<li><a href="power-and-sample-size.html#simulating-power"><span class="toc-section-number">8.1</span> Simulating power</a></li>
<li><a href="power-and-sample-size.html#calculating-power-and-sample-size-for-estimating-mean"><span class="toc-section-number">8.2</span> Calculating power and sample size for estimating mean</a></li>
<li><a href="power-and-sample-size.html#simulating-power-for-proportions"><span class="toc-section-number">8.3</span> Simulating power for proportions</a></li>
</ul></li>
<li><a href="the-sign-test-and-moods-median-test.html#the-sign-test-and-moods-median-test"><span class="toc-section-number">9</span> The sign test and Mood’s median test</a>
<ul>
<li><a href="the-sign-test-and-moods-median-test.html#running-a-maze"><span class="toc-section-number">9.1</span> Running a maze</a></li>
<li><a href="the-sign-test-and-moods-median-test.html#chocolate-chips"><span class="toc-section-number">9.2</span> Chocolate chips</a></li>
<li><a href="the-sign-test-and-moods-median-test.html#the-power-of-the-sign-test"><span class="toc-section-number">9.3</span> The power of the sign test</a></li>
<li><a href="the-sign-test-and-moods-median-test.html#sugar-in-breakfast-cereals"><span class="toc-section-number">9.4</span> Sugar in breakfast cereals</a></li>
<li><a href="the-sign-test-and-moods-median-test.html#fear-of-math"><span class="toc-section-number">9.5</span> Fear of math</a></li>
<li><a href="the-sign-test-and-moods-median-test.html#medical-instructions"><span class="toc-section-number">9.6</span> Medical instructions</a></li>
</ul></li>
<li><a href="matched-pairs-t-and-sign-test.html#matched-pairs-t-and-sign-test"><span class="toc-section-number">10</span> Matched pairs t and sign test</a>
<ul>
<li><a href="matched-pairs-t-and-sign-test.html#measuring-body-fat"><span class="toc-section-number">10.1</span> Measuring body fat</a></li>
<li><a href="matched-pairs-t-and-sign-test.html#throwing-baseballs-and-softballs"><span class="toc-section-number">10.2</span> Throwing baseballs and softballs</a></li>
<li><a href="matched-pairs-t-and-sign-test.html#throwing-baseballs-and-softballs-again"><span class="toc-section-number">10.3</span> Throwing baseballs and softballs, again</a></li>
<li><a href="matched-pairs-t-and-sign-test.html#changes-in-salary"><span class="toc-section-number">10.4</span> Changes in salary</a></li>
<li><a href="matched-pairs-t-and-sign-test.html#body-fat-revisited"><span class="toc-section-number">10.5</span> Body fat revisited</a></li>
</ul></li>
<li><a href="normal-quantile-plots.html#normal-quantile-plots"><span class="toc-section-number">11</span> Normal quantile plots</a>
<ul>
<li><a href="normal-quantile-plots.html#lengths-of-heliconia-flowers"><span class="toc-section-number">11.1</span> Lengths of heliconia flowers</a></li>
<li><a href="normal-quantile-plots.html#ferritin-and-normality"><span class="toc-section-number">11.2</span> Ferritin and normality</a></li>
</ul></li>
<li><a href="analysis-of-variance.html#analysis-of-variance"><span class="toc-section-number">12</span> Analysis of variance</a>
<ul>
<li><a href="analysis-of-variance.html#movie-ratings-and-lengths"><span class="toc-section-number">12.1</span> Movie ratings and lengths</a></li>
<li><a href="analysis-of-variance.html#deer-and-how-much-they-eat"><span class="toc-section-number">12.2</span> Deer and how much they eat</a></li>
<li><a href="analysis-of-variance.html#movie-ratings-again"><span class="toc-section-number">12.3</span> Movie ratings again</a></li>
<li><a href="analysis-of-variance.html#atomic-weight-of-carbon"><span class="toc-section-number">12.4</span> Atomic weight of carbon</a></li>
<li><a href="analysis-of-variance.html#can-caffeine-improve-your-performance-on-a-test"><span class="toc-section-number">12.5</span> Can caffeine improve your performance on a test?</a></li>
</ul></li>
<li><a href="tidying-and-selecting-data.html#tidying-and-selecting-data"><span class="toc-section-number">13</span> Tidying and selecting data</a>
<ul>
<li><a href="tidying-and-selecting-data.html#tidying-the-jays-data"><span class="toc-section-number">13.1</span> Tidying the Jays data</a></li>
<li><a href="tidying-and-selecting-data.html#baseball-and-softball-spaghetti"><span class="toc-section-number">13.2</span> Baseball and softball spaghetti</a></li>
<li><a href="tidying-and-selecting-data.html#ethanol-and-sleep-time-in-rats"><span class="toc-section-number">13.3</span> Ethanol and sleep time in rats</a></li>
<li><a href="tidying-and-selecting-data.html#growth-of-tomatoes"><span class="toc-section-number">13.4</span> Growth of tomatoes</a></li>
<li><a href="tidying-and-selecting-data.html#pain-relief-in-migraine-headaches-again"><span class="toc-section-number">13.5</span> Pain relief in migraine headaches (again)</a></li>
<li><a href="tidying-and-selecting-data.html#location-species-and-disease-in-plants"><span class="toc-section-number">13.6</span> Location, species and disease in plants</a></li>
<li><a href="tidying-and-selecting-data.html#mating-songs-in-crickets"><span class="toc-section-number">13.7</span> Mating songs in crickets</a></li>
<li><a href="tidying-and-selecting-data.html#cars"><span class="toc-section-number">13.8</span> Cars</a></li>
<li><a href="tidying-and-selecting-data.html#number-1-songs"><span class="toc-section-number">13.9</span> Number 1 songs</a></li>
<li><a href="tidying-and-selecting-data.html#bikes-on-college"><span class="toc-section-number">13.10</span> Bikes on College</a></li>
<li><a href="tidying-and-selecting-data.html#feeling-the-heat"><span class="toc-section-number">13.11</span> Feeling the heat</a></li>
</ul></li>
<li><a href="regression.html#regression"><span class="toc-section-number">14</span> Regression</a>
<ul>
<li><a href="regression.html#rainfall-in-california"><span class="toc-section-number">14.1</span> Rainfall in California</a></li>
<li><a href="regression.html#carbon-monoxide-in-cigarettes"><span class="toc-section-number">14.2</span> Carbon monoxide in cigarettes</a></li>
<li><a href="regression.html#maximal-oxygen-uptake-in-young-boys"><span class="toc-section-number">14.3</span> Maximal oxygen uptake in young boys</a></li>
<li><a href="regression.html#facebook-friends-and-grey-matter"><span class="toc-section-number">14.4</span> Facebook friends and grey matter</a></li>
<li><a href="regression.html#endogenous-nitrogen-excretion-in-carp"><span class="toc-section-number">14.5</span> Endogenous nitrogen excretion in carp</a></li>
<li><a href="regression.html#sparrowhawks"><span class="toc-section-number">14.6</span> Sparrowhawks</a></li>
<li><a href="regression.html#salaries-of-social-workers"><span class="toc-section-number">14.7</span> Salaries of social workers</a></li>
<li><a href="regression.html#predicting-volume-of-wood-in-pine-trees"><span class="toc-section-number">14.8</span> Predicting volume of wood in pine trees</a></li>
<li><a href="regression.html#tortoise-shells-and-eggs"><span class="toc-section-number">14.9</span> Tortoise shells and eggs</a></li>
<li><a href="regression.html#crickets-revisited"><span class="toc-section-number">14.10</span> Crickets revisited</a></li>
<li><a href="regression.html#roller-coasters"><span class="toc-section-number">14.11</span> Roller coasters</a></li>
<li><a href="regression.html#running-and-blood-sugar"><span class="toc-section-number">14.12</span> Running and blood sugar</a></li>
<li><a href="regression.html#calories-and-fat-in-pizza"><span class="toc-section-number">14.13</span> Calories and fat in pizza</a></li>
<li><a href="regression.html#where-should-the-fire-stations-be"><span class="toc-section-number">14.14</span> Where should the fire stations be?</a></li>
<li><a href="regression.html#being-satisfied-with-hospital"><span class="toc-section-number">14.15</span> Being satisfied with hospital</a></li>
<li><a href="regression.html#handling-shipments-of-chemicals"><span class="toc-section-number">14.16</span> Handling shipments of chemicals</a></li>
<li><a href="regression.html#salaries-of-mathematicians"><span class="toc-section-number">14.17</span> Salaries of mathematicians</a></li>
<li><a href="regression.html#predicting-gpa-of-computer-science-students"><span class="toc-section-number">14.18</span> Predicting GPA of computer science students</a></li>
</ul></li>
<li><a href="dates-and-times.html#dates-and-times"><span class="toc-section-number">15</span> Dates and times</a>
<ul>
<li><a href="dates-and-times.html#dealing-with-dates-in-the-worcester-heart-attack-study"><span class="toc-section-number">15.1</span> Dealing with dates in the Worcester Heart Attack study</a></li>
<li><a href="dates-and-times.html#growth-of-mizuna-lettuce-seeds"><span class="toc-section-number">15.2</span> Growth of Mizuna lettuce seeds</a></li>
<li><a href="dates-and-times.html#types-of-childbirth"><span class="toc-section-number">15.3</span> Types of childbirth</a></li>
<li><a href="dates-and-times.html#wolves-and-caribou"><span class="toc-section-number">15.4</span> Wolves and caribou</a></li>
</ul></li>
<li><a href="functions.html#functions"><span class="toc-section-number">16</span> Functions</a>
<ul>
<li><a href="functions.html#making-some-r-functions"><span class="toc-section-number">16.1</span> Making some R functions</a></li>
<li><a href="functions.html#the-collatz-sequence"><span class="toc-section-number">16.2</span> The Collatz sequence</a></li>
</ul></li>
<li><a href="the-bootstrap.html#the-bootstrap"><span class="toc-section-number">17</span> The Bootstrap</a>
<ul>
<li><a href="the-bootstrap.html#air-conditioning-failures"><span class="toc-section-number">17.1</span> Air conditioning failures</a></li>
<li><a href="the-bootstrap.html#air-conditioning-failures-bootstrapping-the-median"><span class="toc-section-number">17.2</span> Air conditioning failures: bootstrapping the median</a></li>
</ul></li>
<li><a href="logistic-regression.html#logistic-regression"><span class="toc-section-number">18</span> Logistic regression</a>
<ul>
<li><a href="logistic-regression.html#finding-wolf-spiders-on-the-beach"><span class="toc-section-number">18.1</span> Finding wolf spiders on the beach</a></li>
<li><a href="logistic-regression.html#killing-aphids"><span class="toc-section-number">18.2</span> Killing aphids</a></li>
<li><a href="logistic-regression.html#the-effects-of-substance-a"><span class="toc-section-number">18.3</span> The effects of Substance A</a></li>
<li><a href="logistic-regression.html#what-makes-an-animal-get-infected"><span class="toc-section-number">18.4</span> What makes an animal get infected?</a></li>
<li><a href="logistic-regression.html#the-brain-of-a-cat"><span class="toc-section-number">18.5</span> The brain of a cat</a></li>
<li><a href="logistic-regression.html#how-not-to-get-heart-disease"><span class="toc-section-number">18.6</span> How not to get heart disease</a></li>
<li><a href="logistic-regression.html#successful-breastfeeding"><span class="toc-section-number">18.7</span> Successful breastfeeding</a></li>
<li><a href="logistic-regression.html#making-it-over-the-mountains"><span class="toc-section-number">18.8</span> Making it over the mountains</a></li>
<li><a href="logistic-regression.html#who-needs-the-most-intensive-care"><span class="toc-section-number">18.9</span> Who needs the most intensive care?</a></li>
<li><a href="logistic-regression.html#go-away-and-dont-come-back"><span class="toc-section-number">18.10</span> Go away and don’t come back!</a></li>
</ul></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#logistic-regression-with-ordinal-or-nominal-response"><span class="toc-section-number">19</span> Logistic regression with ordinal or nominal response</a>
<ul>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#do-you-like-your-mobile-phone"><span class="toc-section-number">19.1</span> Do you like your mobile phone?</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#attitudes-towards-abortion"><span class="toc-section-number">19.2</span> Attitudes towards abortion</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#finding-non-missing-values"><span class="toc-section-number">19.3</span> Finding non-missing values</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#european-social-survey-and-voting"><span class="toc-section-number">19.4</span> European Social Survey and voting</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#alligator-food"><span class="toc-section-number">19.5</span> Alligator food</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#how-do-you-like-your-steak-the-data"><span class="toc-section-number">19.6</span> How do you like your steak – the data</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#crimes-in-san-francisco-the-data"><span class="toc-section-number">19.7</span> Crimes in San Francisco – the data</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#how-do-you-like-your-steak"><span class="toc-section-number">19.8</span> How do you like your steak?</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#crimes-in-san-francisco"><span class="toc-section-number">19.9</span> Crimes in San Francisco</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#high-school-and-beyond"><span class="toc-section-number">19.10</span> High School and Beyond</a></li>
<li><a href="logistic-regression-with-ordinal-or-nominal-response.html#what-sports-do-these-athletes-play"><span class="toc-section-number">19.11</span> What sports do these athletes play?</a></li>
</ul></li>
<li><a href="survival-analysis.html#survival-analysis"><span class="toc-section-number">20</span> Survival analysis</a>
<ul>
<li><a href="survival-analysis.html#the-worcester-survey"><span class="toc-section-number">20.1</span> The Worcester survey</a></li>
<li><a href="survival-analysis.html#drug-treatment-programs"><span class="toc-section-number">20.2</span> Drug treatment programs</a></li>
<li><a href="survival-analysis.html#multiple-myeloma"><span class="toc-section-number">20.3</span> Multiple myeloma</a></li>
<li><a href="survival-analysis.html#ovarian-cancer"><span class="toc-section-number">20.4</span> Ovarian cancer</a></li>
</ul></li>
<li><a href="analysis-of-variance-revisited.html#analysis-of-variance-revisited"><span class="toc-section-number">21</span> Analysis of variance revisited</a>
<ul>
<li><a href="analysis-of-variance-revisited.html#acid-rain"><span class="toc-section-number">21.1</span> Acid rain</a></li>
<li><a href="analysis-of-variance-revisited.html#treating-hay-fever"><span class="toc-section-number">21.2</span> Treating hay fever</a></li>
<li><a href="analysis-of-variance-revisited.html#focused-comparisons-of-the-effect-of-caffeine"><span class="toc-section-number">21.3</span> Focused comparisons of the effect of caffeine</a></li>
<li><a href="analysis-of-variance-revisited.html#who-studies-the-most-outside-class"><span class="toc-section-number">21.4</span> Who studies the most outside class?</a></li>
<li><a href="analysis-of-variance-revisited.html#mental-context"><span class="toc-section-number">21.5</span> Mental context</a></li>
<li><a href="analysis-of-variance-revisited.html#trying-on-shirts"><span class="toc-section-number">21.6</span> Trying on shirts</a></li>
<li><a href="analysis-of-variance-revisited.html#productivity-and-research-and-development"><span class="toc-section-number">21.7</span> Productivity and research-and-development</a></li>
<li><a href="analysis-of-variance-revisited.html#treating-leprosy"><span class="toc-section-number">21.8</span> Treating leprosy</a></li>
</ul></li>
<li><a href="multivariate-analysis-of-variance.html#multivariate-analysis-of-variance"><span class="toc-section-number">22</span> Multivariate analysis of variance</a>
<ul>
<li><a href="multivariate-analysis-of-variance.html#fabricated-data"><span class="toc-section-number">22.1</span> Fabricated data</a></li>
<li><a href="multivariate-analysis-of-variance.html#do-characteristics-of-urine-depend-on-obesity"><span class="toc-section-number">22.2</span> Do characteristics of urine depend on obesity?</a></li>
<li><a href="multivariate-analysis-of-variance.html#how-do-height-and-weight-depend-on-sport-played-by-elite-athletes"><span class="toc-section-number">22.3</span> How do height and weight depend on sport played by elite athletes?</a></li>
</ul></li>
<li><a href="repeated-measures.html#repeated-measures"><span class="toc-section-number">23</span> Repeated measures</a>
<ul>
<li><a href="repeated-measures.html#effect-of-drug-on-rat-weight"><span class="toc-section-number">23.1</span> Effect of drug on rat weight</a></li>
<li><a href="repeated-measures.html#social-interaction-among-old-people"><span class="toc-section-number">23.2</span> Social interaction among old people</a></li>
<li><a href="repeated-measures.html#childrens-stress-levels-and-airports"><span class="toc-section-number">23.3</span> Children’s stress levels and airports</a></li>
<li><a href="repeated-measures.html#body-fat-as-repeated-measures"><span class="toc-section-number">23.4</span> Body fat as repeated measures</a></li>
<li><a href="repeated-measures.html#investigating-motor-activity-in-rats"><span class="toc-section-number">23.5</span> Investigating motor activity in rats</a></li>
<li><a href="repeated-measures.html#repeated-measures-with-no-background"><span class="toc-section-number">23.6</span> Repeated measures with no background</a></li>
</ul></li>
<li><a href="discriminant-analysis.html#discriminant-analysis"><span class="toc-section-number">24</span> Discriminant analysis</a>
<ul>
<li><a href="discriminant-analysis.html#telling-whether-a-banknote-is-real-or-counterfeit"><span class="toc-section-number">24.1</span> Telling whether a banknote is real or counterfeit</a></li>
<li><a href="discriminant-analysis.html#urine-and-obesity-what-makes-a-difference"><span class="toc-section-number">24.2</span> Urine and obesity: what makes a difference?</a></li>
<li><a href="discriminant-analysis.html#understanding-a-manova"><span class="toc-section-number">24.3</span> Understanding a MANOVA</a></li>
<li><a href="discriminant-analysis.html#what-distinguishes-people-who-do-different-jobs"><span class="toc-section-number">24.4</span> What distinguishes people who do different jobs?</a></li>
<li><a href="discriminant-analysis.html#observing-children-with-adhd"><span class="toc-section-number">24.5</span> Observing children with ADHD</a></li>
<li><a href="discriminant-analysis.html#growing-corn"><span class="toc-section-number">24.6</span> Growing corn</a></li>
<li><a href="discriminant-analysis.html#understanding-athletes-height-weight-sport-and-gender"><span class="toc-section-number">24.7</span> Understanding athletes’ height, weight, sport and gender</a></li>
</ul></li>
<li><a href="cluster-analysis.html#cluster-analysis"><span class="toc-section-number">25</span> Cluster analysis</a>
<ul>
<li><a href="cluster-analysis.html#sites-on-the-sea-bed"><span class="toc-section-number">25.1</span> Sites on the sea bed</a></li>
<li><a href="cluster-analysis.html#dissimilarities-between-fruits"><span class="toc-section-number">25.2</span> Dissimilarities between fruits</a></li>
<li><a href="cluster-analysis.html#similarity-of-species"><span class="toc-section-number">25.3</span> Similarity of species</a></li>
<li><a href="cluster-analysis.html#rating-beer"><span class="toc-section-number">25.4</span> Rating beer</a></li>
<li><a href="cluster-analysis.html#clustering-the-swiss-bills"><span class="toc-section-number">25.5</span> Clustering the Swiss bills</a></li>
<li><a href="cluster-analysis.html#grouping-similar-cars"><span class="toc-section-number">25.6</span> Grouping similar cars</a></li>
<li><a href="cluster-analysis.html#running-jumping-and-throwing"><span class="toc-section-number">25.7</span> Running, jumping, and throwing</a></li>
<li><a href="cluster-analysis.html#bridges-in-pittsburgh"><span class="toc-section-number">25.8</span> Bridges in Pittsburgh</a></li>
<li><a href="cluster-analysis.html#clustering-the-australian-athletes"><span class="toc-section-number">25.9</span> Clustering the Australian athletes</a></li>
</ul></li>
<li><a href="multidimensional-scaling.html#multidimensional-scaling"><span class="toc-section-number">26</span> Multidimensional Scaling</a>
<ul>
<li><a href="multidimensional-scaling.html#making-a-map-of-wisconsin"><span class="toc-section-number">26.1</span> Making a map of Wisconsin</a></li>
<li><a href="multidimensional-scaling.html#things-that-feel-similar-to-each-other"><span class="toc-section-number">26.2</span> Things that feel similar to each other</a></li>
<li><a href="multidimensional-scaling.html#confusing-letters"><span class="toc-section-number">26.3</span> Confusing letters</a></li>
<li><a href="multidimensional-scaling.html#more-beer-please"><span class="toc-section-number">26.4</span> More beer please</a></li>
<li><a href="multidimensional-scaling.html#feeling-similar-again"><span class="toc-section-number">26.5</span> Feeling similar, again</a></li>
</ul></li>
<li><a href="principal-components-and-factor-analysis.html#principal-components-and-factor-analysis"><span class="toc-section-number">27</span> Principal Components and Factor Analysis</a>
<ul>
<li><a href="principal-components-and-factor-analysis.html#the-weather-somewhere"><span class="toc-section-number">27.1</span> The weather, somewhere</a></li>
<li><a href="principal-components-and-factor-analysis.html#air-pollution"><span class="toc-section-number">27.2</span> Air pollution</a></li>
<li><a href="principal-components-and-factor-analysis.html#a-correlation-matrix"><span class="toc-section-number">27.3</span> A correlation matrix</a></li>
<li><a href="principal-components-and-factor-analysis.html#the-interpersonal-circumplex"><span class="toc-section-number">27.4</span> The Interpersonal Circumplex</a></li>
</ul></li>
<li><a href="frequency-table-analysis.html#frequency-table-analysis"><span class="toc-section-number">28</span> Frequency table analysis</a>
<ul>
<li><a href="frequency-table-analysis.html#college-plans"><span class="toc-section-number">28.1</span> College plans</a></li>
<li><a href="frequency-table-analysis.html#predicting-voting"><span class="toc-section-number">28.2</span> Predicting voting</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="logistic-regression" class="section level1" number="18">
<h1><span class="header-section-number">Chapter 18</span> Logistic regression</h1>
<div class="sourceCode" id="cb1888"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1888-1"><a href="logistic-regression.html#cb1888-1"></a><span class="kw">library</span>(tidyverse)</span></code></pre></div>
<div id="finding-wolf-spiders-on-the-beach" class="section level2" number="18.1">
<h2><span class="header-section-number">18.1</span> Finding wolf spiders on the beach</h2>
<p><a name="q:wolfspider"><em></a>
A team of Japanese researchers were investigating what would
cause the burrowing wolf spider </em>Lycosa ishikariana* to be found
on a beach. They hypothesized that it had to do with the size of the
grains of sand on the beach. They went to 28 beaches in Japan,
measured the average sand grain size (in millimetres), and observed
the presence or absence of this particular spider on each beach. The
data are in <a href="http://www.utsc.utoronto.ca/~butler/d29/spiders.txt">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Why would logistic regression be better than regular
regression in this case?</li>
</ol>
<p>Solution</p>
<p>Because the response variable, whether or not the spider is
present, is a categorical yes/no success/failure kind of variable
rather than a quantitative numerical one, and when you have this
kind of response variable, this is when you want to use logistic
regression.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Read in the data and check that you have something
sensible. (Look at the data file first: the columns are aligned but
the headers are not aligned with them.)</li>
</ol>
<p>Solution</p>
<p>The nature of the file means that you need <code>read_table2</code>:</p>
<div class="sourceCode" id="cb1889"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1889-1"><a href="logistic-regression.html#cb1889-1"></a>my_url &lt;-<span class="st"> &quot;http://www.utsc.utoronto.ca/~butler/d29/spiders.txt&quot;</span></span>
<span id="cb1889-2"><a href="logistic-regression.html#cb1889-2"></a>spider &lt;-<span class="st"> </span><span class="kw">read_table2</span>(my_url)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   Grain.size = col_double(),
##   Spiders = col_character()
## )</code></pre>
<div class="sourceCode" id="cb1891"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1891-1"><a href="logistic-regression.html#cb1891-1"></a>spider</span></code></pre></div>
<pre><code>## # A tibble: 28 x 2
##    Grain.size Spiders
##         &lt;dbl&gt; &lt;chr&gt;  
##  1      0.245 absent 
##  2      0.247 absent 
##  3      0.285 present
##  4      0.299 present
##  5      0.327 present
##  6      0.347 present
##  7      0.356 absent 
##  8      0.36  present
##  9      0.363 absent 
## 10      0.364 present
## # … with 18 more rows</code></pre>
<p>We have a numerical sand grain size and a categorical variable
<code>Spiders</code> that indicates whether the spider was present or
absent. As we were expecting. (The categorical variable is actually
text or <code>chr</code>, which will matter in a minute.)</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Make a boxplot of sand grain size according to whether the
spider is present or absent. Does this suggest that sand grain size
has something to do with presence or absence of the spider?</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb1893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1893-1"><a href="logistic-regression.html#cb1893-1"></a><span class="kw">ggplot</span>(spider, <span class="kw">aes</span>(<span class="dt">x =</span> Spiders, <span class="dt">y =</span> Grain.size)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/starcross-1.png" width="672"  /></p>
<p>The story seems to be that when spiders are present, the sand grain
size tends to be larger. So we would expect to find some kind of
useful relationship in the logistic regression.</p>
<p>Note that we have reversed the cause and effect here: in the boxplot
we are asking “given that the spider is present or absent, how big are the grains of sand?”,
whereas the logistic regression is asking “given the size of the grains of sand, how likely is the spider to be present?”. But if one variable has to do with the other, we would
hope to see the link either way around.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a logistic regression predicting the presence or
absence of spiders from the grain size, and obtain its
<code>summary</code>. Note that you will need to do something with the
response variable first.</li>
</ol>
<p>Solution</p>
<p>The presence or absence of spiders is our response. This is
actually text at the moment:</p>
<div class="sourceCode" id="cb1894"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1894-1"><a href="logistic-regression.html#cb1894-1"></a>spider</span></code></pre></div>
<pre><code>## # A tibble: 28 x 2
##    Grain.size Spiders
##         &lt;dbl&gt; &lt;chr&gt;  
##  1      0.245 absent 
##  2      0.247 absent 
##  3      0.285 present
##  4      0.299 present
##  5      0.327 present
##  6      0.347 present
##  7      0.356 absent 
##  8      0.36  present
##  9      0.363 absent 
## 10      0.364 present
## # … with 18 more rows</code></pre>
<p>so we need to make a factor version of it first. I’m going to live on
the edge and overwrite everything:</p>
<div class="sourceCode" id="cb1896"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1896-1"><a href="logistic-regression.html#cb1896-1"></a>spider &lt;-<span class="st"> </span>spider <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">Spiders =</span> <span class="kw">factor</span>(Spiders))</span>
<span id="cb1896-2"><a href="logistic-regression.html#cb1896-2"></a>spider</span></code></pre></div>
<pre><code>## # A tibble: 28 x 2
##    Grain.size Spiders
##         &lt;dbl&gt; &lt;fct&gt;  
##  1      0.245 absent 
##  2      0.247 absent 
##  3      0.285 present
##  4      0.299 present
##  5      0.327 present
##  6      0.347 present
##  7      0.356 absent 
##  8      0.36  present
##  9      0.363 absent 
## 10      0.364 present
## # … with 18 more rows</code></pre>
<p><code>Spiders</code> is now a factor, correctly. (Sometimes a text
variable gets treated as a factor, sometimes it needs to be an
explicit <code>factor</code>. This is one of those times.)
Now we go ahead and fit the model. I’m naming this as
response-with-a-number, so I still have the Capital Letter. Any choice
of name is good, though.</p>
<div class="sourceCode" id="cb1898"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1898-1"><a href="logistic-regression.html#cb1898-1"></a>Spiders<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(Spiders <span class="op">~</span><span class="st"> </span>Grain.size, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> spider)</span>
<span id="cb1898-2"><a href="logistic-regression.html#cb1898-2"></a><span class="kw">summary</span>(Spiders<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Spiders ~ Grain.size, family = &quot;binomial&quot;, data = spider)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.7406  -1.0781   0.4837   0.9809   1.2582  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)   -1.648      1.354  -1.217   0.2237  
## Grain.size     5.122      3.006   1.704   0.0884 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 35.165  on 27  degrees of freedom
## Residual deviance: 30.632  on 26  degrees of freedom
## AIC: 34.632
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<ol start="5" style="list-style-type: lower-alpha">
<li>Is there a significant relationship between grain size and
presence or absence of spiders at the <span class="math inline">\(\alpha=0.10\)</span> level? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The P-value on the <code>Grain.size</code> line is <em>just</em> less
than 0.10 (it is 0.088), so there is <em>just</em> a significant
relationship.
It isn’t a very strong significance, though. This
might be because we don’t have that much data: even though we have
28 observations, which, on the face of it, is not a very small
sample size, each observation doesn’t tell us much: only whether
the spider was found on that beach or not. Typical sample sizes in
logistic regression are in the hundreds — the same as for
opinion polls, because you’re dealing with the same kind of data.
The weak significance here lends some kind of weak support to the
researchers’ hypothesis, but I’m sure they were hoping for
something better.</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>We want to obtain predicted probabilities of spider presence
for grain sizes of 0.2, 0.5, 0.8 and 1.1 millimetres. Do this by
creating a new data frame with one column called <code>Grain.size</code>
(watch the capital letter!) and those four values, and then feed
this into <code>predict</code>. I only want predicted probabilities, not
any kind of intervals.</li>
</ol>
<p>Solution</p>
<p>Something like this. I like to save all the values first, and
<em>then</em> make a data frame of them, but you can do it in one
go if you prefer:</p>
<div class="sourceCode" id="cb1900"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1900-1"><a href="logistic-regression.html#cb1900-1"></a>Grain.sizes &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.8</span>, <span class="fl">1.1</span>)</span>
<span id="cb1900-2"><a href="logistic-regression.html#cb1900-2"></a>spider.new &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">Grain.size =</span> Grain.sizes)</span>
<span id="cb1900-3"><a href="logistic-regression.html#cb1900-3"></a>spider.new</span></code></pre></div>
<pre><code>## # A tibble: 4 x 1
##   Grain.size
##        &lt;dbl&gt;
## 1        0.2
## 2        0.5
## 3        0.8
## 4        1.1</code></pre>
<p>Another way to make the data frame of values to predict from is directly, using <code>tribble</code>:</p>
<div class="sourceCode" id="cb1902"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1902-1"><a href="logistic-regression.html#cb1902-1"></a>new &lt;-<span class="st"> </span><span class="kw">tribble</span>(</span>
<span id="cb1902-2"><a href="logistic-regression.html#cb1902-2"></a>  <span class="op">~</span>Grain.size,</span>
<span id="cb1902-3"><a href="logistic-regression.html#cb1902-3"></a>  <span class="fl">0.2</span>,</span>
<span id="cb1902-4"><a href="logistic-regression.html#cb1902-4"></a>  <span class="fl">0.5</span>,</span>
<span id="cb1902-5"><a href="logistic-regression.html#cb1902-5"></a>  <span class="fl">0.8</span>,</span>
<span id="cb1902-6"><a href="logistic-regression.html#cb1902-6"></a>  <span class="fl">1.1</span></span>
<span id="cb1902-7"><a href="logistic-regression.html#cb1902-7"></a>)</span>
<span id="cb1902-8"><a href="logistic-regression.html#cb1902-8"></a>new</span></code></pre></div>
<pre><code>## # A tibble: 4 x 1
##   Grain.size
##        &lt;dbl&gt;
## 1        0.2
## 2        0.5
## 3        0.8
## 4        1.1</code></pre>
<p>I have no particular preference here (use whichever makes most sense
to you), but when we come later to combinations of things using
<code>crossing</code>, I think the vector way is easier (make vectors of
each of the things you want combinations of, <em>then</em> combine them
into a data frame).</p>
<p>Now for the actual predictions. Get the predicted probabilities first, using <code>response</code> to get probabilities rather than something else, then put them next to the values being predicted for (using <code>cbind</code> because my <code>pred.prob</code> below is a <code>matrix</code> rather than a data frame:</p>
<div class="sourceCode" id="cb1904"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1904-1"><a href="logistic-regression.html#cb1904-1"></a>pred.prob &lt;-<span class="st"> </span><span class="kw">predict</span>(Spiders<span class="fl">.1</span>, spider.new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb1904-2"><a href="logistic-regression.html#cb1904-2"></a><span class="kw">cbind</span>(spider.new, pred.prob)</span></code></pre></div>
<pre><code>##   Grain.size pred.prob
## 1        0.2 0.3490280
## 2        0.5 0.7136446
## 3        0.8 0.9205335
## 4        1.1 0.9817663</code></pre>
<p>(Second attempt: on my first, the <code>tibble</code> contained
<code>Grain.Sizes</code>!)</p>
<p>This exemplifies my preferred technique in these things: I store the
values to predict for in a vector with a <em>plural</em> name. The
column names in the data frame I make have to have the same (singular)
name as the original data, so the layout in making the data frame is
“singular equals plural”. You’ll see a lot of this as we go through
the course.</p>
<p>I think the data frame of values to predict for is called
<code>spider.new</code> because the original one is called
<code>spider</code>. I have to stop and think about my naming
conventions.</p>
<p>The above is all I need. (The stuff below is my extra comments.)</p>
<p>Note that the probabilities don’t go up linearly. (If they did, they
would soon get bigger than 1!). It’s actually the <em>log-odds</em> that
go up linearly. In fact, if you leave out the <code>type</code> on the
<code>predict</code>, log-odds is what you get:</p>
<div class="sourceCode" id="cb1906"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1906-1"><a href="logistic-regression.html#cb1906-1"></a>pred.log.odds &lt;-<span class="st"> </span><span class="kw">predict</span>(Spiders<span class="fl">.1</span>, spider.new)</span>
<span id="cb1906-2"><a href="logistic-regression.html#cb1906-2"></a><span class="kw">cbind</span>(spider.new, pred.log.odds)</span></code></pre></div>
<pre><code>##   Grain.size pred.log.odds
## 1        0.2    -0.6233144
## 2        0.5     0.9131514
## 3        0.8     2.4496172
## 4        1.1     3.9860831</code></pre>
<p>The meaning of that slope coefficient in the <code>summary</code>, which
is about 5, is that if you increase grain size by 1, you increase the
log-odds by 5. In the table above, we increased the grain size by 0.3
each time, so we would expect to increase the log-odds by
<span class="math inline">\((0.3)(5)=1.5\)</span>, which is (to this accuracy) what happened.</p>
<p>Log-odds are hard to interpret. Odds are a bit easier, and to get
them, we have to <code>exp</code> the log-odds:</p>
<div class="sourceCode" id="cb1908"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1908-1"><a href="logistic-regression.html#cb1908-1"></a><span class="kw">cbind</span>(spider.new, <span class="dt">odds =</span> <span class="kw">exp</span>(pred.log.odds))</span></code></pre></div>
<pre><code>##   Grain.size       odds
## 1        0.2  0.5361644
## 2        0.5  2.4921640
## 3        0.8 11.5839120
## 4        1.1 53.8435749</code></pre>
<p>Thus, with each step of
0.3 in grain size, we <em>multiply</em> the odds of finding a spider by
about</p>
<div class="sourceCode" id="cb1910"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1910-1"><a href="logistic-regression.html#cb1910-1"></a><span class="kw">exp</span>(<span class="fl">1.5</span>)</span></code></pre></div>
<pre><code>## [1] 4.481689</code></pre>
<p>or about 4.5 times. If you’re a gambler, this might give you a feel
for how large the effect of grain size is. Or, of course, you can just
look at the probabilities.</p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Given your previous work in this question, does the trend
you see in your predicted probabilities surprise you? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>My predicted probabilities go up as grain size goes up. This fails
to surprise me for a couple of reasons: first, in my boxplots, I
saw that grain size tended to be larger when spiders were present,
and second, in my logistic regression <code>summary</code>, the slope
was positive, so likewise spiders should be more likely as grain
size goes up. Observing just one of these things is enough, though
of course it’s nice if you can spot both.</p>
</div>
<div id="killing-aphids" class="section level2" number="18.2">
<h2><span class="header-section-number">18.2</span> Killing aphids</h2>
<p>An experiment was designed to examine how well the insecticide rotenone kills
aphids that feed on the chrysanthemum plant called <em>Macrosiphoniella sanborni</em>.
The explanatory variable is the log concentration (in milligrams per litre) of the
insecticide. At each of the five different concentrations,
approximately 50 insects were exposed. The number of insects exposed
at each concentration, and the number killed, are shown below.</p>
<pre><code>
Log-Concentration   Insects exposed    Number killed   
0.96                       50              6               
1.33                       48              16              
1.63                       46              24              
2.04                       49              42              
2.32                       50              44              
</code></pre>
<ol style="list-style-type: lower-alpha">
<li>Get these data into R. You can do this by copying the data
into a file and reading that into R (creating a data frame), or you
can enter the data manually into R using <code>c</code>, since there are
not many values. In the latter case, you can create a data frame or
not, as you wish. Demonstrate that you have the right data in R.</li>
</ol>
<p>Solution</p>
<p>There are a couple of ways. My
current favourite is the <code>tidyverse</code>-approved
<code>tribble</code> method. A <code>tribble</code> is a
“transposed <code>tibble</code>”, in which you copy and paste the data,
inserting column headings and commas in the right places. The
columns don’t have to line up, since it’s the commas that
determine where one value ends and the next one begins:</p>
<div class="sourceCode" id="cb1913"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1913-1"><a href="logistic-regression.html#cb1913-1"></a>dead_bugs &lt;-<span class="st"> </span><span class="kw">tribble</span>(</span>
<span id="cb1913-2"><a href="logistic-regression.html#cb1913-2"></a>  <span class="op">~</span>log_conc, <span class="op">~</span>exposed, <span class="op">~</span>killed,</span>
<span id="cb1913-3"><a href="logistic-regression.html#cb1913-3"></a>  <span class="fl">0.96</span>, <span class="dv">50</span>, <span class="dv">6</span>,</span>
<span id="cb1913-4"><a href="logistic-regression.html#cb1913-4"></a>  <span class="fl">1.33</span>, <span class="dv">48</span>, <span class="dv">16</span>,</span>
<span id="cb1913-5"><a href="logistic-regression.html#cb1913-5"></a>  <span class="fl">1.63</span>, <span class="dv">46</span>, <span class="dv">24</span>,</span>
<span id="cb1913-6"><a href="logistic-regression.html#cb1913-6"></a>  <span class="fl">2.04</span>, <span class="dv">49</span>, <span class="dv">42</span>,</span>
<span id="cb1913-7"><a href="logistic-regression.html#cb1913-7"></a>  <span class="fl">2.32</span>, <span class="dv">50</span>, <span class="dv">44</span></span>
<span id="cb1913-8"><a href="logistic-regression.html#cb1913-8"></a>)</span>
<span id="cb1913-9"><a href="logistic-regression.html#cb1913-9"></a>dead_bugs</span></code></pre></div>
<pre><code>## # A tibble: 5 x 3
##   log_conc exposed killed
##      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.96      50      6
## 2     1.33      48     16
## 3     1.63      46     24
## 4     2.04      49     42
## 5     2.32      50     44</code></pre>
<p>Note that the last data value has no comma after it, but instead has
the closing bracket of <code>tribble</code>.</p>
<p>You can have extra spaces if you wish. They will just be ignored.
If you are clever in R
Studio, you can insert a column of commas all at once (using
“multiple cursors”).
I used to do it like this. I make vectors of each column using <code>c</code> and then glue the columns together into a data frame:</p>
<div class="sourceCode" id="cb1915"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1915-1"><a href="logistic-regression.html#cb1915-1"></a>log_conc &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.96</span>, <span class="fl">1.33</span>, <span class="fl">1.63</span>, <span class="fl">2.04</span>, <span class="fl">2.32</span>)</span>
<span id="cb1915-2"><a href="logistic-regression.html#cb1915-2"></a>exposed &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">50</span>, <span class="dv">48</span>, <span class="dv">46</span>, <span class="dv">49</span>, <span class="dv">50</span>)</span>
<span id="cb1915-3"><a href="logistic-regression.html#cb1915-3"></a>killed &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">16</span>, <span class="dv">24</span>, <span class="dv">42</span>, <span class="dv">44</span>)</span>
<span id="cb1915-4"><a href="logistic-regression.html#cb1915-4"></a>dead_bugs2 &lt;-<span class="st"> </span><span class="kw">tibble</span>(log_conc, exposed, killed)</span>
<span id="cb1915-5"><a href="logistic-regression.html#cb1915-5"></a>dead_bugs2</span></code></pre></div>
<pre><code>## # A tibble: 5 x 3
##   log_conc exposed killed
##      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1     0.96      50      6
## 2     1.33      48     16
## 3     1.63      46     24
## 4     2.04      49     42
## 5     2.32      50     44</code></pre>
<p>The values are correct — I checked them.</p>
<p>Now you see why <code>tribble</code> stands for “transposed tibble”: if you want to construct a data frame by hand, you have to work with columns and then glue them together, but <code>tribble</code> allows you to work “row-wise” with the data as you would lay it out on the page.</p>
<p>The other obvious way to read the data values without typing them is to copy
them into a file and read <em>that</em>. The values as laid out are
aligned in columns. They might be separated by tabs, but they are
not. (It’s hard to tell without investigating, though a tab is by
default eight spaces and these values look farther apart than that.)
I copied them into a file <code>exposed.txt</code> in my current folder
(or use <code>file.choose</code>):</p>
<div class="sourceCode" id="cb1917"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1917-1"><a href="logistic-regression.html#cb1917-1"></a>bugs2 &lt;-<span class="st"> </span><span class="kw">read_table</span>(<span class="st">&quot;exposed.txt&quot;</span>)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   `Log-Concentration` = col_double(),
##   `Insects exposed` = col_double(),
##   Number = col_double(),
##   killed = col_logical()
## )</code></pre>
<div class="sourceCode" id="cb1919"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1919-1"><a href="logistic-regression.html#cb1919-1"></a>bugs2</span></code></pre></div>
<pre><code>## # A tibble: 5 x 4
##   `Log-Concentration` `Insects exposed` Number killed
##                 &lt;dbl&gt;             &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt; 
## 1                0.96                50      6 NA    
## 2                1.33                48     16 NA    
## 3                1.63                46     24 NA    
## 4                2.04                49     42 NA    
## 5                2.32                50     44 NA</code></pre>
<p>This didn’t quite work: the last column <code>Number killed</code> got
split into two, with the actual number killed landing up in
<code>Number</code> and the column <code>killed</code> being empty. If you
look at the data file, the data values for <code>Number killed</code> are
actually aligned with the word <code>Number</code>, which is why it came
out this way. Also, you’ll note, the column names have those
“backticks” around them, because they contain illegal characters
like a minus sign and spaces. Perhaps a good way to
pre-empt
<label for="tufte-mn-128" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-128" class="margin-toggle"><span class="marginnote">My daughter learned the word pre-empt because we like to play a bridge app on my phone; in the game of bridge, you make a pre-emptive bid when you have no great strength but a lot of cards of one suit, say seven, and it won’t be too bad if that suit is trumps, no matter what your partner has. If you have a weakish hand with a lot of cards in one suit, your opponents are probably going to be able to bid and make something, so you pre-emptively bid first to try and make it difficult for them.</span> all these problems is to
make a copy of the data file with the illegal characters replaced by
underscores, which is my file <code>exposed2.txt</code>:</p>
<div class="sourceCode" id="cb1921"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1921-1"><a href="logistic-regression.html#cb1921-1"></a>bugs2 &lt;-<span class="st"> </span><span class="kw">read_table</span>(<span class="st">&quot;exposed2.txt&quot;</span>)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   Log_Concentration = col_double(),
##   Insects_exposed = col_double(),
##   Number_killed = col_double()
## )</code></pre>
<div class="sourceCode" id="cb1923"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1923-1"><a href="logistic-regression.html#cb1923-1"></a>bugs2</span></code></pre></div>
<pre><code>## # A tibble: 5 x 3
##   Log_Concentration Insects_exposed Number_killed
##               &lt;dbl&gt;           &lt;dbl&gt;         &lt;dbl&gt;
## 1              0.96              50             6
## 2              1.33              48            16
## 3              1.63              46            24
## 4              2.04              49            42
## 5              2.32              50            44</code></pre>
<p>This is definitely good. We’d have to be careful with Capital Letters
this way, but it’s definitely good.</p>
<p>You may have thought that this was a lot of fuss to make about reading
in data, but the point is that data can come your way in lots of
different forms, and you need to be able to handle whatever you
receive so that you can do some analysis with it.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li><a name="part:expo">*</a> Looking at the data, would you expect there to be a
significant effect of log-concentration? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The numbers of insects killed goes up <em>sharply</em> as the
concentration increases, while the numbers of insects exposed
don’t change much. So I would expect to see a strong, positive
effect of concentration, and I would expect it to be strongly
significant, especially since we have almost 250 insects altogether.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>We are going to do a logistic regression to predict how
likely an insect is to be killed, as it depends on the
log-concentration. Create a suitable response variable, bearing in
mind (i) that we have lots of insects exposed to each different
concentration, and (ii) what needs to go into each column of the response.</li>
</ol>
<p>Solution</p>
<p>There needs to be a two-column response variable. The first column
needs to be the number of “successes” (insects killed, here) and
the second needs to be the number of “failures” (insects that
survived). We don’t actually have the latter, but we know how many
insects were exposed in total to each dose, so we can work it
out. Like this:</p>
<div class="sourceCode" id="cb1925"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1925-1"><a href="logistic-regression.html#cb1925-1"></a>dead_bugs <span class="op">%&gt;%</span></span>
<span id="cb1925-2"><a href="logistic-regression.html#cb1925-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">survived =</span> exposed <span class="op">-</span><span class="st"> </span>killed) <span class="op">%&gt;%</span></span>
<span id="cb1925-3"><a href="logistic-regression.html#cb1925-3"></a><span class="st">  </span><span class="kw">select</span>(killed, survived) <span class="op">%&gt;%</span></span>
<span id="cb1925-4"><a href="logistic-regression.html#cb1925-4"></a><span class="st">  </span><span class="kw">as.matrix</span>() -&gt;<span class="st"> </span>response</span>
<span id="cb1925-5"><a href="logistic-regression.html#cb1925-5"></a>response</span></code></pre></div>
<pre><code>##      killed survived
## [1,]      6       44
## [2,]     16       32
## [3,]     24       22
## [4,]     42        7
## [5,]     44        6</code></pre>
<p><code>glm</code> requires an R <code>matrix</code> rather than a data
frame, so the last stage of our pipeline is to create one (using the
same numbers that are in the data frame: all the <code>as.</code>
functions do is to change what type of thing it is, without changing
its contents).</p>
<p>It’s also equally good to create the response <em>outside</em> of the
data frame and use <code>cbind</code> to glue its columns together:</p>
<div class="sourceCode" id="cb1927"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1927-1"><a href="logistic-regression.html#cb1927-1"></a>resp2 &lt;-<span class="st"> </span><span class="kw">with</span>(</span>
<span id="cb1927-2"><a href="logistic-regression.html#cb1927-2"></a>  dead_bugs,</span>
<span id="cb1927-3"><a href="logistic-regression.html#cb1927-3"></a>  <span class="kw">cbind</span>(killed, <span class="dt">survived =</span> exposed <span class="op">-</span><span class="st"> </span>killed)</span>
<span id="cb1927-4"><a href="logistic-regression.html#cb1927-4"></a>)</span>
<span id="cb1927-5"><a href="logistic-regression.html#cb1927-5"></a>resp2</span></code></pre></div>
<pre><code>##      killed survived
## [1,]      6       44
## [2,]     16       32
## [3,]     24       22
## [4,]     42        7
## [5,]     44        6</code></pre>
<ol start="4" style="list-style-type: lower-alpha">
<li>Run a suitable logistic regression, and obtain a summary of
the results.</li>
</ol>
<p>Solution</p>
<p>I think you know how to do this by now:</p>
<div class="sourceCode" id="cb1929"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1929-1"><a href="logistic-regression.html#cb1929-1"></a>bugs<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(response <span class="op">~</span><span class="st"> </span>log_conc, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> dead_bugs)</span>
<span id="cb1929-2"><a href="logistic-regression.html#cb1929-2"></a><span class="kw">summary</span>(bugs<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = response ~ log_conc, family = &quot;binomial&quot;, data = dead_bugs)
## 
## Deviance Residuals: 
##       1        2        3        4        5  
## -0.1963   0.2099  -0.2978   0.8726  -0.7222  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -4.8923     0.6426  -7.613 2.67e-14 ***
## log_conc      3.1088     0.3879   8.015 1.11e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 96.6881  on 4  degrees of freedom
## Residual deviance:  1.4542  on 3  degrees of freedom
## AIC: 24.675
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<ol start="5" style="list-style-type: lower-alpha">
<li>Does your analysis support your answer to (<a href="#part:expo">here</a>)?
Explain briefly.</li>
</ol>
<p>Solution</p>
<p>That’s a <em>very</em> small P-value, <span class="math inline">\(1.1\times 10^{-15}\)</span>, on
<code>log_conc</code>, so there is no doubt that concentration has an
effect on an insect’s chances of being killed. This is exactly what
I guessed in (<a href="#part:expo">here</a>), which I did before looking at the
results, honest!</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Obtain predicted probabilities of an insect’s being killed at
each of the log-concentrations in the data set. (This is easier than
it sometimes is, because here you don’t create a new data frame for
<code>predict</code>.)</li>
</ol>
<p>Solution</p>
<p>Just this (notice there are only <em>two</em> things going into
<code>predict</code>):</p>
<div class="sourceCode" id="cb1931"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1931-1"><a href="logistic-regression.html#cb1931-1"></a>prob &lt;-<span class="st"> </span><span class="kw">predict</span>(bugs<span class="fl">.1</span>, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb1931-2"><a href="logistic-regression.html#cb1931-2"></a><span class="kw">cbind</span>(dead_bugs<span class="op">$</span>log_conc, prob)</span></code></pre></div>
<pre><code>##             prob
## 1 0.96 0.1292158
## 2 1.33 0.3191540
## 3 1.63 0.5436313
## 4 2.04 0.8099321
## 5 2.32 0.9105221</code></pre>
<p>or, if you frame everything in terms of the <code>tidyverse</code>, turn
the predictions from a <code>matrix</code> into a <code>tibble</code> first,
and then use <code>bind_cols</code> to glue them together:</p>
<div class="sourceCode" id="cb1933"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1933-1"><a href="logistic-regression.html#cb1933-1"></a><span class="kw">as_tibble</span>(prob) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">bind_cols</span>(dead_bugs)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 4
##   value log_conc exposed killed
##   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1 0.129     0.96      50      6
## 2 0.319     1.33      48     16
## 3 0.544     1.63      46     24
## 4 0.810     2.04      49     42
## 5 0.911     2.32      50     44</code></pre>
<p>The advantage of showing the whole input data frame is that you can
compare the observed with the predicted. For example, 44 out of 50
insects were killed at log-dose 2.32, which is a proportion of 0.88,
pretty close to the prediction of 0.91.</p>
<ol start="7" style="list-style-type: lower-alpha">
<li>People in this kind of work are often interested in the
“median lethal dose”. In this case, that would be the
log-concentration of the insecticide that kills half the
insects. Based on your predictions, roughly what do you think the
median lethal dose is?</li>
</ol>
<p>Solution</p>
<p>The log-concentration of 1.63 is predicted to kill just over half
the insects, so the median lethal dose should be a bit less than
1.63. It should not be as small as 1.33, though, since that
log-concentration only kills less than a third of the insects. So I
would guess somewhere a bit bigger than 1.5. Any guess somewhere in
this ballpark is fine: you really cannot be very accurate.</p>
<p>Extra: this is kind of a strange prediction problem, because we know what
the <em>response</em> variable should be, and we want to know what the
explanatory variable’s value is. Normally we do predictions the
other way around.
<label for="tufte-mn-129" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-129" class="margin-toggle"><span class="marginnote">This kind of thing is sometimes called an inverse prediction.</span>
So the only way to get a more accurate figure is
to try some different log-concentrations, and see which one gets
closest to a probability 0.5 of killing the insect.</p>
<p>Something like this would work:</p>
<div class="sourceCode" id="cb1935"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1935-1"><a href="logistic-regression.html#cb1935-1"></a>lc.new &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">log_conc =</span> <span class="kw">seq</span>(<span class="fl">1.5</span>, <span class="fl">1.63</span>, <span class="fl">0.01</span>))</span>
<span id="cb1935-2"><a href="logistic-regression.html#cb1935-2"></a>prob &lt;-<span class="st"> </span><span class="kw">predict</span>(bugs<span class="fl">.1</span>, lc.new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb1935-3"><a href="logistic-regression.html#cb1935-3"></a><span class="kw">cbind</span>(lc.new, prob)</span></code></pre></div>
<pre><code>##    log_conc      prob
## 1      1.50 0.4429568
## 2      1.51 0.4506406
## 3      1.52 0.4583480
## 4      1.53 0.4660754
## 5      1.54 0.4738191
## 6      1.55 0.4815754
## 7      1.56 0.4893406
## 8      1.57 0.4971110
## 9      1.58 0.5048827
## 10     1.59 0.5126521
## 11     1.60 0.5204154
## 12     1.61 0.5281689
## 13     1.62 0.5359087
## 14     1.63 0.5436313</code></pre>
<p>The closest one of these to a probability of 0.5 is 0.4971, which goes
with a log-concentration of 1.57: indeed, a bit bigger than 1.5 and a
bit less than 1.63. The <code>seq</code> in the construction of the new
data frame is “fill sequence”: go from 1.5 to 1.63 in steps of
0.01. The rest of it is the same as before.</p>
<p>Now, of course this is only our “best guess”, like a single-number
prediction in regression. There is uncertainty attached to it (because
the actual logistic regression might be different from the one we
estimated), so we ought to provide a confidence interval for it. But
I’m riding the bus as I type this, so I can’t look it up right now.</p>
<p>Later: there’s a function called <code>dose.p</code>
in <code>MASS</code> that appears to do this:</p>
<div class="sourceCode" id="cb1937"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1937-1"><a href="logistic-regression.html#cb1937-1"></a><span class="kw">library</span>(MASS)</span>
<span id="cb1937-2"><a href="logistic-regression.html#cb1937-2"></a>lethal &lt;-<span class="st"> </span><span class="kw">dose.p</span>(bugs<span class="fl">.1</span>)</span>
<span id="cb1937-3"><a href="logistic-regression.html#cb1937-3"></a>lethal</span></code></pre></div>
<pre><code>##              Dose         SE
## p = 0.5: 1.573717 0.05159576</code></pre>
<p>We have a sensible point estimate (the same 1.57 that we got by hand),
and we have a standard error, so we can make a confidence interval by
going up and down twice it (or 1.96 times it) from the estimate. The
structure of the result is a bit arcane, though:</p>
<div class="sourceCode" id="cb1939"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1939-1"><a href="logistic-regression.html#cb1939-1"></a><span class="kw">str</span>(lethal)</span></code></pre></div>
<pre><code>##  &#39;glm.dose&#39; Named num 1.57
##  - attr(*, &quot;names&quot;)= chr &quot;p = 0.5:&quot;
##  - attr(*, &quot;SE&quot;)= num [1, 1] 0.0516
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr &quot;p = 0.5:&quot;
##   .. ..$ : NULL
##  - attr(*, &quot;p&quot;)= num 0.5</code></pre>
<p>It is what R calls a “vector with attributes”. To get at the pieces and calculate the interval, we have to do something like this:</p>
<div class="sourceCode" id="cb1941"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1941-1"><a href="logistic-regression.html#cb1941-1"></a>(lethal_est &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(lethal))</span></code></pre></div>
<pre><code>## [1] 1.573717</code></pre>
<div class="sourceCode" id="cb1943"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1943-1"><a href="logistic-regression.html#cb1943-1"></a>(lethal_SE &lt;-<span class="st"> </span><span class="kw">as.vector</span>(<span class="kw">attr</span>(lethal, <span class="st">&quot;SE&quot;</span>)))</span></code></pre></div>
<pre><code>## [1] 0.05159576</code></pre>
<p>and then make the interval:</p>
<div class="sourceCode" id="cb1945"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1945-1"><a href="logistic-regression.html#cb1945-1"></a>lethal_est <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>lethal_SE</span></code></pre></div>
<pre><code>## [1] 1.470526 1.676909</code></pre>
<p>1.47 to 1.68.</p>
<p>I got this idea from page 4.14 of
<a href="http://www.chrisbilder.com/stat875old/schedule_new/chapter4.doc">link</a>. I
think I got a little further than he did. An idea that works more
generally is to get several intervals all at once, say for the
“quartile lethal doses” as well:</p>
<div class="sourceCode" id="cb1947"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1947-1"><a href="logistic-regression.html#cb1947-1"></a>lethal &lt;-<span class="st"> </span><span class="kw">dose.p</span>(bugs<span class="fl">.1</span>, <span class="dt">p =</span> <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>))</span>
<span id="cb1947-2"><a href="logistic-regression.html#cb1947-2"></a>lethal</span></code></pre></div>
<pre><code>##               Dose         SE
## p = 0.25: 1.220327 0.07032465
## p = 0.50: 1.573717 0.05159576
## p = 0.75: 1.927108 0.06532356</code></pre>
<p>This looks like a data frame or matrix, but is actually a
“named vector”, so <code>enframe</code> will get at least some of this and turn
it into a genuine data frame:</p>
<div class="sourceCode" id="cb1949"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1949-1"><a href="logistic-regression.html#cb1949-1"></a><span class="kw">enframe</span>(lethal)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 2
##   name      value     
##   &lt;chr&gt;     &lt;glm.dose&gt;
## 1 p = 0.25: 1.220327  
## 2 p = 0.50: 1.573717  
## 3 p = 0.75: 1.927108</code></pre>
<p>That doesn’t get the SEs, so we’ll make a new column by grabbing the “attribute” as above:</p>
<div class="sourceCode" id="cb1951"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1951-1"><a href="logistic-regression.html#cb1951-1"></a><span class="kw">enframe</span>(lethal) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">SE =</span> <span class="kw">attr</span>(lethal, <span class="st">&quot;SE&quot;</span>))</span></code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   name      value      SE[,1]
##   &lt;chr&gt;     &lt;glm.dose&gt;  &lt;dbl&gt;
## 1 p = 0.25: 1.220327   0.0703
## 2 p = 0.50: 1.573717   0.0516
## 3 p = 0.75: 1.927108   0.0653</code></pre>
<p>and now we make the intervals by making new columns containing the lower and upper limits:</p>
<div class="sourceCode" id="cb1953"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1953-1"><a href="logistic-regression.html#cb1953-1"></a><span class="kw">enframe</span>(lethal) <span class="op">%&gt;%</span></span>
<span id="cb1953-2"><a href="logistic-regression.html#cb1953-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">SE =</span> <span class="kw">attr</span>(lethal, <span class="st">&quot;SE&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb1953-3"><a href="logistic-regression.html#cb1953-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">LCL =</span> value <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>SE, <span class="dt">UCL =</span> value <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>SE)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   name      value      SE[,1] LCL[,1] UCL[,1]
##   &lt;chr&gt;     &lt;glm.dose&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1 p = 0.25: 1.220327   0.0703    1.08    1.36
## 2 p = 0.50: 1.573717   0.0516    1.47    1.68
## 3 p = 0.75: 1.927108   0.0653    1.80    2.06</code></pre>
<p>Now we have intervals for the median lethal dose, as well as for the doses that kill a quarter and three quarters of the aphids.</p>
<p>To end this question, we loaded <code>MASS</code>, so we should unload it before we run into
problems with
<code>select</code> later:</p>
<div class="sourceCode" id="cb1955"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1955-1"><a href="logistic-regression.html#cb1955-1"></a><span class="kw">detach</span>(<span class="st">&quot;package:MASS&quot;</span>, <span class="dt">unload =</span> T)</span></code></pre></div>
<pre><code>## Warning: &#39;MASS&#39; namespace cannot be unloaded:
##   namespace &#39;MASS&#39; is imported by &#39;lme4&#39; so cannot be unloaded</code></pre>
</div>
<div id="the-effects-of-substance-a" class="section level2" number="18.3">
<h2><span class="header-section-number">18.3</span> The effects of Substance A</h2>
<p>In a dose-response experiment, animals (or
cell cultures or human subjects) are exposed to some toxic substance,
and we observe how many of them show some sort of response. In this
experiment, a mysterious Substance A is exposed at various doses to
100 cells at each dose, and the number of cells at each dose that
suffer damage is recorded. The doses were 10, 20, … 70 (mg), and
the number of damaged cells out of 100 were respectively 10, 28, 53,
77, 91, 98, 99.</p>
<ol style="list-style-type: lower-alpha">
<li>Find a way to get these data into R, and show that you have
managed to do so successfully.</li>
</ol>
<p>Solution</p>
<p>There’s not much data here, so we don’t need to create a file,
although you can do so if you like (in the obvious way: type the
doses and damaged cell numbers into a <code>.txt</code> file or
spreadsheet and read in with the appropriate <code>read_</code>
function).
Or, use a <code>tribble</code>:</p>
<div class="sourceCode" id="cb1957"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1957-1"><a href="logistic-regression.html#cb1957-1"></a>dr &lt;-<span class="st"> </span><span class="kw">tribble</span>(</span>
<span id="cb1957-2"><a href="logistic-regression.html#cb1957-2"></a>  <span class="op">~</span>dose, <span class="op">~</span>damaged,</span>
<span id="cb1957-3"><a href="logistic-regression.html#cb1957-3"></a>  <span class="dv">10</span>, <span class="dv">10</span>,</span>
<span id="cb1957-4"><a href="logistic-regression.html#cb1957-4"></a>  <span class="dv">20</span>, <span class="dv">28</span>,</span>
<span id="cb1957-5"><a href="logistic-regression.html#cb1957-5"></a>  <span class="dv">30</span>, <span class="dv">53</span>,</span>
<span id="cb1957-6"><a href="logistic-regression.html#cb1957-6"></a>  <span class="dv">40</span>, <span class="dv">77</span>,</span>
<span id="cb1957-7"><a href="logistic-regression.html#cb1957-7"></a>  <span class="dv">50</span>, <span class="dv">91</span>,</span>
<span id="cb1957-8"><a href="logistic-regression.html#cb1957-8"></a>  <span class="dv">60</span>, <span class="dv">98</span>,</span>
<span id="cb1957-9"><a href="logistic-regression.html#cb1957-9"></a>  <span class="dv">70</span>, <span class="dv">99</span></span>
<span id="cb1957-10"><a href="logistic-regression.html#cb1957-10"></a>)</span>
<span id="cb1957-11"><a href="logistic-regression.html#cb1957-11"></a>dr</span></code></pre></div>
<pre><code>## # A tibble: 7 x 2
##    dose damaged
##   &lt;dbl&gt;   &lt;dbl&gt;
## 1    10      10
## 2    20      28
## 3    30      53
## 4    40      77
## 5    50      91
## 6    60      98
## 7    70      99</code></pre>
<p>Or, make a data frame with the values typed in:</p>
<div class="sourceCode" id="cb1959"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1959-1"><a href="logistic-regression.html#cb1959-1"></a>dr2 &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb1959-2"><a href="logistic-regression.html#cb1959-2"></a>  <span class="dt">dose =</span> <span class="kw">seq</span>(<span class="dv">10</span>, <span class="dv">70</span>, <span class="dv">10</span>),</span>
<span id="cb1959-3"><a href="logistic-regression.html#cb1959-3"></a>  <span class="dt">damaged =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">28</span>, <span class="dv">53</span>, <span class="dv">77</span>, <span class="dv">91</span>, <span class="dv">98</span>, <span class="dv">99</span>)</span>
<span id="cb1959-4"><a href="logistic-regression.html#cb1959-4"></a>)</span>
<span id="cb1959-5"><a href="logistic-regression.html#cb1959-5"></a>dr2</span></code></pre></div>
<pre><code>## # A tibble: 7 x 2
##    dose damaged
##   &lt;dbl&gt;   &lt;dbl&gt;
## 1    10      10
## 2    20      28
## 3    30      53
## 4    40      77
## 5    50      91
## 6    60      98
## 7    70      99</code></pre>
<p><code>seq</code> fills a sequence “10 to 70 in steps of 10”, or you can
just list the doses.</p>
<p>I like this better than making two columns <em>not</em> attached to a
data frame, but that will work as well.</p>
<p>For these, find a way you like, and stick with it.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Would you expect to see a significant effect of dose for
these data?
Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The number of damaged cells goes up sharply as the dose goes up
(from a very small number to almost all of them). So I’d expect
to see a strongly significant effect of dose. This is far from
something that would happen by chance.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Fit a logistic regression modelling the probability of a
cell being damaged as it depends on dose. Display the
results. (Comment on them is coming later.)</li>
</ol>
<p>Solution</p>
<p>This has a bunch of observations at each dose (100 cells, in
fact), so we need to do the two-column response thing: the
successes in the first column and the failures in the
second. This means that we first need to calculate the number of
cells at each dose that were not damaged, by subtracting the
number that <em>were</em> damaged from 100. R makes this easier
than you’d think, as
you see. A <code>mutate</code> is the way to
go: create a new column in <code>dr</code> and save back in
<code>dr</code> (because I like living on the edge):</p>
<div class="sourceCode" id="cb1961"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1961-1"><a href="logistic-regression.html#cb1961-1"></a>dr &lt;-<span class="st"> </span>dr <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">undamaged =</span> <span class="dv">100</span> <span class="op">-</span><span class="st"> </span>damaged)</span>
<span id="cb1961-2"><a href="logistic-regression.html#cb1961-2"></a>dr</span></code></pre></div>
<pre><code>## # A tibble: 7 x 3
##    dose damaged undamaged
##   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;
## 1    10      10        90
## 2    20      28        72
## 3    30      53        47
## 4    40      77        23
## 5    50      91         9
## 6    60      98         2
## 7    70      99         1</code></pre>
<p>The programmer in you is probably complaining “but, 100 is a number and <code>damaged</code> is a vector of 7 numbers. How does R know to subtract <em>each one</em> from 100?” Well, R has what’s known as
“recycling rules”: if you try to add or subtract (or elementwise
multiply or divide) two vectors of different lengths, it recycles the
smaller one by repeating it until it’s as long as the longer one. So
rather than <code>100-damaged</code> giving an error, it does what you
want.
<label for="tufte-mn-130" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-130" class="margin-toggle"><span class="marginnote">The usual application of this is to combine a number with a vector. If you try to subtract a length-2 vector from a length-6 vector, R will repeat the shorter one three times and do the subtraction, but if you try to subtract a length-2 vector from a length-<em>7</em> vector, where you’d have to repeat the shorter one a fractional number of times, R will do it, but you’ll get a warning, because this is probably <em>not</em> what you wanted. Try it and see.</span></p>
<p>I took the risk of saving the new data frame over the old one. If it
had failed for some reason, I could have started again.</p>
<p>Now we have to make our response “matrix” with two columns, using <code>cbind</code>:</p>
<div class="sourceCode" id="cb1963"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1963-1"><a href="logistic-regression.html#cb1963-1"></a>response &lt;-<span class="st"> </span><span class="kw">with</span>(dr, <span class="kw">cbind</span>(damaged, undamaged))</span>
<span id="cb1963-2"><a href="logistic-regression.html#cb1963-2"></a>response</span></code></pre></div>
<pre><code>##      damaged undamaged
## [1,]      10        90
## [2,]      28        72
## [3,]      53        47
## [4,]      77        23
## [5,]      91         9
## [6,]      98         2
## [7,]      99         1</code></pre>
<p>Note that each row adds up to 100, since there were 100 cells at each
dose. This is actually trickier than it looks: the two things in
<code>cbind</code> are columns (vectors), and <code>cbind</code> glues them
together to make an R <code>matrix</code>:</p>
<div class="sourceCode" id="cb1965"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1965-1"><a href="logistic-regression.html#cb1965-1"></a><span class="kw">class</span>(response)</span></code></pre></div>
<pre><code>## [1] &quot;matrix&quot; &quot;array&quot;</code></pre>
<p>which is what <code>glm</code> needs here, even though it looks a lot like
a data frame (which wouldn’t work here). This <em>would</em> be a data
frame:</p>
<div class="sourceCode" id="cb1967"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1967-1"><a href="logistic-regression.html#cb1967-1"></a>dr <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(damaged, undamaged) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">class</span>()</span></code></pre></div>
<pre><code>## [1] &quot;tbl_df&quot;     &quot;tbl&quot;        &quot;data.frame&quot;</code></pre>
<p>and would therefore be the wrong thing to give <code>glm</code>. So I had
to do it with <code>cbind</code>, or use some other trickery, like this:</p>
<div class="sourceCode" id="cb1969"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1969-1"><a href="logistic-regression.html#cb1969-1"></a>dr <span class="op">%&gt;%</span></span>
<span id="cb1969-2"><a href="logistic-regression.html#cb1969-2"></a><span class="st">  </span><span class="kw">select</span>(damaged, undamaged) <span class="op">%&gt;%</span></span>
<span id="cb1969-3"><a href="logistic-regression.html#cb1969-3"></a><span class="st">  </span><span class="kw">as.matrix</span>() -&gt;<span class="st"> </span>resp</span>
<span id="cb1969-4"><a href="logistic-regression.html#cb1969-4"></a><span class="kw">class</span>(resp)</span></code></pre></div>
<pre><code>## [1] &quot;matrix&quot; &quot;array&quot;</code></pre>
<p>Now we fit our model:</p>
<div class="sourceCode" id="cb1971"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1971-1"><a href="logistic-regression.html#cb1971-1"></a>cells<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(response <span class="op">~</span><span class="st"> </span>dose, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> dr)</span>
<span id="cb1971-2"><a href="logistic-regression.html#cb1971-2"></a><span class="kw">summary</span>(cells<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = response ~ dose, family = &quot;binomial&quot;, data = dr)
## 
## Deviance Residuals: 
##        1         2         3         4         5         6         7  
## -0.16650   0.28794  -0.02092  -0.20637  -0.21853   0.54693  -0.06122  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -3.275364   0.278479  -11.76   &lt;2e-16 ***
## dose         0.113323   0.008315   13.63   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 384.13349  on 6  degrees of freedom
## Residual deviance:   0.50428  on 5  degrees of freedom
## AIC: 31.725
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<ol start="4" style="list-style-type: lower-alpha">
<li>Does your output indicate that the probability of damage
really does <em>increase</em> with dose? (There are two things here:
is there really an effect, and which way does it go?)</li>
</ol>
<p>Solution</p>
<p>The slope of <code>dose</code> is significantly nonzero (P-value
less than <span class="math inline">\(2.2 \times 10^{-16}\)</span>, which is as small as it can
be). The slope itself is <em>positive</em>, which means that as
dose goes up, the probability of damage goes up.
That’s all I needed, but if you want to press on: the slope is
0.113, so an increase of 1 in dose goes with an increase of
0.113 in the <em>log-odds</em> of damage. Or it multiplies the
odds of damage by <span class="math inline">\(\exp(0.113)\)</span>. Since 0.113 is small, this is
about <span class="math inline">\(1.113\)</span> (mathematically, <span class="math inline">\(e^x\simeq 1+x\)</span> if <span class="math inline">\(x\)</span> is small),
so that the increase is about 11%.
If you like, you can get a rough CI for the slope by going up
and down twice its standard error (this is the usual
approximately-normal thing). Here that would be</p>
<div class="sourceCode" id="cb1973"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1973-1"><a href="logistic-regression.html#cb1973-1"></a><span class="fl">0.113323</span> <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="fl">0.008315</span></span></code></pre></div>
<pre><code>## [1] 0.096693 0.129953</code></pre>
<p>I thought about doing that in my head, but thought better of it, since
I have R just sitting here. The interval is short (we have lots of
data) and definitely does not contain zero.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Obtain predicted damage probabilities for the doses that
were actually used in the experiment. (This is easier than some of
our other predictions: if you are using the original data, you only
need to feed in the fitted model object and not a data frame of new
data.) Display your predicted probabilities next to the doses and
the observed numbers of damaged cells.</li>
</ol>
<p>Solution</p>
<p>The remaining care that this needs is to make sure that we do
indeed get predicted probabilities, and then some
<code>cbind</code>ing to get the right kind of display:</p>
<div class="sourceCode" id="cb1975"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1975-1"><a href="logistic-regression.html#cb1975-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(cells<span class="fl">.1</span>, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb1975-2"><a href="logistic-regression.html#cb1975-2"></a><span class="kw">with</span>(dr, <span class="kw">cbind</span>(dose, damaged, p))</span></code></pre></div>
<pre><code>##   dose damaged         p
## 1   10      10 0.1050689
## 2   20      28 0.2671957
## 3   30      53 0.5310440
## 4   40      77 0.7786074
## 5   50      91 0.9161232
## 6   60      98 0.9713640
## 7   70      99 0.9905969</code></pre>
<p>If you forget the <code>type="response"</code> you’ll get predicted
log-odds, which are not nearly so easy to interpret.</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Looking at the predicted probabilities, would you say that
the model fits well? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>There were 100 cells tested at each dose, so that the predicted
probabilities should be close to the observed numbers divided by
100. They are in fact <em>very</em> close to this, so the model
fits very well.
Your actual words are a judgement call, so precisely what you
say doesn’t matter so much, but <em>I</em> think this model fit is
actually closer than you could even hope to expect, it’s that
good. But, your call. I think your answer ought to contain
“close” or “fits well” at the very least.</p>
</div>
<div id="what-makes-an-animal-get-infected" class="section level2" number="18.4">
<h2><span class="header-section-number">18.4</span> What makes an animal get infected?</h2>
<p>Some animals got infected with a parasite. We are interested
in whether the likelihood of infection depends on any of the age,
weight and sex of the animals. The data are at
<a href="http://www.utsc.utoronto.ca/~butler/d29/infection.txt">link</a>. The
values are separated by tabs.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data and take a look at the first few lines. Is
this one animal per line, or are several animals with the same age,
weight and sex (and infection status) combined onto one line? How
can you tell?</li>
</ol>
<p>Solution</p>
<p>The usual beginnings, bearing in mind the data layout:</p>
<div class="sourceCode" id="cb1977"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1977-1"><a href="logistic-regression.html#cb1977-1"></a>my_url &lt;-<span class="st"> &quot;http://www.utsc.utoronto.ca/~butler/d29/infection.txt&quot;</span></span>
<span id="cb1977-2"><a href="logistic-regression.html#cb1977-2"></a>infect &lt;-<span class="st"> </span><span class="kw">read_tsv</span>(my_url)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   infected = col_character(),
##   age = col_double(),
##   weight = col_double(),
##   sex = col_character()
## )</code></pre>
<div class="sourceCode" id="cb1979"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1979-1"><a href="logistic-regression.html#cb1979-1"></a>infect</span></code></pre></div>
<pre><code>## # A tibble: 81 x 4
##    infected   age weight sex   
##    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; 
##  1 absent       2      1 female
##  2 absent       9     13 female
##  3 present     15      2 female
##  4 absent      15     16 female
##  5 absent      18      2 female
##  6 absent      20      9 female
##  7 absent      26     13 female
##  8 present     42      6 female
##  9 absent      51      9 female
## 10 present     52      6 female
## # … with 71 more rows</code></pre>
<p>Success.
This appears to be one animal per line, since there is no indication
of frequency (of “how many”). If you were working as a consultant
with somebody’s data, this would be a good thing to confirm with them
before you went any further.</p>
<p>You can check a few more lines to
convince yourself:</p>
<div class="sourceCode" id="cb1981"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1981-1"><a href="logistic-regression.html#cb1981-1"></a>infect <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">n =</span> <span class="dv">20</span>)</span></code></pre></div>
<pre><code>## # A tibble: 81 x 4
##    infected   age weight sex   
##    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; 
##  1 absent       2      1 female
##  2 absent       9     13 female
##  3 present     15      2 female
##  4 absent      15     16 female
##  5 absent      18      2 female
##  6 absent      20      9 female
##  7 absent      26     13 female
##  8 present     42      6 female
##  9 absent      51      9 female
## 10 present     52      6 female
## 11 present     59     12 female
## 12 absent      68     10 female
## 13 absent      72     15 female
## 14 present     73      1 female
## 15 absent      78     15 female
## 16 absent      80     16 female
## 17 present     82     14 female
## 18 present     91     12 female
## 19 present    105      5 female
## 20 present    114      8 female
## # … with 61 more rows</code></pre>
<p>and the story is much the same. The other hint is that you have actual
categories of response, which usually indicates one individual per
row, but not always. If it doesn’t, you have some extra work to do to
bash it into the right format.</p>
<p>Extra: let’s see whether we can come up with an example of that. I’ll make a
smaller example, and perhaps the place to start is
“all possible combinations” of a few things.
If you haven’t seen <code>crossing</code>
before, skip ahead to part (<a href="#part:crossing">here</a>):</p>
<div class="sourceCode" id="cb1983"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1983-1"><a href="logistic-regression.html#cb1983-1"></a>d &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">age =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">12</span>), <span class="dt">gender =</span> <span class="kw">c</span>(<span class="st">&quot;f&quot;</span>, <span class="st">&quot;m&quot;</span>), <span class="dt">infected =</span> <span class="kw">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;n&quot;</span>))</span>
<span id="cb1983-2"><a href="logistic-regression.html#cb1983-2"></a>d</span></code></pre></div>
<pre><code>## # A tibble: 8 x 3
##     age gender infected
##   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   
## 1    10 f      n       
## 2    10 f      y       
## 3    10 m      n       
## 4    10 m      y       
## 5    12 f      n       
## 6    12 f      y       
## 7    12 m      n       
## 8    12 m      y</code></pre>
<p>These might be one individual per row, or they might be more than one,
as they would be if we have a column of frequencies:</p>
<div class="sourceCode" id="cb1985"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1985-1"><a href="logistic-regression.html#cb1985-1"></a>d &lt;-<span class="st"> </span>d <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">freq =</span> <span class="kw">c</span>(<span class="dv">12</span>, <span class="dv">19</span>, <span class="dv">17</span>, <span class="dv">11</span>, <span class="dv">18</span>, <span class="dv">26</span>, <span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb1985-2"><a href="logistic-regression.html#cb1985-2"></a>d</span></code></pre></div>
<pre><code>## # A tibble: 8 x 4
##     age gender infected  freq
##   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;
## 1    10 f      n           12
## 2    10 f      y           19
## 3    10 m      n           17
## 4    10 m      y           11
## 5    12 f      n           18
## 6    12 f      y           26
## 7    12 m      n           16
## 8    12 m      y            8</code></pre>
<p>Now, these are multiple observations per row (the presence of
frequencies means there’s no doubt about that), but the format is
wrong: <code>infected</code> is my response variable, and we want the
frequencies of <code>infected</code> being <code>y</code> or <code>n</code> in
<em>separate</em> columns — that is, we have to <em>untidy</em> the data
a bit to make it suitable for modelling. This is <code>pivot_wider</code>, the
opposite of <code>pivot_longer</code>:</p>
<div class="sourceCode" id="cb1987"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1987-1"><a href="logistic-regression.html#cb1987-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_wider</span>(<span class="dt">names_from=</span>infected, <span class="dt">values_from=</span>freq)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 4
##     age gender     n     y
##   &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1    10 f         12    19
## 2    10 m         17    11
## 3    12 f         18    26
## 4    12 m         16     8</code></pre>
<p>Now you can pull out the columns <code>y</code> and <code>n</code> and make
them into your response, and predict that from <code>age</code> and
<code>gender</code>.</p>
<p>The moral of this story is that if you are going to have multiple
observations per row, you probably want the combinations of
<em>explanatory</em> variables one per row, but you want the categories
of the <em>response</em> variable in separate columns.</p>
<p>Back to where we were the rest of the way.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li><a name="part:plot">*</a> Make suitable plots or summaries of <code>infected</code> against
each of the other variables. (You’ll have to think about
<code>sex</code>, um, you’ll have to think about the <code>sex</code>
variable, because it too is categorical.) Anything sensible is OK
here. You might like to think back to what we did in
Question <a href="#q:wolfspider">here</a> for inspiration. (You can also
investigate <code>table</code>, which does cross-tabulations.)</li>
</ol>
<p>Solution</p>
<p>What comes to my mind for the numerical variables <code>age</code> and
<code>weight</code> is boxplots:</p>
<div class="sourceCode" id="cb1989"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1989-1"><a href="logistic-regression.html#cb1989-1"></a><span class="kw">ggplot</span>(infect, <span class="kw">aes</span>(<span class="dt">x =</span> infected, <span class="dt">y =</span> age)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/fodudu-1.png" width="672"  /></p>
<div class="sourceCode" id="cb1990"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1990-1"><a href="logistic-regression.html#cb1990-1"></a><span class="kw">ggplot</span>(infect, <span class="kw">aes</span>(<span class="dt">x =</span> infected, <span class="dt">y =</span> weight)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/fodudu-2.png" width="672"  /></p>
<p>The variables <code>sex</code> and <code>infected</code> are both
categorical. I guess a good plot for those would be some kind of
grouped bar plot, which I have to think about.
So let’s first try a numerical summary, a
cross-tabulation, which is gotten via <code>table</code>:</p>
<div class="sourceCode" id="cb1991"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1991-1"><a href="logistic-regression.html#cb1991-1"></a><span class="kw">with</span>(infect, <span class="kw">table</span>(sex, infected))</span></code></pre></div>
<pre><code>##         infected
## sex      absent present
##   female     17      11
##   male       47       6</code></pre>
<p>Or, if you like the <code>tidyverse</code>:</p>
<div class="sourceCode" id="cb1993"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1993-1"><a href="logistic-regression.html#cb1993-1"></a>infect <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(sex, infected)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   sex    infected     n
##   &lt;chr&gt;  &lt;chr&gt;    &lt;int&gt;
## 1 female absent      17
## 2 female present     11
## 3 male   absent      47
## 4 male   present      6</code></pre>
<p>Now, bar plots. Let’s start with one variable. The basic bar plot has
categories of a categorical variable along the <span class="math inline">\(x\)</span>-axis and each bar
is a count of how many observations were in that category. What is
nice about <code>geom_bar</code> is that it will do the counting for you,
so that the plot is just this:</p>
<div class="sourceCode" id="cb1995"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1995-1"><a href="logistic-regression.html#cb1995-1"></a><span class="kw">ggplot</span>(infect, <span class="kw">aes</span>(<span class="dt">x =</span> sex)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>()</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-50-1.png" width="672"  /></p>
<p>There are about twice as many males as females.</p>
<p>You may think that this looks like a histogram, which it almost does,
but there is an important difference: the kind of variable on the
<span class="math inline">\(x\)</span>-axis. Here, it is a categorical variable, and you count how many
observations fall in each category (at least, <code>ggplot</code>
does). On a histogram, the <span class="math inline">\(x\)</span>-axis variable is a continuous
<em>numerical</em> one, like height or weight, and you have to
<em>chop it up</em> into intervals (and then you count how many
observations are in each chopped-up interval).</p>
<p>Technically, on a bar plot, the bars have a little gap between them
(as here), whereas the histogram bars are right next to each other,
because the right side of one histogram bar is the left side of the next.</p>
<p>All right, two categorical variables. The idea is that you have each
bar divided into sub-bars based on the frequencies of a second
variable, which is specified by <code>fill</code>. Here’s the basic idea:</p>
<div class="sourceCode" id="cb1996"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1996-1"><a href="logistic-regression.html#cb1996-1"></a><span class="kw">ggplot</span>(infect, <span class="kw">aes</span>(<span class="dt">x =</span> sex, <span class="dt">fill =</span> infected)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>()</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-51-1.png" width="672"  /></p>
<p>This is known in the business as a “stacked bar chart”. The issue is
how much of each bar is blue, which is unnecessarily hard to judge
because the male bar is taller. (Here, it is not so bad, because the
amount of blue in the male bar is smaller and the bar is also
taller. But we got lucky here.)</p>
<p>There are two ways to improve this. One is known as a “grouped bar chart”, which goes like this:</p>
<div class="sourceCode" id="cb1997"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1997-1"><a href="logistic-regression.html#cb1997-1"></a><span class="kw">ggplot</span>(infect, <span class="kw">aes</span>(<span class="dt">x =</span> sex, <span class="dt">fill =</span> infected)) <span class="op">+</span></span>
<span id="cb1997-2"><a href="logistic-regression.html#cb1997-2"></a><span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>)</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-52-1.png" width="672"  /></p>
<p>The absent and present frequencies for females are next to each other,
and the same for males, and you can read off how big they are from the
<span class="math inline">\(y\)</span>-scale. This is my preferred graph for two (or more than two)
categorical variables.</p>
<p>You could switch the roles of <code>sex</code> and <code>infected</code> and
get a different chart, but one that conveys the same information. Try
it. (The reason for doing it the way around I did is that being
infected or not is the response and <code>sex</code> is explanatory, so
that on my plot you can ask “out of the males, how many were infected?”,
which is the way around that makes sense.)</p>
<p>The second way is to go back to stacked bars, but make them the same
height, so you can compare the fractions of the bars that are each
colour. This is <code>position="fill"</code>:</p>
<div class="sourceCode" id="cb1998"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1998-1"><a href="logistic-regression.html#cb1998-1"></a><span class="kw">ggplot</span>(infect, <span class="kw">aes</span>(<span class="dt">x =</span> sex, <span class="dt">fill =</span> infected)) <span class="op">+</span></span>
<span id="cb1998-2"><a href="logistic-regression.html#cb1998-2"></a><span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">position =</span> <span class="st">&quot;fill&quot;</span>)</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-53-1.png" width="672"  /></p>
<p>This also shows that more of the females were infected than the males,
but without getting sidetracked into the issue that there were more
males to begin with.</p>
<p>I wrote this question in early 2017. At that time, I wrote (quote):</p>
<p>I learned about this one approximately two hours ago. I just ordered
Hadley Wickham’s new book “R for Data Science” from Amazon, and it
arrived today. It’s in there. (A good read, by the way. I’m thinking
of using it as a recommended text next year.)
As is so often the way with <code>ggplot</code>, the final answer looks
very simple, but there is a lot of thinking required to get there, and
you end up having even more respect for Hadley Wickham for the clarity
of thinking that enabled this to be specified in a simple way.</p>
<p>(end quote)</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Which, if any, of your explanatory variables appear to be
related to <code>infected</code>? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Let’s go through our output from (<a href="#part:plot">here</a>). In terms of
<code>age</code>, when infection is present, animals are (slightly)
older. So there might be a small age effect. Next, when infection
is present, weight is typically a <em>lot</em> less. So there ought
to be a big weight effect.
Finally, from the table, females are
somewhere around 50-50 infected or not, but very few males are
infected. So there ought to be a big <code>sex</code> effect as well.
This also appears in the grouped bar plot, where the red
(“absent”) bar for males is much taller than the blue
(“present”) bar, but for females the two bars are almost the
same height.
So the story is that we would expect a significant effect of
<code>sex</code> and <code>weight</code>, and maybe of <code>age</code> as well.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a logistic regression predicting <code>infected</code> from
the other three variables. Display the <code>summary</code>.</li>
</ol>
<p>Solution</p>
<p>Thus:</p>
<div class="sourceCode" id="cb1999"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1999-1"><a href="logistic-regression.html#cb1999-1"></a>infect<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(infected <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>weight <span class="op">+</span><span class="st"> </span>sex, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> infect)</span></code></pre></div>
<pre><code>## Error in eval(family$initialize): y values must be 0 &lt;= y &lt;= 1</code></pre>
<p>Oh, I forgot to turn <code>infected</code> into a factor. This is the
shortcut way to do that:</p>
<div class="sourceCode" id="cb2001"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2001-1"><a href="logistic-regression.html#cb2001-1"></a>infect<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">factor</span>(infected) <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>weight <span class="op">+</span><span class="st"> </span>sex, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> infect)</span>
<span id="cb2001-2"><a href="logistic-regression.html#cb2001-2"></a><span class="kw">summary</span>(infect<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = factor(infected) ~ age + weight + sex, family = &quot;binomial&quot;, 
##     data = infect)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.9481  -0.5284  -0.3120  -0.1437   2.2525  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.609369   0.803288   0.759 0.448096    
## age          0.012653   0.006772   1.868 0.061701 .  
## weight      -0.227912   0.068599  -3.322 0.000893 ***
## sexmale     -1.543444   0.685681  -2.251 0.024388 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 83.234  on 80  degrees of freedom
## Residual deviance: 59.859  on 77  degrees of freedom
## AIC: 67.859
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>The “proper” way to do it is to create a new column in the data
frame containing the factor version of <code>infected</code>. Pipeline
fans among you can do it this way:</p>
<div class="sourceCode" id="cb2003"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2003-1"><a href="logistic-regression.html#cb2003-1"></a>infect <span class="op">%&gt;%</span></span>
<span id="cb2003-2"><a href="logistic-regression.html#cb2003-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">infected =</span> <span class="kw">factor</span>(infected)) <span class="op">%&gt;%</span></span>
<span id="cb2003-3"><a href="logistic-regression.html#cb2003-3"></a><span class="st">  </span><span class="kw">glm</span>(infected <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>weight <span class="op">+</span><span class="st"> </span>sex, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> .) -&gt;<span class="st"> </span>infect<span class="fl">.1</span>a</span>
<span id="cb2003-4"><a href="logistic-regression.html#cb2003-4"></a><span class="kw">summary</span>(infect<span class="fl">.1</span>a)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = infected ~ age + weight + sex, family = &quot;binomial&quot;, 
##     data = .)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.9481  -0.5284  -0.3120  -0.1437   2.2525  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.609369   0.803288   0.759 0.448096    
## age          0.012653   0.006772   1.868 0.061701 .  
## weight      -0.227912   0.068599  -3.322 0.000893 ***
## sexmale     -1.543444   0.685681  -2.251 0.024388 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 83.234  on 80  degrees of freedom
## Residual deviance: 59.859  on 77  degrees of freedom
## AIC: 67.859
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Either way is good, and gives the same answer. The second way uses the
<code>data=.</code> trick to ensure that the input data frame to
<code>glm</code> is the output from the previous step, the one with the
factor version of <code>infected</code> in it. The <code>data=.</code> is
needed because <code>glm</code> requires a model formula first rather than
a data frame (if the data were first, you could just omit it).</p>
<ol start="5" style="list-style-type: lower-alpha">
<li><a name="part:remove">*</a> Which variables, if any, would you consider removing from
the model? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>This is the same idea as in multiple regression: look at the end
of the line for each variable to get its individual P-value, and
if that’s not small, you can take that variable out. <code>age</code>
has a P-value of 0.062, which is (just) larger than 0.05, so we
can consider removing this variable. The other two P-values,
0.00089 and 0.024, are definitely less than 0.05, so those
variables should stay.</p>
<p>Alternatively, you can say that the P-value for <code>age</code> is
small enough to be interesting, and therefore that <code>age</code>
should stay. That’s fine, but then you need to be consistent in
the next part.</p>
<p>You probably noted that <code>sex</code> is categorical. However, it
has only the obvious two levels, and such a categorical variable
can be assessed for significance this way. If you were worried
about this, the right way to go is <code>drop1</code>:</p>
<div class="sourceCode" id="cb2005"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2005-1"><a href="logistic-regression.html#cb2005-1"></a><span class="kw">drop1</span>(infect<span class="fl">.1</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Single term deletions
## 
## Model:
## factor(infected) ~ age + weight + sex
##        Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## &lt;none&gt;      59.859 67.859                      
## age     1   63.785 69.785  3.9268 0.0475236 *  
## weight  1   72.796 78.796 12.9373 0.0003221 ***
## sex     1   65.299 71.299  5.4405 0.0196754 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The P-values are similar, but not identical.
<label for="tufte-mn-131" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-131" class="margin-toggle"><span class="marginnote">The <em>test</em> is this way because it’s a generalized linear model rather than a regular regression.</span></p>
<p>I have to stop and think about this. There is a lot of theory that
says there are several ways to do stuff in regression, but they are
all identical. The theory doesn’t quite apply the same in generalized
linear models (of which logistic regression is one): if you had an
infinite sample size, the ways would all be identical, but in practice
you’ll have a very finite amount of data, so they won’t agree.</p>
<p>I’m thinking about my aims here: I want to decide whether each
<span class="math inline">\(x\)</span>-variable should stay in the model, and for that I want a test that
expresses whether the model fits significantly worse if I take it
out. The result I get ought to be the same as physically removing it
and comparing the models with <code>anova</code>,
eg. for <code>age</code>:</p>
<div class="sourceCode" id="cb2007"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2007-1"><a href="logistic-regression.html#cb2007-1"></a>infect<span class="fl">.1</span>b &lt;-<span class="st"> </span><span class="kw">update</span>(infect<span class="fl">.1</span>, . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span>age)</span>
<span id="cb2007-2"><a href="logistic-regression.html#cb2007-2"></a><span class="kw">anova</span>(infect<span class="fl">.1</span>b, infect<span class="fl">.1</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: factor(infected) ~ weight + sex
## Model 2: factor(infected) ~ age + weight + sex
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)  
## 1        78     63.785                       
## 2        77     59.859  1   3.9268  0.04752 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This is the same thing as <code>drop1</code> gives.</p>
<p>So, I think: use <code>drop1</code> to assess whether anything should come
out of a model like this, and use <code>summary</code> to obtain the
slopes to interpret (in this kind of model, whether they’re positive
or negative, and thus what kind of effect each explanatory variable
has on the probability of whatever-it-is.)</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Are the conclusions you drew in (<a href="#part:plot">here</a>) and
(<a href="#part:remove">here</a>) consistent, or not? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>I think they are extremely consistent. When we looked at the
plots, we said that <code>weight</code> and <code>sex</code> had large
effects, and they came out definitely significant. There was a
small difference in age between the infected and non-infected
groups, and <code>age</code> came out borderline significant (with a
P-value definitely larger than for the other variables, so that
the evidence of its usefulness was weaker).</p>
<ol start="7" style="list-style-type: lower-alpha">
<li><a name="part:crossing">*</a>
The first and third quartiles of <code>age</code> are 26 and 130;
the first and third quartiles of <code>weight</code> are 9 and 16. Obtain predicted probabilities for all combinations of these and
<code>sex</code>. (You’ll need to start by making a new data frame, using
<code>crossing</code> to get all the combinations.)</li>
</ol>
<p>Solution</p>
<p>Here’s how <code>crossing</code>
goes. I’ll do it in steps. Note my use of plural names to denote
the things I want all combinations of:</p>
<div class="sourceCode" id="cb2009"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2009-1"><a href="logistic-regression.html#cb2009-1"></a>ages &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">26</span>, <span class="dv">130</span>)</span>
<span id="cb2009-2"><a href="logistic-regression.html#cb2009-2"></a>weights &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">9</span>, <span class="dv">16</span>)</span>
<span id="cb2009-3"><a href="logistic-regression.html#cb2009-3"></a>sexes &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;female&quot;</span>, <span class="st">&quot;male&quot;</span>)</span>
<span id="cb2009-4"><a href="logistic-regression.html#cb2009-4"></a>infect.new &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">age =</span> ages, <span class="dt">weight =</span> weights, <span class="dt">sex =</span> sexes)</span>
<span id="cb2009-5"><a href="logistic-regression.html#cb2009-5"></a>infect.new</span></code></pre></div>
<pre><code>## # A tibble: 8 x 3
##     age weight sex   
##   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; 
## 1    26      9 female
## 2    26      9 male  
## 3    26     16 female
## 4    26     16 male  
## 5   130      9 female
## 6   130      9 male  
## 7   130     16 female
## 8   130     16 male</code></pre>
<p>I could have asked you to include some more values of <code>age</code> and
<code>weight</code>, for example the median as well, to get a clearer
picture. But that would have made <code>infect.new</code> bigger, so I
stopped here.</p>
<p><code>crossing</code> <em>makes</em> a data frame from input vectors, so it
doesn’t matter if those are different lengths. In fact, it’s also
possible to make this data frame from things like quartiles stored in
a data frame. To do that (as we did in the hospital satisfaction
question), you wrap the whole <code>crossing</code> in a <code>with</code>.</p>
<p>Next, the predictions:</p>
<div class="sourceCode" id="cb2011"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2011-1"><a href="logistic-regression.html#cb2011-1"></a>pred &lt;-<span class="st"> </span><span class="kw">predict</span>(infect<span class="fl">.1</span>, infect.new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2011-2"><a href="logistic-regression.html#cb2011-2"></a><span class="kw">cbind</span>(infect.new, pred)</span></code></pre></div>
<pre><code>##   age weight    sex       pred
## 1  26      9 female 0.24733693
## 2  26      9   male 0.06560117
## 3  26     16 female 0.06248811
## 4  26     16   male 0.01404012
## 5 130      9 female 0.55058652
## 6 130      9   male 0.20744380
## 7 130     16 female 0.19903348
## 8 130     16   male 0.05041244</code></pre>
<p>I didn’t ask you to comment on these, since the question is long
enough already. But that’s not going to stop me!</p>
<p>These are predicted probabilities of infection.
<label for="tufte-mn-132" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-132" class="margin-toggle"><span class="marginnote">When you have one observation per line, the predictions are of the <em>second</em> of the two levels of the response variable. When you make that two-column response, the predictions are of the probability of being in the <em>first</em> column. That’s what it is. As the young people say, don’t @ me.</span></p>
<p>The way I remember the one-column-response thing is that the first
level is the baseline (as it is in a regression with a categorical
explanatory variable), and the second level is the one whose
probability is modelled (in the same way that the second, third etc.<br />
levels of a categorical explanatory variable are the ones that appear
in the <code>summary</code> table).</p>
<p>Let’s start with <code>sex</code>. The probabilities of a female being
infected are all much higher than of a corresponding male (with the
same age and weight) being infected. Compare, for example, lines 1 and
2. Or 3 and 4. Etc. So <code>sex</code> has a big effect.</p>
<p>What about <code>weight</code>? As weight goes from 9 to 16, with
everything else the same, the predicted probability of infection goes
sharply <em>down</em>. This is what we saw before: precisely, the
boxplot showed us that infected animals were likely to be less heavy.</p>
<p>Last, <code>age</code>. As age goes up, the probabilities go (somewhat) up
as well. Compare, for example, lines 1 and 5 or lines 4 and 8. I think
this is a less dramatic change than for the other variables, but
that’s a judgement call.</p>
<p>I got this example from (horrible URL warning) here: <a href="https://www.amazon.ca/Statistics-Introduction-Michael-J-Crawley/dp/0470022973/ref=pd_sbs_14_3?_encoding=UTF8&amp;pd_rd_i=0470022973&amp;pd_rd_r=97f19951-0ca9-11e9-9275-b3e00a75f9be&amp;pd_rd_w=EfpAv&amp;pd_rd_wg=2NMH8&amp;pf_rd_p=d4c8ffae-b082-4374-b96d-0608daba52bb&amp;pf_rd_r=HAKACF78DSNTGFPDW3YV&amp;psc=1&amp;refRID=HAKACF78DSNTGFPDW3YV">link</a>
It starts on page 275 in my edition. He goes at the analysis
a different way, but he finishes with
another issue that I want to show you.</p>
<p>Let’s work out the residuals and plot them against our quantitative
explanatory variables. I think the best way to do this is
<code>augment</code> from <code>broom</code>, to create a data frame
containing the residuals alongside the original data:</p>
<div class="sourceCode" id="cb2013"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2013-1"><a href="logistic-regression.html#cb2013-1"></a><span class="kw">library</span>(broom)</span>
<span id="cb2013-2"><a href="logistic-regression.html#cb2013-2"></a>infect<span class="fl">.1</span>a &lt;-<span class="st"> </span>infect<span class="fl">.1</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>(infect)</span>
<span id="cb2013-3"><a href="logistic-regression.html#cb2013-3"></a>infect<span class="fl">.1</span>a <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>()</span></code></pre></div>
<pre><code>## # A tibble: 81 x 10
##    infected   age weight sex    .fitted .resid .std.resid   .hat .sigma  .cooksd
##    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;
##  1 absent       2      1 female   0.407 -1.35      -1.46  0.140   0.872 0.0710  
##  2 absent       9     13 female  -2.24  -0.450     -0.463 0.0544  0.886 0.00162 
##  3 present     15      2 female   0.343  1.04       1.10  0.116   0.878 0.0263  
##  4 absent      15     16 female  -2.85  -0.336     -0.343 0.0416  0.887 0.000657
##  5 absent      18      2 female   0.381 -1.34      -1.43  0.112   0.872 0.0521  
##  6 absent      20      9 female  -1.19  -0.729     -0.755 0.0678  0.883 0.00594 
##  7 absent      26     13 female  -2.02  -0.498     -0.511 0.0515  0.886 0.00189 
##  8 present     42      6 female  -0.227  1.28       1.32  0.0664  0.874 0.0239  
##  9 absent      51      9 female  -0.797 -0.863     -0.886 0.0515  0.882 0.00645 
## 10 present     52      6 female  -0.100  1.22       1.26  0.0609  0.876 0.0191  
## # … with 71 more rows</code></pre>
<div class="sourceCode" id="cb2015"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2015-1"><a href="logistic-regression.html#cb2015-1"></a><span class="kw">ggplot</span>(infect<span class="fl">.1</span>a, <span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> .resid)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb2015-2"><a href="logistic-regression.html#cb2015-2"></a><span class="st">  </span><span class="kw">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-61-1.png" width="672"  /></p>
<p><code>infect.1a</code> is, I think, a genuine <code>data.frame</code> rather
than a <code>tibble</code>.</p>
<p>I don’t quite know what to make of that plot. It doesn’t look quite
random, and yet there are just some groups of points rather than any
real kind of trend.</p>
<p>The corresponding plot with age goes the same way:</p>
<div class="sourceCode" id="cb2017"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2017-1"><a href="logistic-regression.html#cb2017-1"></a><span class="kw">ggplot</span>(infect<span class="fl">.1</span>a, <span class="kw">aes</span>(<span class="dt">x =</span> age, <span class="dt">y =</span> .resid)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb2017-2"><a href="logistic-regression.html#cb2017-2"></a><span class="st">  </span><span class="kw">geom_smooth</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-62-1.png" width="672"  /></p>
<p>Crawley found the slightest suggestion of an up-and-down curve in
there. I’m not sure I agree, but that’s what he saw. As with a
regular regression, the residuals against anything should look random,
with no trends. (Though the residuals from a logistic regression can
be kind of odd, because the response variable can only be 1 or 0.)
Crawley tries adding squared terms to the logistic regression, which
goes like this. The <code>glm</code> statement is long, as they usually
are, so it’s much easier to use <code>update</code>:</p>
<div class="sourceCode" id="cb2019"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2019-1"><a href="logistic-regression.html#cb2019-1"></a>infect<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">update</span>(infect<span class="fl">.1</span>, . <span class="op">~</span><span class="st"> </span>. <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(age<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(weight<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<p>As we saw before, when thinking about what to keep, we want to look at <code>drop1</code>:</p>
<div class="sourceCode" id="cb2020"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2020-1"><a href="logistic-regression.html#cb2020-1"></a><span class="kw">drop1</span>(infect<span class="fl">.2</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Single term deletions
## 
## Model:
## factor(infected) ~ age + weight + sex + I(age^2) + I(weight^2)
##             Df Deviance    AIC    LRT Pr(&gt;Chi)   
## &lt;none&gt;           48.620 60.620                   
## age          1   57.631 67.631 9.0102 0.002685 **
## weight       1   50.443 60.443 1.8222 0.177054   
## sex          1   51.298 61.298 2.6771 0.101800   
## I(age^2)     1   55.274 65.274 6.6534 0.009896 **
## I(weight^2)  1   53.091 63.091 4.4710 0.034474 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The squared terms are both significant. The linear terms,
<code>age</code> and <code>weight</code>, have to stay, regardless of their
significance.
<label for="tufte-mn-133" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-133" class="margin-toggle"><span class="marginnote">When you have higher-order terms, you have to keep the lower-order ones as well: higher powers, or interactions (as we see in ANOVA later).</span>
What do the squared terms do to the predictions? Before, there was a
clear one-directional trend in the relationships with <code>age</code> and
<code>weight</code>. Has that changed? Let’s see. We’ll need a few more
ages and weights to investigate with. Below, I use <code>seq</code> a
different way to get a filled series of a desired length:</p>
<div class="sourceCode" id="cb2022"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2022-1"><a href="logistic-regression.html#cb2022-1"></a>weights &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">9</span>, <span class="dv">16</span>, <span class="dt">length.out =</span> <span class="dv">6</span>)</span>
<span id="cb2022-2"><a href="logistic-regression.html#cb2022-2"></a>weights</span></code></pre></div>
<pre><code>## [1]  9.0 10.4 11.8 13.2 14.6 16.0</code></pre>
<div class="sourceCode" id="cb2024"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2024-1"><a href="logistic-regression.html#cb2024-1"></a>ages &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">26</span>, <span class="dv">130</span>, <span class="dt">length.out =</span> <span class="dv">6</span>)</span>
<span id="cb2024-2"><a href="logistic-regression.html#cb2024-2"></a>ages</span></code></pre></div>
<pre><code>## [1]  26.0  46.8  67.6  88.4 109.2 130.0</code></pre>
<div class="sourceCode" id="cb2026"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2026-1"><a href="logistic-regression.html#cb2026-1"></a>infect.new &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">weight =</span> weights, <span class="dt">age =</span> ages, <span class="dt">sex =</span> sexes)</span>
<span id="cb2026-2"><a href="logistic-regression.html#cb2026-2"></a>infect.new</span></code></pre></div>
<pre><code>## # A tibble: 72 x 3
##    weight   age sex   
##     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 
##  1      9  26   female
##  2      9  26   male  
##  3      9  46.8 female
##  4      9  46.8 male  
##  5      9  67.6 female
##  6      9  67.6 male  
##  7      9  88.4 female
##  8      9  88.4 male  
##  9      9 109.  female
## 10      9 109.  male  
## # … with 62 more rows</code></pre>
<p>The values are kind of dopey, but they are equally spaced between the
two endpoints.</p>
<p>All right, predictions. I’m re-doing the predictions from the previous
model (without the squared terms), for annoying technical
reasons. Then the data frame <code>pp</code> below will contain the
predictions from both models so that we can compare them:</p>
<div class="sourceCode" id="cb2028"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2028-1"><a href="logistic-regression.html#cb2028-1"></a>pred &lt;-<span class="st"> </span><span class="kw">predict</span>(infect<span class="fl">.2</span>, infect.new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2028-2"><a href="logistic-regression.html#cb2028-2"></a>pred.old &lt;-<span class="st"> </span><span class="kw">predict</span>(infect<span class="fl">.1</span>, infect.new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2028-3"><a href="logistic-regression.html#cb2028-3"></a>pp &lt;-<span class="st"> </span><span class="kw">cbind</span>(infect.new, pred.old, pred)</span></code></pre></div>
<p>This is rather a big data frame, so we’ll pull out bits of it to
assess the effect of things. First, the effect of weight (for example
for females of age 46.8, though it is the same idea for all the other
age-sex combinations as well):</p>
<div class="sourceCode" id="cb2029"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2029-1"><a href="logistic-regression.html#cb2029-1"></a>pp <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(age <span class="op">==</span><span class="st"> </span><span class="fl">46.8</span>, sex <span class="op">==</span><span class="st"> &quot;female&quot;</span>)</span></code></pre></div>
<pre><code>##    weight  age    sex  pred.old       pred
## 3     9.0 46.8 female 0.2994990 0.55303814
## 15   10.4 46.8 female 0.2370788 0.42818659
## 27   11.8 46.8 female 0.1842462 0.27804272
## 39   13.2 46.8 female 0.1410112 0.14407377
## 51   14.6 46.8 female 0.1065959 0.05884193
## 63   16.0 46.8 female 0.0797997 0.01935264</code></pre>
<p>The predicted probabilities start off a lot higher and finish a fair
bit lower. What about the effect of <code>age</code>? Let’s take males of
weight 9:</p>
<div class="sourceCode" id="cb2031"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2031-1"><a href="logistic-regression.html#cb2031-1"></a>pp <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(weight <span class="op">==</span><span class="st"> </span><span class="dv">9</span>, sex <span class="op">==</span><span class="st"> &quot;male&quot;</span>)</span></code></pre></div>
<pre><code>##    weight   age  sex   pred.old      pred
## 2       9  26.0 male 0.06560117 0.1066453
## 4       9  46.8 male 0.08369818 0.2674861
## 6       9  67.6 male 0.10622001 0.4412181
## 8       9  88.4 male 0.13391640 0.5468890
## 10      9 109.2 male 0.16748125 0.5660054
## 12      9 130.0 male 0.20744380 0.4990420</code></pre>
<p>This one is rather interesting: first of all, the
predictions are very different. Also, the old predictions went
steadily up, but the new ones go up for a bit, level off and start
coming back down again. This is because of the squared term: without
it, the predicted probabilities have to keep going in the same
direction, either up or down.</p>
<p>Which age, weight and sex of animals is under the most risk under our
new model? There’s a trick here: work out the maximum value of
<code>pred</code>, and then pick out the row(s) where <code>pred</code> is
equal to that maximum value:</p>
<div class="sourceCode" id="cb2033"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2033-1"><a href="logistic-regression.html#cb2033-1"></a>pp <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(pred <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(pred))</span></code></pre></div>
<pre><code>##   weight   age    sex  pred.old      pred
## 9      9 109.2 female 0.4849694 0.8154681</code></pre>
<p>Old, non-heavy females, but curiously enough not the <em>oldest</em>
females (because of that squared term).</p>
<p>This would also work:</p>
<div class="sourceCode" id="cb2035"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2035-1"><a href="logistic-regression.html#cb2035-1"></a>pp <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">max.pred =</span> <span class="kw">max</span>(pred))</span></code></pre></div>
<pre><code>##    max.pred
## 1 0.8154681</code></pre>
<p>but then you wouldn’t see what contributed to that highest predicted
probability. What you might do then is to say
“let’s find all the predicted probabilities bigger than 0.8”:</p>
<div class="sourceCode" id="cb2037"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2037-1"><a href="logistic-regression.html#cb2037-1"></a>pp <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(pred <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.8</span>)</span></code></pre></div>
<pre><code>##   weight   age    sex  pred.old      pred
## 7      9  88.4 female 0.4198664 0.8035256
## 9      9 109.2 female 0.4849694 0.8154681</code></pre>
<p>which includes the highest and second-highest ones. Or, you can
<em>sort</em> the predictions in descending order and look at the first few:</p>
<div class="sourceCode" id="cb2039"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2039-1"><a href="logistic-regression.html#cb2039-1"></a>pp <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(pred)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)</span></code></pre></div>
<pre><code>##    weight   age    sex  pred.old      pred
## 9     9.0 109.2 female 0.4849694 0.8154681
## 7     9.0  88.4 female 0.4198664 0.8035256
## 11    9.0 130.0 female 0.5505865 0.7714535
## 5     9.0  67.6 female 0.3574375 0.7279306
## 21   10.4 109.2 female 0.4063155 0.7278482
## 19   10.4  88.4 female 0.3447044 0.7122362
## 23   10.4 130.0 female 0.4710234 0.6713570
## 17   10.4  67.6 female 0.2879050 0.6182061
## 33   11.8 109.2 female 0.3321903 0.5790306
## 10    9.0 109.2   male 0.1674812 0.5660054</code></pre>
</div>
<div id="the-brain-of-a-cat" class="section level2" number="18.5">
<h2><span class="header-section-number">18.5</span> The brain of a cat</h2>
<p>A large number (315) of psychology students were asked to
imagine that they were serving on a university ethics committee
hearing a complaint against animal research being done by a member of
the faculty. The students were told that the surgery consisted of
implanting a device called a cannula in each cat’s brain, through
which chemicals were introduced into the brain and the cats were then
given psychological tests. At the end of the study, the cats’ brains
were subjected to histological analysis. The complaint asked that the
researcher’s authorization to carry out the study should be withdrawn,
and the cats should be handed over to the animal rights group that
filed the complaint. It was suggested that the research could just as
well be done with computer simulations.</p>
<p>All of the psychology students in the survey were told all of this. In
addition, they read a statement by the researcher that no animal felt
much pain at any time, and that computer simulation was <em>not</em> an
adequate substitute for animal research. Each student was also given
<em>one</em> of the following scenarios that explained the benefit of
the research:</p>
<ul>
<li><p>“cosmetic”: testing the toxicity of chemicals to be used in
new lines of hair care products.</p></li>
<li><p>“theory”: evaluating two competing theories about the function
of a particular nucleus in the brain.</p></li>
<li><p>“meat”: testing a synthetic growth hormone said to potentially
increase meat production.</p></li>
<li><p>“veterinary”: attempting to find a cure for a brain disease
that is killing domesticated cats and endangered species of wild cats.</p></li>
<li><p>“medical”: evaluating a potential cure for a debilitating
disease that afflicts many young adult humans.</p></li>
</ul>
<p>Finally, each student completed two questionnaires: one that would assess their
“relativism”: whether or not they believe in universal moral
principles (low score) or whether they believed that the appropriate
action depends on the person and situation (high score). The second
questionnaire assessed “idealism”: a high score reflects a belief
that ethical behaviour will always lead to good consequences (and thus
that if a behaviour leads to any bad consequences at all, it is
unethical).
<label for="tufte-mn-134" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-134" class="margin-toggle"><span class="marginnote">I get confused about the difference between morals and ethics. This is a very short description of that difference: <a href="http://smallbusiness.chron.com/differences-between-ethical-issues-moral-issues-business-48134.html" class="uri">http://smallbusiness.chron.com/differences-between-ethical-issues-moral-issues-business-48134.html</a>. The basic idea is that morals are part of who you are, derived from religion, philosophy etc. Ethics are how you act in a particular situation: that is, your morals, what you believe, inform your ethics, what you do. That’s why the students had to play the role of an ethics committee, rather than a morals committee; presumably the researcher had good morals, but an ethics committee had to evaluate what he was planning to do, rather than his character as a person.</span></p>
<p>After being exposed to all of that, each student stated their decision
about whether the research should continue or stop.</p>
<p>I should perhaps stress at this point that no actual cats were harmed
in the collection of these data (which can be found as a <code>.csv</code>
file at
<a href="http://www.utsc.utoronto.ca/~butler/d29/decision.csv">link</a>). The
variables in the data set are these:</p>
<ul>
<li><p><code>decision</code>: whether the research should continue or stop (response)</p></li>
<li><p><code>idealism</code>: score on idealism questionnaire</p></li>
<li><p><code>relativism</code>: score on relativism questionnaire</p></li>
<li><p><code>gender</code> of student</p></li>
<li><p><code>scenario</code> of research benefits that the student read.</p></li>
</ul>
<p>A more detailed discussion
<label for="tufte-mn-135" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-135" class="margin-toggle"><span class="marginnote">If you can believe it.</span> of this
study is at
<a href="http://core.ecu.edu/psyc/wuenschk/MV/Multreg/Logistic-SPSS.PDF">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data and check by looking at the structure of
your data frame that you have something sensible. <em>Do not</em> call
your data frame <code>decision</code>, since that’s the name of one of
the variables in it.</li>
</ol>
<p>Solution</p>
<p>So, like this, using the name <code>decide</code> in my case:</p>
<div class="sourceCode" id="cb2041"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2041-1"><a href="logistic-regression.html#cb2041-1"></a>my_url &lt;-<span class="st"> &quot;http://www.utsc.utoronto.ca/~butler/d29/decision.csv&quot;</span></span>
<span id="cb2041-2"><a href="logistic-regression.html#cb2041-2"></a>decide &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   decision = col_character(),
##   idealism = col_double(),
##   relativism = col_double(),
##   gender = col_character(),
##   scenario = col_character()
## )</code></pre>
<div class="sourceCode" id="cb2043"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2043-1"><a href="logistic-regression.html#cb2043-1"></a>decide</span></code></pre></div>
<pre><code>## # A tibble: 315 x 5
##    decision idealism relativism gender scenario
##    &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   
##  1 stop          8.2        5.1 Female cosmetic
##  2 continue      6.8        5.3 Male   cosmetic
##  3 continue      8.2        6   Female cosmetic
##  4 stop          7.4        6.2 Female cosmetic
##  5 continue      1.7        3.1 Female cosmetic
##  6 continue      5.6        7.7 Male   cosmetic
##  7 stop          7.2        6.7 Female cosmetic
##  8 stop          7.8        4   Male   cosmetic
##  9 stop          7.8        4.7 Female cosmetic
## 10 stop          8          7.6 Female cosmetic
## # … with 305 more rows</code></pre>
<p>The variables are all the right things and of the right types: the
decision, gender and the scenario are all text (representing
categorical variables), and idealism and relativism, which were scores
on a test, are quantitative (numerical). There are, as promised, 315
observations.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Fit a logistic regression predicting
<code>decision</code> from <code>gender</code>. Is there an effect of gender?</li>
</ol>
<p>Solution</p>
<p>Turn the response into a <code>factor</code> somehow, either by
creating a new variable in the data frame or like this:</p>
<div class="sourceCode" id="cb2045"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2045-1"><a href="logistic-regression.html#cb2045-1"></a>decide<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">factor</span>(decision) <span class="op">~</span><span class="st"> </span>gender, <span class="dt">data =</span> decide, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb2045-2"><a href="logistic-regression.html#cb2045-2"></a><span class="kw">summary</span>(decide<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = factor(decision) ~ gender, family = &quot;binomial&quot;, 
##     data = decide)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5518  -1.0251   0.8446   0.8446   1.3377  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   0.8473     0.1543   5.491 3.99e-08 ***
## genderMale   -1.2167     0.2445  -4.976 6.50e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 425.57  on 314  degrees of freedom
## Residual deviance: 399.91  on 313  degrees of freedom
## AIC: 403.91
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>The P-value for gender is <span class="math inline">\(6.5 \times 10^{-7}\)</span>, which is very
small, so there is definitely an effect of gender. It’s not
immediately clear what kind of effect it is: that’s the reason for
the next part, and we’ll revisit this slope coefficient in a moment.
Categorical <em>explanatory</em> variables are perfectly all right
as text.
Should I have used <code>drop1</code> to assess the significance? Maybe:</p>
<div class="sourceCode" id="cb2047"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2047-1"><a href="logistic-regression.html#cb2047-1"></a><span class="kw">drop1</span>(decide<span class="fl">.1</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Single term deletions
## 
## Model:
## factor(decision) ~ gender
##        Df Deviance    AIC    LRT  Pr(&gt;Chi)    
## &lt;none&gt;      399.91 403.91                     
## gender  1   425.57 427.57 25.653 4.086e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The thing is, this gives us a P-value but not a slope, which we might
have wanted to try to interpret. Also, the P-value in <code>summary</code>
is so small that it is likely to be still significant in
<code>drop1</code> as well.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>To investigate the effect (or non-effect) of
<code>gender</code>, create a contingency table by feeding
<code>decision</code> and <code>gender</code> into <code>table</code>. What does
this tell you?</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb2049"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2049-1"><a href="logistic-regression.html#cb2049-1"></a><span class="kw">with</span>(decide, <span class="kw">table</span>(decision, gender))</span></code></pre></div>
<pre><code>##           gender
## decision   Female Male
##   continue     60   68
##   stop        140   47</code></pre>
<p>Females are more likely to say that the study should stop (a clear
majority), while males are more evenly split, with a small majority in
favour of the study continuing.</p>
<p>If you want the column percents as well, you can use
<code>prop.table</code>. Two steps: save the table from above into a
variable, then feed <em>that</em> into <code>prop.table</code>, calling for
column percentages rather than row percentages:</p>
<div class="sourceCode" id="cb2051"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2051-1"><a href="logistic-regression.html#cb2051-1"></a>tab &lt;-<span class="st"> </span><span class="kw">with</span>(decide, <span class="kw">table</span>(decision, gender))</span>
<span id="cb2051-2"><a href="logistic-regression.html#cb2051-2"></a><span class="kw">prop.table</span>(tab, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##           gender
## decision      Female      Male
##   continue 0.3000000 0.5913043
##   stop     0.7000000 0.4086957</code></pre>
<p>Why column percentages? Well, thinking back to STAB22 or some such
place, when one of your variables is acting like a response or outcome
(<code>decision</code> here), make the percentages out of the <em>other</em>
one. Given that a student is a female, how likely are they to call for
the research to stop? The other way around makes less sense: given
that a person wanted the research to stop, how likely are they to be
female?</p>
<p>About 70% of females and 40% of males want the research to
stop. That’s a giant-sized difference. No wonder it was significant.</p>
<p>The other way of making the table is to use <code>xtabs</code>, with the
same result:</p>
<div class="sourceCode" id="cb2053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2053-1"><a href="logistic-regression.html#cb2053-1"></a><span class="kw">xtabs</span>(<span class="op">~</span><span class="st"> </span>decision <span class="op">+</span><span class="st"> </span>gender, <span class="dt">data =</span> decide)</span></code></pre></div>
<pre><code>##           gender
## decision   Female Male
##   continue     60   68
##   stop        140   47</code></pre>
<p>In this one, the frequency variable goes on the left side of the
squiggle. We don’t have one here (each row of the data frame
represents one student), so we leave the left side blank. I tried
putting a <code>.</code> there, but that doesn’t work since there is no
“whatever was there before” as there is, for example, in
<code>update</code>.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li><a name="part:whichprob">*</a> Is your slope for <code>gender</code> in the previous logistic
regression positive or negative? Is it applying to males or to females?
Looking at the conclusions from your
contingency table, what probability does that mean your logistic
regression is actually modelling?</li>
</ol>
<p>Solution</p>
<p>My slope is <span class="math inline">\(-1.2167\)</span>, negative, and it is attached to males (note
that the slope is called <code>gendermale</code>: because “female”
is before “male” alphabetically, females are used as the
baseline and this slope says how males compare to them).
This negative male coefficient means that the probability of
whatever is being modelled is <em>less</em> for males than it is for
females. Looking at the contingency table for the last part, the
probability of “stop” should be less for males, so the logistic
regression is actually modelling the probability of
“stop”. Another way to reason that this must be the right answer
is that the two values of <code>decision</code> are <code>continue</code>
and <code>stop</code>; <code>continue</code> is first alphabetically, so
it’s the baseline, and the <em>other</em> one, <code>stop</code>, is the
one whose probability is being modelled.
That’s why I made you do that contingency table. Another way to
think about
this is to do a prediction, which would go like this:</p>
<div class="sourceCode" id="cb2055"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2055-1"><a href="logistic-regression.html#cb2055-1"></a>genders &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Female&quot;</span>, <span class="st">&quot;Male&quot;</span>)</span>
<span id="cb2055-2"><a href="logistic-regression.html#cb2055-2"></a>new &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">gender =</span> genders)</span>
<span id="cb2055-3"><a href="logistic-regression.html#cb2055-3"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(decide<span class="fl">.1</span>, new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2055-4"><a href="logistic-regression.html#cb2055-4"></a><span class="kw">cbind</span>(new, p)</span></code></pre></div>
<pre><code>##   gender         p
## 1 Female 0.7000000
## 2   Male 0.4086957</code></pre>
<p>The probability of whatever-it-is is exactly 70% for females and
about 40% for males. A quick look at the contingency table shows
that exactly 70% (<span class="math inline">\(140/200\)</span>) of the females think the research should
stop, and a bit less than 50% of the males think the same thing. So
the model is predicting the probability of “stop”.</p>
<p>There’s a logic to this: it’s not just this way “because it is”.
It’s the same idea of the first category, now of the response
factor, being a “baseline”, and what actually gets modelled is the
<em>second</em> category, relative to the baseline.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Add the two variables <code>idealism</code> and
<code>relativism</code> to your logistic regression. Do either or both of them add
significantly to your model? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The obvious way of doing this is to type out the entire model,
with the two new variables on the end. You have to remember to
turn <code>decision</code> into a <code>factor</code> again:</p>
<div class="sourceCode" id="cb2057"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2057-1"><a href="logistic-regression.html#cb2057-1"></a>decide<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">factor</span>(decision) <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>idealism <span class="op">+</span><span class="st"> </span>relativism,</span>
<span id="cb2057-2"><a href="logistic-regression.html#cb2057-2"></a>  <span class="dt">data =</span> decide, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span></span>
<span id="cb2057-3"><a href="logistic-regression.html#cb2057-3"></a>)</span>
<span id="cb2057-4"><a href="logistic-regression.html#cb2057-4"></a><span class="kw">summary</span>(decide<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = factor(decision) ~ gender + idealism + relativism, 
##     family = &quot;binomial&quot;, data = decide)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2226  -0.9891   0.4798   0.8748   2.0442  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -1.4876     0.9787  -1.520  0.12849    
## genderMale   -1.1710     0.2679  -4.372 1.23e-05 ***
## idealism      0.6893     0.1115   6.180 6.41e-10 ***
## relativism   -0.3432     0.1245  -2.757  0.00584 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 425.57  on 314  degrees of freedom
## Residual deviance: 346.50  on 311  degrees of freedom
## AIC: 354.5
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>This is not so bad, copying and pasting. But
the way I like better, when you’re making a smallish change to a
longish model, is to use <code>update</code>:</p>
<div class="sourceCode" id="cb2059"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2059-1"><a href="logistic-regression.html#cb2059-1"></a>decide<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">update</span>(decide<span class="fl">.1</span>, . <span class="op">~</span><span class="st"> </span>. <span class="op">+</span><span class="st"> </span>idealism <span class="op">+</span><span class="st"> </span>relativism)</span>
<span id="cb2059-2"><a href="logistic-regression.html#cb2059-2"></a><span class="kw">summary</span>(decide<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = factor(decision) ~ gender + idealism + relativism, 
##     family = &quot;binomial&quot;, data = decide)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2226  -0.9891   0.4798   0.8748   2.0442  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -1.4876     0.9787  -1.520  0.12849    
## genderMale   -1.1710     0.2679  -4.372 1.23e-05 ***
## idealism      0.6893     0.1115   6.180 6.41e-10 ***
## relativism   -0.3432     0.1245  -2.757  0.00584 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 425.57  on 314  degrees of freedom
## Residual deviance: 346.50  on 311  degrees of freedom
## AIC: 354.5
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Either way is good. The conclusion you need to draw is that they both
have something to add, because their P-values are both less than 0.05.</p>
<p>Or (and perhaps better) you can look at <code>drop1</code> of either of these:</p>
<div class="sourceCode" id="cb2061"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2061-1"><a href="logistic-regression.html#cb2061-1"></a><span class="kw">drop1</span>(decide<span class="fl">.2</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Single term deletions
## 
## Model:
## factor(decision) ~ gender + idealism + relativism
##            Df Deviance    AIC    LRT  Pr(&gt;Chi)    
## &lt;none&gt;          346.50 354.50                     
## gender      1   366.27 372.27 19.770 8.734e-06 ***
## idealism    1   393.22 399.22 46.720 8.188e-12 ***
## relativism  1   354.46 360.46  7.956  0.004792 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="6" style="list-style-type: lower-alpha">
<li>Add the variable <code>scenario</code> to your model. That is,
fit a new model with that variable plus all the others.</li>
</ol>
<p>Solution</p>
<p>To my mind, <code>update</code> wins hands down here:</p>
<div class="sourceCode" id="cb2063"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2063-1"><a href="logistic-regression.html#cb2063-1"></a>decide<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">update</span>(decide<span class="fl">.2</span>, . <span class="op">~</span><span class="st"> </span>. <span class="op">+</span><span class="st"> </span>scenario)</span></code></pre></div>
<p>You can display the summary here if you like, but we’re not going to
look at it yet.</p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Use <code>anova</code> to compare the models with and without
<code>scenario</code>. You’ll have to add a <code>test="Chisq"</code> to your
<code>anova</code>, to make sure that the test gets done.
Does <code>scenario</code> make a difference or not, at <span class="math inline">\(\alpha=0.10\)</span>?
Explain briefly.
(The reason we have to do it this way is that
<code>scenario</code> is a factor with five levels, so it has four slope
coefficients. To test them all at once, which is what we need to make
an overall test for <code>scenario</code>, this is the way it has to be
done.)</li>
</ol>
<p>Solution</p>
<p>These are the models that you fit in the last two parts:</p>
<div class="sourceCode" id="cb2064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2064-1"><a href="logistic-regression.html#cb2064-1"></a><span class="kw">anova</span>(decide<span class="fl">.2</span>, decide<span class="fl">.3</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: factor(decision) ~ gender + idealism + relativism
## Model 2: factor(decision) ~ gender + idealism + relativism + scenario
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)  
## 1       311     346.50                       
## 2       307     338.06  4   8.4431  0.07663 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The P-value is not less than 0.05, but it <em>is</em> less than 0.10,
which is what I implied to assess it with, so the scenario does make some
kind of difference.</p>
<p>Extra: another way to do this, which I like better (but the
<code>anova</code> way was what I asked in the original question), is to
look at <code>decide.3</code> and ask “what can I get rid of”, in such a
way that categorical variables stay or go as a whole. This is done
using <code>drop1</code>. It’s a little different from the corresponding
thing in regression because the right way to do the test is not an F
test, but now a chi-squared test (this is true for all generalized
linear models of which logistic regression is one):</p>
<div class="sourceCode" id="cb2066"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2066-1"><a href="logistic-regression.html#cb2066-1"></a><span class="kw">drop1</span>(decide<span class="fl">.3</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Single term deletions
## 
## Model:
## factor(decision) ~ gender + idealism + relativism + scenario
##            Df Deviance    AIC    LRT  Pr(&gt;Chi)    
## &lt;none&gt;          338.06 354.06                     
## gender      1   359.61 373.61 21.546 3.454e-06 ***
## idealism    1   384.40 398.40 46.340 9.943e-12 ***
## relativism  1   344.97 358.97  6.911  0.008567 ** 
## scenario    4   346.50 354.50  8.443  0.076630 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The test for <code>scenario</code> has four degrees of freedom (since
there are five scenarios), and is in fact exactly the same test as in
<code>anova</code>, significant at <span class="math inline">\(\alpha=0.10\)</span>.</p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Look at the <code>summary</code> of your model that contained
<code>scenario</code>. Bearing in mind that the slope coefficient for
<code>scenariocosmetic</code> is zero (since this is the first scenario
alphabetically), which scenarios have the most positive and most
negative slope coefficients? What does that tell you about those
scenarios’ effects?</li>
</ol>
<p>Solution</p>
<p>All right. This is the model I called <code>decide.3</code>:</p>
<div class="sourceCode" id="cb2068"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2068-1"><a href="logistic-regression.html#cb2068-1"></a><span class="kw">summary</span>(decide<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = factor(decision) ~ gender + idealism + relativism + 
##     scenario, family = &quot;binomial&quot;, data = decide)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3350  -0.9402   0.4645   0.8266   2.1564  
## 
## Coefficients:
##                    Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)         -1.5694     1.0426  -1.505   0.1322    
## genderMale          -1.2551     0.2766  -4.537 5.70e-06 ***
## idealism             0.7012     0.1139   6.156 7.48e-10 ***
## relativism          -0.3264     0.1267  -2.576   0.0100 *  
## scenariomeat         0.1565     0.4283   0.365   0.7149    
## scenariomedical     -0.7095     0.4202  -1.688   0.0914 .  
## scenariotheory       0.4501     0.4271   1.054   0.2919    
## scenarioveterinary  -0.1672     0.4159  -0.402   0.6878    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 425.57  on 314  degrees of freedom
## Residual deviance: 338.06  on 307  degrees of freedom
## AIC: 354.06
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>The most positive coefficient is for <code>theory</code> and the most
negative one is for <code>medical</code>. (The zero coefficient is in the
middle.) Since we are modelling the probability of saying that the
research should <em>stop</em> (part (<a href="#part:whichprob">here</a>)), this means that:</p>
<ul>
<li><p>the “theory” scenario (evaluating theories about brain function)
is most likely to lead to someone saying that the research should stop
(other things being equal)</p></li>
<li><p>the “medical” scenario (finding a
cure for a human disease) is most likely to lead to someone saying
that the research should continue (or least likely to say that it
should stop), again, other things being equal.</p></li>
</ul>
<p>These make some kind of sense because being exposed to a scenario
where there are tangible benefits later ought to be most favourable to
the research continuing, and people are not going to be impressed by
something that is “only theoretical” without any clear benefits.
This also lends itself to a <code>predict</code> solution, but it’s a
little fiddly. I need some “average” values for the other variables,
and I don’t know what they are yet:</p>
<div class="sourceCode" id="cb2070"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2070-1"><a href="logistic-regression.html#cb2070-1"></a>decide <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize_if</span>(is.numeric, median)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   idealism relativism
##      &lt;dbl&gt;      &lt;dbl&gt;
## 1      6.5        6.1</code></pre>
<p>(“if the variable is numeric, get me its median”.)</p>
<p>The other thing we need is a list of all the scenarios. Here’s a cute
way to do that:</p>
<div class="sourceCode" id="cb2072"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2072-1"><a href="logistic-regression.html#cb2072-1"></a>scenarios &lt;-<span class="st"> </span>decide <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(scenario) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(scenario)</span>
<span id="cb2072-2"><a href="logistic-regression.html#cb2072-2"></a>scenarios</span></code></pre></div>
<pre><code>## [1] &quot;cosmetic&quot;   &quot;meat&quot;       &quot;medical&quot;    &quot;theory&quot;     &quot;veterinary&quot;</code></pre>
<p>I didn’t really need to know how many observations there were for each
scenario, but it was a handy way to find out which scenarios there
were without listing them all (and then having to pick out the unique
ones).</p>
<p>So now let’s make a data frame to predict from that has all
scenarios for, let’s say, females. (We don’t have an interaction, so
according to the model, the pattern is the same for males and
females. So I could just as well have looked at males.)</p>
<div class="sourceCode" id="cb2074"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2074-1"><a href="logistic-regression.html#cb2074-1"></a>new &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">idealism =</span> <span class="fl">6.5</span>, <span class="dt">relativism =</span> <span class="fl">6.1</span>, <span class="dt">gender =</span> <span class="st">&quot;Female&quot;</span>, <span class="dt">scenario =</span> scenarios)</span>
<span id="cb2074-2"><a href="logistic-regression.html#cb2074-2"></a>new</span></code></pre></div>
<pre><code>## # A tibble: 5 x 4
##   idealism relativism gender scenario  
##      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     
## 1      6.5        6.1 Female cosmetic  
## 2      6.5        6.1 Female meat      
## 3      6.5        6.1 Female medical   
## 4      6.5        6.1 Female theory    
## 5      6.5        6.1 Female veterinary</code></pre>
<div class="sourceCode" id="cb2076"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2076-1"><a href="logistic-regression.html#cb2076-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(decide<span class="fl">.3</span>, new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2076-2"><a href="logistic-regression.html#cb2076-2"></a><span class="kw">cbind</span>(new, p)</span></code></pre></div>
<pre><code>##   idealism relativism gender   scenario         p
## 1      6.5        6.1 Female   cosmetic 0.7304565
## 2      6.5        6.1 Female       meat 0.7601305
## 3      6.5        6.1 Female    medical 0.5713725
## 4      6.5        6.1 Female     theory 0.8095480
## 5      6.5        6.1 Female veterinary 0.6963099</code></pre>
<p>This echoes what we found before: the probability of saying that the
research should stop is highest for “theory” and the lowest for “medical”.</p>
<p>I assumed in my model that the effect of the scenarios was the same for males and
females. If I wanted to test that, I’d have to add an interaction and
test that. This works most nicely using <code>update</code> and then
<code>anova</code>, to fit the model with interaction and compare it with
the model without:</p>
<div class="sourceCode" id="cb2078"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2078-1"><a href="logistic-regression.html#cb2078-1"></a>decide<span class="fl">.4</span> &lt;-<span class="st"> </span><span class="kw">update</span>(decide<span class="fl">.3</span>, . <span class="op">~</span><span class="st"> </span>. <span class="op">+</span><span class="st"> </span>gender <span class="op">*</span><span class="st"> </span>scenario)</span>
<span id="cb2078-2"><a href="logistic-regression.html#cb2078-2"></a><span class="kw">anova</span>(decide<span class="fl">.3</span>, decide<span class="fl">.4</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: factor(decision) ~ gender + idealism + relativism + scenario
## Model 2: factor(decision) ~ gender + idealism + relativism + scenario + 
##     gender:scenario
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1       307     338.06                     
## 2       303     337.05  4   1.0122   0.9079</code></pre>
<p>No evidence at all that the scenarios have different effects for the
different genders. The appropriate <code>predict</code> should show that too:</p>
<div class="sourceCode" id="cb2080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2080-1"><a href="logistic-regression.html#cb2080-1"></a>genders &lt;-<span class="st"> </span>decide <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(gender) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(gender)</span>
<span id="cb2080-2"><a href="logistic-regression.html#cb2080-2"></a>new &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">idealism =</span> <span class="fl">6.5</span>, <span class="dt">relativism =</span> <span class="fl">6.1</span>, <span class="dt">gender =</span> genders, <span class="dt">scenario =</span> scenarios)</span>
<span id="cb2080-3"><a href="logistic-regression.html#cb2080-3"></a>new</span></code></pre></div>
<pre><code>## # A tibble: 10 x 4
##    idealism relativism gender scenario  
##       &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     
##  1      6.5        6.1 Female cosmetic  
##  2      6.5        6.1 Female meat      
##  3      6.5        6.1 Female medical   
##  4      6.5        6.1 Female theory    
##  5      6.5        6.1 Female veterinary
##  6      6.5        6.1 Male   cosmetic  
##  7      6.5        6.1 Male   meat      
##  8      6.5        6.1 Male   medical   
##  9      6.5        6.1 Male   theory    
## 10      6.5        6.1 Male   veterinary</code></pre>
<div class="sourceCode" id="cb2082"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2082-1"><a href="logistic-regression.html#cb2082-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(decide<span class="fl">.4</span>, new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2082-2"><a href="logistic-regression.html#cb2082-2"></a><span class="kw">cbind</span>(new, p)</span></code></pre></div>
<pre><code>##    idealism relativism gender   scenario         p
## 1       6.5        6.1 Female   cosmetic 0.7670133
## 2       6.5        6.1 Female       meat 0.7290272
## 3       6.5        6.1 Female    medical 0.5666034
## 4       6.5        6.1 Female     theory 0.8251472
## 5       6.5        6.1 Female veterinary 0.6908189
## 6       6.5        6.1   Male   cosmetic 0.3928582
## 7       6.5        6.1   Male       meat 0.5438679
## 8       6.5        6.1   Male    medical 0.2860504
## 9       6.5        6.1   Male     theory 0.5237310
## 10      6.5        6.1   Male veterinary 0.4087458</code></pre>
<p>The probability of “stop” is a lot higher for females than for males
(that is the strong <code>gender</code> effect we found earlier), but the
<em>pattern</em> is about the same for males and females: the difference in
probabilities
<label for="tufte-mn-136" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-136" class="margin-toggle"><span class="marginnote">Strictly, we should look at the difference in log-odds.</span>
is about the same, and also both genders have almost the highest predicted
probability for <code>theory</code> (the highest male one is actually for
<code>meat</code> but there’s not much in it)
and the lowest one for
<code>medical</code>, as we found before. The pattern is not
<em>exactly</em> the same because these predictions came from the model
with interaction. If you use the model without interaction, you get this:</p>
<div class="sourceCode" id="cb2084"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2084-1"><a href="logistic-regression.html#cb2084-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(decide<span class="fl">.3</span>, new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2084-2"><a href="logistic-regression.html#cb2084-2"></a><span class="kw">cbind</span>(new, p)</span></code></pre></div>
<pre><code>##    idealism relativism gender   scenario         p
## 1       6.5        6.1 Female   cosmetic 0.7304565
## 2       6.5        6.1 Female       meat 0.7601305
## 3       6.5        6.1 Female    medical 0.5713725
## 4       6.5        6.1 Female     theory 0.8095480
## 5       6.5        6.1 Female veterinary 0.6963099
## 6       6.5        6.1   Male   cosmetic 0.4358199
## 7       6.5        6.1   Male       meat 0.4745996
## 8       6.5        6.1   Male    medical 0.2753530
## 9       6.5        6.1   Male     theory 0.5478510
## 10      6.5        6.1   Male veterinary 0.3952499</code></pre>
<p>and the scenarios are ranked in <em>exactly</em> the same order by males
and females. The probabilities from the two models are very close
(compare them), so there is no value in adding the interaction, as we
found before.</p>
<p>So fitting an interaction was a
waste of time, but it was worth checking whether it was.</p>
<ol style="list-style-type: lower-roman">
<li>Describe the effects that having (i) a higher idealism score
and (ii) a higher relativity score have on a person’s probability of
saying that the research should stop. Do each of these increase or decrease
that probability? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Look back at the summary for the model that I called
<code>decide.3</code>. (Or <code>decide.2</code>: the slope coefficients
are very similar.) The one for <code>idealism</code> is positive, so
that a higher idealism score goes with a greater likelihood of
saying that the research should stop. The slope coefficient for
<code>relativity</code> is negative, so it’s the other way around: a
higher relativity score goes with a <em>lower</em> chance of saying
that the research should stop.
That’s all I needed, but as an extra, we can look back at the
description of these scales in the question.
The <code>relativism</code> one was that a person believed that the
most moral action depends on the situation (as opposed to a person
having something like religious faith that asserts universal moral
principles that are always true. That would be a low score on the
relativism scale). Somebody with a low score on this scale might
believe something like
“it is always wrong to experiment on animals”, whereas somebody with a high relativism score might
say that it was sometimes justified. Thus, other things being
equal, a low relativism score would go with “stop” and a high
relativism score would (or might) go with “continue”. This
would mean a <em>negative</em> slope coefficient for
<code>relativism</code>, which is what we observed. (Are you still
with me? There was some careful thinking there.)</p>
<p>What about <code>idealism</code>? This is a belief that ethical behaviour
will always lead to good consequences, and thus, if the
consequences are bad, the behaviour must not have been ethical. A
person who scores high on idealism is likely to look at the
consequences (experimentation on animals), see that as a bad
thing, and thus conclude that the research should be stopped. The
<code>idealism</code> slope coefficient, by that argument, should be
positive, and is.</p>
<p>This will also lead to a <code>predict</code>. We need “low” and
“high” scores on the idealism and relativism tests. Let’s use
the quartiles:</p>
<div class="sourceCode" id="cb2086"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2086-1"><a href="logistic-regression.html#cb2086-1"></a>decide <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(</span>
<span id="cb2086-2"><a href="logistic-regression.html#cb2086-2"></a>  <span class="dt">i_q1 =</span> <span class="kw">quantile</span>(idealism, <span class="fl">0.25</span>),</span>
<span id="cb2086-3"><a href="logistic-regression.html#cb2086-3"></a>  <span class="dt">i_q3 =</span> <span class="kw">quantile</span>(idealism, <span class="fl">0.75</span>),</span>
<span id="cb2086-4"><a href="logistic-regression.html#cb2086-4"></a>  <span class="dt">r_q1 =</span> <span class="kw">quantile</span>(relativism, <span class="fl">0.25</span>),</span>
<span id="cb2086-5"><a href="logistic-regression.html#cb2086-5"></a>  <span class="dt">r_q3 =</span> <span class="kw">quantile</span>(relativism, <span class="fl">0.75</span>)</span>
<span id="cb2086-6"><a href="logistic-regression.html#cb2086-6"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 4
##    i_q1  i_q3  r_q1  r_q3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   5.6   7.5   5.4   6.8</code></pre>
<p>There is a more elegant way, but this works.
Let’s use the scenario <code>cosmetic</code> that was middling in its
effects, and think about females:</p>
<div class="sourceCode" id="cb2088"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2088-1"><a href="logistic-regression.html#cb2088-1"></a>new &lt;-<span class="st"> </span><span class="kw">crossing</span>(</span>
<span id="cb2088-2"><a href="logistic-regression.html#cb2088-2"></a>  <span class="dt">idealism =</span> <span class="kw">c</span>(<span class="fl">5.6</span>, <span class="fl">7.5</span>), <span class="dt">relativism =</span> <span class="kw">c</span>(<span class="fl">5.4</span>, <span class="fl">6.8</span>),</span>
<span id="cb2088-3"><a href="logistic-regression.html#cb2088-3"></a>  <span class="dt">gender =</span> <span class="st">&quot;Female&quot;</span>, <span class="dt">scenario =</span> <span class="st">&quot;cosmetic&quot;</span></span>
<span id="cb2088-4"><a href="logistic-regression.html#cb2088-4"></a>)</span>
<span id="cb2088-5"><a href="logistic-regression.html#cb2088-5"></a>new</span></code></pre></div>
<pre><code>## # A tibble: 4 x 4
##   idealism relativism gender scenario
##      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   
## 1      5.6        5.4 Female cosmetic
## 2      5.6        6.8 Female cosmetic
## 3      7.5        5.4 Female cosmetic
## 4      7.5        6.8 Female cosmetic</code></pre>
<div class="sourceCode" id="cb2090"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2090-1"><a href="logistic-regression.html#cb2090-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(decide<span class="fl">.3</span>, new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2090-2"><a href="logistic-regression.html#cb2090-2"></a><span class="kw">cbind</span>(new, p)</span></code></pre></div>
<pre><code>##   idealism relativism gender scenario         p
## 1      5.6        5.4 Female cosmetic 0.6443730
## 2      5.6        6.8 Female cosmetic 0.5342955
## 3      7.5        5.4 Female cosmetic 0.8728724
## 4      7.5        6.8 Female cosmetic 0.8129966</code></pre>
<p>For both of the idealism scores, the higher relativism score went with
a lower probability of “stop” (the “negative” effect), and for
both of the relativism scores, the higher idealism score went with a
<em>higher</em> probability of “stop” (the positive effect).</p>
<p>That’s quite enough discussion of the question, except that the data
didn’t come to me in the form that you see them, so I figured I would
like to share the story of the data processing as well. I think this
is important because in your future work you are likely to spend a lot
of your time getting data from how you receive it to something
suitable for analysis.</p>
<p>These data came from a psychology study (with, probably, the students
in a class serving as experimental subjects). Social scientists like
to use SPSS software, so the data came to me as an SPSS <code>.sav</code>
file.
<label for="tufte-mn-137" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-137" class="margin-toggle"><span class="marginnote">If you took STAB23, you’ll have used PSPP, which is a free version of SPSS.</span> The least-fuss way of handling this that I
could think of was to use <code>import</code> from the <code>rio</code>
package, which I think I mentioned before:</p>
<div class="sourceCode" id="cb2092"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2092-1"><a href="logistic-regression.html#cb2092-1"></a><span class="kw">library</span>(rio)</span>
<span id="cb2092-2"><a href="logistic-regression.html#cb2092-2"></a>x &lt;-<span class="st"> </span><span class="kw">import</span>(<span class="st">&quot;/home/ken/Downloads/Logistic.sav&quot;</span>)</span>
<span id="cb2092-3"><a href="logistic-regression.html#cb2092-3"></a><span class="kw">str</span>(x)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:	315 obs. of  11 variables:
##  $ decision   : num  0 1 1 0 1 1 0 0 0 0 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:2] 0 1
##   .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;stop&quot; &quot;continue&quot;
##  $ idealism   : num  8.2 6.8 8.2 7.4 1.7 5.6 7.2 7.8 7.8 8 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F12.4&quot;
##  $ relatvsm   : num  5.1 5.3 6 6.2 3.1 7.7 6.7 4 4.7 7.6 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F12.4&quot;
##  $ gender     : num  0 1 0 0 0 1 0 1 0 0 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot;
##   ..- attr(*, &quot;labels&quot;)= Named num [1:2] 0 1
##   .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;Female&quot; &quot;Male&quot;
##  $ cosmetic   : num  1 1 1 1 1 1 1 1 1 1 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot;
##  $ theory     : num  0 0 0 0 0 0 0 0 0 0 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot;
##  $ meat       : num  0 0 0 0 0 0 0 0 0 0 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot;
##  $ veterin    : num  0 0 0 0 0 0 0 0 0 0 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F1.0&quot;
##  $ idealism_LN: num  2.104 1.917 2.104 2.001 0.531 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot;
##   ..- attr(*, &quot;display_width&quot;)= int 13
##  $ relatvsm_LN: num  1.63 1.67 1.79 1.82 1.13 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot;
##   ..- attr(*, &quot;display_width&quot;)= int 13
##  $ scenario   : num  1 1 1 1 1 1 1 1 1 1 ...
##   ..- attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot;
##   ..- attr(*, &quot;display_width&quot;)= int 10</code></pre>
<p>The last line <code>str</code> displays the “structure” of the data
frame that was obtained. Normally a data frame read into R has a much
simpler structure than this, but this is R trying to interpret how
SPSS does things. Here, each column (listed on the lines beginning
with a dollar sign) has some values, listed after <code>num</code>; they
are all numeric, even the categorical ones. What happened to the
categorical variables is that they got turned into numbers, and they
have a <code>names</code> “attribute” further down that says what those
numbers actually represent.
Thus, on
the <code>gender</code> line, the subjects are a female (0), then a male
(1), then three females, then a male, and so on. Variables like
<code>gender</code> are thus so far neither really factors nor text
variables, and so we’ll have to do a bit of processing before we can
use them: we want to replace the numerical values by the appropriate
“level”.</p>
<p>To turn a numeric variable into text depending on the value, we can
use <code>ifelse</code>, but this gets unwieldy if there are more than two
values to translate. For that kind of job, I think <code>case_when</code>
is a lot easier to read. It also lets us have a catch-all for catching
errors — “impossible” values occur distressingly often in real data:</p>
<div class="sourceCode" id="cb2094"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2094-1"><a href="logistic-regression.html#cb2094-1"></a>xx &lt;-<span class="st"> </span>x <span class="op">%&gt;%</span></span>
<span id="cb2094-2"><a href="logistic-regression.html#cb2094-2"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb2094-3"><a href="logistic-regression.html#cb2094-3"></a>    <span class="dt">decision =</span> <span class="kw">case_when</span>(</span>
<span id="cb2094-4"><a href="logistic-regression.html#cb2094-4"></a>      decision <span class="op">==</span><span class="st"> </span><span class="dv">0</span> <span class="op">~</span><span class="st"> &quot;stop&quot;</span>,</span>
<span id="cb2094-5"><a href="logistic-regression.html#cb2094-5"></a>      decision <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">~</span><span class="st"> &quot;continue&quot;</span>,</span>
<span id="cb2094-6"><a href="logistic-regression.html#cb2094-6"></a>      <span class="ot">TRUE</span> <span class="op">~</span><span class="st"> &quot;error&quot;</span></span>
<span id="cb2094-7"><a href="logistic-regression.html#cb2094-7"></a>    ),</span>
<span id="cb2094-8"><a href="logistic-regression.html#cb2094-8"></a>    <span class="dt">gender =</span> <span class="kw">case_when</span>(</span>
<span id="cb2094-9"><a href="logistic-regression.html#cb2094-9"></a>      gender <span class="op">==</span><span class="st"> </span><span class="dv">0</span> <span class="op">~</span><span class="st"> &quot;Female&quot;</span>,</span>
<span id="cb2094-10"><a href="logistic-regression.html#cb2094-10"></a>      gender <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">~</span><span class="st"> &quot;Male&quot;</span>,</span>
<span id="cb2094-11"><a href="logistic-regression.html#cb2094-11"></a>      <span class="ot">TRUE</span> <span class="op">~</span><span class="st"> &quot;error&quot;</span></span>
<span id="cb2094-12"><a href="logistic-regression.html#cb2094-12"></a>    ),</span>
<span id="cb2094-13"><a href="logistic-regression.html#cb2094-13"></a>    <span class="dt">scenario =</span> <span class="kw">case_when</span>(</span>
<span id="cb2094-14"><a href="logistic-regression.html#cb2094-14"></a>      scenario <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">~</span><span class="st"> &quot;cosmetic&quot;</span>,</span>
<span id="cb2094-15"><a href="logistic-regression.html#cb2094-15"></a>      scenario <span class="op">==</span><span class="st"> </span><span class="dv">2</span> <span class="op">~</span><span class="st"> &quot;theory&quot;</span>,</span>
<span id="cb2094-16"><a href="logistic-regression.html#cb2094-16"></a>      scenario <span class="op">==</span><span class="st"> </span><span class="dv">3</span> <span class="op">~</span><span class="st"> &quot;meat&quot;</span>,</span>
<span id="cb2094-17"><a href="logistic-regression.html#cb2094-17"></a>      scenario <span class="op">==</span><span class="st"> </span><span class="dv">4</span> <span class="op">~</span><span class="st"> &quot;veterinary&quot;</span>,</span>
<span id="cb2094-18"><a href="logistic-regression.html#cb2094-18"></a>      scenario <span class="op">==</span><span class="st"> </span><span class="dv">5</span> <span class="op">~</span><span class="st"> &quot;medical&quot;</span>,</span>
<span id="cb2094-19"><a href="logistic-regression.html#cb2094-19"></a>      <span class="ot">TRUE</span> <span class="op">~</span><span class="st"> &quot;error&quot;</span></span>
<span id="cb2094-20"><a href="logistic-regression.html#cb2094-20"></a>    )</span>
<span id="cb2094-21"><a href="logistic-regression.html#cb2094-21"></a>  )</span>
<span id="cb2094-22"><a href="logistic-regression.html#cb2094-22"></a>xx <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>(cosmetic<span class="op">:</span>veterin))</span></code></pre></div>
<pre><code>## # A tibble: 315 x 7
##    decision idealism relatvsm gender idealism_LN relatvsm_LN scenario
##    &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;   
##  1 stop          8.2      5.1 Female       2.10         1.63 cosmetic
##  2 continue      6.8      5.3 Male         1.92         1.67 cosmetic
##  3 continue      8.2      6   Female       2.10         1.79 cosmetic
##  4 stop          7.4      6.2 Female       2.00         1.82 cosmetic
##  5 continue      1.7      3.1 Female       0.531        1.13 cosmetic
##  6 continue      5.6      7.7 Male         1.72         2.04 cosmetic
##  7 stop          7.2      6.7 Female       1.97         1.90 cosmetic
##  8 stop          7.8      4   Male         2.05         1.39 cosmetic
##  9 stop          7.8      4.7 Female       2.05         1.55 cosmetic
## 10 stop          8        7.6 Female       2.08         2.03 cosmetic
## # … with 305 more rows</code></pre>
<p><code>xx</code> is a “real” <code>data.frame</code> (that’s what
<code>rio</code> reads in), and has some extra columns that we don’t want
to see right now.</p>
<p>I have three new variables being created in one <code>mutate</code>. Each
is being created using a <code>case_when</code>. The thing on the left of
each squiggle is a logical condition being tested; the first of these
logical conditions to come out <code>TRUE</code> provides the value for
the new variable on the right of the squiggle. Thus, if the (old)
<code>scenario</code> is 2, the new <code>scenario</code> will be
<code>theory</code>. The <code>TRUE</code> lines in each case provide
something that is guaranteed to be true, even if all the other lines
are false (eg. if <code>scenario</code> is actually recorded as 7, which
would be an error).</p>
<p>I overwrote the old variable values with the new ones, which is a bit
risky, but then I’d have more things to get rid of later.</p>
<p>My next step is to check that I don’t actually have any errors:</p>
<div class="sourceCode" id="cb2096"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2096-1"><a href="logistic-regression.html#cb2096-1"></a>xx <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(scenario, gender, decision)</span></code></pre></div>
<pre><code>##      scenario gender decision  n
## 1    cosmetic Female continue  8
## 2    cosmetic Female     stop 26
## 3    cosmetic   Male continue 17
## 4    cosmetic   Male     stop 11
## 5        meat Female continue 11
## 6        meat Female     stop 31
## 7        meat   Male continue 12
## 8        meat   Male     stop  9
## 9     medical Female continue 19
## 10    medical Female     stop 24
## 11    medical   Male continue 15
## 12    medical   Male     stop  5
## 13     theory Female continue  8
## 14     theory Female     stop 30
## 15     theory   Male continue 12
## 16     theory   Male     stop 14
## 17 veterinary Female continue 14
## 18 veterinary Female     stop 29
## 19 veterinary   Male continue 12
## 20 veterinary   Male     stop  8</code></pre>
<p>Don’t see any errors there.</p>
<p>So now let’s write what we have to a file. I think a <code>.csv</code>
would be smart:</p>
<div class="sourceCode" id="cb2098"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2098-1"><a href="logistic-regression.html#cb2098-1"></a>xx <span class="op">%&gt;%</span></span>
<span id="cb2098-2"><a href="logistic-regression.html#cb2098-2"></a><span class="st">  </span><span class="kw">select</span>(decision, idealism, relatvsm, gender, scenario) <span class="op">%&gt;%</span></span>
<span id="cb2098-3"><a href="logistic-regression.html#cb2098-3"></a><span class="st">  </span><span class="kw">write_csv</span>(<span class="st">&quot;decision.csv&quot;</span>)</span></code></pre></div>
<p>There is one more tiny detail: in SPSS, variable names can have a
maximum of eight letters. “Relativism” has 10. So the original data
file had the name “relativism” minus the two “i”s. I changed that
so you would be dealing with a proper English word. (That change is
not shown here.)</p>
<p>There is actually a <em>town</em> called Catbrain. It’s in England,
near Bristol, and seems to be home to a street of car dealerships.
Just to show that you can do <em>anything</em> in R (but first I need a Google API key and some packages):</p>
<div class="sourceCode" id="cb2099"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2099-1"><a href="logistic-regression.html#cb2099-1"></a><span class="kw">library</span>(ggmap)</span></code></pre></div>
<pre><code>## Google&#39;s Terms of Service: https://cloud.google.com/maps-platform/terms/.</code></pre>
<pre><code>## Please cite ggmap if you use it! See citation(&quot;ggmap&quot;) for details.</code></pre>
<div class="sourceCode" id="cb2102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2102-1"><a href="logistic-regression.html#cb2102-1"></a><span class="kw">library</span>(ggrepel)</span></code></pre></div>
<div class="sourceCode" id="cb2103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2103-1"><a href="logistic-regression.html#cb2103-1"></a><span class="kw">register_google</span>(api_key)</span>
<span id="cb2103-2"><a href="logistic-regression.html#cb2103-2"></a><span class="kw">has_google_key</span>()</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>My Google API key is hidden in a variable called <code>api_key</code> that I am not showing you. You can get your own!</p>
<div class="sourceCode" id="cb2105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2105-1"><a href="logistic-regression.html#cb2105-1"></a>gg &lt;-<span class="st"> </span><span class="kw">get_map</span>(<span class="st">&quot;Catbrain&quot;</span>, <span class="dt">zoom =</span> <span class="dv">14</span>, <span class="dt">maptype =</span> <span class="st">&quot;roadmap&quot;</span>)</span></code></pre></div>
<pre><code>## Source : https://maps.googleapis.com/maps/api/staticmap?center=Catbrain&amp;zoom=14&amp;size=640x640&amp;scale=2&amp;maptype=roadmap&amp;language=en-EN&amp;key=xxx-Mj1-zNBW4GTnXNAYdGQJDNXU</code></pre>
<pre><code>## Source : https://maps.googleapis.com/maps/api/geocode/json?address=Catbrain&amp;key=xxx-Mj1-zNBW4GTnXNAYdGQJDNXU</code></pre>
<div class="sourceCode" id="cb2108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2108-1"><a href="logistic-regression.html#cb2108-1"></a><span class="kw">ggmap</span>(gg)</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-102-1.png" width="672"  /></p>
<p>The car dealerships are along Lysander Road. Change the <code>zoom</code>
to a bigger number to see them. Evidently, there is no other Catbrain
anywhere in the world, since this is the only one that Google Maps
knows about.</p>
<p>The name, according to
<a href="http://www.bristolpost.co.uk/news/history/name-catbrain-hill-came-825247">link</a>,
means “rough stony soil”, from Middle English, and has nothing to do
with cats or their brains at all.</p>
<p>This picture is actually a <code>ggplot</code>, so you can do things like
plotting points on the map as well:</p>
<div class="sourceCode" id="cb2109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2109-1"><a href="logistic-regression.html#cb2109-1"></a>lons &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">2.60</span>, <span class="fl">-2.62</span>)</span>
<span id="cb2109-2"><a href="logistic-regression.html#cb2109-2"></a>lats &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">51.51</span>, <span class="fl">51.52</span>, <span class="fl">51.53</span>)</span>
<span id="cb2109-3"><a href="logistic-regression.html#cb2109-3"></a>points &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">lon =</span> lons, <span class="dt">lat =</span> lats)</span>
<span id="cb2109-4"><a href="logistic-regression.html#cb2109-4"></a><span class="kw">ggmap</span>(gg) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">data =</span> points, <span class="kw">aes</span>(<span class="dt">x =</span> lon, <span class="dt">y =</span> lat))</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-103-1.png" width="672"  /></p>
<p>Note the unusual way in which you specify the points to
plot. <code>ggmap</code> replaces the usual <code>ggplot</code> which is where
the default data frame and <code>aes</code> for the plot would normally
live, so you have to specify them in <code>geom_point</code> as shown.</p>
<p>I have no idea why you’d want to plot those points. Normally, on a
map, you’d find the longitude and latitude of some named points (a
process known as “geocoding”):</p>
<div class="sourceCode" id="cb2110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2110-1"><a href="logistic-regression.html#cb2110-1"></a>places &lt;-<span class="st"> </span><span class="kw">tribble</span>(</span>
<span id="cb2110-2"><a href="logistic-regression.html#cb2110-2"></a>  <span class="op">~</span>where,</span>
<span id="cb2110-3"><a href="logistic-regression.html#cb2110-3"></a>  <span class="st">&quot;Catbrain UK&quot;</span>,</span>
<span id="cb2110-4"><a href="logistic-regression.html#cb2110-4"></a>  <span class="st">&quot;Bristol UK&quot;</span>,</span>
<span id="cb2110-5"><a href="logistic-regression.html#cb2110-5"></a>  <span class="st">&quot;Taunton UK&quot;</span>,</span>
<span id="cb2110-6"><a href="logistic-regression.html#cb2110-6"></a>  <span class="st">&quot;Newport UK&quot;</span>,</span>
<span id="cb2110-7"><a href="logistic-regression.html#cb2110-7"></a>  <span class="st">&quot;Gloucester UK&quot;</span></span>
<span id="cb2110-8"><a href="logistic-regression.html#cb2110-8"></a>)</span>
<span id="cb2110-9"><a href="logistic-regression.html#cb2110-9"></a>places <span class="op">%&gt;%</span></span>
<span id="cb2110-10"><a href="logistic-regression.html#cb2110-10"></a><span class="st">  </span><span class="kw">mutate_geocode</span>(where) <span class="op">%&gt;%</span></span>
<span id="cb2110-11"><a href="logistic-regression.html#cb2110-11"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">plotname =</span> <span class="kw">ifelse</span>(where <span class="op">==</span><span class="st"> &quot;Catbrain UK&quot;</span>, where, <span class="st">&quot;&quot;</span>)) -&gt;<span class="st"> </span>places</span></code></pre></div>
<pre><code>## Source : https://maps.googleapis.com/maps/api/geocode/json?address=Catbrain+UK&amp;key=xxx-Mj1-zNBW4GTnXNAYdGQJDNXU</code></pre>
<pre><code>## Source : https://maps.googleapis.com/maps/api/geocode/json?address=Bristol+UK&amp;key=xxx-Mj1-zNBW4GTnXNAYdGQJDNXU</code></pre>
<pre><code>## Source : https://maps.googleapis.com/maps/api/geocode/json?address=Taunton+UK&amp;key=xxx-Mj1-zNBW4GTnXNAYdGQJDNXU</code></pre>
<pre><code>## Source : https://maps.googleapis.com/maps/api/geocode/json?address=Newport+UK&amp;key=xxx-Mj1-zNBW4GTnXNAYdGQJDNXU</code></pre>
<pre><code>## Source : https://maps.googleapis.com/maps/api/geocode/json?address=Gloucester+UK&amp;key=xxx-Mj1-zNBW4GTnXNAYdGQJDNXU</code></pre>
<div class="sourceCode" id="cb2116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2116-1"><a href="logistic-regression.html#cb2116-1"></a>places</span></code></pre></div>
<pre><code>## # A tibble: 5 x 4
##   where           lon   lat plotname   
##   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      
## 1 Catbrain UK   -2.61  51.5 Catbrain UK
## 2 Bristol UK    -2.59  51.5 &quot;&quot;         
## 3 Taunton UK    -3.11  51.0 &quot;&quot;         
## 4 Newport UK    -3.00  51.6 &quot;&quot;         
## 5 Gloucester UK -2.24  51.9 &quot;&quot;</code></pre>
<p>Now to plot them on a map. I’ll need to zoom out a bit, so I’ll get another map:</p>
<div class="sourceCode" id="cb2118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2118-1"><a href="logistic-regression.html#cb2118-1"></a>gg &lt;-<span class="st"> </span><span class="kw">get_map</span>(<span class="st">&quot;Catbrain&quot;</span>, <span class="dt">zoom =</span> <span class="dv">9</span>, <span class="dt">maptype =</span> <span class="st">&quot;roadmap&quot;</span>)</span></code></pre></div>
<pre><code>## Source : https://maps.googleapis.com/maps/api/staticmap?center=Catbrain&amp;zoom=9&amp;size=640x640&amp;scale=2&amp;maptype=roadmap&amp;language=en-EN&amp;key=xxx-Mj1-zNBW4GTnXNAYdGQJDNXU</code></pre>
<pre><code>## Source : https://maps.googleapis.com/maps/api/geocode/json?address=Catbrain&amp;key=xxx-Mj1-zNBW4GTnXNAYdGQJDNXU</code></pre>
<div class="sourceCode" id="cb2121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2121-1"><a href="logistic-regression.html#cb2121-1"></a><span class="kw">ggmap</span>(gg) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">data =</span> places, <span class="kw">aes</span>(<span class="dt">x =</span> lon, <span class="dt">y =</span> lat)) <span class="op">+</span></span>
<span id="cb2121-2"><a href="logistic-regression.html#cb2121-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> places, <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span></span>
<span id="cb2121-3"><a href="logistic-regression.html#cb2121-3"></a><span class="st">  </span><span class="kw">geom_text_repel</span>(<span class="dt">data =</span> places, <span class="kw">aes</span>(<span class="dt">label =</span> plotname))</span></code></pre></div>
<pre><code>## Warning in min(x): no non-missing arguments to min; returning Inf</code></pre>
<pre><code>## Warning in max(x): no non-missing arguments to max; returning -Inf</code></pre>
<pre><code>## Warning in min(x): no non-missing arguments to min; returning Inf</code></pre>
<pre><code>## Warning in max(x): no non-missing arguments to max; returning -Inf</code></pre>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-105-1.png" width="672"  /></p>
<p>Now, if you have any sense of the geography of the UK, you know where
you are. The places on the top left of the map are in Wales, including
Caldicot (see question about pottery). The big river (the Severn) is
the border between England and Wales.</p>
<p>More irrelevant extra: the M5 is one of the English “motorways” (like 400-series highways
or US Interstates). The M5 goes from Birmingham to Exeter. You can
tell that this is England because of the huge number of traffic
circles, known there as “roundabouts”. One of the first things they
teach you in British driving schools is how to handle roundabouts:
which lane to approach them in, which (stick-shift) gear to be in, and
when you’re supposed to signal where you’re going. I hope I still
remember all that for when I next drive in England!</p>
</div>
<div id="how-not-to-get-heart-disease" class="section level2" number="18.6">
<h2><span class="header-section-number">18.6</span> How not to get heart disease</h2>
<p>What is associated with heart disease? In a study, a large
number of variables were measured, as follows:</p>
<ul>
<li><p><code>age</code> (years)</p></li>
<li><p><code>sex</code> male or female</p></li>
<li><p><code>pain.type</code> Chest pain type (4 values: typical angina,
atypical angina, non-anginal pain, asymptomatic)</p></li>
<li><p><code>resting.bp</code> Resting blood pressure, on admission to hospital</p></li>
<li><p><code>serum.chol</code> Serum cholesterol</p></li>
<li><p><code>high.blood.sugar</code>: greater than 120, yes or no</p></li>
<li><p><code>electro</code> resting electrocardiographic results (normal,
having ST-T, hypertrophy)</p></li>
<li><p><code>max.hr</code> Maximum heart rate</p></li>
<li><p><code>angina</code> Exercise induced angina (yes or no)</p></li>
<li><p><code>oldpeak</code> ST depression induced by exercise relative to
rest. See <a href="http://lifeinthefastlane.com/ecg-library/st-segment/">link</a>.</p></li>
<li><p><code>slope</code> Slope of peak exercise ST segment. Sloping up,
flat or sloping down</p></li>
<li><p><code>colored</code> number of major vessels (0–3) coloured by fluoroscopy</p></li>
<li><p><code>thal</code> normal, fixed defect, reversible defect</p></li>
<li><p><code>heart.disease</code> 1=absent, 2=present</p></li>
</ul>
<p>I don’t know what most of those are, but we will not let that stand in
our way. Our aim is to find out what variables are associated with
heart disease, and what values of those variables give high
probabilities of heart disease being present. The data are in
<a href="http://www.utsc.utoronto.ca/~butler/d29/heartf.csv">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data. Display the first few lines and convince
yourself that those values are reasonable.</li>
</ol>
<p>Solution</p>
<p>A <code>.csv</code> file, so:</p>
<div class="sourceCode" id="cb2126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2126-1"><a href="logistic-regression.html#cb2126-1"></a>my_url &lt;-<span class="st"> &quot;http://www.utsc.utoronto.ca/~butler/d29/heartf.csv&quot;</span></span>
<span id="cb2126-2"><a href="logistic-regression.html#cb2126-2"></a>heart &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</span></code></pre></div>
<pre><code>## Warning: Missing column names filled in: &#39;X1&#39; [1]</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   X1 = col_double(),
##   age = col_double(),
##   sex = col_character(),
##   pain.type = col_character(),
##   resting.bp = col_double(),
##   serum.chol = col_double(),
##   high.blood.sugar = col_character(),
##   electro = col_character(),
##   max.hr = col_double(),
##   angina = col_character(),
##   oldpeak = col_double(),
##   slope = col_character(),
##   colored = col_double(),
##   thal = col_character(),
##   heart.disease = col_character()
## )</code></pre>
<div class="sourceCode" id="cb2129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2129-1"><a href="logistic-regression.html#cb2129-1"></a>heart</span></code></pre></div>
<pre><code>## # A tibble: 270 x 15
##       X1   age sex   pain.type resting.bp serum.chol high.blood.sugar electro
##    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;  
##  1     1    70 male  asymptom…        130        322 no               hypert…
##  2     2    67 fema… nonangin…        115        564 no               hypert…
##  3     3    57 male  atypical         124        261 no               normal 
##  4     4    64 male  asymptom…        128        263 no               normal 
##  5     5    74 fema… atypical         120        269 no               hypert…
##  6     6    65 male  asymptom…        120        177 no               normal 
##  7     7    56 male  nonangin…        130        256 yes              hypert…
##  8     8    59 male  asymptom…        110        239 no               hypert…
##  9     9    60 male  asymptom…        140        293 no               hypert…
## 10    10    63 fema… asymptom…        150        407 no               hypert…
## # … with 260 more rows, and 7 more variables: max.hr &lt;dbl&gt;, angina &lt;chr&gt;,
## #   oldpeak &lt;dbl&gt;, slope &lt;chr&gt;, colored &lt;dbl&gt;, thal &lt;chr&gt;, heart.disease &lt;chr&gt;</code></pre>
<p>You should check that the variables that should be numbers actually
are, that the variables that should be categorical have (as far as is
shown) the right values as per my description above, and you should
make some comment in that direction.</p>
<p>My variables appear to be correct, apart possibly for that variable
<code>X1</code> which is actually just the row number.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>In a logistic regression, what probability will be
predicted here? Explain briefly but convincingly. (Is each line of
the data file one observation or a summary of several?)</li>
</ol>
<p>Solution</p>
<p>Each line of the data file is a single observation, not
frequencies of yes and no (like the premature babies
question, later, is). The response variable is a factor, so the first level
is the baseline and the <em>second</em> level is the one
predicted. R puts factor levels alphabetically, so <code>no</code> is
first and <code>yes</code> is second. That is, a logistic regression
will predict the probability that a person <em>does</em> have heart disease.
I want to see that logic (which is why I said “convincingly”):
one observation per line, and therefore that the second level of
the factor is predicted, which is <code>yes</code>.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li><a name="part:heart-first">*</a> Fit a logistic regression predicting heart disease from
everything else (if you have a column called <code>X</code> or
<code>X1</code>, ignore that), and display the results.</li>
</ol>
<p>Solution</p>
<p>A lot of typing, since there are so many variables. Don’t forget
that the response variable <em>must</em> be a factor:</p>
<div class="sourceCode" id="cb2131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2131-1"><a href="logistic-regression.html#cb2131-1"></a>heart<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">factor</span>(heart.disease) <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex <span class="op">+</span><span class="st"> </span>pain.type <span class="op">+</span><span class="st"> </span>resting.bp <span class="op">+</span><span class="st"> </span>serum.chol <span class="op">+</span></span>
<span id="cb2131-2"><a href="logistic-regression.html#cb2131-2"></a><span class="st">  </span>high.blood.sugar <span class="op">+</span><span class="st"> </span>electro <span class="op">+</span><span class="st"> </span>max.hr <span class="op">+</span><span class="st"> </span>angina <span class="op">+</span><span class="st"> </span>oldpeak <span class="op">+</span><span class="st"> </span>slope <span class="op">+</span><span class="st"> </span>colored <span class="op">+</span><span class="st"> </span>thal,</span>
<span id="cb2131-3"><a href="logistic-regression.html#cb2131-3"></a><span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> heart</span>
<span id="cb2131-4"><a href="logistic-regression.html#cb2131-4"></a>)</span></code></pre></div>
<p>You can split this over several lines (and probably should), but make
sure to end each line in such a way that there is unambiguously more
to come, for example with a plus or a comma (though probably the fact
that you have an unclosed bracket will be enough).</p>
<p>The output is rather lengthy:</p>
<div class="sourceCode" id="cb2132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2132-1"><a href="logistic-regression.html#cb2132-1"></a><span class="kw">summary</span>(heart<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = factor(heart.disease) ~ age + sex + pain.type + 
##     resting.bp + serum.chol + high.blood.sugar + electro + max.hr + 
##     angina + oldpeak + slope + colored + thal, family = &quot;binomial&quot;, 
##     data = heart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.6431  -0.4754  -0.1465   0.3342   2.8100  
## 
## Coefficients:
##                      Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)         -3.973837   3.133311  -1.268 0.204707    
## age                 -0.016007   0.026394  -0.606 0.544208    
## sexmale              1.763012   0.580761   3.036 0.002400 ** 
## pain.typeatypical   -0.997298   0.626233  -1.593 0.111264    
## pain.typenonanginal -1.833394   0.520808  -3.520 0.000431 ***
## pain.typetypical    -2.386128   0.756538  -3.154 0.001610 ** 
## resting.bp           0.026004   0.012080   2.153 0.031346 *  
## serum.chol           0.006621   0.004228   1.566 0.117322    
## high.blood.sugaryes -0.370040   0.626396  -0.591 0.554692    
## electronormal       -0.633593   0.412073  -1.538 0.124153    
## electroSTT           0.013986   3.184512   0.004 0.996496    
## max.hr              -0.019337   0.011486  -1.683 0.092278 .  
## anginayes            0.596869   0.460540   1.296 0.194968    
## oldpeak              0.449245   0.244631   1.836 0.066295 .  
## slopeflat            0.827054   0.966139   0.856 0.391975    
## slopeupsloping      -0.122787   1.041666  -0.118 0.906166    
## colored              1.199839   0.280947   4.271 1.95e-05 ***
## thalnormal           0.146197   0.845517   0.173 0.862723    
## thalreversible       1.577988   0.838550   1.882 0.059863 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 370.96  on 269  degrees of freedom
## Residual deviance: 168.90  on 251  degrees of freedom
## AIC: 206.9
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>I didn’t ask you for further comment, but note that quite a lot of
these variables are factors, so you get slopes for things like
<code>pain.typeatypical</code>. When you have a factor in a model, there
is a slope for each level except for the first, which is a baseline
(and its slope is taken to be zero). That would be
<code>asymptomatic</code> for <code>pain.type</code>. The <span class="math inline">\(t\)</span>-tests for the
other levels of <code>pain.type</code> say whether that level of pain
type differs significantly (in terms of probability of heart disease)
from the baseline level. Here, pain type <code>atypical</code> is not
significantly different from the baseline, but the other two pain
types, <code>nonanginal</code> and <code>typical</code>, <em>are</em>
significantly different. If you think about this from an ANOVA-like
point of view, the question about <code>pain.type</code>’s significance is
really “is there at least one of the pain types that is different from the others”, and if we’re thinking about whether we should keep
<code>pain.type</code> in the logistic regression, this is the kind of
question we should be thinking about.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Quite a lot of our explanatory variables are factors. To
assess whether the factor as a whole should stay or can be removed,
looking at the slopes won’t help us very much (since they tell us
whether the other levels of the factor differ from the baseline,
which may not be a sensible comparison to make). To assess which
variables are candidates to be removed, factors included (properly),
we can use <code>drop1</code>. Feed <code>drop1</code> a fitted model and
the words <code>test="Chisq"</code> (take care of the capitalization!)
and you’ll get a list of P-values. Which variable is the one that
you would remove first? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Following the instructions:</p>
<div class="sourceCode" id="cb2134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2134-1"><a href="logistic-regression.html#cb2134-1"></a><span class="kw">drop1</span>(heart<span class="fl">.1</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Single term deletions
## 
## Model:
## factor(heart.disease) ~ age + sex + pain.type + resting.bp + 
##     serum.chol + high.blood.sugar + electro + max.hr + angina + 
##     oldpeak + slope + colored + thal
##                  Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## &lt;none&gt;                168.90 206.90                      
## age               1   169.27 205.27  0.3705 0.5427474    
## sex               1   179.16 215.16 10.2684 0.0013533 ** 
## pain.type         3   187.85 219.85 18.9557 0.0002792 ***
## resting.bp        1   173.78 209.78  4.8793 0.0271810 *  
## serum.chol        1   171.34 207.34  2.4484 0.1176468    
## high.blood.sugar  1   169.25 205.25  0.3528 0.5525052    
## electro           2   171.31 205.31  2.4119 0.2994126    
## max.hr            1   171.84 207.84  2.9391 0.0864608 .  
## angina            1   170.55 206.55  1.6562 0.1981121    
## oldpeak           1   172.44 208.44  3.5449 0.0597303 .  
## slope             2   172.98 206.98  4.0844 0.1297422    
## colored           1   191.78 227.78 22.8878 1.717e-06 ***
## thal              2   180.78 214.78 11.8809 0.0026308 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The highest P-value, 0.5525, goes with <code>high.blood.sugar</code>, so
this one comes out first. (The P-value for <code>age</code> is almost as
high, 0.5427, so you might guess that this will be next.)</p>
<p>You might be curious about how these compare with the P-values on
<code>summary</code>. These two P-values are almost the same as the ones
on <code>summary</code>, because they are a two-level factor and a numeric
variable respectively, and so the tests are equivalent in the two
cases. (The P-values are not identical because the tests on
<code>summary</code> and <code>drop1</code> are the kind of thing that would
be identical on a regular regression but are only “asymptotically the same”
in logistic regression, so you’d expect them to be close
without being the same, as here. “Asymptotically the same” means
that if you had an infinitely large sample size, they’d be identical,
but our sample size of 200-odd individuals is not infinitely large!
Anyway, the largest P-value on the <code>summary</code> is 0.9965, which
goes with <code>electroSTT</code>. <code>electro</code>, though, is a factor
with three levels; this P-value says that <code>STT</code> is almost
identical (in its effects on heart disease) with the baseline
<code>hypertrophy</code>. But there is a third level, <code>normal</code>,
which is a bit different from <code>hypertrophy</code>. So the factor
<code>electro</code> overall has some effect on heart disease, which is
reflected in the <code>drop1</code> P-value of 0.12: this might go later,
but it has to stay for now because at least one of its levels is
different from the others in its effect on heart disease. (In backward
elimination, multi-level factors are removed in their entirety if
<em>none</em> of their levels have a different effect from any of the
others.)</p>
<p>The power just went out here, so I am using my laptop on battery on
its own screen, rather than on the big screen I have in my office,
which is much better.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>I’m not going to make you do the whole backward elimination
(I’m going to have you use <code>step</code> for that later), but do one
step: that is, fit a model removing the variable you think should be
removed, using <code>update</code>, and then run <code>drop1</code> again to
see which variable will be removed next.</li>
</ol>
<p>Solution</p>
<p><code>update</code> is the obvious choice here, since we’re making a
small change to a <em>very</em> big model:</p>
<div class="sourceCode" id="cb2136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2136-1"><a href="logistic-regression.html#cb2136-1"></a>heart<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">update</span>(heart<span class="fl">.1</span>, . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span>high.blood.sugar)</span>
<span id="cb2136-2"><a href="logistic-regression.html#cb2136-2"></a><span class="kw">drop1</span>(heart<span class="fl">.2</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Single term deletions
## 
## Model:
## factor(heart.disease) ~ age + sex + pain.type + resting.bp + 
##     serum.chol + electro + max.hr + angina + oldpeak + slope + 
##     colored + thal
##            Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## &lt;none&gt;          169.25 205.25                      
## age         1   169.66 203.66  0.4104  0.521756    
## sex         1   179.27 213.27 10.0229  0.001546 ** 
## pain.type   3   190.54 220.54 21.2943 9.145e-05 ***
## resting.bp  1   173.84 207.84  4.5942  0.032080 *  
## serum.chol  1   171.69 205.69  2.4458  0.117841    
## electro     2   171.65 203.65  2.3963  0.301750    
## max.hr      1   172.35 206.35  3.0969  0.078440 .  
## angina      1   170.78 204.78  1.5323  0.215764    
## oldpeak     1   173.26 207.26  4.0094  0.045248 *  
## slope       2   173.18 205.18  3.9288  0.140240    
## colored     1   191.87 225.87 22.6232 1.971e-06 ***
## thal        2   181.61 213.61 12.3588  0.002072 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The power is back.</p>
<p>The next variable to go is indeed <code>age</code>, with a P-value that
has hardly changed: it is now 0.5218.</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Use <code>step</code> to do a backward elimination to find which
variables have an effect on heart disease. Display your final model
(which you can do by saving the output from <code>step</code> in a
variable, and asking for the summary of that. In <code>step</code>,
you’ll need to specify a starting model (the one from part
(<a href="#part:heart-first">here</a>)), the direction of elimination, and the test
to base the elimination decision on (the same one as you used in
<code>drop1</code>).</li>
</ol>
<p>Solution</p>
<p>The hints ought to lead you to this:</p>
<div class="sourceCode" id="cb2138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2138-1"><a href="logistic-regression.html#cb2138-1"></a>heart<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">step</span>(heart<span class="fl">.1</span>, <span class="dt">direction =</span> <span class="st">&quot;backward&quot;</span>, <span class="dt">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Start:  AIC=206.9
## factor(heart.disease) ~ age + sex + pain.type + resting.bp + 
##     serum.chol + high.blood.sugar + electro + max.hr + angina + 
##     oldpeak + slope + colored + thal
## 
##                    Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## - high.blood.sugar  1   169.25 205.25  0.3528 0.5525052    
## - age               1   169.27 205.27  0.3705 0.5427474    
## - electro           2   171.31 205.31  2.4119 0.2994126    
## - angina            1   170.55 206.55  1.6562 0.1981121    
## &lt;none&gt;                  168.90 206.90                      
## - slope             2   172.98 206.98  4.0844 0.1297422    
## - serum.chol        1   171.34 207.34  2.4484 0.1176468    
## - max.hr            1   171.84 207.84  2.9391 0.0864608 .  
## - oldpeak           1   172.44 208.44  3.5449 0.0597303 .  
## - resting.bp        1   173.78 209.78  4.8793 0.0271810 *  
## - thal              2   180.78 214.78 11.8809 0.0026308 ** 
## - sex               1   179.16 215.16 10.2684 0.0013533 ** 
## - pain.type         3   187.85 219.85 18.9557 0.0002792 ***
## - colored           1   191.78 227.78 22.8878 1.717e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Step:  AIC=205.25
## factor(heart.disease) ~ age + sex + pain.type + resting.bp + 
##     serum.chol + electro + max.hr + angina + oldpeak + slope + 
##     colored + thal
## 
##              Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## - electro     2   171.65 203.65  2.3963  0.301750    
## - age         1   169.66 203.66  0.4104  0.521756    
## - angina      1   170.78 204.78  1.5323  0.215764    
## - slope       2   173.18 205.18  3.9288  0.140240    
## &lt;none&gt;            169.25 205.25                      
## - serum.chol  1   171.69 205.69  2.4458  0.117841    
## - max.hr      1   172.35 206.35  3.0969  0.078440 .  
## - oldpeak     1   173.26 207.26  4.0094  0.045248 *  
## - resting.bp  1   173.84 207.84  4.5942  0.032080 *  
## - sex         1   179.27 213.27 10.0229  0.001546 ** 
## - thal        2   181.61 213.61 12.3588  0.002072 ** 
## - pain.type   3   190.54 220.54 21.2943 9.145e-05 ***
## - colored     1   191.87 225.87 22.6232 1.971e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Step:  AIC=203.65
## factor(heart.disease) ~ age + sex + pain.type + resting.bp + 
##     serum.chol + max.hr + angina + oldpeak + slope + colored + 
##     thal
## 
##              Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## - age         1   172.03 202.03  0.3894 0.5326108    
## - angina      1   173.13 203.13  1.4843 0.2231042    
## &lt;none&gt;            171.65 203.65                      
## - slope       2   175.99 203.99  4.3442 0.1139366    
## - max.hr      1   175.00 205.00  3.3560 0.0669599 .  
## - serum.chol  1   175.11 205.11  3.4610 0.0628319 .  
## - oldpeak     1   175.42 205.42  3.7710 0.0521485 .  
## - resting.bp  1   176.61 206.61  4.9639 0.0258824 *  
## - thal        2   182.91 210.91 11.2633 0.0035826 ** 
## - sex         1   182.77 212.77 11.1221 0.0008531 ***
## - pain.type   3   192.83 218.83 21.1859 9.632e-05 ***
## - colored     1   194.90 224.90 23.2530 1.420e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Step:  AIC=202.03
## factor(heart.disease) ~ sex + pain.type + resting.bp + serum.chol + 
##     max.hr + angina + oldpeak + slope + colored + thal
## 
##              Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## - angina      1   173.57 201.57  1.5385 0.2148451    
## &lt;none&gt;            172.03 202.03                      
## - slope       2   176.33 202.33  4.2934 0.1168678    
## - max.hr      1   175.00 203.00  2.9696 0.0848415 .  
## - serum.chol  1   175.22 203.22  3.1865 0.0742492 .  
## - oldpeak     1   175.92 203.92  3.8856 0.0487018 *  
## - resting.bp  1   176.63 204.63  4.5911 0.0321391 *  
## - thal        2   183.38 209.38 11.3500 0.0034306 ** 
## - sex         1   183.97 211.97 11.9388 0.0005498 ***
## - pain.type   3   193.71 217.71 21.6786 7.609e-05 ***
## - colored     1   195.73 223.73 23.6997 1.126e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Step:  AIC=201.57
## factor(heart.disease) ~ sex + pain.type + resting.bp + serum.chol + 
##     max.hr + oldpeak + slope + colored + thal
## 
##              Df Deviance    AIC     LRT  Pr(&gt;Chi)    
## &lt;none&gt;            173.57 201.57                      
## - slope       2   178.44 202.44  4.8672 0.0877201 .  
## - serum.chol  1   176.83 202.83  3.2557 0.0711768 .  
## - max.hr      1   177.52 203.52  3.9442 0.0470322 *  
## - oldpeak     1   177.79 203.79  4.2135 0.0401045 *  
## - resting.bp  1   178.56 204.56  4.9828 0.0256006 *  
## - thal        2   186.22 210.22 12.6423 0.0017978 ** 
## - sex         1   185.88 211.88 12.3088 0.0004508 ***
## - pain.type   3   200.68 222.68 27.1025 5.603e-06 ***
## - colored     1   196.98 222.98 23.4109 1.308e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The output is very long.
In terms of AIC, which is what <code>step</code> uses, <code>age</code>
hangs on for a bit, but eventually gets eliminated.</p>
<p>There are a lot of variables left.</p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Display the summary of the model that came out of <code>step</code>.</li>
</ol>
<p>Solution</p>
<p>This:</p>
<div class="sourceCode" id="cb2140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2140-1"><a href="logistic-regression.html#cb2140-1"></a><span class="kw">summary</span>(heart<span class="fl">.3</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = factor(heart.disease) ~ sex + pain.type + resting.bp + 
##     serum.chol + max.hr + oldpeak + slope + colored + thal, family = &quot;binomial&quot;, 
##     data = heart)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.7103  -0.4546  -0.1442   0.3864   2.7121  
## 
## Coefficients:
##                      Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)         -4.818418   2.550437  -1.889 0.058858 .  
## sexmale              1.850559   0.561583   3.295 0.000983 ***
## pain.typeatypical   -1.268233   0.604488  -2.098 0.035903 *  
## pain.typenonanginal -2.086204   0.486591  -4.287 1.81e-05 ***
## pain.typetypical    -2.532340   0.748941  -3.381 0.000722 ***
## resting.bp           0.024125   0.011077   2.178 0.029410 *  
## serum.chol           0.007142   0.003941   1.812 0.069966 .  
## max.hr              -0.020373   0.010585  -1.925 0.054262 .  
## oldpeak              0.467028   0.233280   2.002 0.045284 *  
## slopeflat            0.859564   0.922749   0.932 0.351582    
## slopeupsloping      -0.165832   0.991474  -0.167 0.867167    
## colored              1.134561   0.261547   4.338 1.44e-05 ***
## thalnormal           0.323543   0.813442   0.398 0.690818    
## thalreversible       1.700314   0.805127   2.112 0.034699 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 370.96  on 269  degrees of freedom
## Residual deviance: 173.57  on 256  degrees of freedom
## AIC: 201.57
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<p>Not all of the P-values in the <code>step</code> output wound up being
less than 0.05, but they are all at least reasonably small. As
discussed above, some of the P-values in the <code>summary</code> are
definitely <em>not</em> small, but they go with factors where there are
significant effects <em>somewhere</em>. For example, <code>thalnormal</code>
is not significant (that is, <code>normal</code> is not significantly
different from the baseline <code>fixed</code>), but the other level
<code>reversible</code> <em>is</em> different from <code>fixed</code>. You might
be wondering about <code>slope</code>: on the <code>summary</code> there is
nothing close to significance, but on the <code>step</code> output,
<code>slope</code> has at least a reasonably small P-value of 0.088. This
is because the significant difference does not involve the baseline:
it’s actually between <code>flat</code> with a positive slope and
<code>upsloping</code> with a negative one.</p>
<ol start="8" style="list-style-type: lower-alpha">
<li>We are going to make a large number of predictions. Create
a data frame that contains all combinations of representative
values for all the variables in the model that came out of
<code>step</code>. By “representative” I mean all the values for a
categorical variable, and the first and third quartiles for a numeric
variable.</li>
</ol>
<p>Solution</p>
<p>Let’s take a breath first.
There are two pieces of stuff to do here: we need to get the
quartiles of the quantitative variables, and we need all the
different values of the categorical ones. There are several of
each, so we want some kind of automated method.
The easy way of getting the quartiles is via <code>summary</code>
of the whole data frame:</p>
<div class="sourceCode" id="cb2142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2142-1"><a href="logistic-regression.html#cb2142-1"></a><span class="kw">summary</span>(heart)</span></code></pre></div>
<pre><code>##        X1              age            sex             pain.type        
##  Min.   :  1.00   Min.   :29.00   Length:270         Length:270        
##  1st Qu.: 68.25   1st Qu.:48.00   Class :character   Class :character  
##  Median :135.50   Median :55.00   Mode  :character   Mode  :character  
##  Mean   :135.50   Mean   :54.43                                        
##  3rd Qu.:202.75   3rd Qu.:61.00                                        
##  Max.   :270.00   Max.   :77.00                                        
##    resting.bp      serum.chol    high.blood.sugar     electro         
##  Min.   : 94.0   Min.   :126.0   Length:270         Length:270        
##  1st Qu.:120.0   1st Qu.:213.0   Class :character   Class :character  
##  Median :130.0   Median :245.0   Mode  :character   Mode  :character  
##  Mean   :131.3   Mean   :249.7                                        
##  3rd Qu.:140.0   3rd Qu.:280.0                                        
##  Max.   :200.0   Max.   :564.0                                        
##      max.hr         angina             oldpeak        slope          
##  Min.   : 71.0   Length:270         Min.   :0.00   Length:270        
##  1st Qu.:133.0   Class :character   1st Qu.:0.00   Class :character  
##  Median :153.5   Mode  :character   Median :0.80   Mode  :character  
##  Mean   :149.7                      Mean   :1.05                     
##  3rd Qu.:166.0                      3rd Qu.:1.60                     
##  Max.   :202.0                      Max.   :6.20                     
##     colored           thal           heart.disease     
##  Min.   :0.0000   Length:270         Length:270        
##  1st Qu.:0.0000   Class :character   Class :character  
##  Median :0.0000   Mode  :character   Mode  :character  
##  Mean   :0.6704                                        
##  3rd Qu.:1.0000                                        
##  Max.   :3.0000</code></pre>
<p>This is the old-fashioned “base R” way of doing it. The
<code>tidyverse</code> way is to get the Q1 and Q3 of just the variables
that are numeric. To that, we’ll write little functions to get Q1 and
Q3 of anything, and then use <code>summarize_if</code> to apply those to
the quantitative variables:</p>
<div class="sourceCode" id="cb2144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2144-1"><a href="logistic-regression.html#cb2144-1"></a>q1 &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">quantile</span>(x, <span class="fl">0.25</span>)</span>
<span id="cb2144-2"><a href="logistic-regression.html#cb2144-2"></a>q3 &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">quantile</span>(x, <span class="fl">0.75</span>)</span>
<span id="cb2144-3"><a href="logistic-regression.html#cb2144-3"></a>heart <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize_if</span>(is.numeric, <span class="kw">funs</span>(q1, q3))</span></code></pre></div>
<pre><code>## Warning: `funs()` is deprecated as of dplyr 0.8.0.
## Please use a list of either functions or lambdas: 
## 
##   # Simple named list: 
##   list(mean = mean, median = median)
## 
##   # Auto named with `tibble::lst()`: 
##   tibble::lst(mean, median)
## 
##   # Using lambdas
##   list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<pre><code>## # A tibble: 1 x 14
##   X1_q1 age_q1 resting.bp_q1 serum.chol_q1 max.hr_q1 oldpeak_q1 colored_q1 X1_q3
##   &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;
## 1  68.2     48           120           213       133          0          0  203.
## # … with 6 more variables: age_q3 &lt;dbl&gt;, resting.bp_q3 &lt;dbl&gt;,
## #   serum.chol_q3 &lt;dbl&gt;, max.hr_q3 &lt;dbl&gt;, oldpeak_q3 &lt;dbl&gt;, colored_q3 &lt;dbl&gt;</code></pre>
<p>These are actually all the Q1s followed by all the Q3s, but it’s hard
to see that because you only see a few columns. On yours, click the
little right-arrow to see more columns.</p>
<p>One way to see all the results is
to “transpose” the result with the variable-quartile combinations in
a column and the actual quartile values in another:</p>
<div class="sourceCode" id="cb2147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2147-1"><a href="logistic-regression.html#cb2147-1"></a>heart <span class="op">%&gt;%</span></span>
<span id="cb2147-2"><a href="logistic-regression.html#cb2147-2"></a><span class="st">  </span><span class="kw">summarize_if</span>(is.numeric, <span class="kw">funs</span>(q1, q3)) <span class="op">%&gt;%</span></span>
<span id="cb2147-3"><a href="logistic-regression.html#cb2147-3"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>(), <span class="dt">names_to=</span><span class="st">&quot;vq&quot;</span>, <span class="dt">values_to=</span><span class="st">&quot;quartile&quot;</span>) -&gt;<span class="st"> </span>heart2</span>
<span id="cb2147-4"><a href="logistic-regression.html#cb2147-4"></a>heart2</span></code></pre></div>
<pre><code>## # A tibble: 14 x 2
##    vq            quartile
##    &lt;chr&gt;            &lt;dbl&gt;
##  1 X1_q1             68.2
##  2 age_q1            48  
##  3 resting.bp_q1    120  
##  4 serum.chol_q1    213  
##  5 max.hr_q1        133  
##  6 oldpeak_q1         0  
##  7 colored_q1         0  
##  8 X1_q3            203. 
##  9 age_q3            61  
## 10 resting.bp_q3    140  
## 11 serum.chol_q3    280  
## 12 max.hr_q3        166  
## 13 oldpeak_q3         1.6
## 14 colored_q3         1</code></pre>
<p>If you want to be really fancy:</p>
<div class="sourceCode" id="cb2149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2149-1"><a href="logistic-regression.html#cb2149-1"></a>heart <span class="op">%&gt;%</span></span>
<span id="cb2149-2"><a href="logistic-regression.html#cb2149-2"></a><span class="st">  </span><span class="kw">summarize_if</span>(is.numeric, <span class="kw">funs</span>(q1, q3)) <span class="op">%&gt;%</span></span>
<span id="cb2149-3"><a href="logistic-regression.html#cb2149-3"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>(), <span class="dt">names_to=</span><span class="kw">c</span>(<span class="st">&quot;variable&quot;</span>, <span class="st">&quot;which_quartile&quot;</span>), <span class="dt">names_sep=</span><span class="st">&quot;_&quot;</span>, <span class="dt">values_to=</span><span class="st">&quot;quartile&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2149-4"><a href="logistic-regression.html#cb2149-4"></a><span class="st">  </span><span class="kw">pivot_wider</span>(<span class="dt">names_from=</span>which_quartile, <span class="dt">values_from=</span>quartile)</span></code></pre></div>
<pre><code>## # A tibble: 7 x 3
##   variable      q1    q3
##   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;
## 1 X1          68.2 203. 
## 2 age         48    61  
## 3 resting.bp 120   140  
## 4 serum.chol 213   280  
## 5 max.hr     133   166  
## 6 oldpeak      0     1.6
## 7 colored      0     1</code></pre>
<p>You would <em>definitely</em> benefit from running this pipeline one line at a time to see how it works! The <code>summarize_if</code> produces columns with names like <code>age_q1</code>, which are then split up into a variable name and a “which quartile” by the fancy version of <code>pivot_longer</code>. (If you prefer, this is the vanilla version of <code>pivot_longer</code> followed by <code>separate</code>. For yourself, do it the way that makes sense to you.) Finally, I put Q1 and Q3 in their own columns so that you can see them side by side.</p>
<p>The categorical variables are a bit trickier, because they will have
different numbers of possible values. Here’s my idea:</p>
<div class="sourceCode" id="cb2151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2151-1"><a href="logistic-regression.html#cb2151-1"></a>heart <span class="op">%&gt;%</span></span>
<span id="cb2151-2"><a href="logistic-regression.html#cb2151-2"></a><span class="st">  </span><span class="kw">select_if</span>(is.character) <span class="op">%&gt;%</span></span>
<span id="cb2151-3"><a href="logistic-regression.html#cb2151-3"></a><span class="st">  </span><span class="kw">mutate_all</span>(<span class="op">~</span><span class="kw">factor</span>(.)) <span class="op">%&gt;%</span></span>
<span id="cb2151-4"><a href="logistic-regression.html#cb2151-4"></a><span class="st">  </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>##      sex             pain.type   high.blood.sugar        electro    angina   
##  female: 87   asymptomatic:129   no :230          hypertrophy:137   no :181  
##  male  :183   atypical    : 42   yes: 40          normal     :131   yes: 89  
##               nonanginal  : 79                    STT        :  2            
##               typical     : 20                                               
##          slope             thal     heart.disease
##  downsloping: 18   fixed     : 14   no :150      
##  flat       :122   normal    :152   yes:120      
##  upsloping  :130   reversible:104                
## </code></pre>
<p>My thought was that if you pass a genuine factor into <code>summary</code>
(as opposed to a categorical variable that is text), it displays all
its “levels” (different categories). So, to get to that point, I had
to select all the categorical-as-text variables (which is actually all
the ones that are not numeric), and then make a factor out of each of
them. <code>mutate_all</code> does the same thing to all the columns: “for
each column, run <code>factor</code> on it”, and saves the results back in variables
of the same name as they were before. Using <code>summary</code> also
shows how many observations we had in each category.</p>
<p>What I would really like to do is to save these category names
somewhere so I don’t have to type them below when I make all possible
combinations. My go at that:</p>
<div class="sourceCode" id="cb2153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2153-1"><a href="logistic-regression.html#cb2153-1"></a>heart <span class="op">%&gt;%</span></span>
<span id="cb2153-2"><a href="logistic-regression.html#cb2153-2"></a><span class="st">  </span><span class="kw">select_if</span>(is.character) <span class="op">%&gt;%</span></span>
<span id="cb2153-3"><a href="logistic-regression.html#cb2153-3"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>(), <span class="dt">names_to=</span><span class="st">&quot;variable_name&quot;</span>, <span class="dt">values_to=</span><span class="st">&quot;value&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb2153-4"><a href="logistic-regression.html#cb2153-4"></a><span class="st">  </span><span class="kw">distinct</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2153-5"><a href="logistic-regression.html#cb2153-5"></a><span class="st">  </span><span class="kw">arrange</span>(variable_name, value) -&gt;<span class="st"> </span>heart3</span>
<span id="cb2153-6"><a href="logistic-regression.html#cb2153-6"></a>heart3</span></code></pre></div>
<pre><code>## # A tibble: 21 x 2
##    variable_name    value       
##    &lt;chr&gt;            &lt;chr&gt;       
##  1 angina           no          
##  2 angina           yes         
##  3 electro          hypertrophy 
##  4 electro          normal      
##  5 electro          STT         
##  6 heart.disease    no          
##  7 heart.disease    yes         
##  8 high.blood.sugar no          
##  9 high.blood.sugar yes         
## 10 pain.type        asymptomatic
## # … with 11 more rows</code></pre>
<p>Gosh, that was easier than I thought. A <em>lot</em> easier. The
technique is a lot like that idea for making facetted plots of
something against “all the <span class="math inline">\(x\)</span>s”: you collect everything up into one
column containing a variable name and another column containing the
variable value. This contains a lot of repeats; the <code>distinct</code>
keeps one of each and throws away the rest.</p>
<p>Hmm, another way would be to count everything:</p>
<div class="sourceCode" id="cb2155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2155-1"><a href="logistic-regression.html#cb2155-1"></a>heart <span class="op">%&gt;%</span></span>
<span id="cb2155-2"><a href="logistic-regression.html#cb2155-2"></a><span class="st">  </span><span class="kw">select_if</span>(is.character) <span class="op">%&gt;%</span></span>
<span id="cb2155-3"><a href="logistic-regression.html#cb2155-3"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>(), <span class="dt">names_to=</span><span class="st">&quot;variable_name&quot;</span>, <span class="dt">values_to=</span><span class="st">&quot;value&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb2155-4"><a href="logistic-regression.html#cb2155-4"></a><span class="st">  </span><span class="kw">count</span>(variable_name, value) -&gt;<span class="st"> </span>heart3</span>
<span id="cb2155-5"><a href="logistic-regression.html#cb2155-5"></a>heart3 </span></code></pre></div>
<pre><code>## # A tibble: 21 x 3
##    variable_name    value            n
##    &lt;chr&gt;            &lt;chr&gt;        &lt;int&gt;
##  1 angina           no             181
##  2 angina           yes             89
##  3 electro          hypertrophy    137
##  4 electro          normal         131
##  5 electro          STT              2
##  6 heart.disease    no             150
##  7 heart.disease    yes            120
##  8 high.blood.sugar no             230
##  9 high.blood.sugar yes             40
## 10 pain.type        asymptomatic   129
## # … with 11 more rows</code></pre>
<p>That perhaps is more obvious in retrospect, because there are no new
tools there.</p>
<p>Now, we come to setting up the variables that we are going to make all
combinations of. For a quantitative variable such as <code>age</code>, I
need to go back to <code>heart2</code>:</p>
<div class="sourceCode" id="cb2157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2157-1"><a href="logistic-regression.html#cb2157-1"></a>heart2</span></code></pre></div>
<pre><code>## # A tibble: 14 x 2
##    vq            quartile
##    &lt;chr&gt;            &lt;dbl&gt;
##  1 X1_q1             68.2
##  2 age_q1            48  
##  3 resting.bp_q1    120  
##  4 serum.chol_q1    213  
##  5 max.hr_q1        133  
##  6 oldpeak_q1         0  
##  7 colored_q1         0  
##  8 X1_q3            203. 
##  9 age_q3            61  
## 10 resting.bp_q3    140  
## 11 serum.chol_q3    280  
## 12 max.hr_q3        166  
## 13 oldpeak_q3         1.6
## 14 colored_q3         1</code></pre>
<p>and pull out the rows whose names contain <code>age_</code>. This is done
using <code>str_detect</code>
<label for="tufte-mn-138" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-138" class="margin-toggle"><span class="marginnote">If you’re selecting <em>columns</em>, you can use select-helpers, but for rows, not.</span> from
<code>stringr</code>.
<label for="tufte-mn-139" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-139" class="margin-toggle"><span class="marginnote">Which is loaded with the <em>tidyverse</em> so you don’t have to load it.</span>
Here’s how it goes for <code>age</code>:</p>
<div class="sourceCode" id="cb2159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2159-1"><a href="logistic-regression.html#cb2159-1"></a>heart2 <span class="op">%&gt;%</span></span>
<span id="cb2159-2"><a href="logistic-regression.html#cb2159-2"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(vq, <span class="st">&quot;age_&quot;</span>))</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   vq     quartile
##   &lt;chr&gt;     &lt;dbl&gt;
## 1 age_q1       48
## 2 age_q3       61</code></pre>
<p>and one more step to get just the quartiles:</p>
<div class="sourceCode" id="cb2161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2161-1"><a href="logistic-regression.html#cb2161-1"></a>heart2 <span class="op">%&gt;%</span></span>
<span id="cb2161-2"><a href="logistic-regression.html#cb2161-2"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(vq, <span class="st">&quot;age_&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb2161-3"><a href="logistic-regression.html#cb2161-3"></a><span class="st">  </span><span class="kw">pull</span>(quartile)</span></code></pre></div>
<pre><code>## 25% 75% 
##  48  61</code></pre>
<p>We’ll be doing this a few times, so we should write a function to do it:</p>
<div class="sourceCode" id="cb2163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2163-1"><a href="logistic-regression.html#cb2163-1"></a>get_quartiles &lt;-<span class="st"> </span><span class="cf">function</span>(d, x) {</span>
<span id="cb2163-2"><a href="logistic-regression.html#cb2163-2"></a>  d <span class="op">%&gt;%</span></span>
<span id="cb2163-3"><a href="logistic-regression.html#cb2163-3"></a><span class="st">    </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(vq, x)) <span class="op">%&gt;%</span></span>
<span id="cb2163-4"><a href="logistic-regression.html#cb2163-4"></a><span class="st">    </span><span class="kw">pull</span>(quartile)</span>
<span id="cb2163-5"><a href="logistic-regression.html#cb2163-5"></a>}</span></code></pre></div>
<p>and to test:</p>
<div class="sourceCode" id="cb2164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2164-1"><a href="logistic-regression.html#cb2164-1"></a><span class="kw">get_quartiles</span>(heart2, <span class="st">&quot;age_&quot;</span>)</span></code></pre></div>
<pre><code>## 25% 75% 
##  48  61</code></pre>
<p>Yep. I put the underscore in so as to not catch other variables that
have <code>age</code> inside them but not at the end.</p>
<p>For the categorical variables, we need to look in <code>heart3</code>:</p>
<div class="sourceCode" id="cb2166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2166-1"><a href="logistic-regression.html#cb2166-1"></a>heart3</span></code></pre></div>
<pre><code>## # A tibble: 21 x 3
##    variable_name    value            n
##    &lt;chr&gt;            &lt;chr&gt;        &lt;int&gt;
##  1 angina           no             181
##  2 angina           yes             89
##  3 electro          hypertrophy    137
##  4 electro          normal         131
##  5 electro          STT              2
##  6 heart.disease    no             150
##  7 heart.disease    yes            120
##  8 high.blood.sugar no             230
##  9 high.blood.sugar yes             40
## 10 pain.type        asymptomatic   129
## # … with 11 more rows</code></pre>
<p>then choose the rows with the right thing in <code>variable_name</code>, and then
pull just the <code>value</code> column. This is sufficiently like the
previous one that I think we can write a function right away:</p>
<div class="sourceCode" id="cb2168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2168-1"><a href="logistic-regression.html#cb2168-1"></a>get_categories &lt;-<span class="st"> </span><span class="cf">function</span>(d, x) {</span>
<span id="cb2168-2"><a href="logistic-regression.html#cb2168-2"></a>  d <span class="op">%&gt;%</span></span>
<span id="cb2168-3"><a href="logistic-regression.html#cb2168-3"></a><span class="st">    </span><span class="kw">filter</span>(variable_name <span class="op">==</span><span class="st"> </span>x) <span class="op">%&gt;%</span></span>
<span id="cb2168-4"><a href="logistic-regression.html#cb2168-4"></a><span class="st">    </span><span class="kw">pull</span>(value)</span>
<span id="cb2168-5"><a href="logistic-regression.html#cb2168-5"></a>}</span>
<span id="cb2168-6"><a href="logistic-regression.html#cb2168-6"></a><span class="kw">get_categories</span>(heart3, <span class="st">&quot;electro&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;hypertrophy&quot; &quot;normal&quot;      &quot;STT&quot;</code></pre>
<p>All right, setup, using my usual habit of plural names, and using
those functions we just wrote:</p>
<div class="sourceCode" id="cb2170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2170-1"><a href="logistic-regression.html#cb2170-1"></a>sexes &lt;-<span class="st"> </span><span class="kw">get_categories</span>(heart3, <span class="st">&quot;sex&quot;</span>)</span>
<span id="cb2170-2"><a href="logistic-regression.html#cb2170-2"></a>pain.types &lt;-<span class="st"> </span><span class="kw">get_categories</span>(heart3, <span class="st">&quot;pain.type&quot;</span>)</span>
<span id="cb2170-3"><a href="logistic-regression.html#cb2170-3"></a>resting.bps &lt;-<span class="st"> </span><span class="kw">get_quartiles</span>(heart2, <span class="st">&quot;resting.bp_&quot;</span>)</span>
<span id="cb2170-4"><a href="logistic-regression.html#cb2170-4"></a>serum.chols &lt;-<span class="st"> </span><span class="kw">get_quartiles</span>(heart2, <span class="st">&quot;serum.chol_&quot;</span>)</span>
<span id="cb2170-5"><a href="logistic-regression.html#cb2170-5"></a>max.hrs &lt;-<span class="st"> </span><span class="kw">get_quartiles</span>(heart2, <span class="st">&quot;max.hr_&quot;</span>)</span>
<span id="cb2170-6"><a href="logistic-regression.html#cb2170-6"></a>oldpeaks &lt;-<span class="st"> </span><span class="kw">get_quartiles</span>(heart2, <span class="st">&quot;oldpeak_&quot;</span>)</span>
<span id="cb2170-7"><a href="logistic-regression.html#cb2170-7"></a>slopes &lt;-<span class="st"> </span><span class="kw">get_categories</span>(heart3, <span class="st">&quot;slope&quot;</span>)</span>
<span id="cb2170-8"><a href="logistic-regression.html#cb2170-8"></a>coloreds &lt;-<span class="st"> </span><span class="kw">get_quartiles</span>(heart2, <span class="st">&quot;colored_&quot;</span>)</span>
<span id="cb2170-9"><a href="logistic-regression.html#cb2170-9"></a>thals &lt;-<span class="st"> </span><span class="kw">get_categories</span>(heart3, <span class="st">&quot;thal&quot;</span>)</span></code></pre></div>
<p>All combos of all of those (and there will be a lot of those):</p>
<div class="sourceCode" id="cb2171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2171-1"><a href="logistic-regression.html#cb2171-1"></a>heart.new &lt;-<span class="st"> </span><span class="kw">crossing</span>(</span>
<span id="cb2171-2"><a href="logistic-regression.html#cb2171-2"></a>  <span class="dt">sex =</span> sexes, <span class="dt">pain.type =</span> pain.types, <span class="dt">resting.bp =</span> resting.bps,</span>
<span id="cb2171-3"><a href="logistic-regression.html#cb2171-3"></a>  <span class="dt">serum.chol =</span> serum.chols, <span class="dt">max.hr =</span> max.hrs, <span class="dt">oldpeak =</span> oldpeaks, <span class="dt">slope =</span> slopes,</span>
<span id="cb2171-4"><a href="logistic-regression.html#cb2171-4"></a>  <span class="dt">colored =</span> coloreds, <span class="dt">thal =</span> thals</span>
<span id="cb2171-5"><a href="logistic-regression.html#cb2171-5"></a>)</span>
<span id="cb2171-6"><a href="logistic-regression.html#cb2171-6"></a>heart.new</span></code></pre></div>
<pre><code>## # A tibble: 2,304 x 9
##    sex    pain.type  resting.bp serum.chol max.hr oldpeak slope   colored thal  
##    &lt;chr&gt;  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt; 
##  1 female asymptoma…        120        213    133       0 downsl…       0 fixed 
##  2 female asymptoma…        120        213    133       0 downsl…       0 normal
##  3 female asymptoma…        120        213    133       0 downsl…       0 rever…
##  4 female asymptoma…        120        213    133       0 downsl…       1 fixed 
##  5 female asymptoma…        120        213    133       0 downsl…       1 normal
##  6 female asymptoma…        120        213    133       0 downsl…       1 rever…
##  7 female asymptoma…        120        213    133       0 flat          0 fixed 
##  8 female asymptoma…        120        213    133       0 flat          0 normal
##  9 female asymptoma…        120        213    133       0 flat          0 rever…
## 10 female asymptoma…        120        213    133       0 flat          1 fixed 
## # … with 2,294 more rows</code></pre>
<p>Yeah, that’s a lot. Fortunately, we won’t have to look at them all.</p>
<ol style="list-style-type: lower-roman">
<li>Obtain the predicted probabilities of heart disease for
the data frame you constructed in the last part, using your
model that came out of <code>step</code>. Add these predictions to
the data frame from the previous part (as a column in that data
frame).</li>
</ol>
<p>Solution</p>
<p>Get the predictions, which is less scary than it seems:</p>
<div class="sourceCode" id="cb2173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2173-1"><a href="logistic-regression.html#cb2173-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(heart<span class="fl">.3</span>, heart.new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<p>and the easiest way to add these to <code>heart.new</code> is this:</p>
<div class="sourceCode" id="cb2174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2174-1"><a href="logistic-regression.html#cb2174-1"></a>heart.new <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">pred =</span> p) -&gt;<span class="st"> </span>heart.new</span></code></pre></div>
<p>Let’s take a look at a few of the predictions, by way of sanity-checking:</p>
<div class="sourceCode" id="cb2175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2175-1"><a href="logistic-regression.html#cb2175-1"></a>heart.new <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">8</span>)</span></code></pre></div>
<pre><code>## # A tibble: 8 x 10
##   sex   pain.type resting.bp serum.chol max.hr oldpeak slope colored thal 
##   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;
## 1 male  nonangin…        120        280    133     1.6 flat        0 norm…
## 2 male  atypical         140        213    166     0   upsl…       1 reve…
## 3 fema… nonangin…        140        213    133     0   upsl…       0 reve…
## 4 fema… nonangin…        120        280    133     1.6 flat        0 reve…
## 5 fema… typical          120        213    166     1.6 down…       0 fixed
## 6 male  nonangin…        140        280    166     0   upsl…       1 fixed
## 7 male  typical          140        213    133     0   flat        1 fixed
## 8 fema… atypical         120        213    166     0   down…       1 reve…
## # … with 1 more variable: pred &lt;dbl&gt;</code></pre>
<p>This seems at least reasonably sane.</p>
<ol start="10" style="list-style-type: lower-alpha">
<li>Find the largest predicted probability (which is the
predicted probability of heart disease) and display all the
variables that it was a prediction for.</li>
</ol>
<p>Solution</p>
<p>This can be done in one step:</p>
<div class="sourceCode" id="cb2177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2177-1"><a href="logistic-regression.html#cb2177-1"></a>heart.new <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(pred <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(pred))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 10
##   sex   pain.type resting.bp serum.chol max.hr oldpeak slope colored thal   pred
##   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;
## 1 male  asymptom…        140        280    133     1.6 flat        1 reve… 0.984</code></pre>
<p>or if you didn’t think of that, you can find the maximum first, and
then display the rows with predictions close to it:</p>
<div class="sourceCode" id="cb2179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2179-1"><a href="logistic-regression.html#cb2179-1"></a>heart.new <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">m =</span> <span class="kw">max</span>(pred))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##       m
##   &lt;dbl&gt;
## 1 0.984</code></pre>
<div class="sourceCode" id="cb2181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2181-1"><a href="logistic-regression.html#cb2181-1"></a>heart.new <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(pred <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.98</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 10
##   sex   pain.type resting.bp serum.chol max.hr oldpeak slope colored thal   pred
##   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;
## 1 male  asymptom…        140        280    133     1.6 flat        1 reve… 0.984</code></pre>
<p>or even find <em>which</em> row has the maximum, and then display that row:</p>
<div class="sourceCode" id="cb2183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2183-1"><a href="logistic-regression.html#cb2183-1"></a>heart.new <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">row =</span> <span class="kw">which.max</span>(pred))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##     row
##   &lt;int&gt;
## 1  1398</code></pre>
<div class="sourceCode" id="cb2185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2185-1"><a href="logistic-regression.html#cb2185-1"></a>heart.new <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1398</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 10
##   sex   pain.type resting.bp serum.chol max.hr oldpeak slope colored thal   pred
##   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;
## 1 male  asymptom…        140        280    133     1.6 flat        1 reve… 0.984</code></pre>
<p>or sort the rows by <code>pred</code>, descending, and display the top few:</p>
<div class="sourceCode" id="cb2187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2187-1"><a href="logistic-regression.html#cb2187-1"></a>heart.new <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">desc</span>(pred)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">n =</span> <span class="dv">8</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2,304 x 10
##   sex   pain.type resting.bp serum.chol max.hr oldpeak slope colored thal   pred
##   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;
## 1 male  asymptom…        140        280    133     1.6 flat        1 reve… 0.984
## 2 male  asymptom…        140        213    133     1.6 flat        1 reve… 0.975
## 3 male  asymptom…        120        280    133     1.6 flat        1 reve… 0.975
## 4 male  asymptom…        140        280    166     1.6 flat        1 reve… 0.970
## 5 male  asymptom…        140        280    133     0   flat        1 reve… 0.968
## 6 male  asymptom…        140        280    133     1.6 down…       1 reve… 0.964
## 7 male  asymptom…        120        213    133     1.6 flat        1 reve… 0.960
## 8 male  asymptom…        140        280    133     1.6 upsl…       1 reve… 0.958
## # … with 2,296 more rows</code></pre>
<ol start="11" style="list-style-type: lower-alpha">
<li>Compare the <code>summary</code> of the final model from
<code>step</code> with your highest predicted heart disease
probability and the values of the other variables that make it
up. Are they consistent?</li>
</ol>
<p>Solution</p>
<p>Since we were predicting the probability of heart disease, a
more positive slope in the model from <code>step</code> will be
associated with a higher probability of heart disease. So,
there, we are looking for a couple of things: if the variable
is a factor, we’re looking for the level with the most
positive slope (bearing in mind that this might be the
baseline), and for a numeric variable, if the slope is
positive, a <em>high</em> value is associated with heart
disease, and if negative, a low value.
Bearing that in mind, we go back to my
<code>summary(heart.3)</code> and we have:</p>
<ul>
<li><p><code>sex</code>: being male has the higher risk, by a lot</p></li>
<li><p><code>pain</code>: all the slopes shown are negative, so the
highest risk goes with the baseline one
<code>asymptomatic</code>.</p></li>
<li><p><code>resting.bp</code>: positive slope, so higher risk with
higher value.</p></li>
<li><p><code>serum.chol</code>: same.</p></li>
<li><p><code>max.hr</code>: negative slope, so greatest risk with
<em>smaller</em> value.</p></li>
<li><p><code>oldpeak</code>: positive slope, greater risk with
higher value again.</p></li>
<li><p><code>slope</code>: <code>flat</code> has greatest risk.</p></li>
<li><p><code>colored</code>: positive slope, so beware of higher
value.</p></li>
<li><p><code>thal</code>: <code>reversible</code> has greatest risk.</p></li>
</ul>
<p>Then we can do the same thing for the prediction. For the
numerical variables, we may need to check back to the previous
part to see whether the value shown was high or low. Once you
have done that, you can see that the variable values for the
highest predicted probability do indeed match the ones we
thought should be the highest risk.
The interesting thing about this is that after adjusting for
all of the other variables, there is a greater risk of heart
disease if you are male (and the model shows that the risk is
<em>much</em> greater). That is to say, it’s being male that
makes the difference, not the fact that any of the other
variables are different for males.
Perhaps, therefore, the easiest way to avoid a heart attack is to not be male!</p>
</div>
<div id="successful-breastfeeding" class="section level2" number="18.7">
<h2><span class="header-section-number">18.7</span> Successful breastfeeding</h2>
<p>A regular pregnancy lasts 40 weeks, and a
baby that is born at or before 33 weeks is called
“premature”. The number of weeks at which a baby is born is called
its “gestational age”.
Premature babies are usually smaller than normal and
may require special care. It is a good sign if, when the mother and
baby leave the hospital to go home, the baby is successfully breastfeeding.</p>
<p>The data in
<a href="http://www.utsc.utoronto.ca/~butler/d29/breastfeed.csv">link</a> are from
a study of 64 premature infants. There are three columns: the
gestational age (a whole number of weeks), the number of babies of
that gestational age that were successfully breastfeeding when they
left the hospital, and the number that were not. (There were multiple
babies of the same gestational age, so the 64 babies are summarized in
6 rows of data.)</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R and display the data frame.</li>
</ol>
<p>Solution</p>
<p>No great challenge here, I hope:</p>
<div class="sourceCode" id="cb2189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2189-1"><a href="logistic-regression.html#cb2189-1"></a>my_url &lt;-<span class="st"> &quot;http://www.utsc.utoronto.ca/~butler/d29/breastfeed.csv&quot;</span></span>
<span id="cb2189-2"><a href="logistic-regression.html#cb2189-2"></a>breastfeed &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   gest.age = col_double(),
##   bf.yes = col_double(),
##   bf.no = col_double()
## )</code></pre>
<div class="sourceCode" id="cb2191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2191-1"><a href="logistic-regression.html#cb2191-1"></a>breastfeed</span></code></pre></div>
<pre><code>## # A tibble: 6 x 3
##   gest.age bf.yes bf.no
##      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1       28      2     4
## 2       29      2     3
## 3       30      7     2
## 4       31      7     2
## 5       32     16     4
## 6       33     14     1</code></pre>
<p>That looks reasonable.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Verify that there were indeed 64 infants, by having R do a
suitable calculation on your data frame that gives the right answer
for the right reason.</li>
</ol>
<p>Solution</p>
<p>The second and third columns are all frequencies, so it’s a
question of adding them up. For example:</p>
<div class="sourceCode" id="cb2193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2193-1"><a href="logistic-regression.html#cb2193-1"></a>breastfeed <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">total =</span> <span class="kw">sum</span>(bf.yes) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(bf.no))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   total
##   &lt;dbl&gt;
## 1    64</code></pre>
<p>or if you want to go nuts (this one pivot-longers all the frequencies
together into one column and then adds them up):</p>
<div class="sourceCode" id="cb2195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2195-1"><a href="logistic-regression.html#cb2195-1"></a>breastfeed <span class="op">%&gt;%</span></span>
<span id="cb2195-2"><a href="logistic-regression.html#cb2195-2"></a><span class="st">  </span><span class="kw">pivot_longer</span>(bf.yes<span class="op">:</span>bf.no, <span class="dt">names_to=</span><span class="st">&quot;yesno&quot;</span>, <span class="dt">values_to=</span><span class="st">&quot;freq&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb2195-3"><a href="logistic-regression.html#cb2195-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">total =</span> <span class="kw">sum</span>(freq))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   total
##   &lt;dbl&gt;
## 1    64</code></pre>
<p>Find a way to get it done. If it works and it does the right thing,
it’s good.</p>
<p>Do <em>not</em> copy the numbers out of your data frame, type them in
again and use R to add them up. Do something with your data frame as
you read it in.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Do you think, looking at the data, that there is a
relationship between gestational age and whether or not the baby was
successfully breastfeeding when it left the hospital? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The babies with the youngest gestational age (the most premature)
were mostly <em>not</em> breastfeeding when they left the
hospital. Most of the 30- and 31-week babies were breastfeeding,
and almost all of the 32- and 33-week babies were
breastfeeding. So I think there will be a relationship: as
gestational age increases, the probability that the baby will be
breastfeeding will also increase. (This, looking ahead, suggests a
positive slope in a logistic regression.)</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Why is logistic regression a sensible technique to use
here? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The response variable is a yes/no: whether or not an infant is
breastfeeding. We want to predict the probability of the response
being in one or the other category. This is what logistic
regression does. (The explanatory variable(s) are usually
numerical, as here, but they could be factors as well, or a
mixture. The key is the kind of response. The number of babies
that are successfully breastfeeding at a certain gestational age
is modelled as binomial with <span class="math inline">\(n\)</span> being the total number of babies
of that gestational age, and <span class="math inline">\(p\)</span> being something that might
depend, and here <em>does</em> depend, on gestational age.)</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Fit a logistic regression to predict the probability that
an infant will be breastfeeding from its gestational age. Show the
output from your logistic regression.</li>
</ol>
<p>Solution</p>
<p>These are summarized data, rather than one infant per line, so
what we have to do is to make a two-column response “matrix”,
successes in the first column and failures in the second, and then
predict <em>that</em> from gestational age. (That’s why this was
three marks rather than two.)
So, let’s make the <code>response</code> first:</p>
<div class="sourceCode" id="cb2197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2197-1"><a href="logistic-regression.html#cb2197-1"></a>response &lt;-<span class="st"> </span><span class="kw">with</span>(breastfeed, <span class="kw">cbind</span>(bf.yes, bf.no))</span>
<span id="cb2197-2"><a href="logistic-regression.html#cb2197-2"></a>response</span></code></pre></div>
<pre><code>##      bf.yes bf.no
## [1,]      2     4
## [2,]      2     3
## [3,]      7     2
## [4,]      7     2
## [5,]     16     4
## [6,]     14     1</code></pre>
<p>or, more Tidyverse-like, but we have to remember to turn it into a
<code>matrix</code>:</p>
<div class="sourceCode" id="cb2199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2199-1"><a href="logistic-regression.html#cb2199-1"></a>response &lt;-<span class="st"> </span>breastfeed <span class="op">%&gt;%</span></span>
<span id="cb2199-2"><a href="logistic-regression.html#cb2199-2"></a><span class="st">  </span><span class="kw">select</span>(<span class="kw">starts_with</span>(<span class="st">&quot;bf&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb2199-3"><a href="logistic-regression.html#cb2199-3"></a><span class="st">  </span><span class="kw">as.matrix</span>()</span>
<span id="cb2199-4"><a href="logistic-regression.html#cb2199-4"></a>response</span></code></pre></div>
<pre><code>##      bf.yes bf.no
## [1,]      2     4
## [2,]      2     3
## [3,]      7     2
## [4,]      7     2
## [5,]     16     4
## [6,]     14     1</code></pre>
<p>I used a select-helper, because what immediately came to me was that
the names of the columns I wanted started with <code>bf</code>, but
whatever way you have that works is good.
Now we fit the logistic regression:</p>
<div class="sourceCode" id="cb2201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2201-1"><a href="logistic-regression.html#cb2201-1"></a>breastfeed<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(response <span class="op">~</span><span class="st"> </span>gest.age, <span class="dt">data =</span> breastfeed, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb2201-2"><a href="logistic-regression.html#cb2201-2"></a><span class="kw">summary</span>(breastfeed<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = response ~ gest.age, family = &quot;binomial&quot;, data = breastfeed)
## 
## Deviance Residuals: 
##       1        2        3        4        5        6  
## -0.1472  -0.4602   0.8779   0.1114  -0.6119   0.3251  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept) -16.7198     6.0630  -2.758  0.00582 **
## gest.age      0.5769     0.1977   2.918  0.00352 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 11.1772  on 5  degrees of freedom
## Residual deviance:  1.4968  on 4  degrees of freedom
## AIC: 19.556
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<ol start="6" style="list-style-type: lower-alpha">
<li>Does the significance or non-significance of the slope of
<code>gest.age</code> surprise you? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The slope <em>is</em> significant (P-value 0.0035 is much less than
0.05). We said above that we expected there to be a relationship
between gestational age and whether or not the baby was
breastfeeding, and this significant slope is confirming that there
<em>is</em> a relationship. So this is exactly what we expected to
see, and not a surprise at all.
If you concluded above that you did <em>not</em> see a relationship,
you should colour yourself surprised here. Consistency.</p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Is your slope (in the <code>Estimate</code> column) positive or
negative? What does that mean, in terms of gestational ages and
breastfeeding? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>My slope is 0.5769, positive. That means that as the explanatory
variable, gestational age, increases, the probability of the event
(that the baby is breastfeeding) also increases.
This is also what I observed above: almost all of the near-term
(large gestational age) babies were breastfeeding, whereas a fair
few of the small-gestational-age (very premature) ones were not.</p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Obtain the predicted probabilities that an infant will
successfully breastfeed for each of the gestational ages in the data
set, and display them side by side with the observed data.</li>
</ol>
<p>Solution</p>
<p>This is the easier version of <code>predict</code>, where you do not
have to create a data frame of values to predict from (since you
are using the original data).
Thus, you only need something like this:</p>
<div class="sourceCode" id="cb2203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2203-1"><a href="logistic-regression.html#cb2203-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(breastfeed<span class="fl">.1</span>, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2203-2"><a href="logistic-regression.html#cb2203-2"></a><span class="kw">cbind</span>(breastfeed, p)</span></code></pre></div>
<pre><code>##   gest.age bf.yes bf.no         p
## 1       28      2     4 0.3620282
## 2       29      2     3 0.5025820
## 3       30      7     2 0.6427290
## 4       31      7     2 0.7620821
## 5       32     16     4 0.8508177
## 6       33     14     1 0.9103511</code></pre>
<p>You can see that the predicted probabilities go steadily up as the
gestational age goes up, just as we would have expected.</p>
<p>If you only wanted certain gestational ages, for example 25, 30 and
35, you would do that like this:</p>
<div class="sourceCode" id="cb2205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2205-1"><a href="logistic-regression.html#cb2205-1"></a>ages.new &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">gest.age =</span> <span class="kw">c</span>(<span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">35</span>))</span>
<span id="cb2205-2"><a href="logistic-regression.html#cb2205-2"></a>p2 &lt;-<span class="st"> </span><span class="kw">predict</span>(breastfeed<span class="fl">.1</span>, ages.new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2205-3"><a href="logistic-regression.html#cb2205-3"></a><span class="kw">cbind</span>(ages.new, p2)</span></code></pre></div>
<pre><code>##   gest.age         p2
## 1       25 0.09134905
## 2       30 0.64272897
## 3       35 0.96987261</code></pre>
<p>Or, if you wanted to make a graph of the observed and predicted
proportions/probabilities, you could do something like this:</p>
<div class="sourceCode" id="cb2207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2207-1"><a href="logistic-regression.html#cb2207-1"></a>breastfeed <span class="op">%&gt;%</span></span>
<span id="cb2207-2"><a href="logistic-regression.html#cb2207-2"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb2207-3"><a href="logistic-regression.html#cb2207-3"></a>    <span class="dt">total =</span> bf.yes <span class="op">+</span><span class="st"> </span>bf.no,</span>
<span id="cb2207-4"><a href="logistic-regression.html#cb2207-4"></a>    <span class="dt">obs =</span> bf.yes <span class="op">/</span><span class="st"> </span>total</span>
<span id="cb2207-5"><a href="logistic-regression.html#cb2207-5"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb2207-6"><a href="logistic-regression.html#cb2207-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred =</span> p) <span class="op">%&gt;%</span></span>
<span id="cb2207-7"><a href="logistic-regression.html#cb2207-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> gest.age, <span class="dt">y =</span> obs)) <span class="op">+</span></span>
<span id="cb2207-8"><a href="logistic-regression.html#cb2207-8"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> pred)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">size =</span> total))</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-144-1.png" width="672"  /></p>
<p>What did I do there? I first created some new variables:
<code>count</code> is the total number of babies of each gestational age,
<code>obs</code> is the observed proportion of breastfeeding babies at
each gestational age (number of yes divided by total), and
<code>pred</code> which are the predictions we did above. Then I make a
plot on which I plot the observed proportions against gestational age
(as points), and then I want to plot the predictions joined by
lines. To do <em>that</em>, I need to change which <span class="math inline">\(y\)</span>-variable I am
plotting (now <code>pred</code> rather than <code>obs</code>), and the way I
do that is to put an <code>aes</code> inside the <code>geom_line</code> to
say “use the <span class="math inline">\(x\)</span> I had before, but use this <span class="math inline">\(y\)</span> instead”. I also
wanted to draw attention to the gestational ages where more babies
were observed; I did this by making the <em>size</em> of the plotted
points proportional to how many babies there were at that gestational
age (which was the quantity <code>total</code> I calculated above). This
took a couple of attempts to get right: I put <code>size=</code> in the
original <code>aes</code>, but I didn’t realize that it controlled the
line thickness as well (which looked really weird). So I moved the
<code>geom_point</code> to the end and put the <code>size=</code> in there,
to make sure that the size thing <em>only</em> applied to the
points. The legend for <code>total</code> tells you what size point
corresponds to how many total babies.</p>
<p>The idea is that the observed and predicted should be reasonably
close, or at least not grossly different, and I think they <em>are</em>
close, which indicates that our model is doing a good job.</p>
</div>
<div id="making-it-over-the-mountains" class="section level2" number="18.8">
<h2><span class="header-section-number">18.8</span> Making it over the mountains</h2>
<p>In 1846, the Donner party (Donner and Reed
families) left Springfield, Illinois for California in covered
wagons. After reaching Fort Bridger, Wyoming, the leaders decided to
find a new route to Sacramento. They became stranded in the eastern
Sierra Nevada mountains at a place now called Donner Pass, when the
region was hit by heavy snows in late October. By the time the
survivors were rescued on April 21, 1847, 40 out of 87 had died.</p>
<p>After the rescue, the age and gender of each person in the party was
recorded, along with whether they survived or not. The data are in
<a href="http://www.utsc.utoronto.ca/~butler/d29/donner.txt">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data and display its structure. Does that agree
with the description in the previous paragraph?</li>
</ol>
<p>Solution</p>
<p>Nothing very new here:</p>
<div class="sourceCode" id="cb2208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2208-1"><a href="logistic-regression.html#cb2208-1"></a>my_url &lt;-<span class="st"> &quot;http://www.utsc.utoronto.ca/~butler/d29/donner.txt&quot;</span></span>
<span id="cb2208-2"><a href="logistic-regression.html#cb2208-2"></a>donner &lt;-<span class="st"> </span><span class="kw">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   age = col_double(),
##   gender = col_character(),
##   survived = col_character()
## )</code></pre>
<div class="sourceCode" id="cb2210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2210-1"><a href="logistic-regression.html#cb2210-1"></a>donner</span></code></pre></div>
<pre><code>## # A tibble: 45 x 3
##      age gender survived
##    &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   
##  1    23 male   no      
##  2    40 female yes     
##  3    40 male   yes     
##  4    30 male   no      
##  5    28 male   no      
##  6    40 male   no      
##  7    45 female no      
##  8    62 male   no      
##  9    65 male   no      
## 10    45 female no      
## # … with 35 more rows</code></pre>
<p>The ages look like ages, and the other variables are categorical as
promised, with the right levels. So this looks sensible.</p>
<p>I usually write (or rewrite) the data description myself, but the one
I found for these data at
<a href="https://onlinecourses.science.psu.edu/stat504/node/159">link</a> was so
nice that I used it as is. You can see that the data format used on
that website is not as nice as ours. (I did some work to make it look
nicer for you, with proper named categories rather than 0 and 1.)</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make graphical or numerical summaries for each pair of
variables. That is, you should make a graph or numerical summary for
each of
<code>age</code> vs. <code>gender</code>, <code>age</code> vs.<br />
<code>survived</code> and <code>gender</code> vs. <code>survived</code>. In choosing the
kind of graph or summary that you will use, bear in mind that
<code>survived</code> and <code>gender</code> are factors with two
levels.</li>
</ol>
<p>Solution</p>
<p>Thinking about graphs first: we have two numeric-vs-factor graphs
(the ones involving <code>age</code>), which I think should be
boxplots, though they could be something like side-by-side
histograms (if you are willing to grapple with
<code>facet_grid</code>). The other two variables are both
factors, so a good graph for them would be something
like a grouped bar plot (as in the question about parasites earlier).
If you prefer numerical summaries: you could do mean age (or some
other summary of age) for each group defined by gender or
survivorship, and you could do a cross-tabulation of frequencies
for gender and survival. I’ll take any mixture of graphs and
numerical summaries that addresses each pair of variables somehow
and summarizes them in a sensible way.
Starting with <code>age</code> vs. <code>gender</code>:</p>
<div class="sourceCode" id="cb2212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2212-1"><a href="logistic-regression.html#cb2212-1"></a><span class="kw">ggplot</span>(donner, <span class="kw">aes</span>(<span class="dt">x =</span> gender, <span class="dt">y =</span> age)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-146-1.png" width="672"  /></p>
<p>or:</p>
<div class="sourceCode" id="cb2213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2213-1"><a href="logistic-regression.html#cb2213-1"></a><span class="kw">ggplot</span>(donner, <span class="kw">aes</span>(<span class="dt">x =</span> age)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">10</span>) <span class="op">+</span><span class="st"> </span><span class="kw">facet_grid</span>(gender <span class="op">~</span><span class="st"> </span>.)</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-147-1.png" width="672"  /></p>
<p>or:</p>
<div class="sourceCode" id="cb2214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2214-1"><a href="logistic-regression.html#cb2214-1"></a><span class="kw">aggregate</span>(age <span class="op">~</span><span class="st"> </span>gender, donner, mean)</span></code></pre></div>
<pre><code>##   gender      age
## 1 female 31.06667
## 2   male 32.16667</code></pre>
<p>or:</p>
<div class="sourceCode" id="cb2216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2216-1"><a href="logistic-regression.html#cb2216-1"></a>donner <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(gender) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">m =</span> <span class="kw">mean</span>(age))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 2 x 2
##   gender     m
##   &lt;chr&gt;  &lt;dbl&gt;
## 1 female  31.1
## 2 male    32.2</code></pre>
<p>Age vs. <code>survived</code> is the same idea:</p>
<div class="sourceCode" id="cb2219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2219-1"><a href="logistic-regression.html#cb2219-1"></a><span class="kw">ggplot</span>(donner, <span class="kw">aes</span>(<span class="dt">x =</span> survived, <span class="dt">y =</span> age)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-150-1.png" width="672"  /></p>
<p>or:</p>
<div class="sourceCode" id="cb2220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2220-1"><a href="logistic-regression.html#cb2220-1"></a><span class="kw">ggplot</span>(donner, <span class="kw">aes</span>(<span class="dt">x =</span> age)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">10</span>) <span class="op">+</span><span class="st"> </span><span class="kw">facet_grid</span>(survived <span class="op">~</span><span class="st"> </span>.)</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-151-1.png" width="672"  /></p>
<p>or:</p>
<div class="sourceCode" id="cb2221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2221-1"><a href="logistic-regression.html#cb2221-1"></a><span class="kw">aggregate</span>(age <span class="op">~</span><span class="st"> </span>survived, donner, mean)</span></code></pre></div>
<pre><code>##   survived   age
## 1       no 35.48
## 2      yes 27.20</code></pre>
<p>or:</p>
<div class="sourceCode" id="cb2223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2223-1"><a href="logistic-regression.html#cb2223-1"></a>donner <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(survived) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">m =</span> <span class="kw">mean</span>(age))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 2 x 2
##   survived     m
##   &lt;chr&gt;    &lt;dbl&gt;
## 1 no        35.5
## 2 yes       27.2</code></pre>
<p>For <code>survived</code> against <code>gender</code>, the obvious thing is a
cross-tabulation, gotten like this:</p>
<div class="sourceCode" id="cb2226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2226-1"><a href="logistic-regression.html#cb2226-1"></a><span class="kw">with</span>(donner, <span class="kw">table</span>(gender, survived))</span></code></pre></div>
<pre><code>##         survived
## gender   no yes
##   female  5  10
##   male   20  10</code></pre>
<p>or like this:</p>
<div class="sourceCode" id="cb2228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2228-1"><a href="logistic-regression.html#cb2228-1"></a>donner <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(gender, survived) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>())</span></code></pre></div>
<pre><code>## `summarise()` regrouping output by &#39;gender&#39; (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 4 x 3
## # Groups:   gender [2]
##   gender survived     n
##   &lt;chr&gt;  &lt;chr&gt;    &lt;int&gt;
## 1 female no           5
## 2 female yes         10
## 3 male   no          20
## 4 male   yes         10</code></pre>
<p>For a graph, borrow the grouped bar-plot idea from the parasites question:</p>
<div class="sourceCode" id="cb2231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2231-1"><a href="logistic-regression.html#cb2231-1"></a><span class="kw">ggplot</span>(donner, <span class="kw">aes</span>(<span class="dt">x =</span> gender, <span class="dt">fill =</span> survived)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>)</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-156-1.png" width="672"  /></p>
<p>I think this way around for <code>x</code> and <code>fill</code> is better,
since we want to ask something like “out of the females, how many survived”
(that is, gender is explanatory and survival response).</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>For each of the three graphs or summaries in the previous
question, what do they tell you about the relationship between the
pair of variables concerned? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>I think the graphs are the easiest thing to interpret, but use
whatever you got:</p>
<ul>
<li><p>The females on average were younger than the males. (This
was still true with the medians, even though those very old
males might have pulled the mean up.)</p></li>
<li><p>The people who survived were on average younger than those
who didn’t (or, the older people tended not to survive).</p></li>
<li><p>A greater proportion of females survived than males.</p></li>
</ul>
<p>A relevant point about each relationship is good.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a logistic regression predicting survival from age and
gender. Display the summary.</li>
</ol>
<p>Solution</p>
<p>Each row of the data frame is one person, so we can use the
<code>survived</code> column without going through that two-column
response business.
However, the response variable <code>survived</code> is a categorical
variable expressed as text, so we need to make it into a
<code>factor</code> first. Either create a new variable that is the
factor version of <code>survived</code>, or do it right in the <code>glm</code>:</p>
<div class="sourceCode" id="cb2232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2232-1"><a href="logistic-regression.html#cb2232-1"></a>donner<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">factor</span>(survived) <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>gender, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> donner)</span>
<span id="cb2232-2"><a href="logistic-regression.html#cb2232-2"></a><span class="kw">summary</span>(donner<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = factor(survived) ~ age + gender, family = &quot;binomial&quot;, 
##     data = donner)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.7445  -1.0441  -0.3029   0.8877   2.0472  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)  3.23041    1.38686   2.329   0.0198 *
## age         -0.07820    0.03728  -2.097   0.0359 *
## gendermale  -1.59729    0.75547  -2.114   0.0345 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 61.827  on 44  degrees of freedom
## Residual deviance: 51.256  on 42  degrees of freedom
## AIC: 57.256
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>We ought to take a moment to think about what is being predicted here:</p>
<div class="sourceCode" id="cb2234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2234-1"><a href="logistic-regression.html#cb2234-1"></a><span class="kw">levels</span>(<span class="kw">factor</span>(donner<span class="op">$</span>survived))</span></code></pre></div>
<pre><code>## [1] &quot;no&quot;  &quot;yes&quot;</code></pre>
<p>The baseline is the first of these, <code>no</code>, and the thing that is
predicted is the probability of the second one, <code>yes</code> (that is,
the probability of surviving).</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Do both explanatory variables have an impact on survival?
Does that seem to be consistent with your numerical or graphical
summaries? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Both explanatory variables have a P-value (just) less than 0.05, so
they both have an impact on survival: taking either one of them out
of the logistic regression would be a mistake.
To see if this makes sense, go back to your plots or summaries, the
ones involving survival. For age, the mean or median age of the
survivors was less than for the people who died, by five year
(median) or eight years (mean), so it makes sense that there would
be an age effect. For gender, two-thirds of the women survived and
two-thirds of the men died, so there ought to be a gender effect and is.</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Are the men typically older, younger or about the same age as
the women? Considering this, explain carefully what the negative
<code>gendermale</code> slope in your logistic regression means.</li>
</ol>
<p>Solution</p>
<p>The men are typically older than the women.
The negative (and significant) <code>gendermale</code> slope means that
the probability of a male surviving is less than that of a woman
<em>of the same age</em>. Or, though the males are typically
older, <em>even after you allow for that</em>, the males have worse
survival. (<code>genderfemale</code> is the baseline.)
You need to get at the idea of “all else equal” when you’re
assessing regression slopes of any kind: regular regression,
logistic regression or survival analysis (coming up later). That’s
why I said “carefully” in the question. If I say “carefully” or
“precisely”, a complete answer is looking for a specific thing to
show that you understand the issue completely.</p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Obtain the median and quartiles of age, and construct a data
frame that contains all combinations of those ages and the two
genders, with columns called exactly <code>age</code> and
<code>gender</code>. Use this data frame to obtain predicted probabilities
of survival for each of those combinations of age and gender.</li>
</ol>
<p>Solution</p>
<p>I have a standard way of doing this:</p>
<ul>
<li><p>Make a list of all the variable values I’m going to predict
for, using plural names</p></li>
<li><p>Make a data frame containing all combinations, using
<code>crossing</code>, giving the columns the right names</p></li>
<li><p>Feed this data frame into <code>predict</code>, along with a
fitted model, and get a column of predictions.</p></li>
<li><p>Glue those predictions onto the data frame of values to
predict for, and display them.</p></li>
</ul>
<p>That way I can do it without thinking too hard.
There is a lazy way to do step 1 (which I’ll show first), and a way
that is more work but more reliable (because you have to concentrate
less).
Step 1, the lazy way:</p>
<div class="sourceCode" id="cb2236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2236-1"><a href="logistic-regression.html#cb2236-1"></a>donner <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(age) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>##       age      
##  Min.   :15.0  
##  1st Qu.:24.0  
##  Median :28.0  
##  Mean   :31.8  
##  3rd Qu.:40.0  
##  Max.   :65.0</code></pre>
<div class="sourceCode" id="cb2238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2238-1"><a href="logistic-regression.html#cb2238-1"></a>donner <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(gender)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   gender     n
##   &lt;chr&gt;  &lt;int&gt;
## 1 female    15
## 2 male      30</code></pre>
<p>Then construct vectors called <code>ages</code> and <code>genders</code> by
literally copying the values output from above:</p>
<div class="sourceCode" id="cb2240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2240-1"><a href="logistic-regression.html#cb2240-1"></a>ages &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">24</span>, <span class="dv">28</span>, <span class="dv">40</span>)</span>
<span id="cb2240-2"><a href="logistic-regression.html#cb2240-2"></a>genders &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;female&quot;</span>, <span class="st">&quot;male&quot;</span>)</span></code></pre></div>
<p>There is a risk here, because it is very easy to make typos while
copying, so it would be more reliable to compute these (and, as long
as you trust your computation, reproducible as well). Thinking of
reproducibility, if the data set changes, your computation of
quartiles etc. will still work, whereas your copying above won’t.</p>
<p>So, let’s get the median and quartiles of age:</p>
<div class="sourceCode" id="cb2241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2241-1"><a href="logistic-regression.html#cb2241-1"></a>donner <span class="op">%&gt;%</span></span>
<span id="cb2241-2"><a href="logistic-regression.html#cb2241-2"></a><span class="st">  </span><span class="kw">summarize</span>(</span>
<span id="cb2241-3"><a href="logistic-regression.html#cb2241-3"></a>    <span class="dt">q1 =</span> <span class="kw">quantile</span>(age, <span class="fl">0.25</span>),</span>
<span id="cb2241-4"><a href="logistic-regression.html#cb2241-4"></a>    <span class="dt">med =</span> <span class="kw">median</span>(age),</span>
<span id="cb2241-5"><a href="logistic-regression.html#cb2241-5"></a>    <span class="dt">q3 =</span> <span class="kw">quantile</span>(age, <span class="fl">0.75</span>)</span>
<span id="cb2241-6"><a href="logistic-regression.html#cb2241-6"></a>  )</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##      q1   med    q3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    24    28    40</code></pre>
<p>only these came out sideways, so we can “transpose” them:</p>
<div class="sourceCode" id="cb2243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2243-1"><a href="logistic-regression.html#cb2243-1"></a>donner <span class="op">%&gt;%</span></span>
<span id="cb2243-2"><a href="logistic-regression.html#cb2243-2"></a><span class="st">  </span><span class="kw">summarize</span>(</span>
<span id="cb2243-3"><a href="logistic-regression.html#cb2243-3"></a>    <span class="dt">q1 =</span> <span class="kw">quantile</span>(age, <span class="fl">0.25</span>),</span>
<span id="cb2243-4"><a href="logistic-regression.html#cb2243-4"></a>    <span class="dt">med =</span> <span class="kw">median</span>(age),</span>
<span id="cb2243-5"><a href="logistic-regression.html#cb2243-5"></a>    <span class="dt">q3 =</span> <span class="kw">quantile</span>(age, <span class="fl">0.75</span>)</span>
<span id="cb2243-6"><a href="logistic-regression.html#cb2243-6"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb2243-7"><a href="logistic-regression.html#cb2243-7"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>(), <span class="dt">names_to=</span><span class="st">&quot;stat&quot;</span>, <span class="dt">values_to=</span><span class="st">&quot;value&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 3 x 2
##   stat  value
##   &lt;chr&gt; &lt;dbl&gt;
## 1 q1       24
## 2 med      28
## 3 q3       40</code></pre>
<p>and now if we “pull out” the <code>value</code> column, we are good:</p>
<div class="sourceCode" id="cb2245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2245-1"><a href="logistic-regression.html#cb2245-1"></a>ages &lt;-<span class="st"> </span>donner <span class="op">%&gt;%</span></span>
<span id="cb2245-2"><a href="logistic-regression.html#cb2245-2"></a><span class="st">  </span><span class="kw">summarize</span>(</span>
<span id="cb2245-3"><a href="logistic-regression.html#cb2245-3"></a>    <span class="dt">q1 =</span> <span class="kw">quantile</span>(age, <span class="fl">0.25</span>),</span>
<span id="cb2245-4"><a href="logistic-regression.html#cb2245-4"></a>    <span class="dt">med =</span> <span class="kw">median</span>(age),</span>
<span id="cb2245-5"><a href="logistic-regression.html#cb2245-5"></a>    <span class="dt">q3 =</span> <span class="kw">quantile</span>(age, <span class="fl">0.75</span>)</span>
<span id="cb2245-6"><a href="logistic-regression.html#cb2245-6"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb2245-7"><a href="logistic-regression.html#cb2245-7"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>(), <span class="dt">names_to=</span><span class="st">&quot;stat&quot;</span>, <span class="dt">values_to=</span><span class="st">&quot;value&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2245-8"><a href="logistic-regression.html#cb2245-8"></a><span class="st">  </span><span class="kw">pull</span>(value)</span>
<span id="cb2245-9"><a href="logistic-regression.html#cb2245-9"></a>ages</span></code></pre></div>
<pre><code>## 25%     75% 
##  24  28  40</code></pre>
<p>The same kind of idea will get us both genders without typing any genders:</p>
<div class="sourceCode" id="cb2247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2247-1"><a href="logistic-regression.html#cb2247-1"></a>genders &lt;-<span class="st"> </span>donner <span class="op">%&gt;%</span></span>
<span id="cb2247-2"><a href="logistic-regression.html#cb2247-2"></a><span class="st">  </span><span class="kw">count</span>(gender) <span class="op">%&gt;%</span></span>
<span id="cb2247-3"><a href="logistic-regression.html#cb2247-3"></a><span class="st">  </span><span class="kw">pull</span>(gender)</span>
<span id="cb2247-4"><a href="logistic-regression.html#cb2247-4"></a>genders</span></code></pre></div>
<pre><code>## [1] &quot;female&quot; &quot;male&quot;</code></pre>
<p>We don’t care how many there are of each gender; it’s just a device to
get the different genders.
<label for="tufte-mn-140" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-140" class="margin-toggle"><span class="marginnote">The counts are in a column called <em>n</em> which we calculate and then ignore.</span> This is another way:</p>
<div class="sourceCode" id="cb2249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2249-1"><a href="logistic-regression.html#cb2249-1"></a>genders &lt;-<span class="st"> </span>donner <span class="op">%&gt;%</span></span>
<span id="cb2249-2"><a href="logistic-regression.html#cb2249-2"></a><span class="st">  </span><span class="kw">select</span>(gender) <span class="op">%&gt;%</span></span>
<span id="cb2249-3"><a href="logistic-regression.html#cb2249-3"></a><span class="st">  </span><span class="kw">distinct</span>() <span class="op">%&gt;%</span></span>
<span id="cb2249-4"><a href="logistic-regression.html#cb2249-4"></a><span class="st">  </span><span class="kw">pull</span>(gender)</span>
<span id="cb2249-5"><a href="logistic-regression.html#cb2249-5"></a>genders</span></code></pre></div>
<pre><code>## [1] &quot;male&quot;   &quot;female&quot;</code></pre>
<p>The rationale behind this one is that <code>distinct()</code> removes
duplicates (or duplicate combinations if you have more than one
variable), leaving you with only the distinct ones (the ones that are
different from each other).</p>
<p>I don’t think the genders are ever going to change, but it’s the
principle of the thing.</p>
<p>Step 2:</p>
<div class="sourceCode" id="cb2251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2251-1"><a href="logistic-regression.html#cb2251-1"></a>donner.new &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">age =</span> ages, <span class="dt">gender =</span> genders)</span>
<span id="cb2251-2"><a href="logistic-regression.html#cb2251-2"></a>donner.new</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##     age gender
##   &lt;dbl&gt; &lt;chr&gt; 
## 1    24 female
## 2    24 male  
## 3    28 female
## 4    28 male  
## 5    40 female
## 6    40 male</code></pre>
<p>All combinations of the three ages and two genders.</p>
<p>Step 3:</p>
<div class="sourceCode" id="cb2253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2253-1"><a href="logistic-regression.html#cb2253-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(donner<span class="fl">.1</span>, donner.new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2253-2"><a href="logistic-regression.html#cb2253-2"></a>p</span></code></pre></div>
<pre><code>##         1         2         3         4         5         6 
## 0.7947039 0.4393557 0.7389850 0.3643360 0.5255405 0.1831661</code></pre>
<p>Step 4:</p>
<div class="sourceCode" id="cb2255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2255-1"><a href="logistic-regression.html#cb2255-1"></a><span class="kw">cbind</span>(donner.new, p)</span></code></pre></div>
<pre><code>##   age gender         p
## 1  24 female 0.7947039
## 2  24   male 0.4393557
## 3  28 female 0.7389850
## 4  28   male 0.3643360
## 5  40 female 0.5255405
## 6  40   male 0.1831661</code></pre>
<p>These, remember, are predicted probabilities of <em>surviving</em>.</p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Do your predictions support your conclusions from earlier
about the effects of age and gender? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>We said before that the probability of survival was lower if the age
was higher. This is confirmed here: for example, look at rows 1, 3
and 5, which are all females of increasing ages; the probability of
survival decreases. (Or look at males, in rows 2, 4 and 6; the
effect is the same.)</p>
<p>To see the effect of gender, look at two predictions of different
genders but the same age (eg. rows 1 and 2). The female is always
predicted to have the higher survival probability. This is also what
we saw before. The effect of gender is substantial, but not strongly
significant, because we only have 45 observations, not so many when
all we know about each person is whether they survived or not.
I wanted you to think about these different ways to understand the
model, and to understand that they all say the same thing, in
different ways (and thus you can look at whichever of them is most
convenient or comprehensible). For the logistic and survival models,
I find looking at predictions to be the easiest way to understand
what the model is saying.</p>
</div>
<div id="who-needs-the-most-intensive-care" class="section level2" number="18.9">
<h2><span class="header-section-number">18.9</span> Who needs the most intensive care?</h2>
<p>The “APACHE II” is a scale for assessing patients who
arrive in the intensive care unit (ICU) of a hospital. These are seriously
ill patients who may die despite the ICU’s best attempts. APACHE
stands for “Acute Physiology And Chronic Health Evaluation”.
<label for="tufte-mn-141" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-141" class="margin-toggle"><span class="marginnote">As with many of these acronyms, you get the idea that the acronym came first and they devised some words to fit it.</span>
The scale score is calculated from several physiological measurements
such as body temperature, heart rate and the Glasgow coma scale, as
well as the patient’s age. The final result is a score between 0 and
71, with a higher score indicating more severe health issues. Is it
true that a patient with a higher APACHE II score has a higher
probability of dying?</p>
<p>Data from one hospital are in
<a href="http://www.utsc.utoronto.ca/~butler/d29/apache.txt">link</a>. The columns
are: the APACHE II score, the total number of patients who had that
score, and the number of patients with that score who died.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display the data (however much of it
displays). Why are you convinced that have the right thing?</li>
</ol>
<p>Solution</p>
<p>Data values separated by one space, so:</p>
<div class="sourceCode" id="cb2257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2257-1"><a href="logistic-regression.html#cb2257-1"></a>my_url &lt;-<span class="st"> &quot;http://www.utsc.utoronto.ca/~butler/d29/apache.txt&quot;</span></span>
<span id="cb2257-2"><a href="logistic-regression.html#cb2257-2"></a>icu &lt;-<span class="st"> </span><span class="kw">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   apache = col_double(),
##   patients = col_double(),
##   deaths = col_double()
## )</code></pre>
<div class="sourceCode" id="cb2259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2259-1"><a href="logistic-regression.html#cb2259-1"></a>icu</span></code></pre></div>
<pre><code>## # A tibble: 38 x 3
##    apache patients deaths
##     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;
##  1      0        1      0
##  2      2        1      0
##  3      3        4      1
##  4      4       11      0
##  5      5        9      3
##  6      6       14      3
##  7      7       12      4
##  8      8       22      5
##  9      9       33      3
## 10     10       19      6
## # … with 28 more rows</code></pre>
<p>I had to stop and think about what to call the data frame, since one
of the columns is called <code>apache</code>.</p>
<p>Anyway, I appear to have an <code>apache</code> score between 0 and something, a
number of patients and a number of deaths (that is no bigger than the
number of patients). If you check the original data, the <code>apache</code>
scores go up to 41 and are all the values except for a few near the
end, so it makes perfect sense that there would be 38 rows.</p>
<p>Basically, any comment here is good, as long as you make one and it
has something to do with the data.</p>
<p><code>apache</code> scores could be as high as 71, but I imagine a patient would
have to be <em>very</em> ill to get a score anywhere near that high.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Does each row of the data frame relate to one patient or
sometimes to more than one? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>Sometimes to more than one. The number in the <code>patients</code>
column says how many patients that line refers to: that is to say
(for example) the row where <code>apache</code> equals 6 represents
<em>all</em> the patients whose <code>apache</code> score was 6, however many
of them there were (14 in this case).
I had to be careful with the wording because the first two rows of
the data frame actually <em>do</em> refer to only one patient each
(who survived in both cases), but the later rows do refer to more
than one patient.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Explain why this is the kind of situation where you need a
two-column response, and create this response variable, bearing in
mind that I will (later) want you to estimate the probability of
dying, given the <code>apache</code> score.</li>
</ol>
<p>Solution</p>
<p>This needs a two-column response precisely <em>because</em> each row
represents (or could represent) more than one observation.
The two columns are the number of observations referring to the
event of interest (dying), and the number of observations where
that didn’t happen (survived). We don’t actually have the numbers
of survivals, but we can calculate these by subtracting from the
numbers of patients (since a patient must have either lived or
died):</p>
<div class="sourceCode" id="cb2261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2261-1"><a href="logistic-regression.html#cb2261-1"></a>response &lt;-<span class="st"> </span>icu <span class="op">%&gt;%</span></span>
<span id="cb2261-2"><a href="logistic-regression.html#cb2261-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">survivals =</span> patients <span class="op">-</span><span class="st"> </span>deaths) <span class="op">%&gt;%</span></span>
<span id="cb2261-3"><a href="logistic-regression.html#cb2261-3"></a><span class="st">  </span><span class="kw">select</span>(deaths, survivals) <span class="op">%&gt;%</span></span>
<span id="cb2261-4"><a href="logistic-regression.html#cb2261-4"></a><span class="st">  </span><span class="kw">as.matrix</span>()</span>
<span id="cb2261-5"><a href="logistic-regression.html#cb2261-5"></a>response</span></code></pre></div>
<pre><code>##       deaths survivals
##  [1,]      0         1
##  [2,]      0         1
##  [3,]      1         3
##  [4,]      0        11
##  [5,]      3         6
##  [6,]      3        11
##  [7,]      4         8
##  [8,]      5        17
##  [9,]      3        30
## [10,]      6        13
## [11,]      5        26
## [12,]      5        12
## [13,]     13        19
## [14,]      7        18
## [15,]      7        11
## [16,]      8        16
## [17,]      8        19
## [18,]     13         6
## [19,]      7         8
## [20,]      6         7
## [21,]      9         8
## [22,]     12         2
## [23,]      7         6
## [24,]      8         3
## [25,]      8         4
## [26,]      2         4
## [27,]      5         2
## [28,]      1         2
## [29,]      4         3
## [30,]      4         1
## [31,]      3         0
## [32,]      3         0
## [33,]      1         0
## [34,]      1         0
## [35,]      1         0
## [36,]      1         0
## [37,]      1         0
## [38,]      0         1</code></pre>
<p>noting that the deaths column has to come <em>first</em> since that’s
what we want the probability of. It has to be a <code>matrix</code>, so
<code>as.matrix</code> is the final step. You can quickly check that the
two numbers in each row add up to the number of <code>patients</code> for
that row.</p>
<p>Or do everything outside of the data
frame:</p>
<div class="sourceCode" id="cb2263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2263-1"><a href="logistic-regression.html#cb2263-1"></a>survivals &lt;-<span class="st"> </span><span class="kw">with</span>(icu, patients <span class="op">-</span><span class="st"> </span>deaths)</span>
<span id="cb2263-2"><a href="logistic-regression.html#cb2263-2"></a>resp &lt;-<span class="st"> </span><span class="kw">with</span>(icu, <span class="kw">cbind</span>(deaths, survivals))</span>
<span id="cb2263-3"><a href="logistic-regression.html#cb2263-3"></a>resp</span></code></pre></div>
<pre><code>##       deaths survivals
##  [1,]      0         1
##  [2,]      0         1
##  [3,]      1         3
##  [4,]      0        11
##  [5,]      3         6
##  [6,]      3        11
##  [7,]      4         8
##  [8,]      5        17
##  [9,]      3        30
## [10,]      6        13
## [11,]      5        26
## [12,]      5        12
## [13,]     13        19
## [14,]      7        18
## [15,]      7        11
## [16,]      8        16
## [17,]      8        19
## [18,]     13         6
## [19,]      7         8
## [20,]      6         7
## [21,]      9         8
## [22,]     12         2
## [23,]      7         6
## [24,]      8         3
## [25,]      8         4
## [26,]      2         4
## [27,]      5         2
## [28,]      1         2
## [29,]      4         3
## [30,]      4         1
## [31,]      3         0
## [32,]      3         0
## [33,]      1         0
## [34,]      1         0
## [35,]      1         0
## [36,]      1         0
## [37,]      1         0
## [38,]      0         1</code></pre>
<div class="sourceCode" id="cb2265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2265-1"><a href="logistic-regression.html#cb2265-1"></a><span class="kw">class</span>(resp)</span></code></pre></div>
<pre><code>## [1] &quot;matrix&quot; &quot;array&quot;</code></pre>
<p>Or use the dollar sign instead of the <code>with</code>s. Any of those is
good.</p>
<p>I have no objection to your displaying the response matrix.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Fit a logistic regression to estimate the probability of
death from the <code>apache</code> score, and display the results.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb2267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2267-1"><a href="logistic-regression.html#cb2267-1"></a>apache<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(response <span class="op">~</span><span class="st"> </span>apache, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> icu)</span>
<span id="cb2267-2"><a href="logistic-regression.html#cb2267-2"></a><span class="kw">summary</span>(apache<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = response ~ apache, family = &quot;binomial&quot;, data = icu)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2508  -0.5662   0.1710   0.6649   2.3695  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -2.2903     0.2765  -8.282  &lt; 2e-16 ***
## apache        0.1156     0.0160   7.227 4.94e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 106.009  on 37  degrees of freedom
## Residual deviance:  43.999  on 36  degrees of freedom
## AIC: 125.87
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>My naming convention has gotten messed up again. This should really be
called <code>deaths.1</code> or something like that, but that would be a
really depressing name.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Is there a significant effect of <code>apache</code> score on the
probability of survival? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>A gimme two points. The P-value for <code>apache</code> is <span class="math inline">\(4.94 \times 10^{-13}\)</span>, very small, so <code>apache</code> score definitely
has an effect on the probability of survival.</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Is the effect of a larger <code>apache</code> score to increase or to
decrease the probability of death? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The slope coefficient for <code>apache</code> is 0.1156, positive, and
since we are modelling the probability of death (the first column
of the response matrix), this says that as <code>apache</code> goes
up, the probability of death goes up as well.
If you made your response matrix with the columns the wrong way
around, the slope coefficient for <code>apache</code> should be
<span class="math inline">\(-0.1156\)</span>, but the explanation should come to the same place,
because this says that the probability of survival goes down as
<code>apache</code> goes up.</p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Obtain the predicted probability of death for each of the
<code>apache</code> scores that were in the data set. Display these predicted
probabilities next to the <code>apache</code> values that they came
from. (You can display all of them.)</li>
</ol>
<p>Solution</p>
<p>This is the easier version of <code>predict</code> since we don’t have
to make a new data frame of values to predict from:</p>
<div class="sourceCode" id="cb2269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2269-1"><a href="logistic-regression.html#cb2269-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(apache<span class="fl">.1</span>, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb2269-2"><a href="logistic-regression.html#cb2269-2"></a><span class="kw">cbind</span>(icu, p)</span></code></pre></div>
<pre><code>##    apache patients deaths          p
## 1       0        1      0 0.09192721
## 2       2        1      0 0.11313881
## 3       3        4      1 0.12526979
## 4       4       11      0 0.13849835
## 5       5        9      3 0.15287970
## 6       6       14      3 0.16846238
## 7       7       12      4 0.18528595
## 8       8       22      5 0.20337870
## 9       9       33      3 0.22275512
## 10     10       19      6 0.24341350
## 11     11       31      5 0.26533372
## 12     12       17      5 0.28847528
## 13     13       32     13 0.31277589
## 14     14       25      7 0.33815068
## 15     15       18      7 0.36449223
## 16     16       24      8 0.39167143
## 17     17       27      8 0.41953937
## 18     18       19     13 0.44793012
## 19     19       15      7 0.47666442
## 20     20       13      6 0.50555404
## 21     21       17      9 0.53440661
## 22     22       14     12 0.56303077
## 23     23       13      7 0.59124118
## 24     24       11      8 0.61886322
## 25     25       12      8 0.64573711
## 26     26        6      2 0.67172126
## 27     27        7      5 0.69669475
## 28     28        3      1 0.72055875
## 29     29        7      4 0.74323712
## 30     30        5      4 0.76467607
## 31     31        3      3 0.78484314
## 32     32        3      3 0.80372553
## 33     33        1      1 0.82132803
## 34     34        1      1 0.83767072
## 35     35        1      1 0.85278652
## 36     36        1      1 0.86671872
## 37     37        1      1 0.87951866
## 38     41        1      0 0.92058988</code></pre>
<p>The <code>type="response"</code> is needed to make sure the predictions
come out as probabilities. If you omit it, you get log-odds.</p>
<p>The predicted probability (of dying) does indeed go up as
<code>apache</code> goes up.</p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Make a plot of predicted death probability against
<code>apache</code> score (joined by lines) with, also on the plot, the
observed proportion of deaths within each <code>apache</code> score,
plotted against <code>apache</code> score. Does there seem to be good
agreement between observation and prediction?</li>
</ol>
<p>Solution</p>
<p>This means calculating the observed proportions first, adding the
predicted probabilities, and then making the plot, like this:</p>
<div class="sourceCode" id="cb2271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2271-1"><a href="logistic-regression.html#cb2271-1"></a>icu <span class="op">%&gt;%</span></span>
<span id="cb2271-2"><a href="logistic-regression.html#cb2271-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">obs_prop =</span> deaths <span class="op">/</span><span class="st"> </span>patients) <span class="op">%&gt;%</span></span>
<span id="cb2271-3"><a href="logistic-regression.html#cb2271-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred =</span> p) <span class="op">%&gt;%</span></span>
<span id="cb2271-4"><a href="logistic-regression.html#cb2271-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> apache, <span class="dt">y =</span> pred)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span></span>
<span id="cb2271-5"><a href="logistic-regression.html#cb2271-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> obs_prop))</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-174-1.png" width="672"  /></p>
<p>You don’t need to make a column in the pipeline with the predictions
in it; you can just use what I called <code>p</code> directly in the
<code>aes</code>.</p>
<p>Note that you <em>do</em> need to have a new <code>aes</code> inside the
<code>geom_point</code>, however, because the <span class="math inline">\(y\)</span> of the plot has
changed: it needs to be the observed proportion now.</p>
<p>What you actually have to do in this situation depends on what you
have. In this case, we have the total number of patients at each
<code>apache</code> score, but you might have the number of patients
surviving in one column and dying in another, in which case you’d need
to calculate the total first.</p>
<p>I’d say the agreement is pretty good, except for the one patient with
<code>apache</code> of 41 but who somehow survived.</p>
<p>That’s what I asked for, and is full marks if you got it. However, the
points are not all based on the same number of observations. One way
to show that on your plot is to vary the size of the plotted
point
<label for="tufte-mn-142" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-142" class="margin-toggle"><span class="marginnote">By size is meant the <em>area</em> of the circle, which is what our brains perceive as the size of two-dimensional, like the area of a slice in a pie chart. On the plot, the radius of the circle for 20 is less than twice that of the circle for 10, because the area depends on the radius <em>squared</em>.</span>
according to the number of patients it was based on. This is not hard
to do, since we have exactly that in <code>patients</code>:</p>
<div class="sourceCode" id="cb2272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2272-1"><a href="logistic-regression.html#cb2272-1"></a>icu <span class="op">%&gt;%</span></span>
<span id="cb2272-2"><a href="logistic-regression.html#cb2272-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">obs_prop =</span> deaths <span class="op">/</span><span class="st"> </span>patients) <span class="op">%&gt;%</span></span>
<span id="cb2272-3"><a href="logistic-regression.html#cb2272-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred =</span> p) <span class="op">%&gt;%</span></span>
<span id="cb2272-4"><a href="logistic-regression.html#cb2272-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> apache, <span class="dt">y =</span> pred)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>() <span class="op">+</span></span>
<span id="cb2272-5"><a href="logistic-regression.html#cb2272-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> obs_prop, <span class="dt">size =</span> patients))</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-175-1.png" width="672"  /></p>
<p>The points that are far from the prediction are mostly based on a
small number of patients, and the observed proportions for
<code>apache</code> scores with a lot of patients are mostly close to the
prediction. Note that the <code>size</code>, because it is based on one of
the variables, goes <em>inside</em> the <code>aes</code>. If you wanted the
points all to be of size 5, say, you’d do it this way:</p>
<div class="sourceCode" id="cb2273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2273-1"><a href="logistic-regression.html#cb2273-1"></a><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> obs_prop), <span class="dt">size =</span> <span class="dv">5</span>)</span></code></pre></div>
</div>
<div id="go-away-and-dont-come-back" class="section level2" number="18.10">
<h2><span class="header-section-number">18.10</span> Go away and don’t come back!</h2>
<p>When a person has a heart attack and survives it, the major
concern of health professionals is to prevent the person having a
second heart attack. Two factors that are believed to be important are
anger and anxiety; if a heart attack survivor tends to be angry or
anxious, they are believed to put themselves at increased risk of a
second heart attack.</p>
<p>Twenty heart attack survivors took part in a study. Each one was given
a test designed to assess their anxiety (a higher score on the test
indicates higher anxiety), and some of the survivors took an anger
management course.
The data are in
<a href="http://www.utsc.utoronto.ca/~butler/d29/ha2.txt">link</a>; <code>y</code> and
<code>n</code> denote “yes” and “no” respectively. The columns denote
(i) whether or not the person had a second heart attack, (ii) whether
or not the person took the anger management class, (iii) the anxiety
score.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display the data.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb2274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2274-1"><a href="logistic-regression.html#cb2274-1"></a>my_url &lt;-<span class="st"> &quot;http://www.utsc.utoronto.ca/~butler/d29/ha2.txt&quot;</span></span>
<span id="cb2274-2"><a href="logistic-regression.html#cb2274-2"></a>ha &lt;-<span class="st"> </span><span class="kw">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</span></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   second = col_character(),
##   anger = col_character(),
##   anxiety = col_double()
## )</code></pre>
<div class="sourceCode" id="cb2276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2276-1"><a href="logistic-regression.html#cb2276-1"></a>ha</span></code></pre></div>
<pre><code>## # A tibble: 20 x 3
##    second anger anxiety
##    &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;
##  1 y      y          70
##  2 y      y          80
##  3 y      y          50
##  4 y      n          60
##  5 y      n          40
##  6 y      n          65
##  7 y      n          75
##  8 y      n          80
##  9 y      n          70
## 10 y      n          60
## 11 n      y          65
## 12 n      y          50
## 13 n      y          45
## 14 n      y          35
## 15 n      y          40
## 16 n      y          50
## 17 n      n          55
## 18 n      n          45
## 19 n      n          50
## 20 n      n          60</code></pre>
<p>The anxiety scores are numbers; the other two variables are “yes”
and “no”, which makes perfect sense.</p>
<ol start="2" style="list-style-type: lower-alpha">
<li><a name="part:fit">*</a>
Fit a logistic regression predicting whether or not a heart attack
survivor has a second heart attack, as it depends on anxiety score
and whether or not the person took the anger management
class. Display the results.</li>
</ol>
<p>Solution</p>
<p>This:</p>
<div class="sourceCode" id="cb2278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2278-1"><a href="logistic-regression.html#cb2278-1"></a>ha<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(<span class="kw">factor</span>(second) <span class="op">~</span><span class="st"> </span>anger <span class="op">+</span><span class="st"> </span>anxiety, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>, <span class="dt">data =</span> ha)</span>
<span id="cb2278-2"><a href="logistic-regression.html#cb2278-2"></a><span class="kw">summary</span>(ha<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = factor(second) ~ anger + anxiety, family = &quot;binomial&quot;, 
##     data = ha)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.52106  -0.68746   0.00424   0.70625   1.88960  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept) -6.36347    3.21362  -1.980   0.0477 *
## angery      -1.02411    1.17101  -0.875   0.3818  
## anxiety      0.11904    0.05497   2.165   0.0304 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 27.726  on 19  degrees of freedom
## Residual deviance: 18.820  on 17  degrees of freedom
## AIC: 24.82
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>There’s no need to worry about two-column responses here, because each
row of the data frame refers to only one person, and the response
variable <code>second</code> is already a categorical variable with two
categories (that needs to be turned into a <code>factor</code> for
<code>glm</code>).</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>In the previous part, how can you tell that you were
predicting the probability of having a second heart attack (as
opposed to the probability of not having one)?</li>
</ol>
<p>Solution</p>
<p>The levels of a factor are taken in alphabetical order, with
<code>n</code> as the baseline, so we are predicting the probability
of the second one <code>y</code>.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li><a name="part:preds">*</a>
For the two possible values <code>y</code> and <code>n</code> of
<code>anger</code> and the anxiety scores 40, 50 and 60, make a data
frame containing all six combinations, and use it to obtain
predicted probabilities of a second heart attack. Display your
predicted probabilities side by side with what they are predictions
for.</li>
</ol>
<p>Solution</p>
<p>This time, I give you the values I want the predictions for (as
opposed to calculating something like quartiles from the data), so
we might as well just type them in.
Step 1 is to save them (my preference is under plural names):</p>
<div class="sourceCode" id="cb2280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2280-1"><a href="logistic-regression.html#cb2280-1"></a>anxieties &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">60</span>)</span>
<span id="cb2280-2"><a href="logistic-regression.html#cb2280-2"></a>angers &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p>Step 2 is to make a data frame of combinations using
<code>crossing</code>. I’ll call mine <code>new</code>:</p>
<div class="sourceCode" id="cb2281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2281-1"><a href="logistic-regression.html#cb2281-1"></a>new &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">anxiety =</span> anxieties, <span class="dt">anger =</span> angers)</span>
<span id="cb2281-2"><a href="logistic-regression.html#cb2281-2"></a>new</span></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   anxiety anger
##     &lt;dbl&gt; &lt;chr&gt;
## 1      40 n    
## 2      40 y    
## 3      50 n    
## 4      50 y    
## 5      60 n    
## 6      60 y</code></pre>
<p>Step 3 is to do the predictions. Into <code>predict</code> go (in order)
the fitted model, the new data frame that we just made, and something
to make the predictions be probabilities:</p>
<div class="sourceCode" id="cb2283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2283-1"><a href="logistic-regression.html#cb2283-1"></a>p &lt;-<span class="st"> </span><span class="kw">predict</span>(ha<span class="fl">.1</span>, new, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<p>Step 4 is to put these next to the data frame we
created. <code>cbind</code> is easiest, since we don’t know what kind of
thing <code>p</code> might be, and <code>bind_cols</code> is pickier:</p>
<div class="sourceCode" id="cb2284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2284-1"><a href="logistic-regression.html#cb2284-1"></a><span class="kw">cbind</span>(new, p)</span></code></pre></div>
<pre><code>##   anxiety anger          p
## 1      40     n 0.16774789
## 2      40     y 0.06749763
## 3      50     n 0.39861864
## 4      50     y 0.19226955
## 5      60     n 0.68551307
## 6      60     y 0.43908386</code></pre>
<ol start="5" style="list-style-type: lower-alpha">
<li>Use your predictions from the previous part to describe the
effect of changes in <code>anxiety</code> and <code>anger</code> on the
probability of a second heart attack.</li>
</ol>
<p>Solution</p>
<p>The idea is to change one variable . (This is the common refrain of “all else equal”.)</p>
<p>Pick a level of <code>anger</code>, say <code>n</code> (it doesn’t matter
which) and look at the effect of <code>anxiety</code>. The probability
of a second heart attack increases sharply from 0.17 to 0.40 to
0.69. So an increased anxiety score is associated with an
increased probability of second heart attack (all else equal).</p>
<p>To assess the effect of taking the anger management course, pick
an <code>anxiety</code> value, say 40, and compare the probabilities
for <code>anger</code> <code>n</code> and <code>y</code>. For someone who has
not taken the anger management course, the probability is 0.17,
but for someone who has, it drops all the way to 0.07. (The
pattern is the same at the other anxiety scores.)</p>
<p>Extra: the reason it doesn’t matter what value of the other
variable you look at (as long as you keep it fixed) is that the
model is “additive” with no interaction, so that the effect of
one variable does not depend on the value of the other one. If we
wanted to see whether the effect of anxiety was different
according to whether or not the person had taken the anger
management course, we would add an interaction between
<code>anxiety</code> and <code>anger</code>. But we won’t be doing this
kind of thing until we get to analysis of variance, so you don’t
need to worry about it yet.</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Are the effects you described in the previous part
consistent with the <code>summary</code> output from <code>glm</code> that
you obtained in (<a href="#part:fit">here</a>)? Explain briefly how they are, or
are not. (You need an explanation for each of <code>anxiety</code> and
<code>anger</code>, and you will probably get confused if you look at
the P-values, so don’t.)</li>
</ol>
<p>Solution</p>
<p>In the previous part, we found that increased anxiety went with an
increased probability of second heart attack. Back in
(<a href="#part:fit">here</a>), we found a positive slope of 0.11904 for anxiety,
which also means that a higher anxiety score goes with a higher
probability of second heart attack.
That was not too hard. The other one is a little more work.
<code>anger</code> is categorical with two categories <code>n</code> and
<code>y</code>. The first one, <code>n</code>, is the baseline, so
<code>angery</code> shows how <code>y</code> compares to <code>n</code>. The
slope <span class="math inline">\(-1.04211\)</span> is negative, which means that someone who has
taken the anger management course has a <em>lower</em> probability
of a second heart attack than someone who hasn’t (all else
equal). This is the same story that we got from the predictions.
That’s it for that, but I suppose I should talk about those
P-values.
<code>anxiety</code> is significant, so it definitely has an effect on
the probability of a second heart attack. The pattern is clear
enough even with this small data set. Here’s a visual:</p>
<div class="sourceCode" id="cb2286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2286-1"><a href="logistic-regression.html#cb2286-1"></a><span class="kw">ggplot</span>(ha, <span class="kw">aes</span>(<span class="dt">x =</span> second, <span class="dt">y =</span> anxiety)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-183-1.png" width="672"  /></p>
<p>This is the wrong way around in terms of cause and effect, but it
shows pretty clearly that people who suffer a second heart attack have
a higher level of anxiety than those who don’t.</p>
<p>That’s clear enough, but what about <code>anger</code>? That is <em>not</em>
significant, but there seems to be a visible effect of <code>anger</code>
on the predicted probabilities of (<a href="#part:preds">here</a>): there we saw
that if you had done the anger management course, your probability of
a second heart attack was lower. But that’s only the predicted
probability, and there is also uncertainty about that, probably quite
a lot because we don’t have much data. So if we were to think about
confidence intervals for the predicted probabilities, they would be
wide, and for the two levels of <code>anger</code> at a fixed
<code>anxiety</code> they would almost certainly overlap.</p>
<p>Another way of seeing that is a visual, which would be a side-by-side
bar chart:</p>
<div class="sourceCode" id="cb2287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2287-1"><a href="logistic-regression.html#cb2287-1"></a><span class="kw">ggplot</span>(ha, <span class="kw">aes</span>(<span class="dt">x =</span> anger, <span class="dt">fill =</span> second)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>)</span></code></pre></div>
<p><img src="15-logistic-regression_files/figure-html/unnamed-chunk-184-1.png" width="672"  /></p>
<p>A small majority of people who took the anger management did not have
a second heart attack, while a small minority of those who did not,
did.
<label for="tufte-mn-143" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-143" class="margin-toggle"><span class="marginnote">Read that carefully.</span> But with these small numbers, the
difference, even though it points the way we would have guessed, is
not large enough to be significant:</p>
<div class="sourceCode" id="cb2288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2288-1"><a href="logistic-regression.html#cb2288-1"></a><span class="kw">with</span>(ha, <span class="kw">table</span>(anger, second))</span></code></pre></div>
<pre><code>##      second
## anger n y
##     n 4 7
##     y 6 3</code></pre>
<p>This is not nearly far enough from an equal split to be
significant. (It’s the same kind of idea as for Mood’s median test in
C32.)</p>

</div>
</div>
<p style="text-align: center;">
<a href="the-bootstrap.html"><button class="btn btn-default">Previous</button></a>
<a href="logistic-regression-with-ordinal-or-nominal-response.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
