<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 One-sample inference | Problems and Solutions in Applied Statistics</title>
  <meta name="description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 One-sample inference | Problems and Solutions in Applied Statistics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://ritsokiguess.site/pasias" />
  
  <meta property="og:description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
  <meta name="github-repo" content="nxskok/pasias" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 One-sample inference | Problems and Solutions in Applied Statistics" />
  
  <meta name="twitter:description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
  

<meta name="author" content="Ken Butler" />


<meta name="date" content="2021-05-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="working-with-dataframes.html"/>
<link rel="next" href="two-sample-inference.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Problems and Solutions in Applied Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#packages-used-somewhere-in-this-book"><i class="fa fa-check"></i>Packages used somewhere in this book</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-used-to-r-and-r-studio.html"><a href="getting-used-to-r-and-r-studio.html"><i class="fa fa-check"></i><b>1</b> Getting used to R and R Studio</a></li>
<li class="chapter" data-level="2" data-path="reading-in-data.html"><a href="reading-in-data.html"><i class="fa fa-check"></i><b>2</b> Reading in data</a></li>
<li class="chapter" data-level="3" data-path="drawing-graphs.html"><a href="drawing-graphs.html"><i class="fa fa-check"></i><b>3</b> Drawing graphs</a></li>
<li class="chapter" data-level="4" data-path="data-exploration.html"><a href="data-exploration.html"><i class="fa fa-check"></i><b>4</b> Data exploration</a></li>
<li class="chapter" data-level="5" data-path="working-with-dataframes.html"><a href="working-with-dataframes.html"><i class="fa fa-check"></i><b>5</b> Working with dataframes</a></li>
<li class="chapter" data-level="6" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>6</b> One-sample inference</a><ul>
<li class="chapter" data-level="6.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#hunter-gatherers-in-australia"><i class="fa fa-check"></i><b>6.1</b> Hunter-gatherers in Australia</a></li>
<li class="chapter" data-level="6.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#buses-to-boulder"><i class="fa fa-check"></i><b>6.2</b> Buses to Boulder</a></li>
<li class="chapter" data-level="6.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#length-of-gestation-in-north-carolina"><i class="fa fa-check"></i><b>6.3</b> Length of gestation in North Carolina</a></li>
<li class="chapter" data-level="6.4" data-path="one-sample-inference.html"><a href="one-sample-inference.html#inferring-ice-break-up-in-nenana"><i class="fa fa-check"></i><b>6.4</b> Inferring ice break-up in Nenana</a></li>
<li class="chapter" data-level="6.5" data-path="one-sample-inference.html"><a href="one-sample-inference.html#diameters-of-trees"><i class="fa fa-check"></i><b>6.5</b> Diameters of trees</a></li>
<li class="chapter" data-level="6.6" data-path="one-sample-inference.html"><a href="one-sample-inference.html#one-sample-cholesterol"><i class="fa fa-check"></i><b>6.6</b> One-sample cholesterol</a></li>
<li class="chapter" data-level="6.7" data-path="one-sample-inference.html"><a href="one-sample-inference.html#hunter-gatherers-in-australia-1"><i class="fa fa-check"></i><b>6.7</b> Hunter-gatherers in Australia</a></li>
<li class="chapter" data-level="6.8" data-path="one-sample-inference.html"><a href="one-sample-inference.html#buses-to-boulder-1"><i class="fa fa-check"></i><b>6.8</b> Buses to Boulder</a></li>
<li class="chapter" data-level="6.9" data-path="one-sample-inference.html"><a href="one-sample-inference.html#length-of-gestation-in-north-carolina-1"><i class="fa fa-check"></i><b>6.9</b> Length of gestation in North Carolina</a></li>
<li class="chapter" data-level="6.10" data-path="one-sample-inference.html"><a href="one-sample-inference.html#inferring-ice-break-up-in-nenana-1"><i class="fa fa-check"></i><b>6.10</b> Inferring ice break-up in Nenana</a></li>
<li class="chapter" data-level="6.11" data-path="one-sample-inference.html"><a href="one-sample-inference.html#diameters-of-trees-1"><i class="fa fa-check"></i><b>6.11</b> Diameters of trees</a></li>
<li class="chapter" data-level="6.12" data-path="one-sample-inference.html"><a href="one-sample-inference.html#one-sample-cholesterol-1"><i class="fa fa-check"></i><b>6.12</b> One-sample cholesterol</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>7</b> Two-sample inference</a></li>
<li class="chapter" data-level="8" data-path="power-and-sample-size.html"><a href="power-and-sample-size.html"><i class="fa fa-check"></i><b>8</b> Power and sample size</a></li>
<li class="chapter" data-level="9" data-path="the-sign-test.html"><a href="the-sign-test.html"><i class="fa fa-check"></i><b>9</b> The sign test</a></li>
<li class="chapter" data-level="10" data-path="mood-median-test.html"><a href="mood-median-test.html"><i class="fa fa-check"></i><b>10</b> Mood median test</a></li>
<li class="chapter" data-level="11" data-path="matched-pairs-t-and-sign-test.html"><a href="matched-pairs-t-and-sign-test.html"><i class="fa fa-check"></i><b>11</b> Matched pairs t and sign test</a></li>
<li class="chapter" data-level="12" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html"><i class="fa fa-check"></i><b>12</b> Normal quantile plots</a><ul>
<li class="chapter" data-level="12.1" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#lengths-of-heliconia-flowers"><i class="fa fa-check"></i><b>12.1</b> Lengths of heliconia flowers</a></li>
<li class="chapter" data-level="12.2" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#ferritin-and-normality"><i class="fa fa-check"></i><b>12.2</b> Ferritin and normality</a></li>
<li class="chapter" data-level="12.3" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#lengths-of-heliconia-flowers-1"><i class="fa fa-check"></i><b>12.3</b> Lengths of heliconia flowers</a></li>
<li class="chapter" data-level="12.4" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#ferritin-and-normality-1"><i class="fa fa-check"></i><b>12.4</b> Ferritin and normality</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>13</b> Analysis of variance</a></li>
<li class="chapter" data-level="14" data-path="writing-reports.html"><a href="writing-reports.html"><i class="fa fa-check"></i><b>14</b> Writing reports</a></li>
<li class="chapter" data-level="15" data-path="learning-to-code.html"><a href="learning-to-code.html"><i class="fa fa-check"></i><b>15</b> Learning to code</a><ul>
<li class="chapter" data-level="15.1" data-path="learning-to-code.html"><a href="learning-to-code.html#introduction-1"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="learning-to-code.html"><a href="learning-to-code.html#data-and-pre-processing"><i class="fa fa-check"></i><b>15.2</b> Data and pre-processing</a></li>
<li class="chapter" data-level="15.3" data-path="learning-to-code.html"><a href="learning-to-code.html#analysis"><i class="fa fa-check"></i><b>15.3</b> Analysis</a></li>
<li class="chapter" data-level="15.4" data-path="learning-to-code.html"><a href="learning-to-code.html#conclusions-see-note-9"><i class="fa fa-check"></i><b>15.4</b> Conclusions (see note 9)</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="a-comparison-of-four-shampoos-in-treating-dandruff.html"><a href="a-comparison-of-four-shampoos-in-treating-dandruff.html"><i class="fa fa-check"></i><b>16</b> A comparison of four shampoos in treating dandruff</a><ul>
<li class="chapter" data-level="16.1" data-path="a-comparison-of-four-shampoos-in-treating-dandruff.html"><a href="a-comparison-of-four-shampoos-in-treating-dandruff.html#introduction-2"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="a-comparison-of-four-shampoos-in-treating-dandruff.html"><a href="a-comparison-of-four-shampoos-in-treating-dandruff.html#exploratory-analysis"><i class="fa fa-check"></i><b>16.2</b> Exploratory analysis</a></li>
<li class="chapter" data-level="16.3" data-path="a-comparison-of-four-shampoos-in-treating-dandruff.html"><a href="a-comparison-of-four-shampoos-in-treating-dandruff.html#analysis-of-variance-1"><i class="fa fa-check"></i><b>16.3</b> Analysis of Variance</a></li>
<li class="chapter" data-level="16.4" data-path="a-comparison-of-four-shampoos-in-treating-dandruff.html"><a href="a-comparison-of-four-shampoos-in-treating-dandruff.html#assessment-of-assumptions"><i class="fa fa-check"></i><b>16.4</b> Assessment of Assumptions</a></li>
<li class="chapter" data-level="16.5" data-path="a-comparison-of-four-shampoos-in-treating-dandruff.html"><a href="a-comparison-of-four-shampoos-in-treating-dandruff.html#conclusions"><i class="fa fa-check"></i><b>16.5</b> Conclusions</a></li>
<li class="chapter" data-level="16.6" data-path="a-comparison-of-four-shampoos-in-treating-dandruff.html"><a href="a-comparison-of-four-shampoos-in-treating-dandruff.html#end"><i class="fa fa-check"></i><b>16.6</b> End</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="tidying-data.html"><a href="tidying-data.html"><i class="fa fa-check"></i><b>17</b> Tidying data</a></li>
<li class="chapter" data-level="18" data-path="simple-regression.html"><a href="simple-regression.html"><i class="fa fa-check"></i><b>18</b> Simple regression</a></li>
<li class="chapter" data-level="19" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>19</b> Multiple regression</a></li>
<li class="chapter" data-level="20" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html"><i class="fa fa-check"></i><b>20</b> Regression with categorical variables</a><ul>
<li class="chapter" data-level="20.1" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#crickets-revisited"><i class="fa fa-check"></i><b>20.1</b> Crickets revisited</a></li>
<li class="chapter" data-level="20.2" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#pulse-rates-and-marching"><i class="fa fa-check"></i><b>20.2</b> Pulse rates and marching</a></li>
<li class="chapter" data-level="20.3" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#crickets-revisited-1"><i class="fa fa-check"></i><b>20.3</b> Crickets revisited</a></li>
<li class="chapter" data-level="20.4" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#pulse-rates-and-marching-1"><i class="fa fa-check"></i><b>20.4</b> Pulse rates and marching</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dates-and-times.html"><a href="dates-and-times.html"><i class="fa fa-check"></i><b>21</b> Dates and times</a></li>
<li class="chapter" data-level="22" data-path="functions.html"><a href="functions.html"><i class="fa fa-check"></i><b>22</b> Functions</a></li>
<li class="chapter" data-level="23" data-path="vector-and-matrix-algebra.html"><a href="vector-and-matrix-algebra.html"><i class="fa fa-check"></i><b>23</b> Vector and matrix algebra</a><ul>
<li class="chapter" data-level="23.1" data-path="vector-and-matrix-algebra.html"><a href="vector-and-matrix-algebra.html#heights-and-foot-lengths-again"><i class="fa fa-check"></i><b>23.1</b> Heights and foot lengths again</a></li>
<li class="chapter" data-level="23.2" data-path="vector-and-matrix-algebra.html"><a href="vector-and-matrix-algebra.html#heights-and-foot-lengths-again-1"><i class="fa fa-check"></i><b>23.2</b> Heights and foot lengths again</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="the-bootstrap.html"><a href="the-bootstrap.html"><i class="fa fa-check"></i><b>24</b> The Bootstrap</a></li>
<li class="chapter" data-level="25" data-path="bayesian-statistics-with-stan.html"><a href="bayesian-statistics-with-stan.html"><i class="fa fa-check"></i><b>25</b> Bayesian Statistics with Stan</a></li>
<li class="chapter" data-level="26" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>26</b> Logistic regression</a></li>
<li class="chapter" data-level="27" data-path="logistic-regression-with-ordinal-response.html"><a href="logistic-regression-with-ordinal-response.html"><i class="fa fa-check"></i><b>27</b> Logistic regression with ordinal response</a></li>
<li class="chapter" data-level="28" data-path="logistic-regression-with-nominal-response.html"><a href="logistic-regression-with-nominal-response.html"><i class="fa fa-check"></i><b>28</b> Logistic regression with nominal response</a></li>
<li class="chapter" data-level="29" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>29</b> Survival analysis</a></li>
<li class="chapter" data-level="30" data-path="analysis-of-variance-revisited.html"><a href="analysis-of-variance-revisited.html"><i class="fa fa-check"></i><b>30</b> Analysis of variance revisited</a></li>
<li class="chapter" data-level="31" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html"><i class="fa fa-check"></i><b>31</b> Analysis of covariance</a></li>
<li class="chapter" data-level="32" data-path="multivariate-analysis-of-variance.html"><a href="multivariate-analysis-of-variance.html"><i class="fa fa-check"></i><b>32</b> Multivariate analysis of variance</a></li>
<li class="chapter" data-level="33" data-path="repeated-measures.html"><a href="repeated-measures.html"><i class="fa fa-check"></i><b>33</b> Repeated measures</a></li>
<li class="chapter" data-level="34" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html"><i class="fa fa-check"></i><b>34</b> Discriminant analysis</a></li>
<li class="chapter" data-level="35" data-path="hierarchical-cluster-analysis.html"><a href="hierarchical-cluster-analysis.html"><i class="fa fa-check"></i><b>35</b> Hierarchical cluster analysis</a></li>
<li class="chapter" data-level="36" data-path="k-means-cluster-analysis.html"><a href="k-means-cluster-analysis.html"><i class="fa fa-check"></i><b>36</b> K-means cluster analysis</a></li>
<li class="chapter" data-level="37" data-path="drawing-maps-with-leaflet.html"><a href="drawing-maps-with-leaflet.html"><i class="fa fa-check"></i><b>37</b> Drawing maps with Leaflet</a></li>
<li class="chapter" data-level="38" data-path="multidimensional-scaling.html"><a href="multidimensional-scaling.html"><i class="fa fa-check"></i><b>38</b> Multidimensional Scaling</a></li>
<li class="chapter" data-level="39" data-path="principal-components.html"><a href="principal-components.html"><i class="fa fa-check"></i><b>39</b> Principal Components</a><ul>
<li class="chapter" data-level="39.1" data-path="principal-components.html"><a href="principal-components.html#the-weather-somewhere"><i class="fa fa-check"></i><b>39.1</b> The weather, somewhere</a></li>
<li class="chapter" data-level="39.2" data-path="principal-components.html"><a href="principal-components.html#the-weather-somewhere-1"><i class="fa fa-check"></i><b>39.2</b> The weather, somewhere</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>40</b> Factor Analysis</a></li>
<li class="chapter" data-level="41" data-path="frequency-table-analysis.html"><a href="frequency-table-analysis.html"><i class="fa fa-check"></i><b>41</b> Frequency table analysis</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Problems and Solutions in Applied Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="one-sample-inference" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> One-sample inference</h1>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">library</span>(tidyverse)</a></code></pre></div>
<div id="hunter-gatherers-in-australia" class="section level2">
<h2><span class="header-section-number">6.1</span> Hunter-gatherers in Australia</h2>
<p>A hunter-gatherer society is one where people get their food
by hunting, fishing or foraging rather than by agriculture or by
raising animals. Such societies tend to move from place to place.
Anthropologists have studied hunter-gatherer societies in forest
ecosystems across the world. The average population density of these
societies is 7.38 people per 100 km<span class="math inline">\(^2\)</span>. Hunter-gatherer societies on
different continents might have different population densities,
possibly because of large-scale ecological constraints (such as
resource availability), or because of other factors, possibly social
and/or historic, determining population density.</p>
<p>Some hunter-gatherer societies in Australia were studied, and the
population density per 100 km<span class="math inline">\(^2\)</span> recorded for each. The data are in
<a href="http://ritsokiguess.site/datafiles/hg.txt">http://ritsokiguess.site/datafiles/hg.txt</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R. Do you have the correct variables?
How many hunter-gatherer societies in Australia were studied?
Explain briefly.</p></li>
<li><p>The question of interest is whether these Australian
hunter-gatherer societies are like the rest of the world in terms of mean
population density. State suitable null and alternative
hypotheses. <em>Define any symbols you use</em>: that is, if you use a
symbol, you also have to say what it means.</p></li>
<li><p>Test your hypotheses using a suitable test. What do you
conclude, in the context of the data?</p></li>
<li><p>Do you have any doubts about the validity of your test?
Explain briefly, using a suitable graph to support your
explanation.</p></li>
</ol>
</div>
<div id="buses-to-boulder" class="section level2">
<h2><span class="header-section-number">6.2</span> Buses to Boulder</h2>
<p>A bus line operates a route from Denver to Boulder (these
places are in Colorado). The
schedule says that the journey time should be 60 minutes. 11
randomly chosen journey times were recorded, and these are in the
file <a href="http://ritsokiguess.site/datafiles/buses.txt">link</a>, with
journey times shown in minutes.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R, and display the data frame that you
read in.</p></li>
<li><p>Run a suitable test to see whether there is evidence that
the mean journey time differs from 60 minutes. What do you
conclude? (I want a conclusion that says something about journey
times of buses.)</p></li>
<li><p>Give a 95% confidence interval for the mean journey
time. (No R code is needed here.)</p></li>
<li><p>Do you draw consistent conclusions from your test and
confidence interval? Explain briefly.</p></li>
<li><p>Draw a boxplot of the journey times. Do you see a reason
to doubt the test that you did above?</p></li>
</ol>
</div>
<div id="length-of-gestation-in-north-carolina" class="section level2">
<h2><span class="header-section-number">6.3</span> Length of gestation in North Carolina</h2>
<p>The data in file
<a href="http://ritsokiguess.site/datafiles/ncbirths.csv">link</a> are about
500 randomly chosen births of babies in North Carolina. There is a lot
of information: not just the weight at birth of the baby, but whether
the baby was born prematurely, the ages of the parents, whether the
parents are married, how long (in weeks) the pregnancy lasted (this is
called the “gestation”) and so on. We have seen these data before.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in the data from the file into R, bearing in mind what
type of file it is.</p></li>
<li><p>Find a 95% confidence interval for the mean birth weight of
all babies born in North Carolina (of which these babies are a
sample). At the end, you should state what the confidence interval is.
Giving some output is necessary, but <em>not</em> enough by itself.</p></li>
</ol>
<p>If your variable name has a space or other special character (like a
question mark) in it, remember that you have to surround its name with
backticks, as discussed the first time we looked at these data.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li><p>Birth weights of babies born in the United States have a mean
of 7.3 pounds. Is there any evidence that babies born in North
Carolina are less heavy on average? State appropriate hypotheses, do your
test, obtain a P-value and state your conclusion, in terms of the
original data.</p></li>
<li><p>The theory behind the <span class="math inline">\(t\)</span>-test says that the distribution of
birth weights should be (approximately) normally distributed. Obtain a
histogram of the birth weights. Does it look approximately normal?
Comment briefly. (You’ll have to pick a number of bins for your
histogram first. I don’t mind very much what you pick, as long as it’s
not obviously too many or too few bins.)</p></li>
</ol>
</div>
<div id="inferring-ice-break-up-in-nenana" class="section level2">
<h2><span class="header-section-number">6.4</span> Inferring ice break-up in Nenana</h2>
<p>Nenana, Alaska, is about 50 miles west of Fairbanks.
Every spring, there is a contest in Nenana. A wooden tripod is
placed on the frozen river, and people try to guess the exact minute
when the ice melts enough for the tripod to fall through the ice. The
contest started in 1917 as an amusement for railway workers, and has
taken place every year since. Now, hundreds of thousands of people
enter their guesses on the Internet and the prize for the winner can
be as much as $300,000.</p>
<p>Because so much money is at stake, and because the exact same tripod
is placed at the exact same spot on the ice every year, the data are
consistent and accurate. The data are in
<a href="http://ritsokiguess.site/datafiles/nenana.txt">link</a>.</p>
<p>Yes, we saw these data before.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R, as before, or use the data frame that
you read in before. Note that the values are separated by
<em>tabs</em> rather than spaces, so you’ll need an appropriate
<code>read_</code> to read it in.</p></li>
<li><p>Obtain a 90% confidence interval for the mean
<code>JulianDate</code>. What interval do you get? Looking back at your
histogram, do you have any doubts about the validity of what you
have just done?</p></li>
<li><p>An old-timer in Nenana strokes his grey beard and says
“When I were young, I remember the tripod used to fall into the water around May 10”.
In a non-leap year, May 10 is Julian day 130. Test the null hypothesis that the
mean <code>JulianDay</code> is 130, against the alternative that it is less. What do you conclude?
What practical implication does that have
(assuming that the old-timer has a good memory)?</p></li>
<li><p>Plot <code>JulianDate</code> against <code>Year</code> on a
scatterplot. What recent trends, if any, do you see? Comment
briefly. (You did this before, but I have some extra comments on
the graph this time, so feel free to just read this part.)</p></li>
</ol>
</div>
<div id="diameters-of-trees" class="section level2">
<h2><span class="header-section-number">6.5</span> Diameters of trees</h2>
<p>The Wade Tract in Thomas County, Georgia, is an old-growth forest of longleaf pine trees. It has survived in a relatively undisturbed state since before settlements of the area by Europeans. For each tree in the tract, researchers measured the diameter at breast height. This is a standard measure in forestry: it is defined as the diameter of the tree at 4.5 feet above the ground.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> They are interested in the mean diameter at breast height of the trees in this tract. These values are in <a href="http://ritsokiguess.site/datafiles/treediameter.csv">http://ritsokiguess.site/datafiles/treediameter.csv</a>. The diameters are measured in centimetres.
The easiest way to get the URL is to <em>right</em>-click on the blue text and select Copy URL. (If you copy and paste the actual text you might end up with extra spaces, especially if the printed URL goes over two lines.)</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and display (some of) the data.</p></li>
<li><p>Make a suitable plot of your dataframe.</p></li>
<li><p>Obtain a 95% confidence interval for the mean diameter.</p></li>
<li><p>Based on what you have seen so far, would you expect to reject a null hypothesis that the population mean diameter (of all longleaf pines like these) is 35 cm? Explain briefly. Then, carry out the test (against a two-sided alternative) and explain briefly whether you were right.</p></li>
<li><p>Would you expect 35 cm to be in a <em>99%</em> confidence interval for the mean diameter? Explain briefly, and then see if you were right.</p></li>
</ol>
</div>
<div id="one-sample-cholesterol" class="section level2">
<h2><span class="header-section-number">6.6</span> One-sample cholesterol</h2>
<p>The data set <a href="http://ritsokiguess.site/datafiles/cholest.csv">here</a> contains cholesterol
measurements for heart attack patients (at several different times) as
well as for a group of control patients. We will focus on the control
patients in this question.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and display (some of) the data.</p></li>
<li><p>Make a suitable plot of the cholesterol levels of the
control patients, and comment briefly on the shape of the
distribution.</p></li>
<li><p>It is recommended that people in good health, such as the
Control patients here, keep their cholesterol level below 200. Is
there evidence that the mean cholesterol level of the population of
people of which the Control patients are a sample is less than 200? Show that you understand the process,
and state your conclusion in the context of the data.</p></li>
<li><p>What values could the population mean cholesterol level take? You
might need to get some more output to determine this.</p></li>
<li><p>Explain briefly why you would be reasonably happy to trust
the <span class="math inline">\(t\)</span> procedures in this question. (There are two points you need
to make.)</p></li>
</ol>

<p>My solutions follow:</p>
</div>
<div id="hunter-gatherers-in-australia-1" class="section level2">
<h2><span class="header-section-number">6.7</span> Hunter-gatherers in Australia</h2>
<p>A hunter-gatherer society is one where people get their food
by hunting, fishing or foraging rather than by agriculture or by
raising animals. Such societies tend to move from place to place.
Anthropologists have studied hunter-gatherer societies in forest
ecosystems across the world. The average population density of these
societies is 7.38 people per 100 km<span class="math inline">\(^2\)</span>. Hunter-gatherer societies on
different continents might have different population densities,
possibly because of large-scale ecological constraints (such as
resource availability), or because of other factors, possibly social
and/or historic, determining population density.</p>
<p>Some hunter-gatherer societies in Australia were studied, and the
population density per 100 km<span class="math inline">\(^2\)</span> recorded for each. The data are in
<a href="http://ritsokiguess.site/datafiles/hg.txt">http://ritsokiguess.site/datafiles/hg.txt</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R. Do you have the correct variables?
How many hunter-gatherer societies in Australia were studied?
Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The data values are separated by (single) spaces, so <code>read_delim</code>
is the thing:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1">url=<span class="st">&quot;http://ritsokiguess.site/datafiles/hg.txt&quot;</span></a>
<a class="sourceLine" id="cb2-2" title="2">societies=<span class="kw">read_delim</span>(url,<span class="st">&quot; &quot;</span>)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   name = col_character(),
##   density = col_double()
## )</code></pre>
<p>I like to put the URL in a variable first, because if I don’t, the
<code>read_delim</code> line can be rather long. But if you want to do it
in one step, that’s fine, as long as it’s clear that you are doing the
right thing.</p>
<p>Let’s look at the data frame:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1">societies</a></code></pre></div>
<pre><code>## # A tibble: 13 x 2
##    name       density
##    &lt;chr&gt;        &lt;dbl&gt;
##  1 jeidji       17   
##  2 kuku         50   
##  3 mamu         45   
##  4 ngatjan      59.8 
##  5 undanbi      21.7 
##  6 jinibarra    16   
##  7 ualaria       9   
##  8 barkindji    15.4 
##  9 wongaibon     5.12
## 10 jaralde      40   
## 11 tjapwurong   35   
## 12 tasmanians   13.4 
## 13 badjalang    13.4</code></pre>
<p>I have the name of each society and its population density, as
promised (so that is correct). There were 13 societies that were
studied. For me, they were all displayed. For you, you’ll probably see only the first ten, and you’ll have to click Next to see the last three.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>The question of interest is whether these Australian
hunter-gatherer societies are like the rest of the world in terms of mean
population density. State suitable null and alternative
hypotheses. <em>Define any symbols you use</em>: that is, if you use a
symbol, you also have to say what it means.</li>
</ol>
<p>Solution</p>
<p>The mean for the world as a whole (“average”, as stated earlier)
is 7.38. Let <span class="math inline">\(\mu\)</span> denote the population mean for Australia (of
which these societies are a sample). Then our hypotheses are:
<span class="math display">\[ H_0: \mu=7.38\]</span>
and
<span class="math display">\[ H_a: \mu \ne 7.38.\]</span>
There is no reason for a one-sided alternative here, since all we
are interested in is whether Australia is different from the rest
of the world.
<em>Expect to lose a point</em> if you use the symbol <span class="math inline">\(\mu\)</span> without
saying what it means.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Test your hypotheses using a suitable test. What do you
conclude, in the context of the data?</li>
</ol>
<p>Solution</p>
<p>A <span class="math inline">\(t\)</span>-test, since we are testing a mean:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1"><span class="kw">t.test</span>(societies<span class="op">$</span>density,<span class="dt">mu=</span><span class="fl">7.38</span>)</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  societies$density
## t = 3.8627, df = 12, p-value = 0.002257
## alternative hypothesis: true mean is not equal to 7.38
## 95 percent confidence interval:
##  15.59244 36.84449
## sample estimates:
## mean of x 
##  26.21846</code></pre>
<p>The P-value is 0.0023, less than the usual <span class="math inline">\(\alpha\)</span> of 0.05, so we
<em>reject</em> the null hypothesis and conclude that the mean
population density is not equal to 7.38. That is to say, Australia is
different from the rest of the world in this sense.</p>
<p>As you know, “reject the null hypothesis” is only part of the
answer, so gets only part of the marks.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Do you have any doubts about the validity of your test?
Explain briefly, using a suitable graph to support your
explanation.</li>
</ol>
<p>Solution</p>
<p>The assumption behind the <span class="math inline">\(t\)</span>-test is that the data are
approximately normal. We can assess that in several ways, but the
simplest (which is perfectly acceptable at this point) is a
histogram. You’ll need to pick a suitable number of bins. This one
comes from Sturges’ rule:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="kw">ggplot</span>(societies,<span class="kw">aes</span>(<span class="dt">x=</span>density))<span class="op">+</span><span class="kw">geom_histogram</span>(<span class="dt">bins=</span><span class="dv">5</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-37-1.png" width="672" />
Your conclusion might depend on how many bins you chose for your
histogram. Here’s 8 bins (which is really too many with only 13
observations, but it actually shows the shape well):</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" title="1"><span class="kw">ggplot</span>(societies,<span class="kw">aes</span>(<span class="dt">x=</span>density))<span class="op">+</span><span class="kw">geom_histogram</span>(<span class="dt">bins=</span><span class="dv">8</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>or you can get a number of bins from one of the built-in functions,
such as:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1">mybins=<span class="kw">nclass.FD</span>(societies<span class="op">$</span>density)</a>
<a class="sourceLine" id="cb10-2" title="2">mybins</a></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>This one is small. The interquartile range is large and <span class="math inline">\(n\)</span> is small,
so the binwidth will be large and therefore the number of bins will be
small.</p>
<p>Other choices: a one-group boxplot:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" title="1"><span class="kw">ggplot</span>(societies,<span class="kw">aes</span>(<span class="dt">x=</span><span class="dv">1</span>,<span class="dt">y=</span>density))<span class="op">+</span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>This isn’t the best for assessing normality as such, but it will tell
you about lack of symmetry and outliers, which are the most important
threats to the <span class="math inline">\(t\)</span>-test, so it’s fine here. Or, a normal quantile plot:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1"><span class="kw">ggplot</span>(societies,<span class="kw">aes</span>(<span class="dt">sample=</span>density))<span class="op">+</span></a>
<a class="sourceLine" id="cb13-2" title="2"><span class="kw">stat_qq</span>()<span class="op">+</span><span class="kw">stat_qq_line</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<p>This is actually the best way to assess normality, but I’m not
expecting you to use this plot here, because we may not have gotten to
it in class yet. (If you have read ahead and successfully use the
plot, it’s fine.)</p>
<p>After you have drawn your chosen plot (you need <em>one</em> plot), you
need to say something about normality and thus whether you have any
doubts about the validity of your <span class="math inline">\(t\)</span>-test. This will depend on the
graph you drew: if you think your graph is symmetric and outlier-free,
you should have no doubts about your <span class="math inline">\(t\)</span>-test; if you think it has
something wrong with it, you should say what it is and express your
doubts. My guess is that you will think this distribution is skewed to
the right. Most of my plots are saying that.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>On the website where I got these data, they were using the data as
an example for another test, precisely <em>because</em> they thought the
distribution was right-skewed. Later on, we’ll learn about the sign
test for the median, which I think is actually a better test here.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="buses-to-boulder-1" class="section level2">
<h2><span class="header-section-number">6.8</span> Buses to Boulder</h2>
<p>A bus line operates a route from Denver to Boulder (these
places are in Colorado). The
schedule says that the journey time should be 60 minutes. 11
randomly chosen journey times were recorded, and these are in the
file <a href="http://ritsokiguess.site/datafiles/buses.txt">link</a>, with
journey times shown in minutes.</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R, and display the data frame that you
read in.</li>
</ol>
<p>Solution</p>
<p>Since you can read the data directly from the URL, do that (if
you are online) rather than having to copy and paste and save,
and then find the file you saved.
Also, there is only one column, so you can pretend that there
were multiple columns, separated by whatever you like. It’s least
typing to pretend that they were separated by commas like a
<code>.csv</code> file:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/buses.txt&quot;</span></a>
<a class="sourceLine" id="cb14-2" title="2">journey.times &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   minutes = col_double()
## )</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" title="1">journey.times</a></code></pre></div>
<pre><code>## # A tibble: 11 x 1
##    minutes
##      &lt;dbl&gt;
##  1      58
##  2      61
##  3      69
##  4      62
##  5      81
##  6      54
##  7      72
##  8      71
##  9      53
## 10      54
## 11      66</code></pre>
<p>Using <code>read_delim</code> with any delimiter (such as <code>" "</code>)
will also work, and is thus also good.</p>
<p>Variable names in R can have a dot (or an underscore, but not a space)
in them. I have grown accustomed to using dots to separate words. This
works in R but not other languages, but is seen by some as
old-fashioned, with underscores being the modern way.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>
You can also use what is called “camel case”
by starting each “word” after the first with an uppercase
letter like this:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" title="1">journeyTimes &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<p>You have to get the capitalization and punctuation right when you use your variables,
no matter what they’re called. In any of the cases above, there is no
variable called <code>journeytimes</code>. As Jenny Bryan (in
<a href="http://www.stat.ubc.ca/~jenny/STAT545A/block01_basicsWorkspaceWorkingDirProject.html">link</a>)
puts it, boldface in original:
Implicit contract with the computer / scripting language: Computer
will do tedious computation for you. In return, you will be
completely precise in your instructions. Typos matter. Case
matters. <strong>Get better at typing.</strong></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Run a suitable test to see whether there is evidence that
the mean journey time differs from 60 minutes. What do you
conclude? (I want a conclusion that says something about journey
times of buses.)</li>
</ol>
<p>Solution</p>
<p><code>t.test</code> doesn’t take a <code>data=</code> to say which
data frame to use. Wrap it in a <code>with</code>:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1"><span class="kw">with</span>(journey.times, <span class="kw">t.test</span>(minutes, <span class="dt">mu =</span> <span class="dv">60</span>))</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  minutes
## t = 1.382, df = 10, p-value = 0.1971
## alternative hypothesis: true mean is not equal to 60
## 95 percent confidence interval:
##  57.71775 69.73680
## sample estimates:
## mean of x 
##  63.72727</code></pre>
<p>We are testing that the mean journey time is 60 minutes, against the
two-sided alternative (default) that the mean is not equal to 60 minutes. The
P-value, 0.1971, is a lot bigger than the usual <span class="math inline">\(\alpha\)</span> of 0.05, so we cannot
reject the null hypothesis. That is, there is no evidence that the
mean journey time differs from 60 minutes.</p>
<p>As you remember, we have not proved that the mean journey time
<em>is</em> 60 minutes, which is what “accepting the null hypothesis”
would be. We have only failed to reject it, in a shoulder-shrugging
kind of way: “the mean journey time <em>could</em> be 60 minutes”. The
other acceptable word is “retain”; when you say “we retain the null hypothesis”, you imply something
like “we act as if the mean is 60 minutes, at least until we find something better.”</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Give a 95% confidence interval for the mean journey
time. (No R code is needed here.)</li>
</ol>
<p>Solution</p>
<p>Just read it off from the output: 57.72 to 69.74 minutes.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Do you draw consistent conclusions from your test and
confidence interval? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>The test said that we should not reject a mean of 60
minutes. The confidence interval says that 60 minutes is inside
the interval of plausible values for the population mean, which
is another way of saying the same thing. (If we had rejected 60
as a mean, 60 would have been <em>outside</em> the confidence interval.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Draw a boxplot of the journey times. Do you see a reason
to doubt the test that you did above?</li>
</ol>
<p>Solution</p>
<p>The grouping variable is a
“nothing” as in the Ken and Thomas question (part (d)):</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1"><span class="kw">ggplot</span>(journey.times, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">1</span>, <span class="dt">y =</span> minutes)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/brixham-1.png" width="672" /></p>
<p>The assumption behind the <span class="math inline">\(t\)</span>-test is that the population from which
the data come has a normal distribution: ie. symmetric with no
outliers. A small sample (here we have 11 values) even from a normal
distribution might look quite non-normal (as in Assignment 0 from last
week), so I am not hugely concerned by this boxplot. However, it’s
perfectly all right to say that this distribution is skewed, and
therefore we should doubt the <span class="math inline">\(t\)</span>-test, because the upper whisker is
longer than the lower one. In fact, the topmost value is very nearly
an outlier:<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" title="1"><span class="kw">ggplot</span>(journey.times, <span class="kw">aes</span>(<span class="dt">x =</span> minutes)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">5</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/babbacombe-1.png" width="672" /></p>
<p>and there might be skewness as well, so maybe I should have been concerned.</p>
<p>I would be looking for some intelligent comment on the boxplot: what it
looks like vs. what it ought to look like. I don’t so much mind what
that comment is, as long as it’s intelligent enough.</p>
<p>Perhaps I should draw a normal quantile plot:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1"><span class="kw">ggplot</span>(journey.times, <span class="kw">aes</span>(<span class="dt">sample =</span> minutes)) <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq</span>() <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq_line</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<p>The normal quantile plot is saying that the problem is actually at the
<em>bottom</em> of the distribution: the lowest value is not low enough,
but the highest value is actually <em>not</em> too high. So this one
seems to be on the edge between OK and being right-skewed (too bunched
up at the bottom). My take is that with this small sample this is not
too bad. But you are free to disagree.</p>
<p>If you don’t like the normality, you’d use a <em>sign test</em> and test
that the <em>median</em> is not 60 minutes, which you would (at my
guess) utterly fail to reject:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" title="1"><span class="kw">library</span>(smmr)</a>
<a class="sourceLine" id="cb24-2" title="2"><span class="kw">sign_test</span>(journey.times, minutes, <span class="dv">60</span>)</a></code></pre></div>
<pre><code>## $above_below
## below above 
##     4     7 
## 
## $p_values
##   alternative   p_value
## 1       lower 0.8867187
## 2       upper 0.2744141
## 3   two-sided 0.5488281</code></pre>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" title="1"><span class="kw">ci_median</span>(journey.times, minutes)</a></code></pre></div>
<pre><code>## [1] 54.00195 71.99023</code></pre>
<p>and so we do. The median could easily be 60 minutes.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="length-of-gestation-in-north-carolina-1" class="section level2">
<h2><span class="header-section-number">6.9</span> Length of gestation in North Carolina</h2>
<p>The data in file
<a href="http://ritsokiguess.site/datafiles/ncbirths.csv">link</a> are about
500 randomly chosen births of babies in North Carolina. There is a lot
of information: not just the weight at birth of the baby, but whether
the baby was born prematurely, the ages of the parents, whether the
parents are married, how long (in weeks) the pregnancy lasted (this is
called the “gestation”) and so on. We have seen these data before.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in the data from the file into R, bearing in mind what
type of file it is.</li>
</ol>
<p>Solution</p>
<p>This is a <code>.csv</code> file (it came from a spreadsheet), so it
needs reading in accordingly. Work directly from the URL (rather
than downloading the file, unless you are working offline):</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" title="1">myurl &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/ncbirths.csv&quot;</span></a>
<a class="sourceLine" id="cb28-2" title="2">bw &lt;-<span class="st"> </span><span class="kw">read_csv</span>(myurl)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   `Father Age` = col_double(),
##   `Mother Age` = col_double(),
##   `Weeks Gestation` = col_double(),
##   `Pre-natal Visits` = col_double(),
##   `Marital Status` = col_double(),
##   `Mother Weight Gained` = col_double(),
##   `Low Birthweight?` = col_double(),
##   `Weight (pounds)` = col_double(),
##   `Premie?` = col_double(),
##   `Few Visits?` = col_double()
## )</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Find a 95% confidence interval for the mean birth weight of
all babies born in North Carolina (of which these babies are a
sample). At the end, you should state what the confidence interval is.
Giving some output is necessary, but <em>not</em> enough by itself.</li>
</ol>
<p>If your variable name has a space or other special character (like a
question mark) in it, remember that you have to surround its name with
backticks, as discussed the first time we looked at these data.</p>
<p>Solution</p>
<p>This:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" title="1"><span class="kw">t.test</span>(bw<span class="op">$</span><span class="st">`</span><span class="dt">Weight (pounds)</span><span class="st">`</span>)</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  bw$`Weight (pounds)`
## t = 104.94, df = 499, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  6.936407 7.201093
## sample estimates:
## mean of x 
##   7.06875</code></pre>
<p>or (the same, but remember to match your brackets):</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" title="1"><span class="kw">with</span>(bw, <span class="kw">t.test</span>(<span class="st">`</span><span class="dt">Weight (pounds)</span><span class="st">`</span>))</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  Weight (pounds)
## t = 104.94, df = 499, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  6.936407 7.201093
## sample estimates:
## mean of x 
##   7.06875</code></pre>
<p>The confidence interval goes from 6.94 to 7.20 pounds.</p>
<p>There is an annoyance about <code>t.test</code>. Sometimes you can use
<code>data=</code> with it, and sometimes not. When we do a two-sample
<span class="math inline">\(t\)</span>-test later, there is a “model formula” with a squiggle in it,
and there we can use <code>data=</code>, but here not, so you have to use
the dollar sign or the <code>with</code> to say which data frame to get
things from. The distinction seems to be that , you can use <code>data=</code>, and if not, not.</p>
<p>This is one of those things that is a consequence of R’s history. The
original <code>t.test</code> was without the model formula and thus
without the <code>data=</code>, but the model formula got “retro-fitted”
to it later. Since the model formula comes from things like
regression, where <code>data=</code> is legit, that had to be retro-fitted
as well. Or, at least, that’s my understanding.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Birth weights of babies born in the United States have a mean
of 7.3 pounds. Is there any evidence that babies born in North
Carolina are less heavy on average? State appropriate hypotheses, do your
test, obtain a P-value and state your conclusion, in terms of the
original data.</li>
</ol>
<p>Solution</p>
<p>Let <span class="math inline">\(\mu\)</span> be the population mean (the mean weight of all babies born
in North Carolina). Null hypothesis is <span class="math inline">\(H_0: \mu=7.3\)</span> pounds, and the alternative is
that the mean is less: <span class="math inline">\(H_a: \mu&lt;7.3\)</span> pounds.</p>
<p>Note that I defined <span class="math inline">\(\mu\)</span> first before I used it.</p>
<p>This is a one-sided
alternative, which we need to feed into <code>t.test</code>:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" title="1"><span class="kw">t.test</span>(bw<span class="op">$</span><span class="st">`</span><span class="dt">Weight (pounds)</span><span class="st">`</span>, <span class="dt">mu =</span> <span class="fl">7.3</span>, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>)</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  bw$`Weight (pounds)`
## t = -3.4331, df = 499, p-value = 0.0003232
## alternative hypothesis: true mean is less than 7.3
## 95 percent confidence interval:
##      -Inf 7.179752
## sample estimates:
## mean of x 
##   7.06875</code></pre>
<p>$ %$</p>
<p>Or with <code>with</code>. If you see what I mean.</p>
<p>The P-value is 0.0003, which is <em>less</em> than any <span class="math inline">\(\alpha\)</span> we might
have chosen: we <em>reject</em> the null hypothesis in favour of the
alternative, and thus we conclude that the mean birth weight of babies
in North Carolina
is indeed less than 7.3 pounds.</p>
<p>“Reject the null hypothesis” is <em>not</em> a complete answer. You
need to say something about what rejecting the null hypothesis means
<em>in this case</em>: that is, you must make a statement about birth
weights of babies.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>The theory behind the <span class="math inline">\(t\)</span>-test says that the distribution of
birth weights should be (approximately) normally distributed. Obtain a
histogram of the birth weights. Does it look approximately normal?
Comment briefly. (You’ll have to pick a number of bins for your
histogram first. I don’t mind very much what you pick, as long as it’s
not obviously too many or too few bins.)</li>
</ol>
<p>Solution</p>
<p>We did this before (and discussed the number of bins before), so
I’ll just reproduce my 10-bin histogram (which is what I preferred,
but this is a matter of taste):</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" title="1"><span class="kw">ggplot</span>(bw, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="st">`</span><span class="dt">Weight (pounds)</span><span class="st">`</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">10</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>So, we were assessing normality. What about that?</p>
<p>It is mostly normal-looking, but I am suspicious about those
<em>very</em> low birth weights, the ones below about 4 pounds. There
are too many of those, as I see it.</p>
<p>If you think this is approximately normal, you need to make some
comment along the lines of “the shape is approximately symmetric with no outliers”.
I think my first answer is better, but this answer is
worth something, since it is a not completely unreasonable
interpretation of the histogram.</p>
<p>A normal quantile plot is better for assessing normality
than a histogram is, but I won’t make you do one until we have seen
the idea in class. Here’s the normal quantile plot for these data:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" title="1"><span class="kw">ggplot</span>(bw, <span class="kw">aes</span>(<span class="dt">sample =</span> <span class="st">`</span><span class="dt">Weight (pounds)</span><span class="st">`</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq</span>() <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq_line</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>This is rather striking: the lowest birthweights (the ones below 5
pounds or so) are <em>way</em> too low for a normal distribution to
apply. The top end is fine (except perhaps for that one very heavy
baby), but there are too many low birthweights for a normal
distribution to be believable. Note how much clearer this story is
than on the histogram.</p>
<p>Having said that, the <span class="math inline">\(t\)</span>-test, especially with a sample size as big
as this (500), behaves <em>very</em> well when the data are somewhat
non-normal (because it takes advantage of the Central Limit Theorem:
that is, it’s the <em>sampling distribution of the sample mean</em>
whose shape matters). So, even though the data are definitely not
normal, I wouldn’t be too worried about our test.</p>
<p>This perhaps gives some insight as to why Freedman-Diaconis said we
should use so many bins for our histogram. We have a lot of low-end
outliers, so that the IQR is actually <em>small</em> compared to the
overall spread of the data (as measured, say, by the SD or the range)
and so FD thinks we need a lot of bins to describe the shape. Sturges
is based on data being approximately normal, so it will tend to
produce a small number of bins for data that have outliers.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="inferring-ice-break-up-in-nenana-1" class="section level2">
<h2><span class="header-section-number">6.10</span> Inferring ice break-up in Nenana</h2>
<p>Nenana, Alaska, is about 50 miles west of Fairbanks.
Every spring, there is a contest in Nenana. A wooden tripod is
placed on the frozen river, and people try to guess the exact minute
when the ice melts enough for the tripod to fall through the ice. The
contest started in 1917 as an amusement for railway workers, and has
taken place every year since. Now, hundreds of thousands of people
enter their guesses on the Internet and the prize for the winner can
be as much as $300,000.</p>
<p>Because so much money is at stake, and because the exact same tripod
is placed at the exact same spot on the ice every year, the data are
consistent and accurate. The data are in
<a href="http://ritsokiguess.site/datafiles/nenana.txt">link</a>.</p>
<p>Yes, we saw these data before.</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R, as before, or use the data frame that
you read in before. Note that the values are separated by
<em>tabs</em> rather than spaces, so you’ll need an appropriate
<code>read_</code> to read it in.</li>
</ol>
<p>Solution</p>
<p>These are “tab-separated values”, so <code>read_tsv</code> is the
thing, as for the Australian athletes:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" title="1">myurl &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/nenana.txt&quot;</span></a>
<a class="sourceLine" id="cb38-2" title="2">nenana &lt;-<span class="st"> </span><span class="kw">read_tsv</span>(myurl)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   Year = col_double(),
##   JulianDate = col_double(),
##   `Date&amp;Time` = col_character()
## )</code></pre>
<p>Use whatever name you like for the data frame. One that is different
from any of the column headers is smart; then it is clear whether you
mean the whole data frame or one of its columns. <code>ice</code> or
<code>melt</code> or anything like that would also be good.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Obtain a 90% confidence interval for the mean
<code>JulianDate</code>. What interval do you get? Looking back at your
histogram, do you have any doubts about the validity of what you
have just done?</li>
</ol>
<p>Solution</p>
<p>This is a matter of using <code>t.test</code> and pulling out the
interval. Since we are looking for a non-standard interval, we
have to remember <code>conf.level</code> as the way to get the
confidence level that we want. I’m going with <code>with</code> this
time, though the dollar-sign thing is equally as good:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" title="1"><span class="kw">with</span>(nenana, <span class="kw">t.test</span>(JulianDate, <span class="dt">conf.level =</span> <span class="fl">0.90</span>))</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  JulianDate
## t = 197.41, df = 86, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 90 percent confidence interval:
##  124.4869 126.6018
## sample estimates:
## mean of x 
##  125.5443</code></pre>
<p>Between 124.5 and 126.6 days into the year. Converting that into
something we can understand (because I want to), there are
<span class="math inline">\(31+28+31+30=120\)</span> days in
January through April (in a non-leap year), so this says that the mean
breakup date is between about May 4 and May 6.</p>
<p>The <span class="math inline">\(t\)</span>-test is based on an assumption of data coming from a normal
distribution. The histogram we made earlier looks pretty much normal,
so there are no doubts about normality and thus no doubts about the
validity of what we have done, on the evidence we have seen so far. (I
have some doubts on different grounds, based on another of the plots
we did earlier, which I’ll explain later, but all I’m expecting you to
do is to look at the histogram and say “Yep, that’s normal enough”.
Bear in mind that the sample size is 87, which is large
enough for the Central Limit Theorem to be pretty helpful, so that we don’t need the data to be more than “approximately normal” for the sampling distribution of the sample mean to be very close to <span class="math inline">\(t\)</span> with the right df.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>An old-timer in Nenana strokes his grey beard and says
“When I were young, I remember the tripod used to fall into the water around May 10”.
In a non-leap year, May 10 is Julian day 130. Test the null hypothesis that the
mean <code>JulianDay</code> is 130, against the alternative that it is less. What do you conclude?
What practical implication does that have
(assuming that the old-timer has a good memory)?</li>
</ol>
<p>Solution</p>
<p>The test is <code>t.test</code> again, but this time we have to
specify a null mean and a direction of alternative:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" title="1"><span class="kw">with</span>(nenana, <span class="kw">t.test</span>(JulianDate, <span class="dt">mu =</span> <span class="dv">130</span>, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>))</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  JulianDate
## t = -7.0063, df = 86, p-value = 2.575e-10
## alternative hypothesis: true mean is less than 130
## 95 percent confidence interval:
##      -Inf 126.6018
## sample estimates:
## mean of x 
##  125.5443</code></pre>
<p>For a test, look first at the P-value, which is 0.0000000002575: that
is to say, the P-value is very small, definitely smaller than 0.05 (or
any other <span class="math inline">\(\alpha\)</span> you might have chosen). So we <em>reject</em> the
null hypothesis, and conclude that the mean <code>JulianDate</code> is actually
<em>less</em> than 130.</p>
<p>Now, this is the date on which the ice breaks up on average, and we
have concluded that it is <em>earlier</em> than it used to be, since we
are assuming the old-timer’s memory is correct.</p>
<p>This is evidence in
favour of global warming; a small piece of evidence, to be sure, but
the ice is melting earlier than it used to all over the Arctic, so
it’s not just in Nenana that it is happening. You don’t need to get to
the “global warming” part, but I <em>do</em> want you to observe that
the ice is breaking up earlier than it used to.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Plot <code>JulianDate</code> against <code>Year</code> on a
scatterplot. What recent trends, if any, do you see? Comment
briefly. (You did this before, but I have some extra comments on
the graph this time, so feel free to just read this part.)</li>
</ol>
<p>Solution</p>
<p>I liked the <code>ggplot</code> with a smooth trend on it:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" title="1"><span class="kw">ggplot</span>(nenana, <span class="kw">aes</span>(<span class="dt">x =</span> Year, <span class="dt">y =</span> JulianDate)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>()</a></code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
<p>There was something obvious to see: after about 1960, there is a clear
downward trend: the ice is breaking up earlier on average every
year. Even though there is a lot of variability, the overall trend,
viewed this way, is clear (and consistent with the test we did
earlier). Note that the old-timer’s value of 130 is the kind of
<code>JulianDate</code> we would typically observe around 1920, which
would make the old-timer over 90 years old.</p>
<p>All right, why did I say I had some doubts earlier? Well, because of
this downward trend, the mean is not actually the same all the way
through, so it doesn’t make all that much sense to estimate it, which
is what we were doing earlier by doing a confidence interval or a
hypothesis test. What would actually make more sense is to estimate
the mean <code>JulianDate</code> <em>for a particular year</em>. This could
be done by a regression: predict <code>JulianDate</code> from
<code>Year</code>, and then get a
“confidence interval for the mean response”
(as you would have seen in B27 or will see in C67). The
trend isn’t really linear, but is not that far off. I can modify the
previous picture to give you an idea. Putting in <code>method="lm"</code>
fits a line; as we see later, <code>lm</code> does regressions in R:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" title="1"><span class="kw">ggplot</span>(nenana, <span class="kw">aes</span>(<span class="dt">x =</span> Year, <span class="dt">y =</span> JulianDate)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb46-2" title="2"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>)</a></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="pasias_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<p>Compare the confidence interval for the mean <code>JulianDate</code> in
1920: 126 to 131 (the shaded area on the graph), with 2000: 121 to
125. A change of about 5 days over 80 years. And with the recent trend
that we saw above, it’s probably changing faster than that
now. Sobering indeed.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="diameters-of-trees-1" class="section level2">
<h2><span class="header-section-number">6.11</span> Diameters of trees</h2>
<p>The Wade Tract in Thomas County, Georgia, is an old-growth forest of longleaf pine trees. It has survived in a relatively undisturbed state since before settlements of the area by Europeans. For each tree in the tract, researchers measured the diameter at breast height. This is a standard measure in forestry: it is defined as the diameter of the tree at 4.5 feet above the ground.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> They are interested in the mean diameter at breast height of the trees in this tract. These values are in <a href="http://ritsokiguess.site/datafiles/treediameter.csv">http://ritsokiguess.site/datafiles/treediameter.csv</a>. The diameters are measured in centimetres.
The easiest way to get the URL is to <em>right</em>-click on the blue text and select Copy URL. (If you copy and paste the actual text you might end up with extra spaces, especially if the printed URL goes over two lines.)</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display (some of) the data.</li>
</ol>
<p>Solution</p>
<p>The obvious way is this:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/treediameter.csv&quot;</span></a>
<a class="sourceLine" id="cb48-2" title="2">trees &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   diameter = col_double()
## )</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" title="1">trees</a></code></pre></div>
<pre><code>## # A tibble: 40 x 1
##    diameter
##       &lt;dbl&gt;
##  1     10.5
##  2     13.3
##  3     26  
##  4     18.3
##  5     52.2
##  6      9.2
##  7     26.1
##  8     17.6
##  9     40.5
## 10     31.8
## # … with 30 more rows</code></pre>
<p>Call the data frame what you like, though it is better to use a name that tells you what the dataframe contains (rather than something like <code>mydata</code>).</p>
<p>Extra 1: there is only one column, so you can pretend the columns are separated by anything at all. Thus you could use this:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/treediameter.csv&quot;</span></a>
<a class="sourceLine" id="cb52-2" title="2">trees &lt;-<span class="st"> </span><span class="kw">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   diameter = col_double()
## )</code></pre>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" title="1">trees</a></code></pre></div>
<pre><code>## # A tibble: 40 x 1
##    diameter
##       &lt;dbl&gt;
##  1     10.5
##  2     13.3
##  3     26  
##  4     18.3
##  5     52.2
##  6      9.2
##  7     26.1
##  8     17.6
##  9     40.5
## 10     31.8
## # … with 30 more rows</code></pre>
<p>or even this:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/treediameter.csv&quot;</span></a>
<a class="sourceLine" id="cb56-2" title="2">trees &lt;-<span class="st"> </span><span class="kw">read_table</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   diameter = col_double()
## )</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" title="1">trees</a></code></pre></div>
<pre><code>## # A tibble: 40 x 1
##    diameter
##       &lt;dbl&gt;
##  1     10.5
##  2     13.3
##  3     26  
##  4     18.3
##  5     52.2
##  6      9.2
##  7     26.1
##  8     17.6
##  9     40.5
## 10     31.8
## # … with 30 more rows</code></pre>
<p>Extra 2: you might be wondering how they measure the diameter without doing something like drilling a hole through the tree. They don’t actually measure the diameter at all. What they measure is the <em>circumference</em> of the tree, which is easy enough to do with a tape measure. Longleaf pines are usually near circular, so you get the diameter by taking the circumference and dividing by <span class="math inline">\((a)i\)</span>. <a href="https://www.portlandoregon.gov/trees/article/424017">This City of Portland website</a> shows you how it’s done.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a suitable plot of your dataframe.</li>
</ol>
<p>Solution</p>
<p>One quantitative variable, so a histogram. Choose a sensible number of bins. There are 40 observations, so a number of bins up to about 10 is good. Sturges’ rule says 6 since <span class="math inline">\(2^6=64\)</span>:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" title="1"><span class="kw">ggplot</span>(trees, <span class="kw">aes</span>(<span class="dt">x=</span>diameter)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins=</span><span class="dv">6</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
<p>Extra 1: comments come later, but you might care to note (if only for yourself) that the distribution is a little skewed to the right, or, perhaps better, has <em>no</em> left tail at all. You might even observe that diameters cannot be less than 0 (they are measurements), and so you might expect a skew away from the limit.</p>
<p>After you’ve looked at the <span class="math inline">\(t\)</span> procedures for these data, we’ll get back to the shape.</p>
<p>Extra 2: later we look at a more precise tool for assessing normality, the normal quantile plot, which looks like this:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" title="1"><span class="kw">ggplot</span>(trees, <span class="kw">aes</span>(<span class="dt">sample=</span>diameter)) <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq</span>() <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq_line</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<p>If the data come from a normal distribution, the points should follow the straight line, at least approximately. Here, most of the points do, except for the points on the left, which veer away upwards from the line: that is, the highest values, on the right, are about right for a normal distribution, but the lowest values, on the left, <em>don’t go down low enough</em>.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>
Thus, the problem with normality is not the long tail on the right, but the short one on the left. It is hard to get this kind of insight from the histogram, but at the moment, it’s the best we have.</p>
<p>The big problems, for things like <span class="math inline">\(t\)</span>-tests that depend on means, is stuff like outliers, or long tails, with extreme values that might distort the mean. Having short tails, as the left tail here, will make the distribution look non-normal but won’t cause any problems for the <span class="math inline">\(t\)</span>-tests.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Obtain a 95% confidence interval for the mean diameter.</li>
</ol>
<p>Solution</p>
<p>This is <code>t.test</code>, but with <code>conf.level</code> to get the interval (and then you ignore the P-value):</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" title="1"><span class="kw">with</span>(trees, <span class="kw">t.test</span>(diameter))</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  diameter
## t = 9.748, df = 39, p-value = 5.245e-12
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  21.6274 32.9526
## sample estimates:
## mean of x 
##     27.29</code></pre>
<p>The mean diameter of a longleaf pine (like the ones in this tract) is between 21.6 and 33.0 centimetres.</p>
<p>If you prefer, do it this way:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" title="1"><span class="kw">t.test</span>(trees<span class="op">$</span>diameter)</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  trees$diameter
## t = 9.748, df = 39, p-value = 5.245e-12
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  21.6274 32.9526
## sample estimates:
## mean of x 
##     27.29</code></pre>
<p>You need to <em>state the answer</em> and <em>round it off suitably</em>. The actual diameters in the data have one decimal place, so you can give the same accuracy for the CI, or <em>at most</em> two decimals (so 21.63 to 32.95 cm would also be OK).<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> Giving an answer with more decimals is something you cannot possibly justify. Worse even than giving too many decimals is not writing out the interval at all. <em>Never</em> make your reader find something in output. If they want it, tell them what it is.</p>
<p>Thus, here, one mark for the output, one more for saying what the interval is, and the third if you give the interval with a sensible number of decimals.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Based on what you have seen so far, would you expect to reject a null hypothesis that the population mean diameter (of all longleaf pines like these) is 35 cm? Explain briefly. Then, carry out the test (against a two-sided alternative) and explain briefly whether you were right.</li>
</ol>
<p>Solution</p>
<p>The logic is that “plausible” values for the population mean, ones you believe, are inside the interval, and implausible ones that you don’t believe are outside. Remember that the interval is your best answer to “what is the population mean”, and 35 is outside the interval so you don’t think the population mean is 35, and thus you would reject it.</p>
<p>Are we right? Take out the <code>conf.level</code> and put in a <code>mu</code>:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" title="1"><span class="kw">with</span>(trees, <span class="kw">t.test</span>(diameter, <span class="dt">mu =</span> <span class="dv">35</span>))</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  diameter
## t = -2.754, df = 39, p-value = 0.008895
## alternative hypothesis: true mean is not equal to 35
## 95 percent confidence interval:
##  21.6274 32.9526
## sample estimates:
## mean of x 
##     27.29</code></pre>
<p>The P-value is less than our <span class="math inline">\(\alpha\)</span> of 0.05, so we would indeed reject a mean of 35 cm (in favour of the mean being different from 35).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Would you expect 35 cm to be in a <em>99%</em> confidence interval for the mean diameter? Explain briefly, and then see if you were right.</li>
</ol>
<p>Solution</p>
<p>The P-value is less than 0.01 (as well as being less than 0.05), so, in the same way that 35 was outside the 95% interval, it should be outside the 99% CI also. Maybe not by much, though, since the P-value is only just less than 0.01:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" title="1"><span class="kw">with</span>(trees, <span class="kw">t.test</span>(diameter, <span class="dt">conf.level =</span> <span class="fl">0.99</span>))</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  diameter
## t = 9.748, df = 39, p-value = 5.245e-12
## alternative hypothesis: true mean is not equal to 0
## 99 percent confidence interval:
##  19.70909 34.87091
## sample estimates:
## mean of x 
##     27.29</code></pre>
<p>Indeed so, outside, but only just.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="one-sample-cholesterol-1" class="section level2">
<h2><span class="header-section-number">6.12</span> One-sample cholesterol</h2>
<p>The data set <a href="http://ritsokiguess.site/datafiles/cholest.csv">here</a> contains cholesterol
measurements for heart attack patients (at several different times) as
well as for a group of control patients. We will focus on the control
patients in this question.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display (some of) the data.</li>
</ol>
<p>Solution</p>
<p>This is (as you might guess) a , so:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/cholest.csv&quot;</span></a>
<a class="sourceLine" id="cb70-2" title="2">cholest &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   `2-Day` = col_double(),
##   `4-Day` = col_double(),
##   `14-Day` = col_double(),
##   control = col_double()
## )</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" title="1">cholest</a></code></pre></div>
<pre><code>## # A tibble: 30 x 4
##    `2-Day` `4-Day` `14-Day` control
##      &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;
##  1     270     218      156     196
##  2     236     234       NA     232
##  3     210     214      242     200
##  4     142     116       NA     242
##  5     280     200       NA     206
##  6     272     276      256     178
##  7     160     146      142     184
##  8     220     182      216     198
##  9     226     238      248     160
## 10     242     288       NA     182
## # … with 20 more rows</code></pre>
<p>Note for yourself that there are 30 observations (and some missing
ones), and a column called  that is the one we’ll be
working with.</p>
<p>Extra: the 2-day, 4-day and 14-day columns need to be referred to with funny “backticks” around their names, because a column name cannot contain a <code>-</code> or start with a number. This is not a problem here, since we won’t be using those columns, but if we wanted to, this would not work:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" title="1">cholest <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">xbar =</span> <span class="kw">mean</span>(<span class="dv">2</span><span class="op">-</span>Day))</a></code></pre></div>
<pre><code>## Error: Problem with `summarise()` input `xbar`.
## ✖ error in evaluating the argument &#39;x&#39; in selecting a method for function &#39;mean&#39;: object &#39;Day&#39; not found
## ℹ Input `xbar` is `mean(2 - Day)`.</code></pre>
<p>because it is looking for a column called <code>Day</code>, which doesn’t exist. The meaning of <code>2-Day</code> is “take the column called <code>Day</code> and subtract it from 2”. To make this work, we have to supply the backticks ourselves:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" title="1">cholest <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">xbar =</span> <span class="kw">mean</span>(<span class="st">`</span><span class="dt">2-Day</span><span class="st">`</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    xbar
##   &lt;dbl&gt;
## 1  254.</code></pre>
<p>This column also has missing values (at the bottom), so here I’ve asked to remove the missing values<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> before working out the mean. Otherwise the mean is, unhelpfully, missing as well.</p>
<p>You might imagine that dealing with column names like this would get annoying. There is a package called <code>janitor</code> that has a function called <code>clean_names</code> to save you the trouble. Install it first, then load it:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" title="1"><span class="kw">library</span>(janitor)</a></code></pre></div>
<p>and then pipe your dataframe into <code>clean_names</code> and see what happens:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" title="1">cholest <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">clean_names</span>() -&gt;<span class="st"> </span>cholest1</a>
<a class="sourceLine" id="cb79-2" title="2">cholest1</a></code></pre></div>
<pre><code>## # A tibble: 30 x 4
##    x2_day x4_day x14_day control
##     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1    270    218     156     196
##  2    236    234      NA     232
##  3    210    214     242     200
##  4    142    116      NA     242
##  5    280    200      NA     206
##  6    272    276     256     178
##  7    160    146     142     184
##  8    220    182     216     198
##  9    226    238     248     160
## 10    242    288      NA     182
## # … with 20 more rows</code></pre>
<p>These are all legit column names; the <code>-</code> has been replaced by an underscore, and each of the first three column names has gained an <code>x</code> on the front so that it no longer starts with a number. This then works:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" title="1">cholest1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">xbar =</span> <span class="kw">mean</span>(x2_day, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    xbar
##   &lt;dbl&gt;
## 1  254.</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a suitable plot of the cholesterol levels of the
control patients, and comment briefly on the shape of the
distribution.</li>
</ol>
<p>Solution</p>
<p>There is one quantitative variable, so a histogram, as ever:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" title="1"><span class="kw">ggplot</span>(cholest, <span class="kw">aes</span>(<span class="dt">x=</span>control)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins=</span><span class="dv">6</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
<p>Pick a number of bins that shows the shape reasonably well. Too many
or too few won’t. (Sturges’ rule says 6, since there are 30
observations and <span class="math inline">\(2^5=32\)</span>.) Seven bins also works, but by the time you
get to 8 bins or more, you are starting to lose a clear picture of the
shape. Four bins is, likewise, about as low as you can go before
getting too crude a picture.</p>
<p>Choosing one of these numbers of bins will make it clear that the
distribution is somewhat skewed to the right.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>It is recommended that people in good health, such as the
Control patients here, keep their cholesterol level below 200. Is
there evidence that the mean cholesterol level of the population of
people of which the Control patients are a sample is less than 200? Show that you understand the process,
and state your conclusion in the context of the data.</li>
</ol>
<p>Solution</p>
<p>The word “evidence” means to do a hypothesis test and get a
P-value. Choose an <span class="math inline">\(\alpha\)</span> first, such as 0.05.</p>
<p>Testing a mean implies a one-sample <span class="math inline">\(t\)</span>-test. We are trying to
prove that the mean is less than 200, so that’s our alternative:
<span class="math inline">\(H_a: \mu &lt; 200\)</span>, and therefore the null is that the mean is equal
to 200: <span class="math inline">\(H_0: \mu = 200\)</span>. (You might think it makes more logical
sense to have <span class="math inline">\(H_0: \mu \ge 200\)</span>, which is also fine. As long as
the null hypothesis has an equals in it in a logical place, you
are good.)</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" title="1"><span class="kw">with</span>(cholest, <span class="kw">t.test</span>(control, <span class="dt">mu=</span><span class="dv">200</span>, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>))</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  control
## t = -1.6866, df = 29, p-value = 0.05121
## alternative hypothesis: true mean is less than 200
## 95 percent confidence interval:
##      -Inf 200.0512
## sample estimates:
## mean of x 
##  193.1333</code></pre>
<p>This is also good:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" title="1"><span class="kw">t.test</span>(cholest<span class="op">$</span>control, <span class="dt">mu=</span><span class="dv">200</span>, <span class="dt">alternative =</span> <span class="st">&quot;less&quot;</span>)</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  cholest$control
## t = -1.6866, df = 29, p-value = 0.05121
## alternative hypothesis: true mean is less than 200
## 95 percent confidence interval:
##      -Inf 200.0512
## sample estimates:
## mean of x 
##  193.1333</code></pre>
<p>I like the first version better because a lot of what we do later
involves giving a data frame, and then working with things in that
data frame. This is more like that.</p>
<p>This test is -sided because we are looking for evidence of
; if the mean is actually  than 200, we don’t
care about that. For a one-sided test, R requires you to say which
side you are testing.</p>
<p>The P-value is not (quite) less than 0.05, so we cannot quite reject
the null. Therefore, there is no evidence that the mean cholesterol
level (of the people of which the control group are a sample) is less
than 200. Or, this mean is not significantly less than 200. Or, we
conclude that this mean is equal to 200. Or, we conclude that this
mean could be 200. Any of those.</p>
<p>If you chose a different <span class="math inline">\(\alpha\)</span>, draw the right conclusion for the
<span class="math inline">\(\alpha\)</span> you chose. For example, with <span class="math inline">\(\alpha=0.10\)</span>, we  have
evidence that the mean is less than 200. Being consistent is more
important than getting the same answer as me.</p>
<p>Writing out all the steps correctly shows that you understand the process. Anything less doesn’t.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>What values could the population mean cholesterol level take? You
might need to get some more output to determine this.</li>
</ol>
<p>Solution</p>
<p>This is <em>not</em> quoting the sample mean, giving that as your answer, and then stopping. The sample mean should, we hope, be somewhere the population mean, but it is almost certainly not the same as the population mean, because there is variability due to random sampling. (This is perhaps the most important thing in all of Statistics: recognizing that variability exists and dealing with it.)</p>
<p>With that in mind, the question means to get a range of values that the population mean could
be: that is to say, a confidence interval. The one that came out
of the previous output is one-sided, to go with the one-sided
test, but confidence intervals for us are two-sided, so we have to
run the test again, but two-sided, to get it. To do that, take out
the “alternative”, thus (you can also take out the null mean,
since a confidence interval has no null hypothesis):</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" title="1"><span class="kw">with</span>(cholest, <span class="kw">t.test</span>(control))</a></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  control
## t = 47.436, df = 29, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  184.8064 201.4603
## sample estimates:
## mean of x 
##  193.1333</code></pre>
<p>With 95% confidence, the population mean cholesterol level is between
184.8 and 201.5.</p>
<p> This is because in your
statistical life, you are providing results to someone else  They do not have time to go
searching in some output, or to fish through some excessive number of
decimal places. If that’s what you give them, they will ask you to
rewrite your report, wasting everybody’s time when you could have done
it right the first time.</p>
<p>How many decimal places is a good number? Look back at your data. In
this case, the cholesterol values are whole numbers (zero decimal
places). A confidence interval is talking about a mean. In this case,
we have a sample size of 30, which is between 10 and 100, so we can
justify one extra decimal place beyond the data, here one decimal
altogether, or two . (Two is more
justifiable if the sample size is bigger than 100.) See, for example,
<a href="https://www2.southeastern.edu/Academics/Faculty/dgurney/Math241/StatTopics/SciNot.htm">this</a>,
in particular the piece at the bottom.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Explain briefly why you would be reasonably happy to trust
the <span class="math inline">\(t\)</span> procedures in this question. (There are two points you need
to make.)</li>
</ol>
<p>Solution</p>
<p>The first thing is to look back at the graph you made
earlier. This was skewed to the right (“moderately” or
“somewhat” or however you described it). This would seem to say
that the <span class="math inline">\(t\)</span> procedures were not very trustworthy, since the
population distribution doesn’t look very normal in shape.</p>
<p>However, the second thing is to look at the sample size. We have
the central limit theorem, which says (for us) that the larger the
sample is, the less the normality matters, when it comes to
estimating the mean. Here, the sample size is 30, which, for the
central limit theorem, is large enough to overcome moderate
non-normality in the data.</p>
<p>My take, which I was trying to guide you towards, is that our
non-normality was not too bad, and so our sample size is large
enough to trust the <span class="math inline">\(t\)</span> procedures we used.</p>
<p>Extra 1: 
What matters is the tradeoff between sample size and the extent of
the non-normality. If your data is less normal, you need a larger
sample size to overcome it. Even a sample size of 500 might not be
enough if your distribution is very skewed, or if you have extreme
outliers.</p>
<p>The place <span class="math inline">\(n=30\)</span> comes from is back from the days when we only
ever used printed tables. In most textbooks, if you printed the
<span class="math inline">\(t\)</span>-table on one page in a decent-sized font, you’d get to about
29 df before running out of space. Then they would say “<span class="math inline">\(\infty\)</span>
df” and put the normal-distribution <span class="math inline">\(z\)</span> numbers in. If the df you
needed was bigger than what you had in the table, you used this
last line: that is, you called the sample “large”. Try it in
your stats textbooks: I bet the df go up to 30, then you get a few
more, then the <span class="math inline">\(z\)</span> numbers.</p>
<p>Extra 2: By now you are probably thinking that this is very
subjective, and so it is. What actually matters is the shape of
the thing called the . That is to say, what kind of sample means you might get
in repeated samples from your population. The problem is that you
don’t know what the population looks like.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> But we can fake it up, in a couple
of ways: we can play what-if and pretend we know what the population
looks like (to get some understanding for “populations like
that”), or we can use a technique called the “bootstrap” that
will tell us what kind of sample means we might get from the
population that  sample came from (this seems like magic
and, indeed, is).</p>
<p>The moral of the story is that the central limit theorem is more
powerful than you think.</p>
<p>To illustrate my first idea, let’s pretend the population looks like this,
with a flat top:</p>
<p><img src="pasias_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
<p>Only values between 0 and 1 are possible, and each of those is equally
likely. Not very normal in shape. So let’s take some random samples of
size , not in any sense a large sample, from this “uniform”
population, and see what kind of sample means we get. This technique
is called : rather than working out the answer by
math, we’re letting the computer approximate the answer for us. Here’s
one simulated sample:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" title="1">u &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">3</span>)</a>
<a class="sourceLine" id="cb90-2" title="2">u</a></code></pre></div>
<pre><code>## [1] 0.9475841 0.1245953 0.2277288</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" title="1"><span class="kw">mean</span>(u)</a></code></pre></div>
<pre><code>## [1] 0.4333027</code></pre>
<p>and here’s the same thing 1000 times, including a histogram of the
sample means:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" title="1"><span class="kw">tibble</span>(<span class="dt">sim =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb94-2" title="2"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb94-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">runif</span>(<span class="dv">3</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb94-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_mean =</span> <span class="kw">mean</span>(my_sample)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb94-5" title="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> my_mean)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">12</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<p>This is our computer-generated assessment of what the sampling
distribution of the sample mean looks like. Isn’t this looking like a
normal distribution?</p>
<p>Let’s take a moment to realize what this is saying. If the population
looks like the flat-topped uniform distribution, the central limit
theorem kicks in for a sample of size , and thus if your
population looks like this, <span class="math inline">\(t\)</span> procedures will be perfectly good for
<span class="math inline">\(n=3\)</span> or bigger, .</p>
<p>Thus, when you’re thinking about whether to use a <span class="math inline">\(t\)</span>-test or
something else (that we’ll learn about later), the distribution shape
matters, .</p>
<p>I should say a little about my code. I’m not expecting you to figure
out details now (we see the ideas properly in simulating power of
tests), but in words, one line at a time:</p>

<p>Now, the central limit theorem doesn’t always work as nicely as this,
but maybe a sample size of 30 is large enough to overcome the skewness
that we had:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" title="1"><span class="kw">ggplot</span>(cholest, <span class="kw">aes</span>(<span class="dt">x=</span>control)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins=</span><span class="dv">6</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<p>That brings us to my second idea above.</p>
<p>The sample that we had is in some sense an “estimate of the
population”. To think about the sampling distribution of the sample
mean, we need more estimates of the population. How might we get
those? The curious answer is to . This is
the idea behind the . (This is what Lecture 3c is about.) The name comes from the
expression “pulling yourself up by your own bootstraps”, meaning
“to begin an enterprise or recover from a setback without any outside
help” (from <a href="https://www.yourdictionary.com/pull-oneself-up-by-one-s-bootstraps">here</a>),
something that should be difficult or impossible. How is it
possible to understand a sampling distribution with only one sample?</p>
<p>We have to be a bit careful. Taking a sample from the sample would
give us the original sample back. So, instead, we sample , so that each bootstrap sample is different:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" title="1"><span class="kw">sort</span>(cholest<span class="op">$</span>control)</a></code></pre></div>
<pre><code>##  [1] 160 162 164 166 170 176 178 178 182 182 182 182 182 184 186 188 196 198 198 198 200 200 204 206 212 218 230 232 238
## [30] 242</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb98-1" title="1"><span class="kw">sort</span>(<span class="kw">sample</span>(cholest<span class="op">$</span>control, <span class="dt">replace=</span><span class="ot">TRUE</span>))</a></code></pre></div>
<pre><code>##  [1] 164 166 166 166 166 176 178 178 182 182 182 182 182 188 198 198 198 200 200 200 200 204 206 206 218 218 230 232 232
## [30] 242</code></pre>
<p>A bootstrap sample contains repeats of the original data values, and
misses some of the others. Here, the original data had values 160 and 162 that are missing in the bootstrap sample; the original data had one value 166, but the bootstrap sample has <em>four</em>!
I sorted the data and the bootstrap sample
to make this clearer; you will not need to sort. This is a perfectly good bootstrap sample:</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" title="1"><span class="kw">sample</span>(cholest<span class="op">$</span>control, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>##  [1] 242 232 198 160 242 182 182 182 198 162 212 198 242 204 242 242 170 198 182 206 232 170 218 188 166 178 164 160 218
## [30] 196</code></pre>
<p>So now we know what to do: take lots of bootstrap samples, work out
the mean of each, plot the means, and see how normal it looks. The
only new idea here is the sampling with replacement:</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" title="1"><span class="kw">tibble</span>(<span class="dt">sim =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb102-2" title="2"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb102-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">sample</span>(cholest<span class="op">$</span>control, <span class="dt">replace =</span> <span class="ot">TRUE</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb102-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_mean =</span> <span class="kw">mean</span>(my_sample)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb102-5" title="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> my_mean)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">12</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<p>That looks pretty normal, not obviously skewed, and so the <span class="math inline">\(t\)</span>
procedures we used will be reliable enough.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>The height of a typical human breast off the ground. Men have a breast too, you know.<a href="one-sample-inference.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>The normal quantile plot is rather interesting: it says that the uppermost values are approximately normal, but the <em>smallest</em> eight or so values are too bunched up to be normal. That is, normality fails not because of the long tail on the right, but the bunching on the left. Still right-skewed, though.<a href="one-sample-inference.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>In some languages, a dot is used to concatenate bits of text, or as a way of calling a method on an object. But in R, a dot has no special meaning, and is used in function names like <code>t.test</code>. Or <code>p.value</code>.<a href="one-sample-inference.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Whether you think it is or not may depend on how many bins you have on your histogram. With 5 bins it looks like an outlier, but with 6 it does not. Try it and see.<a href="one-sample-inference.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>The height of a typical human breast off the ground. Men have a breast too, you know.<a href="one-sample-inference.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>They cannot go down far enough, because they can’t go below zero.<a href="one-sample-inference.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>One more decimal place than the data is the maximum you give in a CI.<a href="one-sample-inference.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>In R, missing values are labelled <code>NA</code>, and <code>rm</code> is Unix/C shorthand for <em>remove</em>.<a href="one-sample-inference.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>If you did, all
your problems would be over.<a href="one-sample-inference.html#fnref9" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="working-with-dataframes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="two-sample-inference.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["pasias.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
