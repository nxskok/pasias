<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Analysis of variance | Problems and Solutions in Applied Statistics</title>
  <meta name="description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Analysis of variance | Problems and Solutions in Applied Statistics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://ritsokiguess.site/pasias" />
  
  <meta property="og:description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
  <meta name="github-repo" content="nxskok/pasias" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Analysis of variance | Problems and Solutions in Applied Statistics" />
  
  <meta name="twitter:description" content="A set of problems and solutions, in R, on various parts of applied statistics" />
  

<meta name="author" content="Ken Butler" />


<meta name="date" content="2021-06-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="normal-quantile-plots.html"/>
<link rel="next" href="writing-reports.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Problems and Solutions in Applied Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#packages-used-somewhere-in-this-book"><i class="fa fa-check"></i>Packages used somewhere in this book</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-used-to-r-and-r-studio.html"><a href="getting-used-to-r-and-r-studio.html"><i class="fa fa-check"></i><b>1</b> Getting used to R and R Studio</a><ul>
<li class="chapter" data-level="1.1" data-path="getting-used-to-r-and-r-studio.html"><a href="getting-used-to-r-and-r-studio.html#running-r-studio-on-jupyterhub"><i class="fa fa-check"></i><b>1.1</b> Running R Studio on Jupyterhub</a></li>
<li class="chapter" data-level="1.2" data-path="getting-used-to-r-and-r-studio.html"><a href="getting-used-to-r-and-r-studio.html#getting-an-r-studio-cloud-account"><i class="fa fa-check"></i><b>1.2</b> Getting an R Studio Cloud account</a></li>
<li class="chapter" data-level="1.3" data-path="getting-used-to-r-and-r-studio.html"><a href="getting-used-to-r-and-r-studio.html#getting-started"><i class="fa fa-check"></i><b>1.3</b> Getting started</a></li>
<li class="chapter" data-level="1.4" data-path="getting-used-to-r-and-r-studio.html"><a href="getting-used-to-r-and-r-studio.html#reading-data-from-a-file"><i class="fa fa-check"></i><b>1.4</b> Reading data from a file</a></li>
<li class="chapter" data-level="1.5" data-path="getting-used-to-r-and-r-studio.html"><a href="getting-used-to-r-and-r-studio.html#reading-files-different-ways"><i class="fa fa-check"></i><b>1.5</b> Reading files different ways</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reading-in-data.html"><a href="reading-in-data.html"><i class="fa fa-check"></i><b>2</b> Reading in data</a></li>
<li class="chapter" data-level="3" data-path="drawing-graphs.html"><a href="drawing-graphs.html"><i class="fa fa-check"></i><b>3</b> Drawing graphs</a></li>
<li class="chapter" data-level="4" data-path="data-exploration.html"><a href="data-exploration.html"><i class="fa fa-check"></i><b>4</b> Data exploration</a></li>
<li class="chapter" data-level="5" data-path="working-with-dataframes.html"><a href="working-with-dataframes.html"><i class="fa fa-check"></i><b>5</b> Working with dataframes</a></li>
<li class="chapter" data-level="6" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>6</b> One-sample inference</a></li>
<li class="chapter" data-level="7" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>7</b> Two-sample inference</a></li>
<li class="chapter" data-level="8" data-path="power-and-sample-size.html"><a href="power-and-sample-size.html"><i class="fa fa-check"></i><b>8</b> Power and sample size</a></li>
<li class="chapter" data-level="9" data-path="the-sign-test.html"><a href="the-sign-test.html"><i class="fa fa-check"></i><b>9</b> The sign test</a></li>
<li class="chapter" data-level="10" data-path="mood-median-test.html"><a href="mood-median-test.html"><i class="fa fa-check"></i><b>10</b> Mood median test</a></li>
<li class="chapter" data-level="11" data-path="matched-pairs-t-and-sign-test.html"><a href="matched-pairs-t-and-sign-test.html"><i class="fa fa-check"></i><b>11</b> Matched pairs t and sign test</a></li>
<li class="chapter" data-level="12" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html"><i class="fa fa-check"></i><b>12</b> Normal quantile plots</a><ul>
<li class="chapter" data-level="12.1" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#lengths-of-heliconia-flowers"><i class="fa fa-check"></i><b>12.1</b> Lengths of heliconia flowers</a></li>
<li class="chapter" data-level="12.2" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#ferritin-and-normality"><i class="fa fa-check"></i><b>12.2</b> Ferritin and normality</a></li>
<li class="chapter" data-level="12.3" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#lengths-of-heliconia-flowers-1"><i class="fa fa-check"></i><b>12.3</b> Lengths of heliconia flowers</a></li>
<li class="chapter" data-level="12.4" data-path="normal-quantile-plots.html"><a href="normal-quantile-plots.html#ferritin-and-normality-1"><i class="fa fa-check"></i><b>12.4</b> Ferritin and normality</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>13</b> Analysis of variance</a><ul>
<li class="chapter" data-level="13.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#movie-ratings-and-lengths"><i class="fa fa-check"></i><b>13.1</b> Movie ratings and lengths</a></li>
<li class="chapter" data-level="13.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#deer-and-how-much-they-eat"><i class="fa fa-check"></i><b>13.2</b> Deer and how much they eat</a></li>
<li class="chapter" data-level="13.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#movie-ratings-again"><i class="fa fa-check"></i><b>13.3</b> Movie ratings again</a></li>
<li class="chapter" data-level="13.4" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#atomic-weight-of-carbon"><i class="fa fa-check"></i><b>13.4</b> Atomic weight of carbon</a></li>
<li class="chapter" data-level="13.5" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#can-caffeine-improve-your-performance-on-a-test"><i class="fa fa-check"></i><b>13.5</b> Can caffeine improve your performance on a test?</a></li>
<li class="chapter" data-level="13.6" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#reggae-music"><i class="fa fa-check"></i><b>13.6</b> Reggae music</a></li>
<li class="chapter" data-level="13.7" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#watching-tv-and-education"><i class="fa fa-check"></i><b>13.7</b> Watching TV and education</a></li>
<li class="chapter" data-level="13.8" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#death-of-poets"><i class="fa fa-check"></i><b>13.8</b> Death of poets</a></li>
<li class="chapter" data-level="13.9" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#religion-and-studying"><i class="fa fa-check"></i><b>13.9</b> Religion and studying</a></li>
<li class="chapter" data-level="13.10" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#movie-ratings-and-lengths-1"><i class="fa fa-check"></i><b>13.10</b> Movie ratings and lengths</a></li>
<li class="chapter" data-level="13.11" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#deer-and-how-much-they-eat-1"><i class="fa fa-check"></i><b>13.11</b> Deer and how much they eat</a></li>
<li class="chapter" data-level="13.12" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#movie-ratings-again-1"><i class="fa fa-check"></i><b>13.12</b> Movie ratings again</a></li>
<li class="chapter" data-level="13.13" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#atomic-weight-of-carbon-1"><i class="fa fa-check"></i><b>13.13</b> Atomic weight of carbon</a></li>
<li class="chapter" data-level="13.14" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#can-caffeine-improve-your-performance-on-a-test-1"><i class="fa fa-check"></i><b>13.14</b> Can caffeine improve your performance on a test?</a></li>
<li class="chapter" data-level="13.15" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#reggae-music-1"><i class="fa fa-check"></i><b>13.15</b> Reggae music</a></li>
<li class="chapter" data-level="13.16" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#watching-tv-and-education-1"><i class="fa fa-check"></i><b>13.16</b> Watching TV and education</a></li>
<li class="chapter" data-level="13.17" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#death-of-poets-1"><i class="fa fa-check"></i><b>13.17</b> Death of poets</a></li>
<li class="chapter" data-level="13.18" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#religion-and-studying-1"><i class="fa fa-check"></i><b>13.18</b> Religion and studying</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="writing-reports.html"><a href="writing-reports.html"><i class="fa fa-check"></i><b>14</b> Writing reports</a></li>
<li class="chapter" data-level="15" data-path="learning-to-code.html"><a href="learning-to-code.html"><i class="fa fa-check"></i><b>15</b> Learning to code</a><ul>
<li class="chapter" data-level="15.1" data-path="learning-to-code.html"><a href="learning-to-code.html#introduction-1"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="learning-to-code.html"><a href="learning-to-code.html#data-and-pre-processing"><i class="fa fa-check"></i><b>15.2</b> Data and pre-processing</a></li>
<li class="chapter" data-level="15.3" data-path="learning-to-code.html"><a href="learning-to-code.html#analysis"><i class="fa fa-check"></i><b>15.3</b> Analysis</a></li>
<li class="chapter" data-level="15.4" data-path="learning-to-code.html"><a href="learning-to-code.html#conclusions-see-note-9"><i class="fa fa-check"></i><b>15.4</b> Conclusions (see note 9)</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="treating-dandruff.html"><a href="treating-dandruff.html"><i class="fa fa-check"></i><b>16</b> Treating dandruff</a><ul>
<li class="chapter" data-level="16.1" data-path="treating-dandruff.html"><a href="treating-dandruff.html#introduction-2"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="treating-dandruff.html"><a href="treating-dandruff.html#exploratory-analysis"><i class="fa fa-check"></i><b>16.2</b> Exploratory analysis</a></li>
<li class="chapter" data-level="16.3" data-path="treating-dandruff.html"><a href="treating-dandruff.html#analysis-of-variance-1"><i class="fa fa-check"></i><b>16.3</b> Analysis of Variance</a></li>
<li class="chapter" data-level="16.4" data-path="treating-dandruff.html"><a href="treating-dandruff.html#assessment-of-assumptions"><i class="fa fa-check"></i><b>16.4</b> Assessment of Assumptions</a></li>
<li class="chapter" data-level="16.5" data-path="treating-dandruff.html"><a href="treating-dandruff.html#conclusions"><i class="fa fa-check"></i><b>16.5</b> Conclusions</a></li>
<li class="chapter" data-level="16.6" data-path="treating-dandruff.html"><a href="treating-dandruff.html#end"><i class="fa fa-check"></i><b>16.6</b> End</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="tidying-data.html"><a href="tidying-data.html"><i class="fa fa-check"></i><b>17</b> Tidying data</a></li>
<li class="chapter" data-level="18" data-path="simple-regression.html"><a href="simple-regression.html"><i class="fa fa-check"></i><b>18</b> Simple regression</a></li>
<li class="chapter" data-level="19" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>19</b> Multiple regression</a></li>
<li class="chapter" data-level="20" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html"><i class="fa fa-check"></i><b>20</b> Regression with categorical variables</a><ul>
<li class="chapter" data-level="20.1" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#crickets-revisited"><i class="fa fa-check"></i><b>20.1</b> Crickets revisited</a></li>
<li class="chapter" data-level="20.2" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#pulse-rates-and-marching"><i class="fa fa-check"></i><b>20.2</b> Pulse rates and marching</a></li>
<li class="chapter" data-level="20.3" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#crickets-revisited-1"><i class="fa fa-check"></i><b>20.3</b> Crickets revisited</a></li>
<li class="chapter" data-level="20.4" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#pulse-rates-and-marching-1"><i class="fa fa-check"></i><b>20.4</b> Pulse rates and marching</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dates-and-times.html"><a href="dates-and-times.html"><i class="fa fa-check"></i><b>21</b> Dates and times</a></li>
<li class="chapter" data-level="22" data-path="functions.html"><a href="functions.html"><i class="fa fa-check"></i><b>22</b> Functions</a></li>
<li class="chapter" data-level="23" data-path="vector-and-matrix-algebra.html"><a href="vector-and-matrix-algebra.html"><i class="fa fa-check"></i><b>23</b> Vector and matrix algebra</a><ul>
<li class="chapter" data-level="23.1" data-path="vector-and-matrix-algebra.html"><a href="vector-and-matrix-algebra.html#heights-and-foot-lengths-again"><i class="fa fa-check"></i><b>23.1</b> Heights and foot lengths again</a></li>
<li class="chapter" data-level="23.2" data-path="vector-and-matrix-algebra.html"><a href="vector-and-matrix-algebra.html#heights-and-foot-lengths-again-1"><i class="fa fa-check"></i><b>23.2</b> Heights and foot lengths again</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="the-bootstrap.html"><a href="the-bootstrap.html"><i class="fa fa-check"></i><b>24</b> The Bootstrap</a></li>
<li class="chapter" data-level="25" data-path="bayesian-statistics-with-stan.html"><a href="bayesian-statistics-with-stan.html"><i class="fa fa-check"></i><b>25</b> Bayesian Statistics with Stan</a></li>
<li class="chapter" data-level="26" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>26</b> Logistic regression</a></li>
<li class="chapter" data-level="27" data-path="logistic-regression-with-ordinal-response.html"><a href="logistic-regression-with-ordinal-response.html"><i class="fa fa-check"></i><b>27</b> Logistic regression with ordinal response</a></li>
<li class="chapter" data-level="28" data-path="logistic-regression-with-nominal-response.html"><a href="logistic-regression-with-nominal-response.html"><i class="fa fa-check"></i><b>28</b> Logistic regression with nominal response</a></li>
<li class="chapter" data-level="29" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>29</b> Survival analysis</a></li>
<li class="chapter" data-level="30" data-path="analysis-of-variance-revisited.html"><a href="analysis-of-variance-revisited.html"><i class="fa fa-check"></i><b>30</b> Analysis of variance revisited</a></li>
<li class="chapter" data-level="31" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html"><i class="fa fa-check"></i><b>31</b> Analysis of covariance</a></li>
<li class="chapter" data-level="32" data-path="multivariate-analysis-of-variance.html"><a href="multivariate-analysis-of-variance.html"><i class="fa fa-check"></i><b>32</b> Multivariate analysis of variance</a></li>
<li class="chapter" data-level="33" data-path="repeated-measures.html"><a href="repeated-measures.html"><i class="fa fa-check"></i><b>33</b> Repeated measures</a></li>
<li class="chapter" data-level="34" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html"><i class="fa fa-check"></i><b>34</b> Discriminant analysis</a></li>
<li class="chapter" data-level="35" data-path="hierarchical-cluster-analysis.html"><a href="hierarchical-cluster-analysis.html"><i class="fa fa-check"></i><b>35</b> Hierarchical cluster analysis</a></li>
<li class="chapter" data-level="36" data-path="k-means-cluster-analysis.html"><a href="k-means-cluster-analysis.html"><i class="fa fa-check"></i><b>36</b> K-means cluster analysis</a></li>
<li class="chapter" data-level="37" data-path="drawing-maps-with-leaflet.html"><a href="drawing-maps-with-leaflet.html"><i class="fa fa-check"></i><b>37</b> Drawing maps with Leaflet</a></li>
<li class="chapter" data-level="38" data-path="multidimensional-scaling.html"><a href="multidimensional-scaling.html"><i class="fa fa-check"></i><b>38</b> Multidimensional Scaling</a></li>
<li class="chapter" data-level="39" data-path="principal-components.html"><a href="principal-components.html"><i class="fa fa-check"></i><b>39</b> Principal Components</a><ul>
<li class="chapter" data-level="39.1" data-path="principal-components.html"><a href="principal-components.html#the-weather-somewhere"><i class="fa fa-check"></i><b>39.1</b> The weather, somewhere</a></li>
<li class="chapter" data-level="39.2" data-path="principal-components.html"><a href="principal-components.html#the-weather-somewhere-1"><i class="fa fa-check"></i><b>39.2</b> The weather, somewhere</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>40</b> Factor Analysis</a></li>
<li class="chapter" data-level="41" data-path="frequency-table-analysis.html"><a href="frequency-table-analysis.html"><i class="fa fa-check"></i><b>41</b> Frequency table analysis</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Problems and Solutions in Applied Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="analysis-of-variance" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Analysis of variance</h1>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" title="1"><span class="kw">library</span>(tidyverse)</a></code></pre></div>
<div id="movie-ratings-and-lengths" class="section level2">
<h2><span class="header-section-number">13.1</span> Movie ratings and lengths</h2>
<p>Before a movie is shown in theatres, it
receives a “rating” that says what kind of material it
contains. <a href="https://en.wikipedia.org/wiki/Motion_Picture_Association_of_America_film_rating_system">link</a>
explains the categories, from G (suitable for children) to R (anyone
under 17 must be accompanied by parent/guardian). In 2011, two
students collected data on the length (in minutes) and the rating
category, for 15 movies of each rating category, randomly chosen from
all the movies released that year. The data are at
<a href="http://ritsokiguess.site/datafiles/movie-lengths.csv">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R, and display (some of) what you read in.</p></li>
<li><p>Count how many movies there are of each rating.</p></li>
<li><p>Carry out an ANOVA and a Tukey
analysis (if warranted).</p></li>
<li><p>Make a graph to assess whether this ANOVA is
trustworthy. Discuss your graph and its implications briefly.</p></li>
</ol>
</div>
<div id="deer-and-how-much-they-eat" class="section level2">
<h2><span class="header-section-number">13.2</span> Deer and how much they eat</h2>
<p>Do adult deer eat different amounts of food at different
times of the year? The data in
<a href="http://ritsokiguess.site/datafiles/deer.txt">link</a> are the weights
of food (in kilograms) consumed by randomly selected adult deer
observed at different times of the year (in February, May, August and
November). We will assume that these were different deer observed in
the different months. (If the same animals had been observed at
different times, we would have been in the domain of
“repeated measures”, which would require a different analysis,
beyond the scope
of this course.)</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R, and calculate numbers of observations
and the median amounts of food
eaten each month.</p></li>
<li><p>Make side-by-side boxplots of the amount of food eaten each
month. Comment briefly on what you see.</p></li>
<li><p>Run a Mood’s median test as in lecture (ie. not using
<code>smmr</code>). What do you conclude, in the context of the data?</p></li>
<li><p>Run a Mood’s median test using <code>smmr</code>, and compare the
results with the previous part.</p></li>
<li><p>How is it that Mood’s median test does not completely answer the
question you really want to answer? How might you get an answer to the
question you <em>really</em> want answered? Explain briefly, and obtain
the answer you <em>really</em> want, discussing your results briefly.</p></li>
</ol>
</div>
<div id="movie-ratings-again" class="section level2">
<h2><span class="header-section-number">13.3</span> Movie ratings again</h2>
<p>This question again uses the movie rating data at
<a href="http://ritsokiguess.site/datafiles/movie-lengths.csv">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read the data into R and obtain the number of movies of
each rating and the <em>median</em> length of movies of each rating.</p></li>
<li><p>Obtain a suitable graph that assesses the assumptions for
ANOVA. Why do you think it is not reasonable to run ANOVA here? Explain
briefly.</p></li>
<li><p>Run a Mood’s median test (use <code>smmr</code> if you
like). What do you conclude, in the context of the data?</p></li>
</ol>
</div>
<div id="atomic-weight-of-carbon" class="section level2">
<h2><span class="header-section-number">13.4</span> Atomic weight of carbon</h2>
<p>The atomic weight of the chemical element
carbon is 12. Two methods of measuring the atomic weight of samples of
carbon were compared. The results are shown in
<a href="http://ritsokiguess.site/datafiles/carbon.txt">link</a>. The methods
are labelled 1 and 2. The first task is to find out whether the two
methods have different “typical” measures (mean or median, as
appropriate) of the atomic weight of carbon.</p>
<p>For this question, compose a report in R Markdown. (R Markdown is
what you use in an R Notebook, but you can also have a separate R
Markdown document from which you can produce HTML, Word etc. output.)
See part (a) for how to get this started.</p>
<p>Your report should
read like an actual report, not just the answers to some questions
that I set you. To help with that, write some text that links the
parts of the report together smoothly, so that it reads as a coherent
whole. The grader had 3 discretionary marks to award for the overall
quality of your writing. The scale for this was:</p>
<ul>
<li><p>3 points: excellent writing. The report flows smoothly, is easy
to read, and contains everything it should (and nothing it
shouldn’t).</p></li>
<li><p>2 points: satisfactory writing. Not the easiest to read, but
says what it should, and it looks at least somewhat like a report
rather than a string of answers to questions.</p></li>
<li><p>1 point: writing that is hard to read or to understand. If you
get this (or 0), you should consider what you need to do to improve
when you write your project.</p></li>
<li><p>0 points: you answered the questions, but you did almost nothing
to make it read like a report.</p></li>
</ul>
<ol style="list-style-type: lower-alpha">
<li><p>Create a new R Markdown document. To do this, in R Studio, select File,
New File, R Markdown. Type the report title and your name in the
boxes, and leave the output on the default HTML. Click OK.</p></li>
<li><p>Write an introduction that explains the purpose of this
study and the data collected in your own words.</p></li>
<li><p>Begin an appropriately-titled new section in your report,
read the data into R and display the results.</p></li>
<li><p>Make an appropriate plot to compare the measurements
obtained by the two methods. You might need to do something about
the two methods being given as numbers even though they are really
only identifiers. (If you do, your report ought to say what you did
and why.)</p></li>
<li><p>Comment briefly on what you see in your plot.</p></li>
<li><p>Carry out the most appropriate <span class="math inline">\(t\)</span>-test. (You might like to
begin another new section in your report here.)</p></li>
<li><p>Do the most appropriate test you know that does not assume
normally-distributed data.</p></li>
<li><p>Discuss the results of your tests and what they say about
the two methods for measuring the atomic weight of carbon. If it
seems appropriate, put the discussion into a section called
Conclusions.</p></li>
</ol>
</div>
<div id="can-caffeine-improve-your-performance-on-a-test" class="section level2">
<h2><span class="header-section-number">13.5</span> Can caffeine improve your performance on a test?</h2>
<p>Does caffeine help students do better on a certain test? To
find out, 36 students were randomly allocated to three groups (12 in
each group). Each student received a fixed number of cups of coffee
while they were studying, but the students didn’t know whether they
were receiving all full-strength coffee (“high”), all decaf coffee
(“low”) or a 50-50 mixture of the two (“moderate”). For each
subject, their group was recorded as well as their score on the
test. The data are in
<a href="http://ritsokiguess.site/datafiles/caffeine.csv">link</a>, as a
<code>.csv</code> file.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and examine the data. How are the values laid out?</p></li>
<li><p>Explain briefly how the data are not “tidy”.</p></li>
<li><p>Use a suitable tool from the <code>tidyverse</code> to create one
column of test scores and and one column of group labels. Call your
column of group labels <code>amount</code>. Is it a <code>factor</code>?</p></li>
<li><p>Obtain side-by-side boxplots of test scores by amount of caffeine.</p></li>
<li><p>Does caffeine amount seem to have an effect? If so, what
kind of effect?</p></li>
<li><p>Run a suitable analysis of variance to determine whether
the mean test score is equal or unequal for the three groups. What
do you conclude?</p></li>
<li><p>Why is it a good idea to run Tukey’s method here?</p></li>
<li><p>Run Tukey’s method. What do you conclude?</p></li>
</ol>
</div>
<div id="reggae-music" class="section level2">
<h2><span class="header-section-number">13.6</span> Reggae music</h2>
<p>Reggae is a music genre that originated in Jamaica in the late 1960s. One of the most famous reggae bands was Bob Marley and the Wailers.
In a survey, 729 students were asked to rate reggae music on a scale from 1, “don’t like it at all” to 6, “like it a lot”.
We will treat the ratings as quantitative.
Each student was also asked to classify their home town as one of “big city”, “suburban”, “small town”, “rural”. Does a student’s opinion of reggae depend on the kind of home town they come from? The data are in <a href="http://ritsokiguess.site/datafiles/reggae.csv">http://ritsokiguess.site/datafiles/reggae.csv</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and display (some of) the data.</p></li>
<li><p>How many students are from each different size of town?</p></li>
<li><p>Make a suitable graph of the two variables in this data frame.</p></li>
<li><p>Discuss briefly why you might prefer to run Mood’s median test to compare ratings among home towns.</p></li>
<li><p>Suppose that somebody wanted to run Welch ANOVA on these data. What would be a reasonable argument to support that?</p></li>
<li><p>Run Mood’s median test and display the output.</p></li>
<li><p>Explain briefly why running pairwise median tests is a good idea, run them, and display the results.</p></li>
<li><p>Summarize, as concisely as possible, how the home towns differ in terms of their students’ ratings of reggae music.</p></li>
</ol>
</div>
<div id="watching-tv-and-education" class="section level2">
<h2><span class="header-section-number">13.7</span> Watching TV and education</h2>
<p>The General Social Survey is a large survey of a large number of people. One of the questions on the survey is “how many hours of TV do you watch in a typical day?” Another is “what is your highest level of education attained”, on this scale:</p>
<ul>
<li><strong>HSorLess</strong>: completed no more than high h school</li>
<li><strong>College</strong>: completed some form of college, either a community college (like Centennial) or a four-year university (like UTSC)</li>
<li><strong>Graduate</strong>: completed a graduate degree such as an MSc.</li>
</ul>
<p>Do people with more education tend to watch more TV? We will be exploring this. The data are in <a href="http://ritsokiguess.site/datafiles/gss_tv.csv">http://ritsokiguess.site/datafiles/gss_tv.csv</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and display (some of) the data.</p></li>
<li><p>For each level of education, obtain the number of observations, the mean and the median of the number of hours of TV watched.</p></li>
<li><p>What does your answer to the previous part tell you about the shapes of the distributions of the numbers of hours of TV watched? Explain briefly.</p></li>
<li><p>Obtain a suitable graph of your data frame.</p></li>
<li><p>Does your plot indicate that your guess about the distribution shape was correct? Explain briefly.</p></li>
<li><p>Run a suitable test to compare the average number of hours of TV watched for people with each amount of education. (“Average” could be mean or median, whichever you think is appropriate.)</p></li>
<li><p>What do you conclude from your test, in the context of the data?</p></li>
<li><p>Why might you now want to run some kind of follow-up test? Run the appropriate thing and explain briefly what you conclude from it, in the context of the data.</p></li>
</ol>
</div>
<div id="death-of-poets" class="section level2">
<h2><span class="header-section-number">13.8</span> Death of poets</h2>
<p>Some people believe that poets, especially female poets, die younger than other types of writer. <a href="https://en.wikipedia.org/wiki/W._B._Yeats">William Butler Yeats</a><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> wrote:</p>
<blockquote>
<p>She is the Gaelic<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> muse, for she gives inspiration to those she persecutes. The Gaelic poets die young, for she is restless, and will not let them remain long on earth.</p>
</blockquote>
<p>A literature student wanted to investigate this, and so collected a sample of 123 female writers (of three different types), and noted the age at death of each writer.</p>
<p>The data are in <a href="http://ritsokiguess.site/datafiles/writers.csv">http://ritsokiguess.site/datafiles/writers.csv</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and display (some of) the data.</p></li>
<li><p>Make a suitable plot of the ages and types of writing.</p></li>
<li><p>Obtain a summary table showing, for each type of writing, the number of writers of that type, along with the mean, median and standard deviation of their ages at death.</p></li>
<li><p>Run a complete analysis, starting with an ordinary (not Welch) analysis of variance, that ends with a conclusion in the context of the data and an assessment of assumptions.</p></li>
</ol>
</div>
<div id="religion-and-studying" class="section level2">
<h2><span class="header-section-number">13.9</span> Religion and studying</h2>
<p>Many students at a certain university were asked about the importance of religion in their lives (categorized as “not”, “fairly”, or “very” important), and also about the number of
hours they spent studying per week. (This was part of a much larger survey.) We want to see whether there is any kind of relationship between these two variables. The data are in <a href="http://ritsokiguess.site/datafiles/student_relig.csv">here</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Read in and display (some of) the data.</p></li>
<li><p>Obtain the number of observations and the mean and standard deviation of study hours for each level of importance.</p></li>
<li><p>Comment briefly on how the groups compare in terms of study hours.</p></li>
<li><p>Make a suitable graph of this data set.</p></li>
<li><p>The statistician in this study decided that the data were sufficiently normal in shape given the (very large) sample sizes, but was concerned about unequal spreads among the three groups.
Given this,
run a suitable analysis and display the output. (This includes a suitable follow-up test, if warranted.)</p></li>
<li><p>What do you conclude from your analysis of the previous part, in the context of the data?</p></li>
</ol>
<p>My solutions follow:</p>
</div>
<div id="movie-ratings-and-lengths-1" class="section level2">
<h2><span class="header-section-number">13.10</span> Movie ratings and lengths</h2>
<p>Before a movie is shown in theatres, it
receives a “rating” that says what kind of material it
contains. <a href="https://en.wikipedia.org/wiki/Motion_Picture_Association_of_America_film_rating_system">link</a>
explains the categories, from G (suitable for children) to R (anyone
under 17 must be accompanied by parent/guardian). In 2011, two
students collected data on the length (in minutes) and the rating
category, for 15 movies of each rating category, randomly chosen from
all the movies released that year. The data are at
<a href="http://ritsokiguess.site/datafiles/movie-lengths.csv">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R, and display (some of) what you read in.</li>
</ol>
<p>Solution</p>
<p><code>read_csv</code>:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/movie-lengths.csv&quot;</span></a>
<a class="sourceLine" id="cb67-2" title="2">movies &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   length = col_double(),
##   rating = col_character()
## )</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" title="1">movies</a></code></pre></div>
<pre><code>## # A tibble: 60 x 2
##    length rating
##     &lt;dbl&gt; &lt;chr&gt; 
##  1     25 G     
##  2     75 G     
##  3     88 G     
##  4     63 G     
##  5     76 G     
##  6     97 G     
##  7     68 G     
##  8     82 G     
##  9     98 G     
## 10     74 G     
## # … with 50 more rows</code></pre>
<p>Something that looks like a length in minutes, and a rating.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Count how many movies there are of each rating.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" title="1">movies <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(rating)</a></code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   rating     n
##   &lt;chr&gt;  &lt;int&gt;
## 1 G         15
## 2 PG        15
## 3 PG-13     15
## 4 R         15</code></pre>
<p>Fifteen of each rating. (It’s common to have the same number of
observations in each group, but not necessary for a one-way ANOVA.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Carry out an ANOVA and a Tukey
analysis (if warranted).</li>
</ol>
<p>Solution</p>
<p>ANOVA first:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" title="1">length<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">aov</span>(length <span class="op">~</span><span class="st"> </span>rating, <span class="dt">data =</span> movies)</a>
<a class="sourceLine" id="cb73-2" title="2"><span class="kw">summary</span>(length<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## rating       3  14624    4875   11.72 4.59e-06 ***
## Residuals   56  23295     416                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This P-value is 0.00000459, which is way less than 0.05.</p>
<p>Having rejected the null (which said “all means equal”), we now need to
do Tukey, thus:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" title="1"><span class="kw">TukeyHSD</span>(length<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = length ~ rating, data = movies)
## 
## $rating
##                diff        lwr       upr     p adj
## PG-G      26.333333   6.613562 46.053104 0.0044541
## PG-13-G   42.800000  23.080229 62.519771 0.0000023
## R-G       30.600000  10.880229 50.319771 0.0007379
## PG-13-PG  16.466667  -3.253104 36.186438 0.1327466
## R-PG       4.266667 -15.453104 23.986438 0.9397550
## R-PG-13  -12.200000 -31.919771  7.519771 0.3660019</code></pre>
<p>Cast your eye down the <code>p adj</code> column and look for the ones
that are significant, here the first three. These are all comparisons
with the G (“general”) movies, which are shorter on average than the
others (which are not significantly different from each other).</p>
<p>If you like, you can make a table of means to verify that:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" title="1">movies <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb77-2" title="2"><span class="st">  </span><span class="kw">group_by</span>(rating) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb77-3" title="3"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(length))</a></code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   rating  mean
##   &lt;chr&gt;  &lt;dbl&gt;
## 1 G       80.6
## 2 PG     107. 
## 3 PG-13  123. 
## 4 R      111.</code></pre>
<p>When we do this problem in SAS, you’ll see the Tukey get handled a
different way, one that you might find more appealing.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Make a graph to assess whether this ANOVA is
trustworthy. Discuss your graph and its implications briefly.</li>
</ol>
<p>Solution</p>
<p>The obvious graph is a boxplot:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" title="1"><span class="kw">ggplot</span>(movies, <span class="kw">aes</span>(<span class="dt">x =</span> rating, <span class="dt">y =</span> length)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
<p>For ANOVA, we are looking for approximately normal distributions
within each group and approximately equal spreads. Without the
outliers, I would be more or less happy with that, but the G movies
have a low outlier that would pull the mean down and the PG and PG-13
movies have outliers that would pull the mean up. So a comparison of
means might make the differences look more significant than they
should. Having said that, you could also say that the ANOVA is
<em>very</em> significant, so even considering the effect of the
outliers, the differences between G and the others are still likely to
be significant.</p>
<p>Extra: the way to go if you don’t trust the ANOVA is (as for the
two-sample <span class="math inline">\(t\)</span>) the Mood’s median test. This applies to any number of
groups, and works in the same way as before:</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" title="1"><span class="kw">library</span>(smmr)</a>
<a class="sourceLine" id="cb80-2" title="2"><span class="kw">median_test</span>(movies, length, rating)</a></code></pre></div>
<pre><code>## $table
##        above
## group   above below
##   G         2    13
##   PG        7     7
##   PG-13    12     3
##   R         8     6
## 
## $test
##        what        value
## 1 statistic 13.752380952
## 2        df  3.000000000
## 3   P-value  0.003262334</code></pre>
<p>Still significant, though not quite as small a P-value as before
(which echoes our thoughts about what the outliers might do to the
means). If you look at the table above the test results, you see that
the G movies are mostly shorter than the overall median, but now the
PG-13 movies are mostly <em>longer</em>. So the picture is a little
different.</p>
<p>Mood’s median test does not naturally come with something like Tukey.
What you can do is to do all the pairwise Mood’s median tests, between
each pair of groups, and then adjust to allow for your having done
several tests at once. I thought this was generally useful enough that
I put it into <code>smmr</code> under the name <code>pairwise_median_test</code>:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" title="1"><span class="kw">pairwise_median_test</span>(movies, length, rating)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 4
##   g1    g2      p_value adj_p_value
##   &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;       &lt;dbl&gt;
## 1 G     PG    0.00799      0.0479  
## 2 G     PG-13 0.0000590    0.000354
## 3 G     R     0.0106       0.0635  
## 4 PG    PG-13 0.0106       0.0635  
## 5 PG    R     0.715        1       
## 6 PG-13 R     0.273        1</code></pre>
<p>You can ignore those (adjusted) P-values rather stupidly bigger than
1. These are not significant.</p>
<p>There are two significant differences in median length: between G
movies and the two flavours of PG movies. The G movies are
significantly shorter (as you can tell from the boxplot), but the
difference between G and R movies is no longer significant (a change
from the regular ANOVA).</p>
<p>You may be puzzled by something in the boxplot: how is it that the G
movies are significantly shorter than the PG movies, but not
significantly shorter than the R movies, <em>when the difference in
medians between G and R movies is bigger</em>? In Tukey, if the
difference in means is bigger, the P-value is
smaller.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>
The resolution to this puzzle, such as it is, is that Mood’s median
test is not directly comparing the medians of the groups (despite its
name); it’s counting values above and below a <em>joint</em> median,
which might be a different story.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="deer-and-how-much-they-eat-1" class="section level2">
<h2><span class="header-section-number">13.11</span> Deer and how much they eat</h2>
<p>Do adult deer eat different amounts of food at different
times of the year? The data in
<a href="http://ritsokiguess.site/datafiles/deer.txt">link</a> are the weights
of food (in kilograms) consumed by randomly selected adult deer
observed at different times of the year (in February, May, August and
November). We will assume that these were different deer observed in
the different months. (If the same animals had been observed at
different times, we would have been in the domain of
“repeated measures”, which would require a different analysis,
beyond the scope
of this course.)</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R, and calculate numbers of observations
and the median amounts of food
eaten each month.</li>
</ol>
<p>Solution</p>
<p>The usual stuff for data values separated by (single) spaces:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" title="1">myurl &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/deer.txt&quot;</span></a>
<a class="sourceLine" id="cb84-2" title="2">deer &lt;-<span class="st"> </span><span class="kw">read_delim</span>(myurl, <span class="st">&quot; &quot;</span>)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   month = col_character(),
##   food = col_double()
## )</code></pre>
<p>and then, recalling that <code>n()</code> is the handy way of getting the
number of observations in each group:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" title="1">deer <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb86-2" title="2"><span class="st">  </span><span class="kw">group_by</span>(month) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb86-3" title="3"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">med =</span> <span class="kw">median</span>(food))</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   month     n   med
##   &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;
## 1 Aug       6  4.7 
## 2 Feb       5  4.8 
## 3 May       6  4.35
## 4 Nov       5  5.2</code></pre>
<p>When you want the number of observations <em>plus</em> some other
summaries, as here, the group-by and summarize idea is the way, using
<code>n()</code> to get the number of observations in each
group. <code>count</code> counts the number of observations per group when
you <em>only</em> have grouping variables.</p>
<p>The medians differ a bit, but it’s hard to judge without a sense of
spread, which the boxplots (next) provide. November is a bit higher
and May a bit lower.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make side-by-side boxplots of the amount of food eaten each
month. Comment briefly on what you see.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" title="1"><span class="kw">ggplot</span>(deer, <span class="kw">aes</span>(<span class="dt">x =</span> month, <span class="dt">y =</span> food)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
<p>This offers the suggestion that maybe November will be significantly
higher than the rest and May significantly lower, or at least they
will be significantly different from each other.</p>
<p>This is perhaps getting ahead of the game: we should be thinking about
spread and shape. Bear in mind that there are only 5 or 6 observations
in each group, so you won’t be able to say much about normality. In
any case, we are going to be doing a Mood’s median test, so any lack
of normality doesn’t matter (eg. perhaps that 4.4 observation in
August). Given the small sample sizes, I actually think the spreads
are quite similar.</p>
<p>Another way of looking at the data, especially with these small sample
sizes, is a “dot plot”: instead of making a boxplot for each month,
we plot the actual points for each month as if we were making a
scatterplot:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" title="1"><span class="kw">ggplot</span>(deer, <span class="kw">aes</span>(<span class="dt">x =</span> month, <span class="dt">y =</span> food)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
<p>Wait a minute. There were five deer in February and six in
August. Where did they go?</p>
<p>The problem is <em>overplotting</em>: more than one of the deer plotted
in the same place on the plot, because the amounts of food eaten were
only given to one decimal place and there were some duplicated values.
One way to solve this is to randomly
move the points around so that no two of them plot in the same
place. This is called <em>jittering</em>, and is done like this:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" title="1"><span class="kw">ggplot</span>(deer, <span class="kw">aes</span>(<span class="dt">x =</span> month, <span class="dt">y =</span> food)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="dv">0</span>, <span class="dt">height =</span> <span class="fl">0.05</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<p>Now you see all the deer, and you can see that two pairs of points in
August and one pair of points in February are close enough on the
jittered plot that they would have been the same to one decimal place.</p>
<p>I wanted to
keep the points above the months they belong to, so I only allowed vertical
jitter (that’s the <code>width</code> and <code>height</code> in the
<code>geom_jitter</code>; the width is zero so there is no horizontal
jittering).
If you like, you can colour the
months; it’s up to you whether you think that’s making the plot easier
to read, or is overkill (see my point on the facetted plots on the
2017 midterm).</p>
<p>This way you see the whole distribution for each month. Normally it’s
nicer to see the summary made by the boxplots, but here there are not
very many points. The value of 4.4 in August does look quite a bit
lower than the rest, but the other months look believably normal given
the small sample sizes. I don’t know about equal spreads (November
looks more spread out), but normality looks believable. Maybe this is
the kind of situation in which Welch’s ANOVA is a good idea. (If you
believe that the normality-with-unequal-spreads is a reasonable
assumption to make, then the Welch ANOVA will be more powerful than
the Mood’s median test, and so should be preferred.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Run a Mood’s median test as in lecture (ie. not using
<code>smmr</code>). What do you conclude, in the context of the data?</li>
</ol>
<p>Solution</p>
<p>To give you some practice with the mechanics, first find the
overall median:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" title="1">deer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">med =</span> <span class="kw">median</span>(food))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##     med
##   &lt;dbl&gt;
## 1   4.7</code></pre>
<p>or</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" title="1"><span class="kw">median</span>(deer<span class="op">$</span>food)</a></code></pre></div>
<pre><code>## [1] 4.7</code></pre>
<p>I like the first way because it’s the same idea as we did before, just
not differentiating by month. I think there are some observations
exactly equal to the median, which will mess things up later:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" title="1">deer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(food <span class="op">==</span><span class="st"> </span><span class="fl">4.7</span>)</a></code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   month  food
##   &lt;chr&gt; &lt;dbl&gt;
## 1 Feb     4.7
## 2 Feb     4.7
## 3 Aug     4.7
## 4 Aug     4.7</code></pre>
<p>There are, two in February and two in August.</p>
<p>Next, make (and save) a table of the observations within each month
that are above and below this median:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" title="1">tab1 &lt;-<span class="st"> </span><span class="kw">with</span>(deer, <span class="kw">table</span>(month, food <span class="op">&lt;</span><span class="st"> </span><span class="fl">4.7</span>))</a>
<a class="sourceLine" id="cb97-2" title="2">tab1</a></code></pre></div>
<pre><code>##      
## month FALSE TRUE
##   Aug     4    2
##   Feb     5    0
##   May     0    6
##   Nov     5    0</code></pre>
<p>or</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" title="1">tab2 &lt;-<span class="st"> </span><span class="kw">with</span>(deer, <span class="kw">table</span>(month, food <span class="op">&gt;</span><span class="st"> </span><span class="fl">4.7</span>))</a>
<a class="sourceLine" id="cb99-2" title="2">tab2</a></code></pre></div>
<pre><code>##      
## month FALSE TRUE
##   Aug     4    2
##   Feb     2    3
##   May     6    0
##   Nov     0    5</code></pre>
<p>Either of these is good, but note that they are different. Two of the
February observations (the ones that were exactly 4.7) have
“switched sides”,
and (look carefully) two of the August ones also. Hence the
test results will be different, and <code>smmr</code> (later) will give
different results again:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb101-1" title="1"><span class="kw">chisq.test</span>(tab1, <span class="dt">correct =</span> F)</a></code></pre></div>
<pre><code>## Warning in chisq.test(tab1, correct = F): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tab1
## X-squared = 16.238, df = 3, p-value = 0.001013</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" title="1"><span class="kw">chisq.test</span>(tab2, <span class="dt">correct =</span> F)</a></code></pre></div>
<pre><code>## Warning in chisq.test(tab2, correct = F): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tab2
## X-squared = 11.782, df = 3, p-value = 0.008168</code></pre>
<p>The warnings are because of the small frequencies. If you’ve done
these by hand before (which you will have if you took PSYC08), you’ll
remember that thing about “expected frequencies less than 5”. This
is that. It means “don’t take those P-values <em>too</em> seriously.”</p>
<p>The P-values are different, but they are both clearly significant, so the
median amounts of food eaten in the different months are not all the
same. (This is the same “there are differences” that you get from an
ANOVA, which you would follow up with Tukey.) Despite the injunction
not to take the P-values too seriously, I think these are small enough
that they could be off by a bit without affecting the conclusion.</p>
<p>The first table came out with a smaller P-value because it looked more
extreme: all of the February measurements were taken as higher than
the overall median (since we were counting “strictly less” and
“the rest”). In the second table, the February measurements look more
evenly split, so the overall P-value is not quite so small.</p>
<p>You can make a guess as to what <code>smmr</code> will come out with
(next), since it throws away any data values exactly equal to the median.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Run a Mood’s median test using <code>smmr</code>, and compare the
results with the previous part.</li>
</ol>
<p>Solution</p>
<p>Off we go:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb107-1" title="1"><span class="kw">library</span>(smmr)</a>
<a class="sourceLine" id="cb107-2" title="2"><span class="kw">median_test</span>(deer, food, month)</a></code></pre></div>
<pre><code>## $table
##      above
## group above below
##   Aug     2     2
##   Feb     3     0
##   May     0     6
##   Nov     5     0
## 
## $test
##        what        value
## 1 statistic 13.950000000
## 2        df  3.000000000
## 3   P-value  0.002974007</code></pre>
<p>The P-value came out in between the other two, but the conclusion is
the same all three ways: the months are not all the same in terms of
median food eaten. The researchers can then go ahead and try to figure
out <em>why</em> the animals eat different amounts in the different months.</p>
<p>You might be wondering how you could get rid of the equal-to-median
values in the build-it-yourself way. This is <code>filter</code> from
<code>dplyr</code>, which you use first:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb109-1" title="1">deer2 &lt;-<span class="st"> </span>deer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(food <span class="op">!=</span><span class="st"> </span><span class="fl">4.7</span>)</a>
<a class="sourceLine" id="cb109-2" title="2">tab3 &lt;-<span class="st"> </span><span class="kw">with</span>(deer2, <span class="kw">table</span>(month, food <span class="op">&lt;</span><span class="st"> </span><span class="fl">4.7</span>))</a>
<a class="sourceLine" id="cb109-3" title="3">tab3</a></code></pre></div>
<pre><code>##      
## month FALSE TRUE
##   Aug     2    2
##   Feb     3    0
##   May     0    6
##   Nov     5    0</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb111-1" title="1"><span class="kw">chisq.test</span>(tab3)</a></code></pre></div>
<pre><code>## Warning in chisq.test(tab3): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tab3
## X-squared = 13.95, df = 3, p-value = 0.002974</code></pre>
<p>which is exactly what <code>smmr</code> does, so the answer is
identical.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>
How would an ANOVA come out here? My guess is, very similarly:</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" title="1">deer<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">aov</span>(food <span class="op">~</span><span class="st"> </span>month, <span class="dt">data =</span> deer)</a>
<a class="sourceLine" id="cb114-2" title="2"><span class="kw">summary</span>(deer<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## month        3 2.3065  0.7688   22.08 2.94e-06 ***
## Residuals   18 0.6267  0.0348                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" title="1"><span class="kw">TukeyHSD</span>(deer<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = food ~ month, data = deer)
## 
## $month
##               diff         lwr        upr     p adj
## Feb-Aug  0.1533333 -0.16599282  0.4726595 0.5405724
## May-Aug -0.3333333 -0.63779887 -0.0288678 0.0290758
## Nov-Aug  0.5733333  0.25400718  0.8926595 0.0004209
## May-Feb -0.4866667 -0.80599282 -0.1673405 0.0021859
## Nov-Feb  0.4200000  0.08647471  0.7535253 0.0109631
## Nov-May  0.9066667  0.58734052  1.2259928 0.0000013</code></pre>
<p>The conclusion is the same, but the P-value on the <span class="math inline">\(F\)</span>-test is much
smaller. I think this is because the <span class="math inline">\(F\)</span>-test uses the actual values,
rather than just whether they are bigger or smaller than 4.7. The
Tukey says that all the months are different in terms of (now) mean,
except for February and August, which were those two very similar ones
on the boxplot.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>How is it that Mood’s median test does not completely answer the
question you really want to answer? How might you get an answer to the
question you <em>really</em> want answered? Explain briefly, and obtain
the answer you <em>really</em> want, discussing your results briefly.</li>
</ol>
<p>Solution</p>
<p>That’s rather a lot, so let’s take those things one at a
time.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<p>Mood’s median test is really like the <span class="math inline">\(F\)</span>-test in ANOVA: it’s testing
the null hypothesis
that the groups (months) all have the same median (of food eaten),
against the alternative that the null is not true. We rejected this
null, but we don’t know which months differ significantly from
which. To resolve this in ANOVA, we do Tukey (or Games-Howell if we
did the Welch ANOVA). The corresponding thing here is to do all the
possible two-group Mood tests on all the pairs of groups, and, after
adjusting for doing (here) six tests at once, look at the adjusted
P-values to see how the months differ in terms of food eaten.</p>
<p>This is accomplished in <code>smmr</code> via <code>pairwise_median_test</code>,
thus:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" title="1"><span class="kw">pairwise_median_test</span>(deer, food, month)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 4
##   g1    g2    p_value adj_p_value
##   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;       &lt;dbl&gt;
## 1 Aug   Feb   0.147       0.884  
## 2 Aug   May   0.0209      0.126  
## 3 Aug   Nov   0.00270     0.0162 
## 4 Feb   May   0.00157     0.00939
## 5 Feb   Nov   0.0578      0.347  
## 6 May   Nov   0.00157     0.00939</code></pre>
<p>This compares each month with each other month. Looking at the last
column, there are only three significant differences: August-November,
February-May and May-November. Going back to the table of medians we
made in (a), November is significantly higher (in terms of median food
eaten) than August and May (but not February), and February is
significantly higher than May. The other differences are not big
enough to be significant.</p>
<p>Extra: Pairwise median tests done this way are not likely to be very
sensitive (that is, powerful), for a couple of reasons: (i) the usual
one that the median tests don’t use the data very efficiently, and
(ii) the way I go from the unadjusted to the adjusted P-values is via
Bonferroni (here, multiply the P-values by 6), which is known to be
safe but conservative. This is why the Tukey produced more significant
differences among the months than the pairwise median tests did.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="movie-ratings-again-1" class="section level2">
<h2><span class="header-section-number">13.12</span> Movie ratings again</h2>
<p>This question again uses the movie rating data at
<a href="http://ritsokiguess.site/datafiles/movie-lengths.csv">link</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read the data into R and obtain the number of movies of
each rating and the <em>median</em> length of movies of each rating.</li>
</ol>
<p>Solution</p>
<p>Reading in is as in the other question using these data (just copy
your code, or mine).</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/movie-lengths.csv&quot;</span></a>
<a class="sourceLine" id="cb120-2" title="2">movies &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   length = col_double(),
##   rating = col_character()
## )</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" title="1">movies</a></code></pre></div>
<pre><code>## # A tibble: 60 x 2
##    length rating
##     &lt;dbl&gt; &lt;chr&gt; 
##  1     25 G     
##  2     75 G     
##  3     88 G     
##  4     63 G     
##  5     76 G     
##  6     97 G     
##  7     68 G     
##  8     82 G     
##  9     98 G     
## 10     74 G     
## # … with 50 more rows</code></pre>
<p>Now, the actual for-credit part, which is a <code>group_by</code> and
<code>summarize</code>:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" title="1">movies <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb124-2" title="2"><span class="st">  </span><span class="kw">group_by</span>(rating) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb124-3" title="3"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>(), <span class="dt">med =</span> <span class="kw">median</span>(length))</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   rating count   med
##   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;
## 1 G         15    82
## 2 PG        15   100
## 3 PG-13     15   117
## 4 R         15   103</code></pre>
<p>The G movies have a smaller median than the others, but also the PG-13
movies seem to be longer on average (not what we found before).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Obtain a suitable graph that assesses the assumptions for
ANOVA. Why do you think it is not reasonable to run ANOVA here? Explain
briefly.</li>
</ol>
<p>Solution</p>
<p>The graph would seem to be a boxplot, side by side for each group:</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" title="1"><span class="kw">ggplot</span>(movies, <span class="kw">aes</span>(<span class="dt">x =</span> rating, <span class="dt">y =</span> length)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-96-1.png" width="672" /></p>
<p>We are looking for approximate normal distributions with approximately
equal spreads, which I don’t think we have: there are outliers, at the
low end for G movies, and at the high end for PG and PG-13
movies. Also, you might observe that the distribution of lengths for R
movies is skewed to the right. (Noting either the outliers or skewness
as a reason for not believing normality is enough, since all we need
is <em>one</em> way that normality fails.)</p>
<p>I think the spreads (as measured by the interquartile ranges) are
acceptably similar, but since we have rejected normality, it is a bit
late for that.</p>
<p>So I think it is far from reasonable to run an ANOVA here. In my
opinion 15 observations in each group is not enough to gain much from
the Central Limit Theorem either.</p>
<p>Extra: since part of the assumption for ANOVA is (approximate)
normality, it would also be entirely reasonable to make normal
quantile plots, one for each movie type, facetted. Remember the
process: you pretend that you are making a normal quantile plot for
all the data together, regardless of group, and then at the last
minute, you throw in a <code>facet_wrap</code>. I’ve written the code out
on three lines, so that you can see the pieces: the “what to plot”,
then the normal quantile plot part, then the facetting:</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb127-1" title="1"><span class="kw">ggplot</span>(movies, <span class="kw">aes</span>(<span class="dt">sample =</span> length)) <span class="op">+</span></a>
<a class="sourceLine" id="cb127-2" title="2"><span class="st">  </span><span class="kw">stat_qq</span>() <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb127-3" title="3"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>rating)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-97-1.png" width="672" /></p>
<p>Since there are four movie ratings, <code>facet_wrap</code> has arranged
them into a <span class="math inline">\(2\times 2\)</span> grid, which satisfyingly means that each
normal quantile plot is more or less square and thus easy to
interpret.</p>
<p>The principal problem unveiled by these plots is outliers. It looks as
if the G movies have one low outlier, the PG movies have two high
outliers, the PG-13 movies have one or maybe three high outliers
(depending on how you count them), and the R movies have none. Another
way to look at the last two is you could call them curved, with too
much bunching up at the bottom and (on PG-13) too much spread-out-ness
at the top, indicating right-skewed distributions. The distribution
of lengths of the R-rated movies is too bunched up at the bottom, but
as you would expect for a normal at the top. The R movies show the
right-skewedness in an odd way: usually this skewness shows up by
having too many high values, but this time it’s having too <em>few</em>
<em>low</em> values.</p>
<p>The assumption for ANOVA is that all four of these are at least
approximately normal (with the same spread). We found problems with
the normality on at least three of them, so we definitely have doubts
about trusting ANOVA here.</p>
<p>I could have used <code>scales=free</code> here to get a separate <span class="math inline">\(y\)</span>-axis
for each plot, but since the <span class="math inline">\(y\)</span>-axis is movie length each time, and
all four groups would be expected to have at least roughly similar
movie lengths, I left it as it was. (The other advantage of leaving
the scales the same is that you can compare spread by comparing the
slopes of the lines on these graphs; since the lines connect the
observed and theoretical quartiles, a steeper slope means a larger
IQR. Here, the R line is steepest and the PG line is flattest. Compare
this with the spreads of the boxplots.)</p>
<p>Extra extra: if you want, you can compare the normal quantile plots
with the boxplots to see whether you get the same conclusion from
both. For the G movies, the low outlier shows up both ways, and the
rest of the distribution is at least more or less normal. For the PG
movies, I’d say the distribution is basically normal except for the
highest two values (on both plots). For the PG-13 movies, only the
highest value shows up as an outlier, but the next two apparent
outliers on the normal quantile plot are at the upper end of the long
upper whisker, so the boxplot is saying “right-skewed with one upper outlier” rather than “three upper outliers”. The distribution of
the R movies is skewed right, with the bunching at the bottom showing
up as the very small lower whisker.</p>
<p>The boxplots and the normal quantile plots are basically telling the
same story in each case, but they are doing it in a slightly different
way.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Run a Mood’s median test (use <code>smmr</code> if you
like). What do you conclude, in the context of the data?</li>
</ol>
<p>Solution</p>
<p>The smart way is to use <code>smmr</code>, since it is much easier:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" title="1"><span class="kw">library</span>(smmr)</a>
<a class="sourceLine" id="cb128-2" title="2"><span class="kw">median_test</span>(movies, length, rating)</a></code></pre></div>
<pre><code>## $table
##        above
## group   above below
##   G         2    13
##   PG        7     7
##   PG-13    12     3
##   R         8     6
## 
## $test
##        what        value
## 1 statistic 13.752380952
## 2        df  3.000000000
## 3   P-value  0.003262334</code></pre>
<p>The movies do not all have the same median length, or at least one of
the rating types has movies of different median length from the
others. Or something equivalent to that. It’s the same conclusion as
for ANOVA, only with medians instead of means.</p>
<p>You can speculate about why the test came out significant.
My guess is that the G movies are shorter than
average, and that the PG-13 movies are longer than average. (We had
the first conclusion before, but not the second. This is where medians
are different from means.)</p>
<p>The easiest way to see which movie types really differ in length from
which is to do all the pairwise median tests, which is in
<code>smmr</code> thus:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" title="1"><span class="kw">pairwise_median_test</span>(movies, length, rating)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 4
##   g1    g2      p_value adj_p_value
##   &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;       &lt;dbl&gt;
## 1 G     PG    0.00799      0.0479  
## 2 G     PG-13 0.0000590    0.000354
## 3 G     R     0.0106       0.0635  
## 4 PG    PG-13 0.0106       0.0635  
## 5 PG    R     0.715        1       
## 6 PG-13 R     0.273        1</code></pre>
<p>The inputs for this are the same ones in the same order as for
<code>median_test</code>. (A design decision on my part, since otherwise
<em>I</em> would never have been able to remember how to run these!)
Only the first two of these are significant (look in the last
column). We can remind ourselves of the sample medians:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" title="1">movies <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb132-2" title="2"><span class="st">  </span><span class="kw">group_by</span>(rating) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb132-3" title="3"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>(), <span class="dt">med =</span> <span class="kw">median</span>(length))</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   rating count   med
##   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;
## 1 G         15    82
## 2 PG        15   100
## 3 PG-13     15   117
## 4 R         15   103</code></pre>
<p>The G movies are significantly shorter than the PG and PG-13 movies,
but not quite significantly different from the R movies. This is a
little odd, since the difference in sample medians between G and PG,
significant, is <em>less</em> than for G and R (not significant).
There are several Extras here, which you can skip if you don’t care
about the background. First, we can do the median test by hand:
This has about four steps: (i) find the median of all the data, (ii) make a
table tabulating the number of values above and below the overall
median for each group, (iii) test the table for association, (iv)
draw a conclusion.
Thus (i):</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" title="1"><span class="kw">median</span>(movies<span class="op">$</span>length)</a></code></pre></div>
<pre><code>## [1] 100</code></pre>
<p>or</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" title="1">movies <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">med =</span> <span class="kw">median</span>(length))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##     med
##   &lt;dbl&gt;
## 1   100</code></pre>
<p>or store it in a variable,
and then (ii):</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" title="1">tab1 &lt;-<span class="st"> </span><span class="kw">with</span>(movies, <span class="kw">table</span>(length <span class="op">&lt;</span><span class="st"> </span><span class="dv">100</span>, rating))</a>
<a class="sourceLine" id="cb138-2" title="2">tab1</a></code></pre></div>
<pre><code>##        rating
##          G PG PG-13  R
##   FALSE  2  8    12  9
##   TRUE  13  7     3  6</code></pre>
<p>or</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb140-1" title="1">tab2 &lt;-<span class="st"> </span><span class="kw">with</span>(movies, <span class="kw">table</span>(length <span class="op">&gt;</span><span class="st"> </span><span class="dv">100</span>, rating))</a>
<a class="sourceLine" id="cb140-2" title="2">tab2</a></code></pre></div>
<pre><code>##        rating
##          G PG PG-13  R
##   FALSE 13  8     3  7
##   TRUE   2  7    12  8</code></pre>
<p>These differ because there are evidently some movies of length exactly
100 minutes, and it matters whether you count <span class="math inline">\(&lt;\)</span> and <span class="math inline">\(\ge\)</span> (as in
<code>tab1</code>) or <span class="math inline">\(&gt;\)</span> and <span class="math inline">\(le\)</span> (<code>tab2</code>). Either is good.</p>
<p>Was I right about movies of length exactly 100 minutes?</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb142-1" title="1">movies <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(length <span class="op">==</span><span class="st"> </span><span class="dv">100</span>)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   length rating
##    &lt;dbl&gt; &lt;chr&gt; 
## 1    100 PG    
## 2    100 R</code></pre>
<p>One PG and one R. It makes a difference to the R movies, but if you
look carefully, it makes a difference to the PG movies as well,
because the False and True switch roles between <code>tab1</code> and
<code>tab2</code> (compare the G movies, for instance).
You
need to store your table in a variable because it has to get passed on
to <code>chisq.test</code> below, (iii):</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb144-1" title="1"><span class="kw">chisq.test</span>(tab1, <span class="dt">correct =</span> F)</a></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tab1
## X-squared = 14.082, df = 3, p-value = 0.002795</code></pre>
<p>or</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb146-1" title="1"><span class="kw">chisq.test</span>(tab2, <span class="dt">correct =</span> F)</a></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tab2
## X-squared = 13.548, df = 3, p-value = 0.003589</code></pre>
<p>Either is correct, or, actually, without the <code>correct=F</code>.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
<p>The conclusion (iv) is the same either way: the null of no association
is clearly rejected (with a P-value of 0.0028 or 0.0036 as
appropriate), and therefore whether a movie is longer or shorter than
median length depends on what rating it has: that is, the median
lengths do differ among the ratings. The same conclusion, in other
words, as the <span class="math inline">\(F\)</span>-test gave, though with not quite such a small
P-value.</p>
<p>Second, you might be curious about how
we might do something like Tukey having found some significant
differences (that is, what’s lurking in the background of
<code>pairwise_median_test</code>).</p>
<p>Let’s first suppose we are comparing G and PG movies. We need
to pull out just those, and then compare them using
<code>smmr</code>. Because the first input to <code>median_test</code> is a
data frame, it fits neatly into a pipe (with the data frame omitted):</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb148-1" title="1">movies <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb148-2" title="2"><span class="st">  </span><span class="kw">filter</span>(rating <span class="op">==</span><span class="st"> &quot;G&quot;</span> <span class="op">|</span><span class="st"> </span>rating <span class="op">==</span><span class="st"> &quot;PG&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb148-3" title="3"><span class="st">  </span><span class="kw">median_test</span>(length, rating)</a></code></pre></div>
<pre><code>## $table
##      above
## group above below
##    G      4    11
##    PG    10     3
## 
## $test
##        what       value
## 1 statistic 7.035897436
## 2        df 1.000000000
## 3   P-value 0.007989183</code></pre>
<p>We’re going to be doing this about six times — <span class="math inline">\({4 \choose 2}=6\)</span> choices
of two rating groups to compare out of the four — so we should have a
function to do it. I think the input to the function should be a data
frame that has a column called <code>rating</code>, and two names of
ratings to compare:</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb150-1" title="1">comp2 &lt;-<span class="st"> </span><span class="cf">function</span>(rat_<span class="dv">1</span>, rat_<span class="dv">2</span>, d) {</a>
<a class="sourceLine" id="cb150-2" title="2">  d <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb150-3" title="3"><span class="st">    </span><span class="kw">filter</span>(rating <span class="op">==</span><span class="st"> </span>rat_<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>rating <span class="op">==</span><span class="st"> </span>rat_<span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb150-4" title="4"><span class="st">    </span><span class="kw">median_test</span>(length, rating)</a>
<a class="sourceLine" id="cb150-5" title="5">}</a></code></pre></div>
<p>The way I wrote this function is that you have to specify the movie
ratings in quotes. It is <em>possible</em> to write it in such a way
that you input them without quotes, <code>tidyverse</code> style, but that
gets into “non-standard evaluation” and <code>enquo()</code> and
<code>!!</code>, which (i) I have to look up every time I want to do it,
and (ii) I am feeling that the effort involved in explaining it to you
is going to exceed the benefit you will gain from it. I mastered it enough
to make it work in <code>smmr</code> (note that you specify column names
without quotes there). There are tutorials on this kind of thing if
you’re interested.</p>
<p>Anyway, testing:</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb151-1" title="1"><span class="kw">comp2</span>(<span class="st">&quot;G&quot;</span>, <span class="st">&quot;PG&quot;</span>, movies)</a></code></pre></div>
<pre><code>## $table
##      above
## group above below
##    G      4    11
##    PG    10     3
## 
## $test
##        what       value
## 1 statistic 7.035897436
## 2        df 1.000000000
## 3   P-value 0.007989183</code></pre>
<p>That works, but I really only want to pick out the P-value, which is
in the list item <code>test</code> in the column <code>value</code>, the third
entry. So let’s rewrite the function to return just that:</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb153-1" title="1">comp2 &lt;-<span class="st"> </span><span class="cf">function</span>(rat_<span class="dv">1</span>, rat_<span class="dv">2</span>, d) {</a>
<a class="sourceLine" id="cb153-2" title="2">  d <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb153-3" title="3"><span class="st">    </span><span class="kw">filter</span>(rating <span class="op">==</span><span class="st"> </span>rat_<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>rating <span class="op">==</span><span class="st"> </span>rat_<span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb153-4" title="4"><span class="st">    </span><span class="kw">median_test</span>(length, rating) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb153-5" title="5"><span class="st">    </span><span class="kw">pluck</span>(<span class="st">&quot;test&quot;</span>, <span class="st">&quot;value&quot;</span>, <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb153-6" title="6">}</a>
<a class="sourceLine" id="cb153-7" title="7"><span class="kw">comp2</span>(<span class="st">&quot;G&quot;</span>, <span class="st">&quot;PG&quot;</span>, movies)</a></code></pre></div>
<pre><code>## [1] 0.007989183</code></pre>
<p>Gosh.</p>
<p>What <code>median_test</code> returns is an R <code>list</code> that has two
things in it, one called <code>table</code> and one called
<code>test</code>. The thing called <code>test</code> is a data frame with a
column called <code>value</code> that contains the P-values. The third of
these is the two-sided P-value that we want.</p>
<p>You might not have seen <code>pluck</code> before. This is a way of
getting things out of complicated data structures. This one takes the
output from <code>median_test</code> and from it grabs the piece called
<code>test</code>. This is a data frame. Next, we want the column called
<code>value</code>, and from that we want the third row. These are
specified one after the other to <code>pluck</code> and it pulls out the
right thing.</p>
<p>So now our function returns just the P-value.</p>
<p>I have to say that it took me several goes and some playing around in
R Studio to sort this one out. Once I thought I understood
<code>pluck</code>, I wondered why my function was not returning a
value. And then I realized that I was saving the value inside the
function and not returning it. Ooops. The nice thing about
<code>pluck</code> is that I can put it on the end of the pipeline and and
it will pull out (and return) whatever I want it to.</p>
<p>Let’s grab a hold of the different rating groups we have:</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb155-1" title="1">the_ratings &lt;-<span class="st"> </span><span class="kw">unique</span>(movies<span class="op">$</span>rating)</a>
<a class="sourceLine" id="cb155-2" title="2">the_ratings</a></code></pre></div>
<pre><code>## [1] &quot;G&quot;     &quot;PG-13&quot; &quot;PG&quot;    &quot;R&quot;</code></pre>
<p>The Pythonisti among you will know how to finish this off: do a
loop-inside-a-loop over the rating groups, and get the P-value for
each pair. You can do that in R, if you must. It’s not pretty at all,
but it works:</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb157-1" title="1">ii &lt;-<span class="st"> </span><span class="kw">character</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb157-2" title="2">jj &lt;-<span class="st"> </span><span class="kw">character</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb157-3" title="3">pp &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb157-4" title="4"><span class="cf">for</span> (i <span class="cf">in</span> the_ratings) {</a>
<a class="sourceLine" id="cb157-5" title="5">  <span class="cf">for</span> (j <span class="cf">in</span> the_ratings) {</a>
<a class="sourceLine" id="cb157-6" title="6">    pval &lt;-<span class="st"> </span><span class="kw">comp2</span>(i, j, movies)</a>
<a class="sourceLine" id="cb157-7" title="7">    ii &lt;-<span class="st"> </span><span class="kw">c</span>(ii, i)</a>
<a class="sourceLine" id="cb157-8" title="8">    jj &lt;-<span class="st"> </span><span class="kw">c</span>(jj, j)</a>
<a class="sourceLine" id="cb157-9" title="9">    pp &lt;-<span class="st"> </span><span class="kw">c</span>(pp, pval)</a>
<a class="sourceLine" id="cb157-10" title="10">  }</a>
<a class="sourceLine" id="cb157-11" title="11">}</a>
<a class="sourceLine" id="cb157-12" title="12"><span class="kw">tibble</span>(ii, jj, pp)</a></code></pre></div>
<pre><code>## # A tibble: 16 x 3
##    ii    jj           pp
##    &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;
##  1 G     G     1        
##  2 G     PG-13 0.0000590
##  3 G     PG    0.00799  
##  4 G     R     0.0106   
##  5 PG-13 G     0.0000590
##  6 PG-13 PG-13 1        
##  7 PG-13 PG    0.0106   
##  8 PG-13 R     0.273    
##  9 PG    G     0.00799  
## 10 PG    PG-13 0.0106   
## 11 PG    PG    1        
## 12 PG    R     0.715    
## 13 R     G     0.0106   
## 14 R     PG-13 0.273    
## 15 R     PG    0.715    
## 16 R     R     1</code></pre>
<p>This is a lot of fiddling about, since you have to initialize three
vectors, and then update them every time through the loop. It’s hard
to read, because the actual business part of the loop is the
calculation of the P-value, and that’s almost hidden by all the
book-keeping. (It’s also slow and inefficient, though the slowness
doesn’t matter too much here since it’s not a very big problem.)</p>
<p>Let’s try another way:</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb159-1" title="1"><span class="kw">crossing</span>(<span class="dt">first =</span> the_ratings, <span class="dt">second =</span> the_ratings)</a></code></pre></div>
<pre><code>## # A tibble: 16 x 2
##    first second
##    &lt;chr&gt; &lt;chr&gt; 
##  1 G     G     
##  2 G     PG    
##  3 G     PG-13 
##  4 G     R     
##  5 PG    G     
##  6 PG    PG    
##  7 PG    PG-13 
##  8 PG    R     
##  9 PG-13 G     
## 10 PG-13 PG    
## 11 PG-13 PG-13 
## 12 PG-13 R     
## 13 R     G     
## 14 R     PG    
## 15 R     PG-13 
## 16 R     R</code></pre>
<p>This does “all possible combinations” of one rating with another. We
don’t actually need all of that; we just need the ones where the first
one is (alphabetically) strictly less than the second one. This is
because we’re never comparing a rating with itself, and each pair of
ratings appears twice, once in alphabetical order, and once the other
way around. The ones we need are these:</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb161-1" title="1"><span class="kw">crossing</span>(<span class="dt">first =</span> the_ratings, <span class="dt">second =</span> the_ratings) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb161-2" title="2"><span class="st">  </span><span class="kw">filter</span>(first <span class="op">&lt;</span><span class="st"> </span>second)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   first second
##   &lt;chr&gt; &lt;chr&gt; 
## 1 G     PG    
## 2 G     PG-13 
## 3 G     R     
## 4 PG    PG-13 
## 5 PG    R     
## 6 PG-13 R</code></pre>
<p>A technique thing to note: instead of asking
“how do I pick out the distinct pairs of ratings?”,
I use two simpler tools: first I make
all the combinations of pairs of ratings, and then out of those, pick
the ones that are alphabetically in ascending order, which we know how
to do.</p>
<p>Now we want to call our function <code>comp2</code> for each of the things
in <code>first</code> <em>and</em> each of the things in <code>second</code>,
and make a new column called <code>pval</code> that contains exactly
that. <code>comp2</code> expects single movie ratings for each of its inputs, not a vector of each, so the way to go about this is <code>rowwise</code>:</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb163-1" title="1"><span class="kw">crossing</span>(<span class="dt">first =</span> the_ratings, <span class="dt">second =</span> the_ratings) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb163-2" title="2"><span class="st">  </span><span class="kw">filter</span>(first <span class="op">&lt;</span><span class="st"> </span>second) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb163-3" title="3"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb163-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pval =</span> <span class="kw">comp2</span>(first, second, movies))</a></code></pre></div>
<pre><code>## # A tibble: 6 x 3
## # Rowwise: 
##   first second      pval
##   &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;
## 1 G     PG     0.00799  
## 2 G     PG-13  0.0000590
## 3 G     R      0.0106   
## 4 PG    PG-13  0.0106   
## 5 PG    R      0.715    
## 6 PG-13 R      0.273</code></pre>
<p>One more thing: we’re doing 6 tests at once here, so we’re giving
ourselves 6 chances to reject a null (all medians equal) that might
have been true. So the true probability of a type I error is no longer
0.05 but something bigger.</p>
<p>The easiest way around that is to do a so-called Bonferroni
adjustment: instead of rejecting if the P-value is less than 0.05, we
only reject if it is less than <span class="math inline">\(0.05/6\)</span>, since we are doing 6
tests. This is a fiddly calculation to do by hand, but it’s easy to
build in another <code>mutate</code>, thus:<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb165-1" title="1"><span class="kw">crossing</span>(<span class="dt">first =</span> the_ratings, <span class="dt">second =</span> the_ratings) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb165-2" title="2"><span class="st">  </span><span class="kw">filter</span>(first <span class="op">&lt;</span><span class="st"> </span>second) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb165-3" title="3"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb165-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pval =</span> <span class="kw">comp2</span>(first, second, movies)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb165-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">reject =</span> (pval <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span> <span class="op">/</span><span class="st"> </span><span class="dv">6</span>))</a></code></pre></div>
<pre><code>## # A tibble: 6 x 4
## # Rowwise: 
##   first second      pval reject
##   &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt; 
## 1 G     PG     0.00799   TRUE  
## 2 G     PG-13  0.0000590 TRUE  
## 3 G     R      0.0106    FALSE 
## 4 PG    PG-13  0.0106    FALSE 
## 5 PG    R      0.715     FALSE 
## 6 PG-13 R      0.273     FALSE</code></pre>
<p>And not a loop in sight.</p>
<p>This is how I coded it in <code>pairwise_median_test</code>. If you want to
check it, it’s on Github:
<a href="https://raw.githubusercontent.com/nxskok/smmr/master/R/pairwise_median_test.R">link</a>.
The function <code>median_test_pair</code> is the same as <code>comp2</code>
above.</p>
<p>So the only significant differences are now G compared to PG and
PG-13. There is not a significant difference in median movie length
between G and R, though it is a close call. We thought the PG-13
movies might have a significantly different median from other rating
groups beyond G, but they turn out not to have. (The third and fourth
comparisons would have been significant had we not made the Bonferroni
adjustment to compensate for doing six tests at once; with that
adjustment, we only reject if the P-value is less than
<span class="math inline">\(0.05/6=0.0083\)</span>, and so 0.0106 is not quite small enough to reject
with.)</p>
<p>Listing the rating groups sorted by median would give you an idea of
how far different the medians have to be to be significantly different:</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb167-1" title="1">medians &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb167-2" title="2"><span class="st">  </span><span class="kw">group_by</span>(rating) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb167-3" title="3"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">med =</span> <span class="kw">median</span>(length)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb167-4" title="4"><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(med))</a>
<a class="sourceLine" id="cb167-5" title="5">medians</a></code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   rating   med
##   &lt;chr&gt;  &lt;dbl&gt;
## 1 PG-13    117
## 2 R        103
## 3 PG       100
## 4 G         82</code></pre>
<p>Something rather interesting has happened: even though the comparison of
G and PG (18 apart) is significant, the comparison of G and R (21
apart) is not significant. This seems very odd, but it happens because
the Mood median test is not actually literally comparing the sample
medians, but only assessing the splits of values above and below the
median of the combined sample. A subtlety, rather than an error, I’d say.</p>
<p>Here’s something extremely flashy to finish with:</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb169-1" title="1"><span class="kw">crossing</span>(<span class="dt">first =</span> the_ratings, <span class="dt">second =</span> the_ratings) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb169-2" title="2"><span class="st">  </span><span class="kw">filter</span>(first <span class="op">&lt;</span><span class="st"> </span>second) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb169-3" title="3"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb169-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pval =</span> <span class="kw">comp2</span>(first, second, movies)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb169-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">reject =</span> (pval <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.05</span> <span class="op">/</span><span class="st"> </span><span class="dv">6</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb169-6" title="6"><span class="st">  </span><span class="kw">left_join</span>(medians, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;first&quot;</span> =<span class="st"> &quot;rating&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb169-7" title="7"><span class="st">  </span><span class="kw">left_join</span>(medians, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;second&quot;</span> =<span class="st"> &quot;rating&quot;</span>))</a></code></pre></div>
<pre><code>## # A tibble: 6 x 6
## # Rowwise: 
##   first second      pval reject med.x med.y
##   &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 G     PG     0.00799   TRUE      82   100
## 2 G     PG-13  0.0000590 TRUE      82   117
## 3 G     R      0.0106    FALSE     82   103
## 4 PG    PG-13  0.0106    FALSE    100   117
## 5 PG    R      0.715     FALSE    100   103
## 6 PG-13 R      0.273     FALSE    117   103</code></pre>
<p>The additional two lines look up the medians of the rating groups in
<code>first</code>, then <code>second</code>, so that you can see the actual
medians of the groups being compared each time. You see that medians
different by 30 are definitely different, ones differing by 15 or less
are definitely not different, and ones differing by about 20 could go
either way.</p>
<p>I think that’s <em>quite</em> enough of that.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="atomic-weight-of-carbon-1" class="section level2">
<h2><span class="header-section-number">13.13</span> Atomic weight of carbon</h2>
<p>The atomic weight of the chemical element
carbon is 12. Two methods of measuring the atomic weight of samples of
carbon were compared. The results are shown in
<a href="http://ritsokiguess.site/datafiles/carbon.txt">link</a>. The methods
are labelled 1 and 2. The first task is to find out whether the two
methods have different “typical” measures (mean or median, as
appropriate) of the atomic weight of carbon.</p>
<p>For this question, compose a report in R Markdown. (R Markdown is
what you use in an R Notebook, but you can also have a separate R
Markdown document from which you can produce HTML, Word etc. output.)
See part (a) for how to get this started.</p>
<p>Your report should
read like an actual report, not just the answers to some questions
that I set you. To help with that, write some text that links the
parts of the report together smoothly, so that it reads as a coherent
whole. The grader had 3 discretionary marks to award for the overall
quality of your writing. The scale for this was:</p>
<ul>
<li><p>3 points: excellent writing. The report flows smoothly, is easy
to read, and contains everything it should (and nothing it
shouldn’t).</p></li>
<li><p>2 points: satisfactory writing. Not the easiest to read, but
says what it should, and it looks at least somewhat like a report
rather than a string of answers to questions.</p></li>
<li><p>1 point: writing that is hard to read or to understand. If you
get this (or 0), you should consider what you need to do to improve
when you write your project.</p></li>
<li><p>0 points: you answered the questions, but you did almost nothing
to make it read like a report.</p></li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Create a new R Markdown document. To do this, in R Studio, select File,
New File, R Markdown. Type the report title and your name in the
boxes, and leave the output on the default HTML. Click OK.</li>
</ol>
<p>Solution</p>
<p>You’ll
see the title and your name in a section at the top of the document,
and below that you’ll see a template document, as you would for an R
Notebook. The difference is that where you are used to seeing
Preview, it now says “knit”, but this has the same effect of
producing the formatted version of your report.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Write an introduction that explains the purpose of this
study and the data collected in your own words.</li>
</ol>
<p>Solution</p>
<p>Something like this:</p>
<blockquote>
<p>This study is intended to compare two different methods
(labelled 1 and 2) for measuring the atomic weight of carbon
(which is known in actual fact to be 12). Fifteen samples of
carbon were used; ten of these were assessed using method 1 and
the remaining five using method 2. The primary interest in this
particular study is to see whether there is a difference in the
mean or median atomic weight as measured by the two methods.</p>
</blockquote>
<p>Before that, start a new section like this:
<code>## Introduction</code>.
Also, get used to expressing your understanding in your words,
not mine. (Using my words, in my courses, is likely to be
worth very little.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Begin an appropriately-titled new section in your report,
read the data into R and display the results.</li>
</ol>
<p>Solution</p>
<p>Values separated by spaces:</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/carbon.txt&quot;</span></a>
<a class="sourceLine" id="cb171-2" title="2">carbon &lt;-<span class="st"> </span><span class="kw">read_delim</span>(my_url, <span class="st">&quot; &quot;</span>)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   method = col_double(),
##   weight = col_double()
## )</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" title="1">carbon</a></code></pre></div>
<pre><code>## # A tibble: 15 x 2
##    method weight
##     &lt;dbl&gt;  &lt;dbl&gt;
##  1      1   12.0
##  2      1   12.0
##  3      1   12.0
##  4      1   12.0
##  5      1   12.0
##  6      1   12.0
##  7      1   12.0
##  8      1   12.0
##  9      1   12.0
## 10      1   12.0
## 11      2   12.0
## 12      2   12.0
## 13      2   12.0
## 14      2   12.0
## 15      2   12.0</code></pre>
<p>I would expect you to include, without being told to include it, some
text in your report indicating that you have sensible data: two
methods labelled 1 and 2 as promised, and a bunch<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>
of atomic
weights close to the nominal figure of 12.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Make an appropriate plot to compare the measurements
obtained by the two methods. You might need to do something about
the two methods being given as numbers even though they are really
only identifiers. (If you do, your report ought to say what you did
and why.)</li>
</ol>
<p>Solution</p>
<p>The appropriate plot, with a categorical method and quantitative
weight, is something like a boxplot. If you’re not careful,
<code>method</code> will get treated as a quantitative variable,
which you don’t want; the easiest way around that, for a boxplot
at least, is to turn it into a factor like this:</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb175-1" title="1"><span class="kw">ggplot</span>(carbon, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(method), <span class="dt">y =</span> weight)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/seewerin-1.png" width="672" /></p>
<p>If you insist, you could do a faceted histogram (above and below, for preference):</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb176-1" title="1"><span class="kw">ggplot</span>(carbon, <span class="kw">aes</span>(<span class="dt">x =</span> weight)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb176-2" title="2"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>method, <span class="dt">ncol =</span> <span class="dv">1</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/schuomarcher-1.png" width="672" /></p>
<p>There are really not enough data values for a histogram to be of much
help, so I don’t like this as much.</p>
<p>If you are thinking ahead (we are going to be doing a <span class="math inline">\(t\)</span>-test), then
you’ll realize that normality is the kind of thing we’re looking for,
in which case normal quantile plots would be the thing. However, we
might have to be rather forgiving for method 2 since there are only 5
observations:</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" title="1"><span class="kw">ggplot</span>(carbon, <span class="kw">aes</span>(<span class="dt">sample =</span> weight)) <span class="op">+</span></a>
<a class="sourceLine" id="cb177-2" title="2"><span class="st">  </span><span class="kw">stat_qq</span>() <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb177-3" title="3"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>method)</a></code></pre></div>
<p><img src="pasias_files/figure-html/mulichs-1.png" width="672" /></p>
<p>I don’t mind these coming out side by side, though I would rather have
them squarer.</p>
<p>I would say, boxplots are the best, normal quantile plots are also
acceptable, but expect to lose something for histograms because they
offer only a rather crude comparison in this case.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Comment briefly on what you see in your plot.</li>
</ol>
<p>Solution</p>
<p>In boxplots, if that’s what you drew, there are several things
that deserve comment: the medians, the spreads and the
shapes. The median for method 1 is a little bit lower than for
method 2 (the means are probably more different, given the
shapes of the boxes). The spread for method 2 is a lot
bigger. (Looking forward, that suggests a Welch-Satterthwaite
rather than a pooled test.) As for shape, the method 2
measurements seem more or less symmetric (the whiskers are equal
anyway, even if the position of the median in the box isn’t),
but the method 1 measurements have a low outlier.
The histograms are hard to compare. Try to say something about
centre and spread and shape. I think the method 2 histogram has
a slightly higher centre and definitely bigger spread. On my
histogram for method 1, the distribution looks skewed left.
If you did normal quantile plots, say something sensible about
normality for each of the two methods. For method 1, I would say
the low value is an outlier and the rest of the values look
pretty straight. Up to you whether you think there is a curve on
the plot (which would indicate skewness, but then that highest
value is too high: it would be bunched up with the other values
below 12.01 if there were really skewness).
For method 2, it’s really hard to say anything since there are
only five values. Given where the line goes, there isn’t much
you can say to doubt normality. Perhaps the best you can say
here is that in a sample of size 5, it’s difficult to assess
normality at all.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Carry out the most appropriate <span class="math inline">\(t\)</span>-test. (You might like to
begin another new section in your report here.)</li>
</ol>
<p>Solution</p>
<p>This would be the Welch-Satterthwaite version of the two-sample
<span class="math inline">\(t\)</span>-test, since the two groups do appear to have different spreads:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb178-1" title="1"><span class="kw">t.test</span>(weight <span class="op">~</span><span class="st"> </span>method, <span class="dt">data =</span> carbon)</a></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  weight by method
## t = -1.817, df = 5.4808, p-value = 0.1238
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.027777288  0.004417288
## sample estimates:
## mean in group 1 mean in group 2 
##        12.00260        12.01428</code></pre>
<p>Imagining that this is a report that would go to your boss, you ought
to defend your choice of the Welch-Satterthwaite test (as I did
above), and not just do the default <span class="math inline">\(t\)</span>-test without comment.</p>
<p>If, in your discussion above, you thought the spreads were equal
enough, then you should do the pooled <span class="math inline">\(t\)</span>-test here, which goes like this:</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb180-1" title="1"><span class="kw">t.test</span>(weight <span class="op">~</span><span class="st"> </span>method, <span class="dt">data =</span> carbon, <span class="dt">var.equal =</span> T)</a></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  weight by method
## t = -2.1616, df = 13, p-value = 0.04989
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -2.335341e-02 -6.588810e-06
## sample estimates:
## mean in group 1 mean in group 2 
##        12.00260        12.01428</code></pre>
<p>The point here is that you should do the right test based on your
conclusion. Being consistent is the most important thing. (In this
case, note that the P-values are very different. We’ll get to that
shortly.)</p>
<p>If we were doing this in SAS, as we see later, we’d get a test at the
bottom of the output that compares the two variances. I feel that it’s
just as good to eyeball the spreads and make a call about whether they
are “reasonably close”. Or even, to always do the
Welch-Satterthwaite test on the basis that it is pretty good even if
the two populations have the same variance. (If this last point of
view is one that you share, you ought to say something about that when
you do your <span class="math inline">\(t\)</span>-test.)</p>
<p>Extra: I guess this is a good place to say something about tests for comparing
variances, given that you might be pondering that. There are
several that I can think of, that R can do, of which I mention two.</p>
<p>The first is the <span class="math inline">\(F\)</span>-test for variances that you might have learned in
B57 (that is the basis for the ANOVA <span class="math inline">\(F\)</span>-test):</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb182-1" title="1"><span class="kw">var.test</span>(weight <span class="op">~</span><span class="st"> </span>method, <span class="dt">data =</span> carbon)</a></code></pre></div>
<pre><code>## 
##  F test to compare two variances
## 
## data:  weight by method
## F = 0.35768, num df = 9, denom df = 4, p-value = 0.1845
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.04016811 1.68758230
## sample estimates:
## ratio of variances 
##          0.3576842</code></pre>
<p>This, unfortunately, is rather dependent on the data in the two groups
being approximately normal. Since we are talking variances rather than
means, there is no Central Limit Theorem to rescue us for large
samples (quite aside from the fact that these samples are <em>not</em>
large). Since the ANOVA <span class="math inline">\(F\)</span>-test is based on the same theory, this is
why normality is also more important in ANOVA than it is in a <span class="math inline">\(t\)</span>-test.</p>
<p>The second is Levene’s test. This doesn’t depend on normality (at
least, not nearly so much), so I like it better in general:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb184-1" title="1"><span class="kw">library</span>(car)</a>
<a class="sourceLine" id="cb184-2" title="2"><span class="kw">leveneTest</span>(weight <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(method), <span class="dt">data =</span> carbon)</a></code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  1  0.9887 0.3382
##       13</code></pre>
<p>Levene’s test takes a different approach: first the absolute
differences from the group medians are calculated, and then an ANOVA
is run on the absolute differences. If, say, one of the groups has a
larger spread than the other(s), its absolute differences from the
median will tend to be bigger.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>
As for what we conclude here, well, neither of the variance tests show
any significance at all, so from that point of view there is no
evidence against using the pooled <span class="math inline">\(t\)</span>-test. Having said that, the
samples are small, and so it would be difficult to <em>prove</em> that
the two methods have different variance, even if they actually
did.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
<p>Things are never as clear-cut as you would like. In the end, it all
comes down to making a call and defending it.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Do the most appropriate test you know that does not assume
normally-distributed data.</li>
</ol>
<p>Solution</p>
<p>That would be Mood’s median test. Since I didn’t say anything
about building it yourself, feel free to use <code>smmr</code>:</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb186-1" title="1"><span class="kw">library</span>(smmr)</a>
<a class="sourceLine" id="cb186-2" title="2"><span class="kw">median_test</span>(carbon, weight, method)</a></code></pre></div>
<pre><code>## $table
##      above
## group above below
##     1     3     6
##     2     4     1
## 
## $test
##        what      value
## 1 statistic 2.80000000
## 2        df 1.00000000
## 3   P-value 0.09426431</code></pre>
<p>As an aside, if you have run into a non-parametric test such as
Mann-Whitney or Kruskal-Wallis that applies in this situation, be
careful about using it here, because they have additional assumptions
that you may not want to trust. Mann-Whitney started life as a test for
“equal distributions.”<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> This
means that the null is equal location <em>and</em> equal spread, and if
you reject the null, one of those has failed. But here, we suspect that
equal spread will fail, so that the Mann-Whitney test may end up
rejecting <em>whether or not</em> the medians are different, so it won’t
answer the question you want an answer to. Mood’s median test doesn’t
have that problem; all it’s saying if the null is true is that the
medians are equal; the spreads could be anything at all.</p>
<p>The same kind of issues apply to the signed-rank test vs. the sign
test. In the case of the signed-rank test, the extra assumption is of
a symmetric distribution — to my mind, if you don’t believe
normality, you probably don’t have much confidence in symmetry
either. That’s why I like the sign test and Mood’s median test: in the
situation where you don’t want to be dealing with assumptions, these
tests don’t make you worry about that.</p>
<p>Another comment that you don’t need to make is based on the
not-quite-significance of the Mood test. The P-value is less than 0.10
but not less than 0.05, so it doesn’t quite reach significance by the
usual standard. But if you look up at the table, the frequencies seem
rather unbalanced: 6 out of the remaining 9 weights in group 1 are
below the overall median, but 4 out of 5 weights in group 2 are
above. This seems as if it ought to be significant, but bear in mind
that the sample sizes are small, and thus Mood’s median test needs
<em>very</em> unbalanced frequencies, which we don’t quite have here.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Discuss the results of your tests and what they say about
the two methods for measuring the atomic weight of carbon. If it
seems appropriate, put the discussion into a section called
Conclusions.</li>
</ol>
<p>Solution</p>
<p>Begin by pulling out the P-values for your preferred test(s) and
say what they mean. The P-value for the Welch-Satterthwaite
<span class="math inline">\(t\)</span>-test is 0.1238, which indicates no difference in mean atomic
weights between the two methods. The Mood median test gives a
similarly non-significant 0.0943, indicating no difference in
the <em>median</em> weights. If you think both tests are
plausible, then give both P-values and do a compare-and-contrast
with them; if you think that one of the tests is clearly
preferable, then say so (and why) and focus on that test’s
results.</p>
<p>If you thought the pooled test was the right one, then you’ll
have a bit more discussion to do, since its P-value is 0.0499,
and at <span class="math inline">\(\alpha=0.05\)</span> this test disagrees with the others. If you
are comparing this test with the Mood test, you ought to make
some kind of reasoned recommendation about which test to
believe.</p>
<p>As ever, be consistent in your reasoning.</p>
<p>Extra: this dataset, where I found it, was actually being used to
illustrate a case where the pooled and the Welch-Satterthwaite
tests disagreed. The authors of the original paper that used
this dataset (a 1987 paper by Best and Rayner;<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a>
the data come from 1924!) point out that the
pooled <span class="math inline">\(t\)</span>-test can be especially misleading when the smaller
sample is also the one with the larger variance. This is what
happened here.</p>
<p>In the Best and Rayner paper, the Mood (or the Mann-Whitney) test was
not being considered, but I think it’s good practice to draw a
picture and make a call about which test is appropriate.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="can-caffeine-improve-your-performance-on-a-test-1" class="section level2">
<h2><span class="header-section-number">13.14</span> Can caffeine improve your performance on a test?</h2>
<p>Does caffeine help students do better on a certain test? To
find out, 36 students were randomly allocated to three groups (12 in
each group). Each student received a fixed number of cups of coffee
while they were studying, but the students didn’t know whether they
were receiving all full-strength coffee (“high”), all decaf coffee
(“low”) or a 50-50 mixture of the two (“moderate”). For each
subject, their group was recorded as well as their score on the
test. The data are in
<a href="http://ritsokiguess.site/datafiles/caffeine.csv">link</a>, as a
<code>.csv</code> file.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and examine the data. How are the values laid out?</li>
</ol>
<p>Solution</p>
<p><code>read_csv</code> because it’s a <code>.csv</code> file:</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb188-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/caffeine.csv&quot;</span></a>
<a class="sourceLine" id="cb188-2" title="2">caffeine.untidy &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   Sub = col_double(),
##   High = col_double(),
##   Moderate = col_double(),
##   None = col_double()
## )</code></pre>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" title="1">caffeine.untidy</a></code></pre></div>
<pre><code>## # A tibble: 12 x 4
##      Sub  High Moderate  None
##    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;
##  1     1    72       68    68
##  2     2    65       80    74
##  3     3    68       64    59
##  4     4    83       65    61
##  5     5    79       69    65
##  6     6    92       79    72
##  7     7    69       80    80
##  8     8    74       63    58
##  9     9    78       69    65
## 10    10    83       70    60
## 11    11    88       83    78
## 12    12    71       75    75</code></pre>
<p>The first column is the number of the subject (actually within each
group, since each student only tried one amount of caffeine). Then
follow the test scores for the students in each group, one group per column.</p>
<p>I gave the data frame a kind of dumb name, since (looking ahead) I
could see that I would need a less-dumb name for the tidied-up data,
and it seemed sensible to keep <code>caffeine</code> for that.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Explain briefly how the data are not “tidy”.</li>
</ol>
<p>Solution</p>
<p>The last three columns are all scores on the test: that is, they
all measure the same thing, so they should all be in the same column.
Or, there should be a column of scores, and a separate column
naming the groups. Or, there were 36 observations in the data, so
there should be 36 rows. You always have a variety of ways to
answer these, any of which will do.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Use a suitable tool from the <code>tidyverse</code> to create one
column of test scores and and one column of group labels. Call your
column of group labels <code>amount</code>. Is it a <code>factor</code>?</li>
</ol>
<p>Solution</p>
<p>We are combining several columns into one, so this is <code>pivot_longer</code>:</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" title="1">caffeine.untidy <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb192-2" title="2"><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span>Sub, <span class="dt">names_to =</span> <span class="st">&quot;amount&quot;</span>, <span class="dt">values_to =</span> <span class="st">&quot;score&quot;</span>) -&gt;<span class="st"> </span>caffeine</a></code></pre></div>
<p>I didn’t ask you to list the resulting data frame, but it is smart to
at least look for yourself, to make sure <code>pivot_longer</code> has done
what you expected.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb193-1" title="1">caffeine</a></code></pre></div>
<pre><code>## # A tibble: 36 x 3
##      Sub amount   score
##    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;
##  1     1 High        72
##  2     1 Moderate    68
##  3     1 None        68
##  4     2 High        65
##  5     2 Moderate    80
##  6     2 None        74
##  7     3 High        68
##  8     3 Moderate    64
##  9     3 None        59
## 10     4 High        83
## # … with 26 more rows</code></pre>
<p>A column of amounts of caffeine, and a column of test scores. This is
what we expected. There should be 12 each of the <code>amount</code>s,
which you can check if you like:</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb195-1" title="1">caffeine <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(amount)</a></code></pre></div>
<pre><code>## # A tibble: 3 x 2
##   amount       n
##   &lt;chr&gt;    &lt;int&gt;
## 1 High        12
## 2 Moderate    12
## 3 None        12</code></pre>
<p>Indeed.</p>
<p>Note that <code>amount</code> is text, not a factor. Does this matter? We’ll see.</p>
<p>This is entirely the kind of situation where you need <code>pivot_longer</code>,
so get used to seeing where it will be useful.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Obtain side-by-side boxplots of test scores by amount of caffeine.</li>
</ol>
<p>Solution</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" title="1"><span class="kw">ggplot</span>(caffeine, <span class="kw">aes</span>(<span class="dt">x =</span> amount, <span class="dt">y =</span> score)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-130-1.png" width="672" /></p>
<p>Note that this is <em>much more difficult</em> if you don’t have a tidy data frame. (Try it and see.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Does caffeine amount seem to have an effect? If so, what
kind of effect?</li>
</ol>
<p>Solution</p>
<p>On average, exam scores seem to be higher when the amount of
caffeine is higher (with
the effect being particularly pronounced for High caffeine).
If you want to, you can also say the the effect of caffeine seems
to be small, relative to the amount of variability there is (there
is a lot). The point is that you say <em>something</em> supported by
the boxplot.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Run a suitable analysis of variance to determine whether
the mean test score is equal or unequal for the three groups. What
do you conclude?</li>
</ol>
<p>Solution</p>
<p>Something like this:</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" title="1">caff<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">aov</span>(score <span class="op">~</span><span class="st"> </span>amount, <span class="dt">data =</span> caffeine)</a>
<a class="sourceLine" id="cb198-2" title="2"><span class="kw">summary</span>(caff<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## amount       2  477.7  238.86   3.986 0.0281 *
## Residuals   33 1977.5   59.92                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The P-value on the <span class="math inline">\(F\)</span>-test is less than 0.05, so we reject the null
hypothesis (which says that all the groups have equal means) in favour
of the alternative: the group means are not all the same (one or more
of them is different from the others).</p>
<p>Notice that the boxplot and the <code>aov</code> are quite happy for
<code>amount</code> to be text rather than a factor (they actually do want
a factor, but if the input is text, they’ll create one).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Why is it a good idea to run Tukey’s method here?</li>
</ol>
<p>Solution</p>
<p>The analysis of variance <span class="math inline">\(F\)</span>-test is significant, so that the
groups are not all the same. Tukey’s method will tell us which
group(s) differ(s) from the others. There are three groups, so
there are differences to find that we don’t know about yet.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Run Tukey’s method. What do you conclude?</li>
</ol>
<p>Solution</p>
<p>This kind of thing:</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb200-1" title="1">caff<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">TukeyHSD</span>(caff<span class="fl">.1</span>)</a>
<a class="sourceLine" id="cb200-2" title="2">caff<span class="fl">.3</span></a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = score ~ amount, data = caffeine)
## 
## $amount
##                    diff       lwr       upr     p adj
## Moderate-High -4.750000 -12.50468  3.004679 0.3025693
## None-High     -8.916667 -16.67135 -1.161987 0.0213422
## None-Moderate -4.166667 -11.92135  3.588013 0.3952176</code></pre>
<p>The high-caffeine group definitely has a higher mean test score than
the no-caffeine group. (The Moderate group is not significantly
different from either of the other groups.)
Both the
comparisons involving Moderate could go either way (the interval for
the difference in means includes zero). The None-High comparison,
however, is away from zero, so this is the significant one. As is
usual, we are pretty sure that the difference in means (this way
around) is negative, but we are not at all clear about how big it is,
because the confidence interval is rather long.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></p>
<p>Extra: the normality and equal spreads assumptions look perfectly good, given the boxplots, and I don’t think there’s any reason to consider any other test. You might like to assess that with normal quantile plots:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb202-1" title="1"><span class="kw">ggplot</span>(caffeine, <span class="kw">aes</span>(<span class="dt">sample=</span>score)) <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb202-2" title="2"><span class="st">  </span><span class="kw">stat_qq_line</span>() <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span>amount, <span class="dt">ncol=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-133-1.png" width="672" /></p>
<p>There’s nothing to worry about there normality-wise. If anything, there’s a little evidence of <em>short</em> tails (in the None group especially), but you’ll recall that short tails don’t affect the mean and thus pose no problems for the ANOVA. Those three lines also have pretty much the same slope, indicating very similar spreads. Regular ANOVA is the best test here. (Running eg. Mood’s median test would be a mistake here, because it doesn’t use the data as efficiently (counting only aboves and belows) as the ANOVA does, and so the ANOVA will give a better picture of what differs from what.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="reggae-music-1" class="section level2">
<h2><span class="header-section-number">13.15</span> Reggae music</h2>
<p>Reggae is a music genre that originated in Jamaica in the late 1960s. One of the most famous reggae bands was Bob Marley and the Wailers.
In a survey, 729 students were asked to rate reggae music on a scale from 1, “don’t like it at all” to 6, “like it a lot”.
We will treat the ratings as quantitative.
Each student was also asked to classify their home town as one of “big city”, “suburban”, “small town”, “rural”. Does a student’s opinion of reggae depend on the kind of home town they come from? The data are in <a href="http://ritsokiguess.site/datafiles/reggae.csv">http://ritsokiguess.site/datafiles/reggae.csv</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display (some of) the data.</li>
</ol>
<p>Solution</p>
<p>This is (evidently) a <code>.csv</code>, so:</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb203-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/reggae.csv&quot;</span></a>
<a class="sourceLine" id="cb203-2" title="2">reggae &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   home = col_character(),
##   rating = col_double()
## )</code></pre>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb205-1" title="1">reggae</a></code></pre></div>
<pre><code>## # A tibble: 729 x 2
##    home     rating
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 big city      1
##  2 big city      2
##  3 big city      2
##  4 big city      2
##  5 big city      2
##  6 big city      2
##  7 big city      2
##  8 big city      2
##  9 big city      3
## 10 big city      3
## # … with 719 more rows</code></pre>
<p>The students shown are all from big cities, but there are others, as you can check by scrolling down.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>How many students are from each different size of town?</li>
</ol>
<p>Solution</p>
<p>This is the usual kind of application of <code>count</code>:</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb207-1" title="1">reggae <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(home)</a></code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   home           n
##   &lt;chr&gt;      &lt;int&gt;
## 1 big city      89
## 2 rural         96
## 3 small town   176
## 4 suburban     368</code></pre>
<p>Another, equally good, way (you can ignore the warning):</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb209-1" title="1">reggae <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(home) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-2" title="2"><span class="kw">summarize</span>(<span class="dt">n=</span><span class="kw">n</span>())</a></code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   home           n
##   &lt;chr&gt;      &lt;int&gt;
## 1 big city      89
## 2 rural         96
## 3 small town   176
## 4 suburban     368</code></pre>
<p>Most of the students in this data set are from suburbia.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Make a suitable graph of the two variables in this data frame.</li>
</ol>
<p>Solution</p>
<p>One quantitative, one categorical: a boxplot, as ever:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb211-1" title="1"><span class="kw">ggplot</span>(reggae, <span class="kw">aes</span>(<span class="dt">x=</span>home, <span class="dt">y=</span>rating)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-137-1.png" width="672" /></p>
<p>Extra 1: the last three boxplots really are identical, because the medians, means, quartiles and extreme values are all equal. However, the <em>data values</em> are not all the same, as you see below.</p>
<p>Extra 2: I said that the ratings should be treated as quantitative, to guide you towards this plot.
You could otherwise have taken the point of view that the ratings were (ordered) categorical, in which case the right graph would have been a grouped bar chart, as below.
There is a question about which variable should be <code>x</code> and which should be <code>fill</code>.
I am taking the point of view that we want to compare ratings within each category of <code>home</code>, which I think makes sense here (see discussion below), which breaks my “rule” that the categorical variable with fewer categories should be <code>x</code>.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb212-1" title="1"><span class="kw">ggplot</span>(reggae, <span class="kw">aes</span>(<span class="dt">x=</span>home, <span class="dt">fill=</span><span class="kw">factor</span>(rating))) <span class="op">+</span><span class="st"> </span><span class="kw">geom_bar</span>(<span class="dt">position =</span> <span class="st">&quot;dodge&quot;</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-138-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Discuss briefly why you might prefer to run Mood’s median test to compare ratings among home towns.</li>
</ol>
<p>Solution</p>
<p>The issue here is whether <em>all</em> of the rating distributions (within each category of <code>home</code>) are sufficiently close to normal in shape.
The “big city” group is clearly skewed to the left. This is enough to make us favour Mood’s median test over ANOVA.</p>
<p>A part-marks answer is to note that the big-city group has smaller spread than the other groups (as measured by the IQR). This is answering the wrong question, though.
Remember the process: first we assess normality. If that fails, we use Mood’s median test. Then, with normality OK, we assess equal spreads. If <em>that</em> fails, we use Welch ANOVA, and if both normality and equal spreads pass, we use regular ANOVA.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Suppose that somebody wanted to run Welch ANOVA on these data. What would be a reasonable argument to support that?</li>
</ol>
<p>Solution</p>
<p>The argument would have to be that normality is all right, given the sample sizes. We found earlier that there are between 89 and 368 students in each group. These are large samples, and might be enough to overcome the non-normality we see.</p>
<p>The only real concern I have is with the big city group. This is the least normal, and also the smallest sample. The other groups seem to have the kind of non-normality that will easily be taken care of by the sample sizes we have.</p>
<p>Extra: the issue is really about the sampling distribution of the mean within each group. Does that look normal enough? This could be assessed by looking at each group, one at a time, and taking bootstrap samples. Here’s the big-city group:</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb213-1" title="1">reggae <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(home<span class="op">==</span><span class="st">&quot;big city&quot;</span>) -&gt;<span class="st"> </span>bigs</a>
<a class="sourceLine" id="cb213-2" title="2"><span class="kw">tibble</span>(<span class="dt">sim =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb213-3" title="3"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb213-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">sample</span>(bigs<span class="op">$</span>rating, <span class="dt">replace =</span> T))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb213-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_mean =</span> <span class="kw">mean</span>(my_sample)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb213-6" title="6"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> my_mean)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">12</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-139-1.png" width="672" /></p>
<p>Not too much wrong with that. This shows that the sample size is indeed big enough to cope with the skewness.</p>
<p>You can do any of the others the same way.</p>
<p>If you’re feeling bold, you can get hold of all three bootstrapped sampling distributions at once, like this:</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb214-1" title="1">reggae <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-2" title="2"><span class="st">  </span><span class="kw">nest_by</span>(home) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">list</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-4" title="4"><span class="st">  </span><span class="kw">unnest</span>(sim) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-5" title="5"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-6" title="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">sample</span>(data<span class="op">$</span>rating, <span class="dt">replace =</span> <span class="ot">TRUE</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-7" title="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_mean =</span> <span class="kw">mean</span>(my_sample)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-8" title="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> my_mean)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">12</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb214-9" title="9"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>home, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-140-1.png" width="672" /></p>
<p>All of these distributions look very much normal, so there is no cause for concern anywhere.</p>
<p>This was rather a lot of code, so let me take you through it. The first thing is that we want to treat the different students’ homes separately, so the first step is this:</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb215-1" title="1">reggae <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb215-2" title="2"><span class="st">  </span><span class="kw">nest_by</span>(home) </a></code></pre></div>
<pre><code>## # A tibble: 4 x 2
## # Rowwise:  home
##   home                     data
##   &lt;chr&gt;      &lt;list&lt;tibble[,1]&gt;&gt;
## 1 big city             [89 × 1]
## 2 rural                [96 × 1]
## 3 small town          [176 × 1]
## 4 suburban            [368 × 1]</code></pre>
<p>This subdivides the students’ reggae ratings according to where their home is. The things in <code>data</code> are data frames containing a column <code>rating</code> for in each case the students who had the <code>home</code> shown.</p>
<p>Normally, we would start by making a dataframe with a column called <code>sim</code> that labels the 1000 or so simulations. This time, we want <em>four</em> sets of simulations, one for each <code>home</code>, which we can set up this way:</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb217-1" title="1">reggae <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb217-2" title="2"><span class="st">  </span><span class="kw">nest_by</span>(home) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb217-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">list</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>)) </a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
## # Rowwise:  home
##   home                     data sim          
##   &lt;chr&gt;      &lt;list&lt;tibble[,1]&gt;&gt; &lt;list&gt;       
## 1 big city             [89 × 1] &lt;int [1,000]&gt;
## 2 rural                [96 × 1] &lt;int [1,000]&gt;
## 3 small town          [176 × 1] &lt;int [1,000]&gt;
## 4 suburban            [368 × 1] &lt;int [1,000]&gt;</code></pre>
<p>The definition of <code>sim</code> happens by group, or rowwise, by <code>home</code> (however you want to look at it). Next, we need to spread out those <code>sim</code> values so that we’ll have one row per bootstrap sample:</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb219-1" title="1">reggae <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb219-2" title="2"><span class="st">  </span><span class="kw">nest_by</span>(home) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb219-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">list</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb219-4" title="4"><span class="st">  </span><span class="kw">unnest</span>(sim) </a></code></pre></div>
<pre><code>## # A tibble: 4,000 x 3
## # Groups:   home [4]
##    home                   data   sim
##    &lt;chr&gt;    &lt;list&lt;tibble[,1]&gt;&gt; &lt;int&gt;
##  1 big city           [89 × 1]     1
##  2 big city           [89 × 1]     2
##  3 big city           [89 × 1]     3
##  4 big city           [89 × 1]     4
##  5 big city           [89 × 1]     5
##  6 big city           [89 × 1]     6
##  7 big city           [89 × 1]     7
##  8 big city           [89 × 1]     8
##  9 big city           [89 × 1]     9
## 10 big city           [89 × 1]    10
## # … with 3,990 more rows</code></pre>
<p><span class="math inline">\(4 \times 1000 = 4000\)</span> rows. Note that the <code>data</code> column now contains multiple copies of all the ratings for the students with that <code>home</code>, which seems wasteful, but it makes our life easier because what we want is a bootstrap sample from the right set of students, namely the <code>rating</code> column from the dataframe <code>data</code> in each row. Thus, from here out, everything is the same as we have done before: work rowwise, get a bootstrap sample , find its mean, plot it. The one thing we need to be careful of is to make a <em>separate</em> histogram for each <code>home</code>, since each of the <em>four</em> distributions need to look normal. I used different scales for each one, since they are centred in different places; this has the side benefit of simplifying the choice of the number of bins. (See what happens if you omit the <code>scales = "free"</code>.)</p>
<p>In any case, all is absolutely fine. We’ll see how this plays out below.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Run Mood’s median test and display the output.</li>
</ol>
<p>Solution</p>
<p>Data frame, quantitative column, categorical column:</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb221-1" title="1"><span class="kw">median_test</span>(reggae, rating, home)</a></code></pre></div>
<pre><code>## $table
##             above
## group        above below
##   big city      51    21
##   rural         25    49
##   small town    64    89
##   suburban     120   187
## 
## $test
##        what        value
## 1 statistic 2.733683e+01
## 2        df 3.000000e+00
## 3   P-value 5.003693e-06</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>Explain briefly why running pairwise median tests is a good idea, run them, and display the results.</li>
</ol>
<p>Solution</p>
<p>The Mood’s median test is significant, with a P-value of 0.000005, so the median ratings are not all the same. We want to find out how they differ.</p>
<p>(The table of aboves and belows, and for that matter the boxplot earlier, suggest that big-city will be different from the rest, but it is not clear whether there will be any other significant differences.)</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb223-1" title="1"><span class="kw">pairwise_median_test</span>(reggae, rating, home)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 4
##   g1         g2            p_value adj_p_value
##   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;       &lt;dbl&gt;
## 1 big city   rural      0.00000746  0.0000448 
## 2 big city   small town 0.0000491   0.000295  
## 3 big city   suburban   0.00000110  0.00000663
## 4 rural      small town 0.788       1         
## 5 rural      suburban   0.740       1         
## 6 small town suburban   0.963       1</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Summarize, as concisely as possible, how the home towns differ in terms of their students’ ratings of reggae music.</li>
</ol>
<p>Solution</p>
<p>The students from big cities like reggae more than students from other places. The other kinds of hometown do not differ significantly.</p>
<p>Extra 1: Given the previous discussion, you might be wondering how Welch ANOVA (and maybe even regular ANOVA) compare. Let’s find out:</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb225-1" title="1"><span class="kw">oneway.test</span>(rating<span class="op">~</span>home,<span class="dt">data=</span>reggae)</a></code></pre></div>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  rating and home
## F = 16.518, num df = 3.00, denom df = 257.07, p-value = 7.606e-10</code></pre>
<p>and</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb227-1" title="1"><span class="kw">gamesHowellTest</span>(rating<span class="op">~</span><span class="kw">factor</span>(home),<span class="dt">data=</span>reggae)</a></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using Games-Howell test</code></pre>
<pre><code>## data: rating by factor(home)</code></pre>
<pre><code>##            big city rural small town
## rural      1.1e-07  -     -         
## small town 2.9e-06  0.74  -         
## suburban   4.9e-09  0.91  0.94</code></pre>
<pre><code>## 
## P value adjustment method: none</code></pre>
<pre><code>## alternative hypothesis: two.sided</code></pre>
<p>The conclusions are identical with Mood’s median test, and the P-values are not that different, either.</p>
<p>This makes me wonder how an ordinary ANOVA with Tukey would have come out:</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb233-1" title="1">reggae <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb233-2" title="2"><span class="kw">aov</span>(rating<span class="op">~</span>home, <span class="dt">data=</span>.) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb233-3" title="3"><span class="kw">TukeyHSD</span>()</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = rating ~ home, data = .)
## 
## $home
##                            diff        lwr        upr     p adj
## rural-big city      -1.20681180 -1.8311850 -0.5824386 0.0000048
## small town-big city -1.00510725 -1.5570075 -0.4532070 0.0000194
## suburban-big city   -1.09404006 -1.5952598 -0.5928203 0.0000002
## small town-rural     0.20170455 -0.3366662  0.7400753 0.7695442
## suburban-rural       0.11277174 -0.3735106  0.5990540 0.9329253
## suburban-small town -0.08893281 -0.4778062  0.2999406 0.9354431</code></pre>
<p>Again, almost identical.</p>
<p>Extra 2: some Bob Marley and the Wailers for you:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=RhJ0q7X3DLM">from 1980</a></li>
<li><a href="https://www.youtube.com/watch?v=rf8GjhXvOjU">from 1973</a></li>
</ul>
<p>Reggae music at its finest.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="watching-tv-and-education-1" class="section level2">
<h2><span class="header-section-number">13.16</span> Watching TV and education</h2>
<p>The General Social Survey is a large survey of a large number of people. One of the questions on the survey is “how many hours of TV do you watch in a typical day?” Another is “what is your highest level of education attained”, on this scale:</p>
<ul>
<li><strong>HSorLess</strong>: completed no more than high h school</li>
<li><strong>College</strong>: completed some form of college, either a community college (like Centennial) or a four-year university (like UTSC)</li>
<li><strong>Graduate</strong>: completed a graduate degree such as an MSc.</li>
</ul>
<p>Do people with more education tend to watch more TV? We will be exploring this. The data are in <a href="http://ritsokiguess.site/datafiles/gss_tv.csv">http://ritsokiguess.site/datafiles/gss_tv.csv</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display (some of) the data.</li>
</ol>
<p>Solution</p>
<p>Exactly the usual:</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb235-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/gss_tv.csv&quot;</span></a>
<a class="sourceLine" id="cb235-2" title="2">gss &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   degree = col_character(),
##   tvhours = col_double()
## )</code></pre>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb237-1" title="1">gss</a></code></pre></div>
<pre><code>## # A tibble: 905 x 2
##    degree   tvhours
##    &lt;chr&gt;      &lt;dbl&gt;
##  1 HSorLess       1
##  2 HSorLess       1
##  3 HSorLess       4
##  4 HSorLess       3
##  5 HSorLess       6
##  6 College        1
##  7 HSorLess       5
##  8 College        1
##  9 College        3
## 10 HSorLess       1
## # … with 895 more rows</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>For each level of education, obtain the number of observations, the mean and the median of the number of hours of TV watched.</li>
</ol>
<p>Solution</p>
<p><code>group_by</code> and <code>summarize</code>, using <code>n()</code> to get the number of observations (rather than <code>count</code> because you want some numerical summaries as well):</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb239-1" title="1">gss <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(degree) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb239-2" title="2"><span class="kw">summarise</span>(<span class="dt">n=</span><span class="kw">n</span>(), <span class="dt">mean=</span><span class="kw">mean</span>(tvhours), <span class="dt">med=</span><span class="kw">median</span>(tvhours))</a></code></pre></div>
<pre><code>## # A tibble: 3 x 4
##   degree       n  mean   med
##   &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 College    195  2.27     2
## 2 Graduate    70  1.84     1
## 3 HSorLess   640  3.33     3</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>What does your answer to the previous part tell you about the shapes of the distributions of the numbers of hours of TV watched? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>In each of the three groups, the mean is greater than the median, so I think the distributions are skewed to the right. Alternatively, you could say that you expect to see some outliers at the upper end.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Obtain a suitable graph of your data frame.</li>
</ol>
<p>Solution</p>
<p>One quantitative variable and one categorical one, so a boxplot. (I hope you are getting the hang of this by now.)</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb241-1" title="1"><span class="kw">ggplot</span>(gss, <span class="kw">aes</span>(<span class="dt">x=</span>degree, <span class="dt">y=</span>tvhours)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-151-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Does your plot indicate that your guess about the distribution shape was correct? Explain briefly.</li>
</ol>
<p>Solution</p>
<p>I guessed before that the distributions would be right-skewed, and they indeed are, with the long upper tails. Or, if you suspected upper outliers, they are here as well.</p>
<p>Say what you guessed before, and how your graph confirms it (or doesn’t, if it doesn’t.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Run a suitable test to compare the average number of hours of TV watched for people with each amount of education. (“Average” could be mean or median, whichever you think is appropriate.)</li>
</ol>
<p>Solution</p>
<p>From the boxplot, the distributions are definitely not all normal; in fact, none of them are. So we should use Mood’s median test, thus:</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb242-1" title="1"><span class="kw">median_test</span>(gss, tvhours, degree)</a></code></pre></div>
<pre><code>## $table
##           above
## group      above below
##   College     67    70
##   Graduate    18    36
##   HSorLess   355   126
## 
## $test
##        what        value
## 1 statistic 5.608269e+01
## 2        df 2.000000e+00
## 3   P-value 6.634351e-13</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="7" style="list-style-type: lower-alpha">
<li>What do you conclude from your test, in the context of the data?</li>
</ol>
<p>Solution</p>
<p>The P-value of <span class="math inline">\(6.6\times 10^{-13}\)</span> is extremely small, so we conclude that not all of the education groups watch the same median amount of TV.
Or, there are differences in the median amount of TV watched among the three groups.</p>
<p>An answer of “the education groups are different” is <em>wrong</em>, because you don’t know that they are <em>all</em> different. It might be that some of them are different and some of them are the same. The next part gets into that.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="8" style="list-style-type: lower-alpha">
<li>Why might you now want to run some kind of follow-up test? Run the appropriate thing and explain briefly what you conclude from it, in the context of the data.</li>
</ol>
<p>Solution</p>
<p>The overall Mood test is significant, so there are some differences between the education groups, but we don’t know where they are. Pairwise median tests will reveal where any differences are:</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb244-1" title="1"><span class="kw">pairwise_median_test</span>(gss, tvhours, degree)</a></code></pre></div>
<pre><code>## # A tibble: 3 x 4
##   g1       g2        p_value   adj_p_value
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;         &lt;dbl&gt;
## 1 College  Graduate 5.12e- 2 0.154        
## 2 College  HSorLess 8.06e-10 0.00000000242
## 3 Graduate HSorLess 3.06e- 7 0.000000919</code></pre>
<p>The people whose education is high school or less are significantly different from the other two education levels. The boxplot reveals that this is because they watch <em>more</em> TV on average. The college and graduate groups are not significantly different (in median TV watching).</p>
<p>Extra 1:</p>
<p>You might have been surprised that the College and Graduate medians were not significantly different. After all, they look quite different on the boxplot. Indeed, the P-value for comparing just those two groups is 0.0512, only just over 0.05. But remember that we are doing three tests at once, so the Bonferroni adjustment is to multiply the P-values by 3, so this P-value is “really” some way from being significant.
I thought I would investigate this in more detail:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb246-1" title="1">gss <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(degree <span class="op">!=</span><span class="st"> &quot;HSorLess&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb246-2" title="2"><span class="kw">median_test</span>(tvhours, degree)</a></code></pre></div>
<pre><code>## $table
##           above
## group      above below
##   College     67    70
##   Graduate    18    36
## 
## $test
##        what     value
## 1 statistic 3.8027625
## 2        df 1.0000000
## 3   P-value 0.0511681</code></pre>
<p>The College group are about 50-50 above and below the overall median, but the Graduate group are two-thirds below. This suggests that the Graduate group watches less TV, and with these sample sizes I would have expected a smaller P-value. But it didn’t come out that way.</p>
<p>You might also be concerned that there are in total more values below the grand median (106) than above (only 85). This must mean that there are a lot of data values <em>equal</em> to the grand median:</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb248-1" title="1">gss <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(degree <span class="op">!=</span><span class="st"> &quot;HSorLess&quot;</span>) -&gt;<span class="st"> </span>gss1</a>
<a class="sourceLine" id="cb248-2" title="2">gss1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">med=</span><span class="kw">median</span>(tvhours))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##     med
##   &lt;dbl&gt;
## 1     2</code></pre>
<p>and</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb250-1" title="1">gss1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(tvhours)</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    tvhours     n
##      &lt;dbl&gt; &lt;int&gt;
##  1       0    15
##  2       1    91
##  3       2    74
##  4       3    51
##  5       4    17
##  6       5     5
##  7       6     6
##  8       7     2
##  9       8     3
## 10      12     1</code></pre>
<p>Everybody gave a whole number of hours, and there are not too many different ones; in addition, a lot of them are equal to the grand median of 2.</p>
<p>Extra 2:</p>
<p>Regular ANOVA and Welch ANOVA should be non-starters here because of the non-normality, but you might be curious about how they would perform:</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb252-1" title="1">gss<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">aov</span>(tvhours<span class="op">~</span>degree, <span class="dt">data=</span>gss)</a>
<a class="sourceLine" id="cb252-2" title="2"><span class="kw">summary</span>(gss<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##              Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## degree        2    267  133.30   25.18 2.27e-11 ***
## Residuals   902   4774    5.29                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb254-1" title="1"><span class="kw">TukeyHSD</span>(gss<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = tvhours ~ degree, data = gss)
## 
## $degree
##                         diff        lwr       upr     p adj
## Graduate-College  -0.4238095 -1.1763372 0.3287181 0.3831942
## HSorLess-College   1.0598958  0.6181202 1.5016715 0.0000001
## HSorLess-Graduate  1.4837054  0.8037882 2.1636225 0.0000011</code></pre>
<p>and</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb256-1" title="1"><span class="kw">oneway.test</span>(tvhours<span class="op">~</span>degree, <span class="dt">data=</span>gss)</a></code></pre></div>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  tvhours and degree
## F = 37.899, num df = 2.00, denom df = 206.22, p-value = 9.608e-15</code></pre>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb258-1" title="1"><span class="kw">gamesHowellTest</span>(tvhours<span class="op">~</span><span class="kw">factor</span>(degree), <span class="dt">data=</span>gss)</a></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using Games-Howell test</code></pre>
<pre><code>## data: tvhours by factor(degree)</code></pre>
<pre><code>##          College Graduate
## Graduate 0.12    -       
## HSorLess 2.4e-10 1.7e-10</code></pre>
<pre><code>## 
## P value adjustment method: none</code></pre>
<pre><code>## alternative hypothesis: two.sided</code></pre>
<p>The conclusions are actually identical to our Mood test, and the P-values are actually not all that much different. Which makes me wonder just how bad the sampling distributions of the sample means are. Bootstrap to the rescue:</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb264-1" title="1">gss <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb264-2" title="2"><span class="st">  </span><span class="kw">nest_by</span>(degree) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb264-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">list</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb264-4" title="4"><span class="st">  </span><span class="kw">unnest</span>(sim) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb264-5" title="5"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb264-6" title="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">sample</span>(data<span class="op">$</span>tvhours, <span class="dt">replace =</span> <span class="ot">TRUE</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb264-7" title="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_mean =</span> <span class="kw">mean</span>(my_sample)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb264-8" title="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> my_mean)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">12</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb264-9" title="9"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>degree, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-159-1.png" width="672" /></p>
<p>Coding this made my head hurt, but building it one line at a time, I pretty much got it right first time. In words:</p>
<ul>
<li>“compress” the dataframe to get one row per degree and a list-column called <code>data</code> with the number of hours of TV watched for each person with that <code>degree</code></li>
<li>generate 1000 <code>sim</code>s for each <code>degree</code> (to guide the taking of bootstrap samples shortly)</li>
<li>organize into one row per <code>sim</code></li>
<li>then take bootstrap samples as normal and work out the mean of each one</li>
<li>make histograms for each <code>degree</code>, using a different scale for each one. (This has the advantage that the normal number of <code>bins</code> will work for all the histograms.)</li>
</ul>
<p>If you are not sure about what happened, run it one line at a time and see what the results look like after each one.</p>
<p>Anyway, even though the data was very much not normal, these sampling distributions are very normal-looking, suggesting that something like Welch ANOVA would have been not nearly as bad as you would have guessed. This is evidently because of the big sample sizes. (This also explains why the two other flavours of ANOVA gave results very similar to Mood’s median test.)</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="death-of-poets-1" class="section level2">
<h2><span class="header-section-number">13.17</span> Death of poets</h2>
<p>Some people believe that poets, especially female poets, die younger than other types of writer. <a href="https://en.wikipedia.org/wiki/W._B._Yeats">William Butler Yeats</a><a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a> wrote:</p>
<blockquote>
<p>She is the Gaelic<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> muse, for she gives inspiration to those she persecutes. The Gaelic poets die young, for she is restless, and will not let them remain long on earth.</p>
</blockquote>
<p>A literature student wanted to investigate this, and so collected a sample of 123 female writers (of three different types), and noted the age at death of each writer.</p>
<p>The data are in <a href="http://ritsokiguess.site/datafiles/writers.csv">http://ritsokiguess.site/datafiles/writers.csv</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display (some of) the data.</li>
</ol>
<p>Solution</p>
<p>The usual:</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb265-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/writers.csv&quot;</span></a>
<a class="sourceLine" id="cb265-2" title="2">writers &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   Type1 = col_double(),
##   Type = col_character(),
##   Age = col_double()
## )</code></pre>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb267-1" title="1">writers</a></code></pre></div>
<pre><code>## # A tibble: 123 x 3
##    Type1 Type     Age
##    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;
##  1     1 Novels    57
##  2     1 Novels    90
##  3     1 Novels    67
##  4     1 Novels    56
##  5     1 Novels    90
##  6     1 Novels    72
##  7     1 Novels    56
##  8     1 Novels    90
##  9     1 Novels    80
## 10     1 Novels    74
## # … with 113 more rows</code></pre>
<p>There are indeed 123 writers. The second column shows the principal type of writing each writer did, and the third column shows their age at death. The first column is a numerical code for the type of writing, which we ignore (since we can handle the text writing type).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Make a suitable plot of the ages and types of writing.</li>
</ol>
<p>Solution</p>
<p>As usual, one quantitative and one categorical, so a boxplot:</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb269-1" title="1"><span class="kw">ggplot</span>(writers, <span class="kw">aes</span>(<span class="dt">x=</span>Type, <span class="dt">y=</span>Age)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-161-1.png" width="672" /></p>
<p>At this point, a boxplot is best, since right now you are mostly after a general sense of what is going on, rather than assessing normality in particular (that will come later).</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Obtain a summary table showing, for each type of writing, the number of writers of that type, along with the mean, median and standard deviation of their ages at death.</li>
</ol>
<p>Solution</p>
<p>The customary <code>group_by</code> and <code>summarize</code>:</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb270-1" title="1">writers <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Type) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb270-2" title="2"><span class="kw">summarize</span>(<span class="dt">n=</span><span class="kw">n</span>(), <span class="dt">mean=</span><span class="kw">mean</span>(Age), <span class="dt">med=</span><span class="kw">median</span>(Age), <span class="dt">sd=</span><span class="kw">sd</span>(Age))</a></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   Type           n  mean   med    sd
##   &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 Nonfiction    24  76.9  77.5  14.1
## 2 Novels        67  71.4  73    13.1
## 3 Poems         32  63.2  68    17.3</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Run a complete analysis, starting with an ordinary (not Welch) analysis of variance, that ends with a conclusion in the context of the data and an assessment of assumptions.</li>
</ol>
<p>Solution</p>
<p>I’ve left this fairly open-ended, to see how well you know what needs to be included and what it means. There is a lot of room here for explanatory text to show that you know what you are doing. One output followed by another <em>without</em> any explanatory text suggests that you are just copying what I did without any idea about why you are doing it.</p>
<p>The place to start is the ordinary (not Welch) ANOVA. You may not think that this is the best thing to do (you’ll have a chance to talk about that later), but I wanted to make sure that you practiced the procedure:</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb272-1" title="1">writers<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">aov</span>(Age<span class="op">~</span>Type, <span class="dt">data=</span>writers)</a>
<a class="sourceLine" id="cb272-2" title="2"><span class="kw">summary</span>(writers<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##              Df Sum Sq Mean Sq F value  Pr(&gt;F)   
## Type          2   2744  1372.1   6.563 0.00197 **
## Residuals   120  25088   209.1                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This says that the mean ages at death of the three groups of writers are not all the same, or that there are differences among those writers (in terms of mean age at death). “The mean ages of the types of writer are different” is not accurate enough, because it comes too close to saying that <em>all three</em> groups are different, which is more than you can say right now.</p>
<p>The <span class="math inline">\(F\)</span>-test is significant, meaning that there are some differences among<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a> the means, and Tukey’s method will enable us to see which ones differ:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb274-1" title="1"><span class="kw">TukeyHSD</span>(writers<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Age ~ Type, data = writers)
## 
## $Type
##                         diff       lwr       upr     p adj
## Novels-Nonfiction  -5.427239 -13.59016  2.735681 0.2591656
## Poems-Nonfiction  -13.687500 -22.95326 -4.421736 0.0018438
## Poems-Novels       -8.260261 -15.63375 -0.886772 0.0240459</code></pre>
<p>There is a significant difference in mean age at death between the poets and both the other types of writer. The novelists and the nonfiction writers do not differ significantly in mean age at death.</p>
<p>We know from the boxplots (or the summary table) that this significant difference was because the poets died <em>younger</em> on average, which is exactly what the literature student was trying to find out. Thus, female poets really do die younger on average than female writers of other types. It is best to bring this point out, since this is the reason we (or the literature student) were doing this analysis in the first place. See Extra 1 for more.</p>
<p>So now we need to assess the assumptions on which the ANOVA depends.</p>
<p>The assumption we made is that the ages at death of the authors of each different type had approximately a normal distribution (given the sample sizes) with approximately equal spread. The boxplots definitely look skewed to the left (well, not the poets so much, but the others definitely). So now consider the sample sizes: 24, 67, and 32 for the three groups (respectively), and make a call about whether you think the normality is good enough. You are certainly entitled to declare the two outliers on the nonfiction writers to be too extreme given a sample size of only 24. Recall that once one sample fails normality, that’s all you need.</p>
<p>Now, since you specifically want normality, you could reasonably look at normal quantile plots instead of the boxplots. Don’t just get normal quantile plots, though; say something about why you want them instead of the boxplots you drew earlier:</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb276-1" title="1"><span class="kw">ggplot</span>(writers, <span class="kw">aes</span>(<span class="dt">sample =</span> Age)) <span class="op">+</span></a>
<a class="sourceLine" id="cb276-2" title="2"><span class="kw">stat_qq</span>() <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq_line</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb276-3" title="3"><span class="kw">facet_wrap</span>(<span class="op">~</span>Type)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-165-1.png" width="672" /></p>
<p>I see that the Nonfiction writers have two outliers at the low end (and are otherwise not bad); the writers of Novels don’t go up high enough (it’s almost as if there is some magic that stops them living beyond 90!); the writers of Poems have a short-tailed distribution. You’ll remember that short tails are not a problem, since the mean is still descriptive of such a distribution; it’s <em>long</em> tails or outliers or skewness that you need to be worried about. The outliers in the Nonfiction writers are the biggest concern.</p>
<p>Are you concerned that these outliers are a problem, given the sample size? There are only 24 nonfiction writers (from your table of means earlier), so the Central Limit Theorem will help a bit. Make a call about whether these outliers are a big enough problem. You can go either way on this, as long as you raise the relevant issues.</p>
<p>Another approach you might take is to look at the P-values. The one in the <span class="math inline">\(F\)</span>-test is really small, and so is one of the ones in the Tukey. So even if you think the analysis is a bit off, those conclusions are not likely to change. The 0.02 P-value in the Tukey, however, is another story. This could become non-significant in actual fact if the P-value is not to be trusted.</p>
<p>Yet another approach (looking at the bootstrapped sampling distributions of the sample means) is in Extra 3. This gets more than a little hairy with three groups, especially doing it the way I do.</p>
<p>If you think that the normality is not good enough, it’s a good idea to suggest that we might do a Mood’s Median Test instead, and you could even do it (followed up with pairwise median tests). If you think that normality is all right, you might then look at the spreads. I think you ought to conclude that these are close enough to equal (the SDs from the summary table or the heights of the boxes on the boxplots), and so there is no need to do a Welch ANOVA. (Disagree if you like, but be prepared to make the case.)</p>
<p>I have several Extras:</p>
<p>Extra 1: having come to that tidy conclusion, we really ought to back off a bit. These writers were (we assume) a random sample of some population, but they were actually mostly Americans, with a few Canadian and Mexican writers. So this appears to be true at least for North American writers. But this is (or might be) a different thing to the Yeats quote about female Gaelic poets.</p>
<p>There is a more prosaic reason. It is harder (in most places, but especially North America) to get poetry published than it is to find a market for other types of writing. (A would-be novelist, say, can be a journalist or write for magazines to pay the bills while they try to find a publisher for their novel.) Thus a poet is living a more precarious existence, and that might bring about health problems.</p>
<p>Extra 2: with the non-normality in mind, maybe Mood’s median test is the thing:</p>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb277-1" title="1"><span class="kw">median_test</span>(writers, Age, Type)</a></code></pre></div>
<pre><code>## $table
##             above
## group        above below
##   Nonfiction    17     6
##   Novels        33    30
##   Poems         10    22
## 
## $test
##        what       value
## 1 statistic 9.872664561
## 2        df 2.000000000
## 3   P-value 0.007180888</code></pre>
<p>The P-value here is a bit bigger than for the <span class="math inline">\(F\)</span>-test, but it is still clearly significant. Hence, we do the pairwise median tests to find out which medians differ:</p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb279-1" title="1"><span class="kw">pairwise_median_test</span>(writers, Age, Type)</a></code></pre></div>
<pre><code>## # A tibble: 3 x 4
##   g1         g2     p_value adj_p_value
##   &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt;       &lt;dbl&gt;
## 1 Nonfiction Novels 0.0531      0.159  
## 2 Nonfiction Poems  0.00119     0.00358
## 3 Novels     Poems  0.0142      0.0426</code></pre>
<p>The conclusion here is exactly the same as for the ANOVA. The P-values have moved around a bit, though: the first one is a little closer to significance (remember, look at the last column since we are doing three tests at once) and the last one is now only just significant.</p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb281-1" title="1">writers <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(Type) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb281-2" title="2"><span class="kw">summarize</span>(<span class="dt">n=</span><span class="kw">n</span>(), <span class="dt">mean=</span><span class="kw">mean</span>(Age), <span class="dt">med=</span><span class="kw">median</span>(Age), <span class="dt">sd=</span><span class="kw">sd</span>(Age))</a></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   Type           n  mean   med    sd
##   &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 Nonfiction    24  76.9  77.5  14.1
## 2 Novels        67  71.4  73    13.1
## 3 Poems         32  63.2  68    17.3</code></pre>
<p>In both of these two cases (Nonfiction-Novels and Novels-Poems), the medians are closer together than the means are. That would explain why the Novels-Poems P-value would increase, but not why the Nonfiction-Novels one would decrease.</p>
<p>I would have no objection <em>in general</em> to your running a Mood’s Median Test on these data, but the point of <em>this</em> problem was to give you practice with <code>aov</code>.</p>
<p>Extra 3: the other way to assess if the normality is OK given the sample sizes is to obtain bootstrap sampling distributions of the sample means for each <code>Type</code>. The sample size for the novelists is 67, so I would expect the skewness there to be fine, but the two outliers among the Nonfiction writers may be cause for concern, since there are only 24 of those altogether.</p>
<p>Let’s see if we can do all three at once (I like living on the edge). I take things one step at a time, building up a pipeline as I go. Here’s how it starts:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb283-1" title="1">writers <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nest_by</span>(Type)</a></code></pre></div>
<pre><code>## # A tibble: 3 x 2
## # Rowwise:  Type
##   Type                     data
##   &lt;chr&gt;      &lt;list&lt;tibble[,2]&gt;&gt;
## 1 Nonfiction           [24 × 2]
## 2 Novels               [67 × 2]
## 3 Poems                [32 × 2]</code></pre>
<p>The thing <code>data</code> is a so-called list-column. The dataframes we have mostly seen so far are like spreadsheets, in that each “cell” or “entry” in a dataframe has something like a number or a piece of text in it (or, occasionally, a thing that is True or False, or a date). Tibble-type dataframes are more flexible than that, however: each cell of a dataframe could contain <em>anything.</em></p>
<p>In this one, the three things in the column <code>data</code> are each <em>dataframes</em>,<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> containing the column called <code>Age</code> from the original dataframe. These are the ages at death of the writers of that particular <code>Type</code>. These are the things we want bootstrap samples of.</p>
<p>I’m not at all sure how this is going to go, so let’s shoot for just 5 bootstrap samples to start with. If we can get it working, we can scale up the number of samples later, but having a smaller number of samples is easier to look at:</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb285-1" title="1">writers <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nest_by</span>(Type) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb285-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">list</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>))</a></code></pre></div>
<pre><code>## # A tibble: 3 x 3
## # Rowwise:  Type
##   Type                     data sim      
##   &lt;chr&gt;      &lt;list&lt;tibble[,2]&gt;&gt; &lt;list&gt;   
## 1 Nonfiction           [24 × 2] &lt;int [5]&gt;
## 2 Novels               [67 × 2] &lt;int [5]&gt;
## 3 Poems                [32 × 2] &lt;int [5]&gt;</code></pre>
<p>Let me break off at this point to say that we want 1000 bootstrap samples for the writers of each type, so this is the kind of thing we need to start with. <code>nest_by</code> has an implied <code>rowwise</code>, so we get three lots of values in <code>sim</code>; the <code>list</code> is needed since each one is five values rather than just one. The next stage is to unnest these, and then do <em>another</em> <code>rowwise</code> to work with all the (more) rows of the dataframe we now have. After that, the process should look more or less familiar:</p>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb287-1" title="1">writers <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nest_by</span>(Type) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb287-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">list</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb287-3" title="3"><span class="st">  </span><span class="kw">unnest</span>(sim) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb287-4" title="4"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb287-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">sample</span>(data<span class="op">$</span>Age, <span class="dt">replace =</span> <span class="ot">TRUE</span>)))</a></code></pre></div>
<pre><code>## # A tibble: 15 x 4
## # Rowwise:  Type
##    Type                     data   sim my_sample 
##    &lt;chr&gt;      &lt;list&lt;tibble[,2]&gt;&gt; &lt;int&gt; &lt;list&gt;    
##  1 Nonfiction           [24 × 2]     1 &lt;dbl [24]&gt;
##  2 Nonfiction           [24 × 2]     2 &lt;dbl [24]&gt;
##  3 Nonfiction           [24 × 2]     3 &lt;dbl [24]&gt;
##  4 Nonfiction           [24 × 2]     4 &lt;dbl [24]&gt;
##  5 Nonfiction           [24 × 2]     5 &lt;dbl [24]&gt;
##  6 Novels               [67 × 2]     1 &lt;dbl [67]&gt;
##  7 Novels               [67 × 2]     2 &lt;dbl [67]&gt;
##  8 Novels               [67 × 2]     3 &lt;dbl [67]&gt;
##  9 Novels               [67 × 2]     4 &lt;dbl [67]&gt;
## 10 Novels               [67 × 2]     5 &lt;dbl [67]&gt;
## 11 Poems                [32 × 2]     1 &lt;dbl [32]&gt;
## 12 Poems                [32 × 2]     2 &lt;dbl [32]&gt;
## 13 Poems                [32 × 2]     3 &lt;dbl [32]&gt;
## 14 Poems                [32 × 2]     4 &lt;dbl [32]&gt;
## 15 Poems                [32 × 2]     5 &lt;dbl [32]&gt;</code></pre>
<p>That seems to be about the right thing; the bootstrap samples appear to be the right size, considering how many writers of each type our dataset had. From here, work out the mean of each sample:</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb289-1" title="1">writers <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nest_by</span>(Type) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb289-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">list</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb289-3" title="3"><span class="st">  </span><span class="kw">unnest</span>(sim) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb289-4" title="4"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb289-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">sample</span>(data<span class="op">$</span>Age, <span class="dt">replace =</span> <span class="ot">TRUE</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb289-6" title="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_mean =</span> <span class="kw">mean</span>(my_sample))</a></code></pre></div>
<pre><code>## # A tibble: 15 x 5
## # Rowwise:  Type
##    Type                     data   sim my_sample  my_mean
##    &lt;chr&gt;      &lt;list&lt;tibble[,2]&gt;&gt; &lt;int&gt; &lt;list&gt;       &lt;dbl&gt;
##  1 Nonfiction           [24 × 2]     1 &lt;dbl [24]&gt;    78.5
##  2 Nonfiction           [24 × 2]     2 &lt;dbl [24]&gt;    80.6
##  3 Nonfiction           [24 × 2]     3 &lt;dbl [24]&gt;    77.3
##  4 Nonfiction           [24 × 2]     4 &lt;dbl [24]&gt;    77.9
##  5 Nonfiction           [24 × 2]     5 &lt;dbl [24]&gt;    73.4
##  6 Novels               [67 × 2]     1 &lt;dbl [67]&gt;    71.1
##  7 Novels               [67 × 2]     2 &lt;dbl [67]&gt;    73.3
##  8 Novels               [67 × 2]     3 &lt;dbl [67]&gt;    71.9
##  9 Novels               [67 × 2]     4 &lt;dbl [67]&gt;    69.1
## 10 Novels               [67 × 2]     5 &lt;dbl [67]&gt;    73.2
## 11 Poems                [32 × 2]     1 &lt;dbl [32]&gt;    69.3
## 12 Poems                [32 × 2]     2 &lt;dbl [32]&gt;    63.5
## 13 Poems                [32 × 2]     3 &lt;dbl [32]&gt;    64.9
## 14 Poems                [32 × 2]     4 &lt;dbl [32]&gt;    59.8
## 15 Poems                [32 × 2]     5 &lt;dbl [32]&gt;    61.8</code></pre>
<p>and then you could plot those means. This seems to be working, so let’s scale up to 1000 simulations, and make normal quantile plots of the bootstrapped sampling distributions, one for each Type of writer:</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb291-1" title="1">writers <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nest_by</span>(Type) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb291-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">list</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb291-3" title="3"><span class="st">  </span><span class="kw">unnest</span>(sim) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb291-4" title="4"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb291-5" title="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">sample</span>(data<span class="op">$</span>Age, <span class="dt">replace =</span> <span class="ot">TRUE</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb291-6" title="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_mean =</span> <span class="kw">mean</span>(my_sample)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb291-7" title="7"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> my_mean)) <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb291-8" title="8"><span class="st">  </span><span class="kw">stat_qq_line</span>() <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span>Type, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-173-1.png" width="672" /></p>
<p>These three normal quantile plots are all acceptable, to my mind, although the Nonfiction one, with the two outliers and the smallest sample size, is still a tiny bit skewed to the left. Apart from that, the three sampling distributions of the sample means are close to normal, so our <code>aov</code> is much better than you might have thought from looking at the boxplots. That’s the result of having large enough samples to get help from the Central Limit Theorem.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
</div>
<div id="religion-and-studying-1" class="section level2">
<h2><span class="header-section-number">13.18</span> Religion and studying</h2>
<p>Many students at a certain university were asked about the importance of religion in their lives (categorized as “not”, “fairly”, or “very” important), and also about the number of
hours they spent studying per week. (This was part of a much larger survey.) We want to see whether there is any kind of relationship between these two variables. The data are in <a href="http://ritsokiguess.site/datafiles/student_relig.csv">here</a>.</p>
<ol style="list-style-type: lower-alpha">
<li>Read in and display (some of) the data.</li>
</ol>
<p>Solution</p>
<p>The usual. This is a straightforward one:</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb292-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/student_relig.csv&quot;</span></a>
<a class="sourceLine" id="cb292-2" title="2">student &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   ReligImp = col_character(),
##   StudyHrs = col_double()
## )</code></pre>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb294-1" title="1">student</a></code></pre></div>
<pre><code>## # A tibble: 686 x 2
##    ReligImp StudyHrs
##    &lt;chr&gt;       &lt;dbl&gt;
##  1 Fairly          3
##  2 Fairly         30
##  3 Fairly         16
##  4 Not             4
##  5 Not            12
##  6 Fairly         20
##  7 Fairly          4
##  8 Not            15
##  9 Fairly          7
## 10 Fairly         40
## # … with 676 more rows</code></pre>
<p>686 students, with columns obviously named for religious importance and study hours.</p>
<p>Extra:</p>
<p>I said this came from a bigger survey, actually this one:</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb296-1" title="1">my_url &lt;-<span class="st"> &quot;http://ritsokiguess.site/datafiles/student0405.csv&quot;</span></a>
<a class="sourceLine" id="cb296-2" title="2">student0 &lt;-<span class="st"> </span><span class="kw">read_csv</span>(my_url)</a></code></pre></div>
<pre><code>## 
## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## cols(
##   Sex = col_character(),
##   GPA = col_double(),
##   ReligImp = col_character(),
##   MissClass = col_double(),
##   Seat = col_character(),
##   PartyDays = col_double(),
##   StudyHrs = col_double()
## )</code></pre>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb298-1" title="1">student0</a></code></pre></div>
<pre><code>## # A tibble: 690 x 7
##    Sex      GPA ReligImp MissClass Seat   PartyDays StudyHrs
##    &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;
##  1 Female  3.7  Fairly           1 Back           5        3
##  2 Male    3.2  Fairly           3 Front          3       30
##  3 Female  3.01 Fairly           0 Middle         8       16
##  4 Female  3.77 Not              0 Middle         0        4
##  5 Male    3.28 Not              0 Middle         8       12
##  6 Female  2.8  Fairly           0 Middle         2       20
##  7 Male    2.5  Fairly           3 Back           1        4
##  8 Male    3.11 Not              0 Front          2       15
##  9 Male    3.15 Fairly           2 Back          15        7
## 10 Male    3.44 Fairly           0 Middle         1       40
## # … with 680 more rows</code></pre>
<p>There are four extra rows here. Why? Let’s look at a <code>summary</code> of the dataframe:</p>

<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb300-1" title="1"><span class="kw">summary</span>(student0) </a></code></pre></div>
<pre><code>##      Sex                 GPA          ReligImp           MissClass          Seat             PartyDays         StudyHrs    
##  Length:690         Min.   :1.500   Length:690         Min.   :0.0000   Length:690         Min.   : 0.000   Min.   : 0.00  
##  Class :character   1st Qu.:2.930   Class :character   1st Qu.:0.0000   Class :character   1st Qu.: 3.000   1st Qu.: 6.25  
##  Mode  :character   Median :3.200   Mode  :character   Median :1.0000   Mode  :character   Median : 7.000   Median :10.00  
##                     Mean   :3.179                      Mean   :0.9064                      Mean   : 7.501   Mean   :13.16  
##                     3rd Qu.:3.515                      3rd Qu.:1.0000                      3rd Qu.:11.000   3rd Qu.:16.00  
##                     Max.   :4.000                      Max.   :6.0000                      Max.   :31.000   Max.   :70.00  
##                     NA&#39;s   :3                          NA&#39;s   :1                                            NA&#39;s   :4</code></pre>

<p>You get information about each variable. For the text variables, you don’t learn much, only how many there are. (See later for more on this.)
For each of the four quantitative variables, you see
some stats about each one, along with a count of missing values. The study hours variable is evidently skewed to the right (mean bigger than median), which we will have to think about later.</p>
<p>R also has a “factor” variable type, which is the “official” way to handle categorical variables in R. Sometimes it matters, but most of the time leaving categorical variables as text is just fine. <code>summary</code> handles these
differently. My second line of code below says “for each variable that is text, make it into a factor”:</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb302-1" title="1">student0 <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb302-2" title="2"><span class="kw">mutate</span>(<span class="kw">across</span>(<span class="kw">where</span>(is.character), <span class="op">~</span><span class="kw">factor</span>(.))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb302-3" title="3"><span class="kw">summary</span>()</a></code></pre></div>
<pre><code>##      Sex           GPA          ReligImp     MissClass          Seat       PartyDays         StudyHrs    
##  Female:382   Min.   :1.500   Fairly:319   Min.   :0.0000   Back  :134   Min.   : 0.000   Min.   : 0.00  
##  Male  :308   1st Qu.:2.930   Not   :222   1st Qu.:0.0000   Front :151   1st Qu.: 3.000   1st Qu.: 6.25  
##               Median :3.200   Very  :149   Median :1.0000   Middle:404   Median : 7.000   Median :10.00  
##               Mean   :3.179                Mean   :0.9064   NA&#39;s  :  1   Mean   : 7.501   Mean   :13.16  
##               3rd Qu.:3.515                3rd Qu.:1.0000                3rd Qu.:11.000   3rd Qu.:16.00  
##               Max.   :4.000                Max.   :6.0000                Max.   :31.000   Max.   :70.00  
##               NA&#39;s   :3                    NA&#39;s   :1                                      NA&#39;s   :4</code></pre>
<p>For factors, you also get how many observations there are in each category, and the number of missing values, which we didn’t get before.
However, <code>ReligImp</code> does not have any missing values.</p>
<p>I said there were four missing values for study hours, that is, four students who left that blank on their survey.
We want to get rid of those students (that is, remove those whole rows), and, to simplify things for you, let’s keep only the study hours and importance of religion columns. That goes like this:</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb304-1" title="1">student0 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">drop_na</span>(StudyHrs) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb304-2" title="2"><span class="kw">select</span>(ReligImp, StudyHrs)</a></code></pre></div>
<pre><code>## # A tibble: 686 x 2
##    ReligImp StudyHrs
##    &lt;chr&gt;       &lt;dbl&gt;
##  1 Fairly          3
##  2 Fairly         30
##  3 Fairly         16
##  4 Not             4
##  5 Not            12
##  6 Fairly         20
##  7 Fairly          4
##  8 Not            15
##  9 Fairly          7
## 10 Fairly         40
## # … with 676 more rows</code></pre>
<p>Then I saved that for you. 686 rows instead of 690, having removed the four rows with missing <code>StudyHrs</code>.</p>
<p>Another (better, but more complicated) option is to use the package <code>pointblank</code>, which produces much more detailed data validation reports. You would start that by piping your data into <code>scan_data()</code> to get a (very) detailed report of missingness and data values, and then you can check your data for particular problems, such as missing values, or values bigger or smaller than they should be, for the variables you care about. See <a href="https://github.com/rich-iannone/pointblank">here</a> for more.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Obtain the number of observations and the mean and standard deviation of study hours for each level of importance.</li>
</ol>
<p>Solution</p>
<p><code>group_by</code> and <code>summarize</code> (spelling the latter with s or z as you prefer):</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb306-1" title="1">student <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(ReligImp) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb306-2" title="2"><span class="kw">summarize</span>(<span class="dt">n=</span><span class="kw">n</span>(), <span class="dt">mean_sh=</span><span class="kw">mean</span>(StudyHrs), <span class="dt">sd_sh=</span><span class="kw">sd</span>(StudyHrs))</a></code></pre></div>
<pre><code>## # A tibble: 3 x 4
##   ReligImp     n mean_sh sd_sh
##   &lt;chr&gt;    &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1 Fairly     316    12.9  9.00
## 2 Not        222    11.7  8.49
## 3 Very       148    16.0 11.3</code></pre>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Comment briefly on how the groups compare in terms of study hours.</li>
</ol>
<p>Solution</p>
<p>The students who think religion is very important have a higher mean number of study hours. The other two groups seem similar.</p>
<p>As far as the SDs are concerned, make a call. You could say that the very-important group also has a (slightly) larger SD, or you could say that the SDs are all very similar.<br />
I would actually favour the second one, but this is going to be a question about Welch ANOVA, so go whichever way you like.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="4" style="list-style-type: lower-alpha">
<li>Make a suitable graph of this data set.</li>
</ol>
<p>Solution</p>
<p>This kind of data is one quantitative and one categorical variable, so once again a boxplot:</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb308-1" title="1"><span class="kw">ggplot</span>(student, <span class="kw">aes</span>(<span class="dt">x=</span>ReligImp, <span class="dt">y=</span>StudyHrs)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-180-1.png" width="672" /></p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="5" style="list-style-type: lower-alpha">
<li>The statistician in this study decided that the data were sufficiently normal in shape given the (very large) sample sizes, but was concerned about unequal spreads among the three groups.
Given this,
run a suitable analysis and display the output. (This includes a suitable follow-up test, if warranted.)</li>
</ol>
<p>Solution</p>
<p>Normal-enough data (in the statistician’s estimation) and unequal spreads means a Welch ANOVA:</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb309-1" title="1"><span class="kw">oneway.test</span>(StudyHrs<span class="op">~</span>ReligImp, <span class="dt">data=</span>student)</a></code></pre></div>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  StudyHrs and ReligImp
## F = 7.9259, num df = 2.0, denom df = 350.4, p-value = 0.0004299</code></pre>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb311-1" title="1"><span class="kw">gamesHowellTest</span>(StudyHrs<span class="op">~</span><span class="kw">factor</span>(ReligImp), <span class="dt">data=</span>student)</a></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using Games-Howell test</code></pre>
<pre><code>## data: StudyHrs by factor(ReligImp)</code></pre>
<pre><code>##      Fairly  Not    
## Not  0.26035 -      
## Very 0.00906 0.00026</code></pre>
<pre><code>## 
## P value adjustment method: none</code></pre>
<pre><code>## alternative hypothesis: two.sided</code></pre>
<p>Games-Howell is the suitable follow-up here, to go with the Welch ANOVA. It is warranted because the Welch ANOVA was significant.</p>
<p>Make sure you have installed and loaded <code>PMCMRplus</code> before trying the second half of this.</p>
<p>Extra: for large data sets, boxplots make it look as if the outlier problem is bad, because a boxplot of a large amount of data will almost certainly contain some outliers (according to Tukey’s definition).
Tukey envisaged a boxplot as something you could draw by hand for a smallish data set, and couldn’t foresee something like R and the kind of data we might be able to deal with. To show you the kind of thing I mean, let’s draw some random samples of varying sizes from normal distributions, which should not have outliers, and see how their boxplots look:</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb317-1" title="1"><span class="kw">tibble</span>(<span class="dt">n=</span><span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">30</span>, <span class="dv">100</span>, <span class="dv">300</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb317-2" title="2"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb317-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">rnorm</span>(n))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb317-4" title="4"><span class="st">  </span><span class="kw">unnest</span>(my_sample) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb317-5" title="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(n), <span class="dt">y =</span> my_sample)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-183-1.png" width="672" /></p>
<p>As the sample size gets bigger, the number of outliers gets bigger, and the whiskers get longer.
All this means is that in a larger sample, you are more likely to see a small number of values that are further out, and that is not necessarily a reason for concern. Here, the outliers are only one value out of 100 and two out of 300, but they have what looks like an outsize influence on the plot. In the boxplot for our data, the distributions were a bit skewed, but the outliers may not have been as much of a problem as they looked.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>
<ol start="6" style="list-style-type: lower-alpha">
<li>What do you conclude from your analysis of the previous part, in the context of the data?</li>
</ol>
<p>Solution</p>
<p>The Welch ANOVA was significant, so the religious-importance groups are not all the same in terms of mean study hours, and we need to figure out which groups differ from which. (Or say this in the previous part if you wish.)</p>
<p>The students for whom religion was very important had a significantly different mean number of study hours than the other students; the Fairly and Not groups were not significantly different from each other.
Looking back at the means (or the boxplots), the significance was because the Very group studied for <em>more</em> hours than the other groups.
It seems that religion has to be very important to a student to positively affect how much they study.</p>
<p>Extra: you might have been concerned that the study hours within the groups were not nearly normal enough to trust the Welch ANOVA. But the groups were large, so there is a lot of help from the Central Limit Theorem.
Enough? Well, that is hard to judge.</p>
<p>My take on this is to bootstrap the sampling distribution of the sample mean for each group. If <em>that</em> looks normal, then we ought to be able to trust the <span class="math inline">\(F\)</span>-test (regular or Welch, as appropriate). The code is complicated (I’ll explain the ideas below):</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb318-1" title="1">student <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-2" title="2"><span class="st">  </span><span class="kw">nest_by</span>(ReligImp) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">list</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-4" title="4"><span class="st">  </span><span class="kw">unnest</span>(sim) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-5" title="5"><span class="st">  </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-6" title="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_sample =</span> <span class="kw">list</span>(<span class="kw">sample</span>(data<span class="op">$</span>StudyHrs, <span class="dt">replace =</span> <span class="ot">TRUE</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-7" title="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">my_mean =</span> <span class="kw">mean</span>(my_sample)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb318-8" title="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> my_mean)) <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq</span>() <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb318-9" title="9"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>ReligImp, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)</a></code></pre></div>
<p><img src="pasias_files/figure-html/unnamed-chunk-184-1.png" width="672" /></p>
<p>To truly understand what’s going on, you probably need to run this code one line at a time.</p>
<p>Anyway, these normal quantile plots are <em>very</em> normal. This says that the sampling distributions of the sample means are <em>very much</em> normal in shape, which means that
the sample sizes are definitely large enough to overcome the apparently bad skewness that we saw on the boxplots. In other words, using a regular or Welch ANOVA will be perfectly good; there is no need to reach for Mood’s median test here, despite what you might think from looking at the boxplots, because the sample sizes are so large.</p>
<p>The code, line by line:</p>
<ul>
<li>create mini-data-frames called <code>data</code>, containing one column called <code>StudyHrs</code>, for each <code>ReligImp</code> group</li>
<li>set up for 1000 bootstrap samples for each group, and (next line) arrange for one row per bootstrap sample</li>
<li>work rowwise</li>
<li>generate the bootstrap samples</li>
<li>work out the mean of each bootstrap sample</li>
<li>plot normal quantile plots of them, using different facets for each group.</li>
</ul>
<p>Finally, you might have wondered whether we needed to do Welch:</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb319-1" title="1">student<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">aov</span>(StudyHrs<span class="op">~</span>ReligImp, <span class="dt">data=</span>student)</a>
<a class="sourceLine" id="cb319-2" title="2"><span class="kw">summary</span>(student<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##              Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## ReligImp      2   1721   860.7   9.768 6.57e-05 ***
## Residuals   683  60184    88.1                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb321-1" title="1"><span class="kw">TukeyHSD</span>(student<span class="fl">.1</span>)</a></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = StudyHrs ~ ReligImp, data = student)
## 
## $ReligImp
##                  diff        lwr       upr     p adj
## Not-Fairly  -1.195917 -3.1267811 0.7349462 0.3135501
## Very-Fairly  3.143047  0.9468809 5.3392122 0.0023566
## Very-Not     4.338964  1.9991894 6.6787385 0.0000454</code></pre>
<p>It didn’t make much difference, and the conclusions are identical. So I think either way would have been defensible.</p>
<p>The value of doing Tukey is that we get confidence intervals for the difference of means between each group, and this gives us an “effect size”: the students for whom religion was very important studied on average three or four hours per week more than the other students, and you can look at the confidence intervals to see how much uncertainty there is in those estimates. Students vary a lot in how much they study, but the sample sizes are large, so the intervals are not that long.</p>
<p><span class="math inline">\(\blacksquare\)</span></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>An Irish, that is to say, Gaelic, poet (see below), but a male one.<a href="analysis-of-variance.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>Gaelic is a language of Scotland and Ireland, and the culture of the people who speak it.<a href="analysis-of-variance.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Actually, this doesn’t always work if the sample sizes in each group are different. If you’re comparing two small groups, it takes a <em>very large</em> difference in means to get a small P-value. But in this case the sample sizes are all the same.<a href="analysis-of-variance.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>The computer scientists among you will note that I should not use equals or not-equals to compare a decimal floating-point number, since decimal numbers are not represented exactly in the computer. R, however, is ahead of us here, since when you try to do “food not equal to 4.7”, it tests whether food is more than a small distance away from 4.7, which is the right way to do it. In R, therefore, code like my <code>food !=  4.7</code> does exactly what I want, but in a language like C, it <em>does not</em>, and you have to be more careful: <code>abs(food-4.7)&gt;1e-8</code>, or something like that. The small number <code>1e-8</code> (<span class="math inline">\(10^{-8}\)</span>) is typically equal to <strong>machine epsilon</strong>, the smallest number on a computer that is distinguishable from zero.<a href="analysis-of-variance.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Most of these parts are old from assignment questions that I actually asked a previous class to do, but not this part. I added it later.<a href="analysis-of-variance.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>See discussion elsewhere about Yates’ Correction and fixed margins.<a href="analysis-of-variance.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>In the pairwise median test in <code>smmr</code>, I did this backwards: rather than changing the alpha that you compare each P-value with from 0.05 to 0.05/6, I flip it around so that you adjust the P-values by <em>multiplying</em> them by 6, and then comparing the adjusted P-values with the usual 0.05. It comes to the same place in the end, except that this way you can get adjusted P-values that are greater than 1, which makes no sense. You read those as being definitely not significant.<a href="analysis-of-variance.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>It’s probably better in a report to use language a bit more formal than <em>a bunch</em>. Something like <em>a number</em> would be better.<a href="analysis-of-variance.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>The use of absolute differences, and the median, downplays the influence of outliers. The assumption here is that the absolute differences from the medians are approximately normal, which seems a less big assumption than assuming the actual data are approximately normal.<a href="analysis-of-variance.html#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>This is coming back to the <em>power</em> of something like Levene’s test; the power of any test is not going to be very big if the sample sizes are small.<a href="analysis-of-variance.html#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>The test goes back to the 1940s.<a href="analysis-of-variance.html#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p>Best, D. J., and J. C. W. Rayner. “Welch’s Approximate Solution for the Behrens–Fisher Problem.” Technometrics 29, no. 2 (May 1, 1987): 205–10. <a href="doi:10.1080/00401706.1987.10488211" class="uri">doi:10.1080/00401706.1987.10488211</a>. The data set is near the end.<a href="analysis-of-variance.html#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p>We’d need a lot more students to make it narrower, but this is not surprising since students vary in a lot of other ways that were not measured here.<a href="analysis-of-variance.html#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p>Perhaps a better word here would be <em>principle</em>, to convey the idea that you can do something else if it works better for your purposes.<a href="analysis-of-variance.html#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p>An Irish, that is to say, Gaelic, poet (see below), but a male one.<a href="analysis-of-variance.html#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p>Gaelic is a language of Scotland and Ireland, and the culture of the people who speak it.<a href="analysis-of-variance.html#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p>There might be differences between two things, but among three or more.<a href="analysis-of-variance.html#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p>Like those Russian dolls.<a href="analysis-of-variance.html#fnref19" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="normal-quantile-plots.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="writing-reports.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["pasias.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
