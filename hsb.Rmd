##  High School and Beyond


 A survey called High School and Beyond was given to a large
number of American high school seniors (grade 12) by the National
Center of Education Statistics. The data set at
[link](http://ritsokiguess.site/datafiles/hsb.csv) is a random
sample of 200 of those students.

The variables collected are:



* `gender`: student's gender, female or male.

* `race`: the student's race (African-American,
Asian,
`r tufte::margin_note("I'm always amused at how Americans put all Asians    into one group.")`  Hispanic, White).

* `ses`: Socio-economic status of student's family (low,
middle, or high)

* `schtyp`: School type, public or private.

* `prog`: Student's program, general, academic, or
vocational. 

* `read`: Score on standardized reading test.

* `write`: Score on standardized writing test.

* `math`: Score on standardized math test.

* `science`: Score on standardized science test.

* `socst`: Score on standardized social studies test.



Our aim is to see how socio-economic status is related to the other
variables. 



(a) Read in and display (some of) the data.

Solution


This is a `.csv` file (I tried to make it easy for you):
```{r }
my_url <- "http://ritsokiguess.site/datafiles/hsb.csv"
hsb <- read_csv(my_url)
hsb
```

       
$\blacksquare$

(b) Explain briefly why an ordinal logistic regression is
appropriate for our aims.

Solution


The response variable `ses` is categorical, with
categories that come in order (low less than middle less than
high). 

$\blacksquare$

(c) Fit an ordinal logistic regression predicting
socio-economic status from the scores on the five standardized
tests. (You don't need to display the results.) You will probably
go wrong the first time. What kind of thing does your response
variable have to be? 

Solution


It has to be an `ordered` factor, which you can create in
the data frame (or outside, if you prefer):
```{r }
hsb <- hsb %>% mutate(ses = ordered(ses, c("low", "middle", "high")))
hsb
```

  

`ses` is now `ord`. Good. Now fit the model:



```{r}
ses.1 <- polr(ses ~ read + write + math + science + socst, data = hsb)
```

       

No errors is good.

$\blacksquare$

(d) Remove any non-significant explanatory variables one at a
time. Use `drop1` to decide which one to remove next.

Solution


```{r }
drop1(ses.1, test = "Chisq")
```

       

I would have expected the AIC column to come out in order, but it
doesn't. Never mind. Scan for the largest P-value, which belongs to
`read`. (This also has the lowest AIC.) So, remove `read`:

```{r }
ses.2 <- update(ses.1, . ~ . - read)
drop1(ses.2, test = "Chisq")
```

 

Note how the P-value for `science` has come down a long way.

A close call, but `math` goes next.  The `update`
doesn't take long to type:

```{r }
ses.3 <- update(ses.2, . ~ . - math)
drop1(ses.3, test = "Chisq")
```

 

`science` has become significant now (probably because it was
strongly correlated with at least one of the variables we removed (at
my guess, `math`). That is, we didn't need both
`science` and `math`, but we *do* need *one* of
them. 

I think we can guess what will happen now: `write` comes out,
and the other two variables will stay, so that'll be where we stop:

```{r }
ses.4 <- update(ses.3, . ~ . - write)
drop1(ses.4, test = "Chisq")
```

 

Indeed so. We need just the science and social studies test scores to
predict socio-economic status.

Using AIC to decide on which variable to remove next will give the
same answer here, but I would like to see the `test=` part in
your `drop1` to give P-values (expect to lose something, but
not too much, if that's not there).

Extras: I talked about correlation among the explanatory variables
earlier, which I can explore:

```{r }
hsb %>% dplyr::select(read:socst) %>% cor()
```

 

The first time I did this, I forgot that I had `MASS` loaded
(for the `polr`), and so, to get the right `select`, I
needed to say which one I wanted.

Anyway, the correlations are all moderately high. There's nothing that
stands out as being much higher than the others. The lowest two are
between social studies and math, and social studies and science. That
would be part of the reason that social studies needs to stay. The
highest correlation is between math and reading, which surprises me
(they seem to be different skills).

So there was not as much insight there as I expected.

The other thing is that you can use `step` for the
variable-elimination task as well:

```{r size="footnotesize"}
ses.5 <- step(ses.1, direction = "backward", test = "Chisq")
```

 

I would accept you doing it this way, again *as long as you have
the `test=` there as well*.

$\blacksquare$

(e) The quartiles of the `science` test score are 44 
and 58. The quartiles of the `socst` test score are 46 and 61. Make
a data frame that has all combinations of those quartiles. If your best
regression had any other explanatory variables in it, also put the
*medians* of those variables into this data frame.


Solution


Thus, most obviously:
```{r }
sciences <- c(44, 58)
socsts <- c(46, 61)
new <- crossing(science = sciences, socst = socsts)
new
```

  

Since there are only two variables left, this new data frame has only
$2^2=4$ rows.

There is a veiled hint here that these are the two variables that
should have remained in your regression. If that was not what you got,
find the median of any other variables you had, and put that into your
`new`. For example, if you still had `math`, you'd do
this:
`r tufte::margin_note("That is *maths* as the apparently-plural of  *math*, not as the British name for mathematics.")`

```{r }
hsb %>% summarize(m = median(math))
maths <- 52
new2 <- crossing(science = sciences, socst = socsts, math = maths)
new2
```

 

$\blacksquare$

(f) Use the data frame you created in the previous part, together
with your best model, to obtain predicted probabilities of being in
each `ses` category.


Solution


This is `predict`, and we've done the setup. My best model
was called `ses.4`:
```{r }
p <- predict(ses.4, new, type = "probs")
cbind(new, p)
```

   

If you forgot which `type` to use, guess one that's obviously
wrong, and it will tell you what your options are. That ought to be
enough to trigger your memory of the right thing.

If you get the `type` right, but the `predict` still
doesn't work, check the construction  of your `new` data frame
very carefully. That's likely where your problem is.

$\blacksquare$

(g) What is the effect of an increased science score on the
likelihood of a student being in the different socioeconomic groups,
all else equal?  Explain briefly. In your explanation, state clearly
how you are using your answer to the previous part.


Solution


Use your predictions; hold the `socst` score constant (that's
the all else equal part). So compare the first and third rows (or,
if you like, the second and fourth rows) of your predictions and see
what happens as the science score goes from 44 to 58.
What I see is that the probability of being `low` goes
noticeably *down* as the science score increases, the
probability of `middle` stays about the same, and the
probability of `high` goes `up` (by about the same
amount as the probability of `low` went down). 
In other words, an increased science score goes with an increased
chance of `high` (and a decreased chance of `low`).
If your best model doesn't have `science` in it, then you
need to say something like "`science` has no effect on   socio-economic status", 
consistent with what you concluded before: if
you took it out, it's because you thought it had no effect.
Extra: the effect of an increased social studies score is almost
exactly the same as an increased science score (so I didn't ask you
about that). From a social-science  point of view, this makes
perfect sense: the higher the social-economic stratum a student
comes from, the better they are likely to do in school. 
I've been phrasing this as "association", because really the cause
and effect is the other way around: a student's family socioeconomic
status is explanatory, and school performance is response. But this
was the nicest example I could find of an ordinal response data set.

$\blacksquare$




