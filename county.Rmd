##  Family doctors and county size


 The United States is divided into a large number of
counties: areas larger than a city but much smaller than a state. 
This question will work with
a data set of the 440 largest counties, which can be found in
[link](http://ritsokiguess.site/datafiles/smsa.txt). 

The variables in the data set are:



* an ID number of the county

* the name of the county (text)

* the state in which the county is located (text)

* land area of the county (square miles)

* total population

* Percent of population aged 18--34

* Percent of population aged 65 or older

* Number of active physicians

* Number of hospital beds

* Total number of serious crimes

* Percent high school graduates (percent of all adults aged 25 or
older that completed grade 12)

* Percent of population with bachelor's degrees (B.\ Sc.\ or BA)

* Percent of population below poverty level

* Percent of labour force that is unemployed (labour force
includes those who could be employed, and excludes
university/college students, those serving in military, those who
cannot work for health reasons).

* Per capita (mean) income of entire population

* Total personal income of entire population (millions of dollars)

* Region of the US (1=northeast, 2=north central, 3=south, 4=west)


Our aim in this question is to understand the factors affecting the
number of active physicians (family doctors) in a county.



(a) Read the data into SAS. Display the values for yourself, but
not to hand in (if you were handing this in).


Solution


This kind of thing:
\begin{Datastep}
filename myurl url "http://ritsokiguess.site/datafiles/smsa.txt";        
proc import 
datafile=myurl
dbms=dlm
out=county
replace;
delimiter=' ';
getnames=yes;
\end{Datastep}
You ought to run this with `proc print` on the end, until
you are happy that you have it right, \emph{but if you were to
hand in 440 lines of `proc print` output, you would
deserve to lose as many marks as the grader decides to
deduct}. Or more.
All the variables that are percentages had names starting with
`pct`. This makes it easier to find them below.

$\blacksquare$

(b) List the first 10 observations of your data set, and
check that the columns that should be percentages actually look
like percentages. Hint: to display a certain number of rows,
*specify a data set name with `data=`* and put
`obs=` and a number *in brackets* on the end of the line.


Solution


The hint suggests this (I was trying not to give it away
completely). You have to specify a name for your data set; it
doesn't work otherwise:
\begin{Sascode}[store=sa]
proc print data=county (obs=10);
\end{Sascode}
\Listing[store=sa, fontsize=footnotesize]{saa}
This displays all the many variables for the first 10
observations. Now, because I named the "percent" variables
beginning with `pct`, I can easily check that these
percentages of people: aged 18--34, aged over 65, completing high
school, with a bachelor's degree, in poverty, and unemployed
look like percentages, and these are the only ones that do. (You
should be checking six variables altogether.)
I thought you could do this by using a `where` line with
`_N_` in it to pick out the rows you want, but it doesn't
work. You can use `_N_` when creating a new data set with
`data` and `set`, but not otherwise. That seems
like way too much trouble here.

$\blacksquare$

(c) We are going to predict the number of physicians in a
county from some of the other variables. Start by obtaining a
scatterplot of the number of physicians against the land
area. What do you see, and what potential problems might this
cause for a regression?


Solution


\begin{Sascode}[store=sd]
proc sgplot;
scatter x=area y=physicians;
\end{Sascode}
\Graphic[store=sd,scale=0.8]{sdd}
Almost all the data points are at the bottom left of the
picture, with only a few elsewhere. There are a few
counties with very big land area (one especially big), and
a few counties with a lot of physicians (not always the
ones with large land area). As a result, the relationship
is not at all clear.
One of the problems with regression is ``influential
points'', observations that are very different from the
others. We seem to have a few of them here. The problem
with influential points is that they can (as their name
implies) influence where the regression goes, even though
there are only a few of them.
This is more discussion than you need, but I want you to
observe two things: (i) that the majority of the points
are bottom left (or that only a few are elsewhere), to
answer "what do you see", and (ii) the points far away
from the others can have a big influence over where the
regression line goes, to answer "potential problems". 
I guess this plot also shows a non-linear relationship,
but that's not the best answer because the evidence for
non-linearity is in those (relatively few) points off by
themselves, not in the big mass of points bottom left, for
which it's very unclear what kind of trend there is.

$\blacksquare$

(d) One way to solve the problems unearthed in the
previous part is to transform the variables that can be very
large. Create a new data set with log-transformed number of
physicians, land area and population.


Solution


This is `data` and `set`:
\begin{Datastep}
data county2;
set county;
logphys=log(physicians);
logpop=log(pop);
logarea=log(area);
\end{Datastep}
If you like, print out the first few lines to check that
the new values look sensible. Or you can summarize, eg.
like this:
\begin{Sascode}[store=gamun]
proc means;
var physicians logphys pop logpop area logarea;
\end{Sascode}
\Listing[store=gamun, fontsize=footnotesize]{gamunn}
The minimum and maximum of the logged variables should be
the (natural) logs of the original values:
```{r }
log(39)
log(23677)
log(100043)
log(8863164)
log(15)
log(20062)
```



That appears to check out.

Note that taking logs has made the very big values not so very
big. There is a county with over 8 million people in it! But the log
of that is only about 16.

The log of the mean (population, say) is not the same as the mean of
the log-population. You might like to think about why not.

$\blacksquare$

(e) Draw histograms of your three new variables. Do they
have something like normal distributions?


Solution


The obvious thing is to draw the histograms one at a time, copying and
pasting your code. Log-physicians:

\begin{Sascode}[store=javuq]
proc sgplot;
histogram logphys;
\end{Sascode}

\Graphic[store=javuq, scale=0.7]{javuqq}

Log-population:

\begin{Sascode}[store=semuv]
proc sgplot;
histogram logpop;
\end{Sascode}

\Graphic[store=semuv, scale=0.7]{semuvv}

Log-area:

\begin{Sascode}[store=mibol]
proc sgplot;
histogram logarea;
\end{Sascode}

\Graphic[store=mibol, scale=0.7]{miboll}

Log-area is nice and symmetric. Log-population is still a bit skewed,
and log-physicians is a bit skewed with an outlier. But if you compare
the histograms of the original variables, things are a lot better
than they were.

I wanted to say something about normal distributions and regression
at this point, since that often seems misunderstood. What
you actually *need* is for the "errors" to be normally
distributed, and since you never actually observe the errors
themselves, you look at the residuals, and if they are approximately
normal, with no patterns in relation to anything else, you are
good. There is *no* need for the $y$ values or the $x$ values to
be normally distributed; in fact, the theory of regression says only
that the $x$'s are *given* (not random at all), or, if you
prefer, you work *conditional* on the $x$'s you observed. 

A little bit of the theory, for those who care: you assume that the
model (one $x$) is $y_i=\alpha+\beta x_i +e_i$, where the errors $e_i$
are the only random thing, and they have independent normal
distributions with mean 0 and variance $\sigma^2$. The $x_i$ are
fixed, and the intercept $\alpha$ and slope $\beta$ are constant
parameters to be estimated (which is done by maximum likelihood or
least squares). Another way to look at this, because of properties of
the normal distribution, is that the $y_i$ have independent normal
distributions with mean $\alpha+\beta x_i$ and constant variance
$\sigma^2$. I actually like this way better, because it transfers over
to generalized linear models, which you might see later. Generalized
linear models don't have "errors" in the same sense; they have a
distribution for the response, with a mean that depends on the $x$ and
a variance that might depend on the distribution. For example,
logistic regression says that $y_i$ has a binomial distribution with a
success probability $p_i$ that depends on the $x_i$. In a typical
application, $x$ might be the dose of some poison and $y$ might be
whether an animal lives or dies. In a binomial distribution, the mean
and the variance both depend on $p$, so once you know the mean, you
also know the variance.

As I said, you never actually observe the $e_i$; the best you
can do is *estimate* them, using the residuals. The independence
of the errors plays out in the need for randomness in any graphs
involving residuals; the normality of the errors plays out in wanting
the normal quantile plot of the residuals to be straight, and the
constant variance plays out in wanting no fanning-out.

Having said all of that, if the distribution of your $x$'s has
outliers, so (probably) will the distribution of your $y$'s, and then
you will be dealing with influential points. It is not
*necessary* for the distribution of your $x$'s to be even
approximately normal, but it generally makes your life easier if it
is. 

So that's why I had you do the transformations and look at the
histograms afterwards.

$\blacksquare$

(f) Do a regression predicting the log-number of physicians from the
log-population and log-area. Display and comment on the results (the
printed part, not the graphs, yet). 



Solution


Nothing terribly surprising in the code. I forgot that you
separate explanatory variables in SAS by a space, not a plus, so I
had to do it twice:
\begin{Sascode}[store=fehig]
proc reg;
model logphys=logpop logarea;
\end{Sascode}
\Listing[store=fehig, fontsize=footnotesize]{fehigg}
A nice high R-squared (for this kind of thing) of 82.25\%. Both
explanatory variables are strongly significant. Log-population has
a positive slope and log-area has a negative one. That means that
counties with a higher population have more physicians (no
surprise there!). Counties with a larger area have fewer
physicians, even after accounting for population. That is to say,
you can't just say that larger counties are likely to be more
sparsely populated and *that's* the reason they have fewer
doctors. I think you have to say something along the lines of
cities having to be big enough to support having a physician, and
a county with large area might have a decent-sized population but
not very many cities of any size and therefore not many places
where it is profitable for a doctor to be. Something like that.


$\blacksquare$

(g) Check the residual plots for the regression you just did. Do you
see anything unacceptable?



Solution


Here is that array of graphs:
\Graphic[store=fehig, scale=0.7]{fehigh}

Residuals vs.\ fitted values top left looks pretty much like a random
cloud (a couple of outliers). You might see some fanning in, but on
the other hand this might be driven by the few counties that happen to
have a small predicted value and a large-in-size residual. When you
have a lot of data, it's important to beware of problems that are
really only caused by a few points.  The normal quantile plot looks
pretty straight, with maybe a few outliers at the top; residuals
against log-area (on the right) a nice random scatter; residuals vs.\
log-population has some fanning in. This might be because even the
distribution of log-population was still skewed and we ought to have
gone further in our transformation (something like reciprocal, maybe,
instead of log).

I might think about some other way of transforming population, but
overall I think this is not too bad.


$\blacksquare$

(h) The regression you just did predicts log-physicians from
log-population and log-area. Do a little algebra to get a relationship
predicting the actual number of physicians from (functions of) the
other variables. Simplify your result as far as you can.



Solution


I can't remember whether I promised "no math" or ``very little
math'' at the start of the course, but anyway.  Let's define some
symbols to make our lives easier: let $d$ be the number of
physicians ("d" for "doctor"), $p$ be the population and $a$
the area of a county. Then our regression says (rounding things
off a bit):
$$ \log d = -9.05 + 1.30 \log p - 0.17 \log a $$
Take $e$-to-the-power-of both sides, which I'll write $\exp$:
$$ d = \exp(-9.05 + 1.30 \log p - 0.17 \log a) $$
Adding things inside $\exp$ means multiplying the separate $\exp$'s:
$$ d = \exp(-9.05) \exp(1.30 \log p) \exp(-0.17 \log a)$$
A piece of math: $\exp(a \log x)=\{\exp(\log x)\}^a = x^a$:
$$ d = e^{-9.05} p^{1.30} a^{-0.17}$$
and you can work out the first $\exp$ if you like (it's a very
small number). 
This is a multiplicative model: the contribution of increasing
population is to *multiply* predicted number of physicians by
something. You can even work out what: if you multiply  the
population by 2, leaving everything else fixed, you get this:
\begin{eqnarray*}
{ d(2p) \over d(p) }  &=&  
{ e^{-9.05} (2p)^{1.30} a^{-0.17} \over e^{-9.05} p^{1.30} a^{-0.17} \\
&=& 2^{1.3} = 2.46
\end{eqnarray*}
since almost everything cancels: that is, doubling the population
slightly more than doubles the number of physicians, if the area
of a county is held constant. Doubling the area while holding the
population constant, by the same logic, changes the number of
physicians by a factor of $2^{-0.17}=0.89$; that is, making it
about 90\% of what it was before.
Clearly there is an effect of population density at work here.

$\blacksquare$

(i) To satisfy the curiosity that you probably have, find the ten
largest counties by population and then list them. Where do you think
the second-largest county is?



Solution


This is actually the same strategy that you would use in R, but
implemented differently: make a new data set that is the old one
sorted (in descending order) by population, and then display its first
ten lines. SAS has a `proc sort` that does this:

\begin{Sascode}[store=tanum]
proc sort;
by descending pop;
proc print data=county2 (obs=10);
var name state area pop;
\end{Sascode}

\Listing[store=tanum, fontsize=footnotesize]{tanumm}

What `proc sort` does is to sort the data set by the
variable(s) requested and *save it back* in a data set of the
same name. That's why my `proc print` worked. (If you don't
like that, you put an `out=` on the `proc sort` line
with a new data set name.)

All of Los Angeles is in one county, which makes it the biggest one in
the entire country. You might not know where Cook County is, but it's
in Illinois, and the biggest city in Illinois is Chicago, so you might
guess that it includes Chicago. If you look it up on Google Maps,
you'll see that you were exactly right.^[If you're as old as I  am, you'll remember a TV series called *ER* starring a very young  George Clooney, which was set in Cook County Hospital, in Chicago.]

The other ones that you may not know:



* Harris County is Houston, Texas

* Kings County is Brooklyn, New York

* Maricopa County is Phoenix, Arizona

* Wayne County is Detroit, Michigan

* Dade County is Miami, Florida (and part of the Everglades).


There are 3144 counties in the US altogether, but the top 146 of them
contain half the country's population. The smallest county is in
Hawaii, and has a population of 88. It's here:
[link](https://www.google.ca/maps/place/Kalawao+County,+HI,+USA/@21.2021259,-156.9809354,13z/data=!3m1!4b1!4m5!3m4!1s0x7eaac65579ddc6f9:0xe77e605e9cb41ca2!8m2!3d21.2273942!4d-156.9749731). The
second smallest is in Texas, here:
[link](https://www.google.ca/maps/place/Loving+County,+TX,+USA/@31.8257709,-103.7953638,11z/data=!3m1!4b1!4m5!3m4!1s0x86e4ce71ef41234d:0xdeecafd0cb46ec56!8m2!3d31.8883434!4d-103.6362715). 

$\blacksquare$




