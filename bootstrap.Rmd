##  Air conditioning failures


 Back in 1963, there was a report on failures in
air-conditioning equipment in
\href{https://en.wikipedia.org/wiki/Boeing_720}{Boeing 720}
aircraft. For one aircraft, the air-conditioning equipment failed 12
times, and the number of hours it ran before failing each time was
recorded. The data are in
[link](https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv). Boeing
was interested in the mean failure time, because the company wanted to
plan for engineers to fix the failures (and thus needed to estimate a
failure *rate*).

There is randomization here. Your answers will differ slightly from
mine, unless you throw in this before you start (or at least before
you generate your first random numbers).

```{r }
set.seed(457299)
```

 



(a) Read in the data, and observe that you have the correct number
of rows. (Note that the failure times are in ascending order).

Solution


This is a `.csv` so `read_csv` is the thing:
```{r }
my_url <- "https://raw.githubusercontent.com/nxskok/pasias/master/air_conditioning.csv"
aircon <- read_csv(my_url)
aircon
```

     

Twelve rows (12 failure times).


(b) What do you notice about the *shape* of the distribution of failure times? Explain briefly.

Solution


Make a suitable graph. The obvious one is a histogram:

```{r }
ggplot(aircon, aes(x = hours)) + geom_histogram(bins = 7)
```

 

You'll have to play with the number of bins (there are only 12 observations). I got 7 from the Freedman-Diaconis rule:

```{r }
nclass.FD(aircon$hours)
```

 

I was a little suspicious that the data would not be much like normal (I have run into failure times before), so I kept away from the Sturges rule.

Another possibility is a one-group boxplot:

```{r }
ggplot(aircon, aes(y = hours, x = 1)) + geom_boxplot()
```

 

If you like, you can do a normal quantile plot. I rank that third here, because there is nothing immediately implying a comparison with the *normal* distribution, but I would accept it:

```{r }
ggplot(aircon, aes(sample = hours)) + stat_qq() + stat_qq_line()
```

 
Pick a visual and defend it.

All three of these graphs are showing a strong skewness to the right. 

Extra: this is probably not a surprise, because a time until failure
cannot be less than zero, and distributions with a limit tend to be
skewed away from that limit. (If you look back at the data, there are
some very small failure times, but there are also some very big
ones. The very small ones are saying that the lower limit matters.) If
you were modelling these times until failure, you might use a
distribution like the exponential or gamma or Weibull.


(c) Obtain the means of 1000 bootstrap samples (that is, samples from the data with replacement). Save them.

Solution


Something like this, therefore:

```{r}
tibble(sim = 1:1000) %>% 
  rowwise() %>% 
  mutate(sample = list(sample(aircon$hours, replace = TRUE))) %>% 
  mutate(sample_mean = mean(sample)) -> means
means
```

Forgetting the `rowwise` will cause all sorts of trouble.




(d) Make a normal quantile plot of your bootstrap distribution. What do you see? Explain briefly.

Solution


This:

```{r }
ggplot(means, aes(sample = sample_mean)) + stat_qq() + stat_qq_line()
```

 

This is still skewed to the right (it has a curved shape, or, the low values and the high values are both too high compared to the normal). 

Extra: this is less skewed than the original data was, because, with a
sample size of 12, we have a *little* help from the Central Limit
Theorem, but not much. This picture is the one that has to be normal
enough for $t$ procedures to work, and it is not. This comes back into
the picture when we compare our confidence intervals later.

Also, it makes sense to see how *normal* a sampling distribution of a
mean is, so a normal quantile plot would be my first choice for this.


(e) Obtain the 95\% bootstrap percentile confidence interval for the mean.

Solution


This is the 2.5 and 97.5 percentiles of the bootstrapped sampling distribution of the mean:

```{r }
quantile(means, c(0.025, 0.975))
```

 


(f) Obtain the 95\% bootstrap-$t$ confidence interval for
the mean, and compare your two intervals.

Solution


The key is to remember that the original sample (and thus each bootstrap sample) had $n=12$, so there are $12-1=11$ df. (The fact that there were 1000 bootstrap samples is neither here nor there). This is how I like to do it:

```{r }
t_star <- qt(0.975, 11)
t_star
mean(means) + c(-1, 1) * t_star * sd(means)
```

 

The `c(-1, 1)` thing is the calculation version of the $\pm$,
and gets both limits at once. Pull the above apart to see how it works. If
you don't like that, you might prefer something like this:

```{r }
mean <- mean(means)
sd <- sd(means)
margin <- t_star * sd
mean - margin
mean + margin
```

 

I apologize for the crazy first line of that!
As for comparison: the bootstrap-$t$ interval goes down a lot further,
though the upper limits are quite similar (on this scale). Both
intervals are very long and don't tell us much about the population
mean time to failure, which is not very surprising given the small
sample size ($n=12$) and the large variability in the data.

Extra: the non-normality of the bootstrap (sampling) distribution says that we should definitely not trust the bootstrap-$t$, and probably not the bootstrap percentile interval either. Which brings us to the next part.


(g) Obtain the BCa 95\% confidence interval for the mean.

Solution


This means (possibly) installing and (certainly) loading the `bootstrap` package, and then:

```{r }
theta <- function(x) {
  mean(x)
}
bca_all <- with(aircon, bcanon(hours, 1000, theta))
bca <- bca_all$confpoints
bca
```

 

Pull out the ones from this that you need: the top one and the bottom one, to get an interval of `r round(bca[1,2], 1)` 
to `r round(bca[8,2], 1)`. 

I seem to need to define the function `theta` first and pass it into `bcanon` as the third input. You may have more luck with `bcanon(hours, 1000, mean)` than I did. Try it.

Or, if you feel like some extra coding: turn this matrix into a data frame, grab the rows you want, and then the column you want:

```{r }
bca %>%
  as_tibble() %>%
  filter(alpha %in% c(0.025, 0.975)) %>%
  pull(`bca point`)
```

 


(h) Compare the BCa confidence interval with the other ones. Which one would you recommend? Explain briefly.

Solution


In this example, the bootstrap-$t$ and percentile intervals are very different, so we should use neither of them, and prefer the BCa interval. 

Extra: as usual in this kind of case, the BCa contains values for the mean pulled out into the long tail, but that's a proper adjustment for the sampling distribution being skewed.



