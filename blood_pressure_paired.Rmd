## The dentist and blood pressure

 Going to the dentist is scary for a lot of people. One way in which this might show up is that people might have higher blood pressure on average before their dentist's appointment than an hour after the appointment is done. Ten randomly-chosen individuals have their (systolic) blood pressure measured while they are in a dentist's waiting room, and then again one hour after their appointment is finished.

The data are in [http://ritsokiguess.site/datafiles/blood_pressure1.csv](http://ritsokiguess.site/datafiles/blood_pressure1.csv).


(a) Read in and display the data.

Solution


```{r blood-pressure-paired-1}
my_url <- "http://ritsokiguess.site/datafiles/blood_pressure1.csv"
blood_pressure <- read_csv(my_url)
blood_pressure
```

Aside: A blood pressure is usually given as two numbers, like ``120 over 80''. The first number, which is the one shown in our data, is called the systolic blood pressure. It is the pressure in the arteries when the heart is pumping. The second is called the diastolic blood pressure, and it is the pressure in the arteries when the heart is resting.

$\blacksquare$


(b) What kind of experimental design is this? How do you know? Explain briefly.

Solution


This is a matched pairs design. We know this because we have two measurements on each person, or the same people were measured before and after seeing the dentist. (The thing that it is *not* is one group of people measured before seeing the dentist, and a *different* group of people measured afterwards, so a two-sample test is *not* the right thing.)


$\blacksquare$


(c) Run a suitable $t$-test on these data. What do you conclude, in the context of the data?

Solution


A matched-pairs $t$-test, then. Remember, we want to see whether blood pressure is *lower* afterwards (that is, before is *greater* than after), so this needs to be one-sided:

```{r blood-pressure-paired-2}
with(blood_pressure, t.test(before, after, alternative = "greater", paired = TRUE))
```

There are some variations possible here: `before` and `after` could be switched (in which case `alternative` must be reversed also).

Or, you can do a one-sample $t$ on the differences, with the right `alternative` corresponding to the way you took differences. If you are looking ahead, you might realize that working out the differences *now* and adding them to the dataframe will be a good idea:

```{r blood-pressure-paired-3}
blood_pressure %>% 
mutate(difference = before - after) -> blood_pressure
blood_pressure
```

I took the differences this way around since I was expecting, if anything, the before numbers to be bigger than the after ones. And then:

```{r blood-pressure-paired-4}
with(blood_pressure, t.test(difference, mu = 0, alternative = "greater"))
```

If you did the differences the other way around, your `alternative` will need to be the other way around also.

The P-value (either way) is 0.008,^[Give the P-value, and round it off to about this accuracy so that your reader can see easily (i) how it compares to 0.05, and (ii) about how big it is. More than two decimal places is too many.] so we have evidence that the mean blood pressure before is greater than the mean blood pressure after.


$\blacksquare$


(d) Run a suitable sign test on these data. What do you conclude, in the context of the data?

Solution


A sign test on the differences. By this point, you will realize that you will need to have obtained the differences. Get them here if you did not already get them:

```{r blood-pressure-paired-5}
sign_test(blood_pressure, difference, 0)
```

This one gives us all three P-values. The way around I found the differences, the one we want is "upper", 0.055. There is not quite evidence that median blood pressure before is higher. 


$\blacksquare$


(e) Draw a suitable normal quantile plot of these data, one that will enable you to decide between the tests you ran in the previous two parts.

Solution



The *differences* are supposed to be approximately normal if a matched-pairs $t$-test is the thing:

```{r vilingers}
ggplot(blood_pressure, aes(sample=difference)) + stat_qq() + stat_qq_line()
```


$\blacksquare$


(f) Discuss briefly which of your two tests is the more appropriate one to run.

Solution


Make a call about whether the differences are normal enough. You have a couple of angles you can take:

- the lowest two values are too low, so we have two outliers at the low end
- the lowest *and* highest values are too extreme, so that we have a long-tailed distribution

Either of these would suggest a non-normal distribution, which I think you have to conclude from this plot.

The best answer also considers the sample size: there are only 10 differences, a small sample size, and so we will not get much help from the Central Limit Theorem (the sample size is likely not enough^[But see the Extra.] to overcome those two outliers or the long tails). Thus, we should *not* trust the $t$-test and should prefer the sign test.

Extra: you might be disappointed to go through this and come to the conclusion that there was not a decrease in blood pressure between before and after.

What has happened, I think, is that we have only a small sample (10 people), and having 8 positive differences and 2 negative ones is not quite unbalanced enough (with such a small sample) to rule out chance: that is to say, a median difference of zero. The $t$-test accounted for the size of the differences, and if you believed the normality was satisfactory, you could demonstrate a difference between before and after. But if you didn't like the normality, you were out of luck: the only test you have is an apparently not very powerful one.

If you wanted to, you could bootstrap the sampling distribution of the sample mean and see how normal it looks:

```{r haschin}
tibble(sim =  1:10000) %>% 
  rowwise() %>% 
  mutate(the_sample = list(sample(blood_pressure$difference, replace = TRUE))) %>% 
  mutate(the_mean = mean(the_sample)) %>% 
  ggplot(aes(sample = the_mean)) + stat_qq() + stat_qq_line()
```

(Code note: you can do anything with the result of a simulation, and you can use anything that might need to be normal as input to a normal quantile plot. Now that we have the normal quantile plot as a tool, we can use it wherever it might be helpful.)

This is actually not nearly as bad as I was expecting. Even a sample size of 10 is providing some help. The bootstrapped sampling distribution is somewhat left-skewed, which is not a surprise given the two low outliers. However, it is rather close to normal, suggesting that the $t$-test is not as bad as we thought.

(I did 10,000 simulations because I was having trouble seeing how non-normal it was. With this many, I can be pretty sure that this distribution is somewhat left-skewed.)


$\blacksquare$





