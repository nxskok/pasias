##  Calculating power and sample size for estimating mean


 We are planning a study to estimate a population mean. The
population standard deviation is believed to be 20, and the population
distribution is believed to be approximately normal. We will be
testing the null hypothesis that the population mean is 100. Suppose
the population mean is actually 110, and we want to determine how
likely we are to (correctly) reject the null hypothesis in this case,
using a two-sided (but one-sample) test with $\alpha=0.05$.



(a) We will take a sample of size $n=30$. Calculate the power of
this test.


Solution


`power.t.test`. Fill in: sample size `n`, difference
in means `delta` ($10=110-100$), population SD `sd`,
type of test `type` (`one.sample`) and kind of
alternative hypothesis `alternative`
(`two.sided`). Leave out `power` since that's what
we want:

```{r power20-1 }
power.t.test(n=30,delta=10,sd=20,type="one.sample",alternative="two.sided")
``` 

I meant "calculate" exactly rather than "estimate" (by
simulation). Though if you want to, you can do that as well, thus:

```{r power20-2 }
tibble(sim = 1:1000) %>% 
  rowwise() %>% 
  mutate(samples = list(rnorm(30, 110, 20))) %>% 
  mutate(ttest = list(t.test(samples, mu= 100))) %>% 
  mutate(pvals = ttest$p.value) %>% 
  count(pvals<=0.05)
``` 

That came out alarmingly close to the exact answer. 


$\blacksquare$

(b) Find the sample size necessary to obtain a power
of at least 0.80 under these conditions. What sample size do you
need? Explain briefly how your answer is
consistent with (a).


Solution


Again, the implication is "by calculation".
This time, in `power.t.test`, put in 0.80 for
`power` and leave out `n`. The order of things
doesn't matter (since I have named everything that's going into
`power.t.test`): 

```{r power20-3 }
power.t.test(delta=10,power=0.80,sd=20,type="one.sample",alternative="two.sided")  
``` 

To get sample size for power at least 0.80, we have to round 33.36
*up* to the next whole number, ie.\ $n=34$ is needed. (A sample
of size 33 wouldn't quite have enough power.)

This answer is consistent with (a) because a sample size of 30 gave a
power a bit less than 0.80, and so to increase the power by a little
(0.75 to 0.80),
we had to increase the sample size by a little (30 to 34).

Extra: estimating sample sizes by simulation is tricky, because the sample size
has to be input to the simulation. That means your only strategy is to
try different sample sizes until you find one that gives the right power.

In this case, we know that a sample of size 30 doesn't give quite
enough power, so we have to up the sample size a bit. How about we try
40? I copied and pasted my code from above and changed 30 to 40:


```{r power20-4 }
tibble(sim = 1:1000) %>% 
  rowwise() %>% 
  mutate(samples = list(rnorm(40, 110, 20))) %>% 
  mutate(ttest = list(t.test(samples, mu= 100))) %>% 
  mutate(pvals = ttest$p.value) %>% 
  count(pvals<=0.05)
``` 

Now the power is a bit too big, so we don't need a sample size quite
as big as 40. So probably our next guess would be 35. But before we
copy and paste again, we should be thinking about making a function of
it first, with the sample size as input. Copy-paste once more and edit:

```{r power20-5 }
sim_power=function(n) {
  tibble(sim = 1:1000) %>% 
    rowwise() %>% 
    mutate(samples = list(rnorm(n, 110, 20))) %>% 
    mutate(ttest = list(t.test(samples, mu= 100))) %>% 
    mutate(pvals = ttest$p.value) %>% 
    ungroup() %>% 
    count(pvals<=0.05)
}
``` 

In the grand scheme of things, we might want to have the null and true
means, population SD and $\alpha$ be inputs to the function as well,
so that we have a more general tool, but this will do for now.



Let's run it with a sample size of 35:

```{r power20-6 }
sim_power(35)
``` 

and I'm going to call that good. (Because there is randomness in the
estimation of the power, don't expect to get *too* close to the
right answer. This one came out a fair bit less than the right answer;
the power for $n=35$ should be a bit *more* than 0.80.)

Now that you have the software to do it, you can see that figuring out
a sample size like this, at least roughly, won't take very long: each
one of these simulations takes maybe seconds to run, and all you have
to do is copy and paste the previous one, and edit it to contain the
new sample size before running it again. You're making the computer
work hard while you lazily sip your coffee, but there's no harm in
that: programmer's brain cells are more valuable than computer CPU
cycles, and you might as well save your brain cells for when you
really need them.

You might even think about automating this further. The easiest way, now that we have the function, is something like this:

```{r power20-7}
tibble(ns = seq(20, 50, 5)) %>% 
  rowwise() %>% 
  mutate(power_tab = list(sim_power(ns))) %>% 
  unnest(power_tab) %>% 
  pivot_wider(names_from = `pvals <= 0.05`, values_from = n)
```

The business end of this is happening in the first three lines. I wasn't thinking of this when I originally wrote `sim_power` to return a dataframe, so there is a  bit more fiddling after the simulations are done: I have to `unnest` to see what the list-column `power_tab` actually contains, and because of the layout of the output from unnesting `sim_power` (long format), it looks better if I pivot it wider, so that I can just cast my eye down the TRUE column and see the power increasing as the sample size increases.

You might  also think of something like bisection to find the sample size that has power 0.8, but it starts getting tricky because of the randomness; just by chance, it may be that sometimes the simulated power goes *down* as the sample size goes up. With 1000 simulations each time, it seems that the power ought to hit 80% with a sample size between 30 and 35.


